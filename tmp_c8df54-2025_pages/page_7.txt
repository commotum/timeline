                                                  Reflection System for the Abstraction and Reasoning Corpus
        330    Table 4 shows that the ARC performance by different re-             6. Related Work
        331    flection system configurations varies between 133 and 166           Most of the previous ARC attempts can be split into two
        332    solved evaluation tasks. In a 2-solver setting, with DSL            categories: Program synthesis solvers and methods that
        333    Search and Claude 3 Opus, Llama-3 70B struggles as a                rely on machine learning. In contrast, machine learning
        334    reflection model, solving only 133 tasks. GPT-4-turbo and           implementations vary from neuro-symbolic models to the
        335    GPT-4o perform significantly better as reflection models,           latest LLMs.
        336    solving 165 and 166 ARC tasks respectively. When adding
        337    a fine-tuned Llama-3 8B as a third solver, the reflection           6.1. Program Synthesis Solvers
        338    system solves 163 ARC tasks.
        339    Ourbest 2-solver and 3-solver configurations both outper-           Apopular program synthesis solver for ARC is the DSL
        340    form the best single LLM, Claude 3 Opus (74), and the best          Search implementation by IceCuber which achieves 40%
        341    program synthesis approach, DSL Search (160). Based on              accuracy on the complete ARC evaluation dataset. The DSL
        342    the results, we argue that the proposed reflection system is        solution is based on brute-force search. It applies transfor-
        343    an effective approach for combining LLMs and program                mations of varying depth in parallel and greedily stacking
        344    synthesis solvers for enhanced ARC performance.                     them to fit training samples (Icecuber, 2023). The final
        345                                                                        prediction is ensembled based on the most solved training
        346    5.6. Previous Approaches                                            samples and least depth.
        347
        348    Todemonstratetheeffectivenessofourreflectionsystem,we               Another promising program synthesis approach is the
        349    comparetheARCperformanceofouroptimalconfiguration                   the Generalized Planning for Abstract Reasoning (GPAR)
        350    to previous publicly available approaches. We present sys-          solver (Lei et al., 2024). It casts an ARC problem as a
        351    tems that have been tested on the complete ARC evaluation           generalized planning (GP) problem, where a solution is
        352    dataset and split the categories into LLMs, neuro-symbolic          formalized as a planning program with pointers (Lei et al.,
        353    models and program synthesis solvers. We also compare to            2024). On 160 of the 400 ARC evaluation tasks, GPAR
        354    a previous attempt combining different ARC solvers with a           outperforms the DSL Search by 10% (Lei et al., 2024).
        355    voting ensemble (Bober-Irizar & Banerjee, 2024).
        356    Table 5 compares our approach to some publicly available            6.2. Neuro-symbolic Models
        357    systems on the ARC evaluation dataset.                              Neuro-symbolic models have emerged as promising AI sys-
        358                                                                        tems that aim at integrating the ability to learn from experi-
        359                                                                        ence, and the ability to reason from what has been learned
        360                                                                        (Garcez et al., 2019). In neuro-symbolic computing, knowl-
        361      System                      Method                     ARC        edge is represented in symbolic form, whereas learning and
        362      Type                                                 Correct      reasoning are computed by a neural network (Garcez et al.,
        363                               DreamCoder                   18/400      2019).
        364      Neuro-          (Bober-Irizar & Banerjee, 2024)
        365      Symbolic                    CodeIt                    59/400      The first neuro-symbolic approach to solving ARC was
        366                             (Butt et al., 2024)                        DreamCoder (Alford, 2021). It used neural networks to
        367                                  GPT-4                     32/400      guide its ability to write programs (Bober-Irizar & Banerjee,
        368                      (Bober-Irizar & Banerjee, 2024)                   2024). An initial implementation of DreamCoder (Alford,
        369      LLM                 Fine-Tuned Llama-3 8B             34/400      2021) solves 2 ARC evaluation tasks, and an updated ver-
                                          Llama-3 70B                  36/400
        370                              Claude 3 Opus                 74/400      sion with a Perceptual Abstraction & Reasoning Language
        371                                Brute Force                 26/400      (PeARL)achieves 18 (Bober-Irizar & Banerjee, 2024).
        372                          (Ainooson et al., 2023a)                      CodeIteration (CodeIt) is a recent neuro-symbolic model
        373      Program              Neurodiversity solver            45/400
        374      Synthesis           (Ainooson et al., 2023b)                      that approaches ARC (Butt et al., 2024) as a programming-
        375                                DSLSearch                   160/400     by-examples problem by training a policy to produce pro-
                                         (Icecuber, 2023)                          grams when shown demonstration examples (Butt et al.,
        376      Ensemble                    Voting                    161/400     2024). Experiments on the complete ARC evaluation set
        377                      (Bober-Irizar & Banerjee, 2024)                   showthat CodeIt solves 59 tasks, significantly outperform-
        378      Multiple              Reflection System               166/400     ing previous neuro-symbolic approaches.
        379      Solvers      (Solvers: DSL Search, Claude 3 Opus;
        380                            Reflection: GPT-4o)
        381                                                                        6.3. Large Language Models
        382    Table 5. Number of correctly solved ARC evaluation tasks across     Previous research that explores LLMs on ARC has been
        383    different system types. The reflection system achieves an ARC
               accuracy of 166.                                                    primarily focused on OpenAIâ€™s GPT models (Mitchell et al.,
        384
                                                                                7
