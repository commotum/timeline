                                                        TReB:AComprehensiveBenchmarkforEvaluatingTableReasoningCapabilitiesofLargeLanguageModels
                                                                                                                           Table 4: Performance with Different Model Types
                                                                                                  NLU                           TU                                      TBO                                       TCO                                        DA                                      ADA
                                                       ModelType                                 TCoT TCoT                      PoT         ICoT          TCoT           PoT          ICoT         TCoT            PoT          ICoT         TCoT            PoT         ICoT          TCoT            PoT         ICoT          Overall
                                      General LLMs                                                64.04         57.06          54.26        57.09         47.51         60.09         54.85         53.46         64.38         61.23         44.88         49.92         52.54         33.96         31.24        32.61             51.19
                                      CodeOptimizedLLMs                                           38.78         39.16          46.83        40.07         37.05         55.51         52.76         34.36         52.79         48.54         28.23         47.23         45.58         22.84         26.26        28.35             40.27
                                      DeepThinkingLLMs                                            62.69         64.47          60.76        79.51         73.27         65.85         67.79         69.65         61.13         71.03         55.35         55.39         61.12         38.12         38.96        51.31             61.02
                                      MathOptimizedLLMs                                           37.17         27.11          16.99        39.30         32.11         19.90         30.67         36.09         25.31         39.63         21.73         16.27         31.76         12.62          6.81        19.64             25.82
                                      Table Reasoning Optimized LLMs                              66.20         61.79          55.71        58.97         57.05         50.10         46.57         63.45         60.69         55.10         43.85         47.15         54.78         31.97         30.49        38.66             51.41
                                                                Comparison of table reasoning under different reasoning modes (all tasks)                                                       Comparison of table reasoning under different reasoning modes (focused on precise calculation tasks)
                                                                                                                                                                                  TCoT    70                                                                                                                                        TCoT
                                                                                                                                                                                  PoT                                                                                                                                               PoT
                                        50                                                                                                                                        ICoT                                                                                                                                              ICoT
                                                                                                                                                                                          60
                                       e40                                                                                                                                                50
                                                                                                                                                                                          40
                                        30
                                                                                                                                                                                          30
                                       LLM-as-a-judge Scor20
                                                                                                                                                                                          20
                                        10                                                                                                                                                10
                                         0               TU                         TBO                         TCO                         DA                         ADA                 0     Table General Operations   Table Correlation Analysis  Table Distribution Testing    Multi-step Operations  Multi-step Correlation Analysis
                                                                                 Figure 2: Comparison of table reasoning capability under different reasoning modes.
                                   in this study. Actually, each model’s performance is influ-                                                                                                 table trend emerges: TCoT underperforms in calculation-
                                   enced by multiple factors, including parameter size, training                                                                                               intensive tasks. This is because TCoT fundamentally relies
                                   strategies, and evaluation configurations, etc. Notably, Deep                                                                                               ontoken-based predictions and lacks the capability to per-
                                   Thinking LLMs, introduced in 2025, represent a new type                                                                                                     formprecise computations. In contrast, PoT and ICoT excel
                                   of models trained using more advanced methodologies com-                                                                                                    in such tasks by leveraging its ability to write and execute
                                   paredtotheirpredecessors. Thisadvancedtrainingapproach                                                                                                      code in a sandbox environment, allowing it to compute pre-
                                   contributes to their superior performance in table reasoning.                                                                                               cise results. Notably, the ICoT mode enables iterative code
                                                                                                                                                                                               generation, allowing the model to self-reflect and correct er-
                                   4.2.4. PERFORMANCE ANALYSIS BY INFERENCE MODE                                                                                                               rors. This iterative coding and execution mechanism enables
                                   Weanalyzemodelperformanceacrossthethree inference                                                                                                           ICoT to excel in handling complex numerical operations
                                   modes: TCoT, PoT, and ICoT. As shown in Figure 2, the                                                                                                       and calculation-based table reasoning tasks.
                                   left panel provides an overall overview, where the results                                                                                                  4.2.5. EXACT MATCH ACCURACY ANALYSIS
                                   are averaged across all sub-tasks under each table reasoning
                                   skill and grouped by the three inference modes. Overall,                                                                                                    In this subsection, we calculate the exact match accuracy
                                   models under the ICoT mode achieve better performance,                                                                                                      for specific tasks where the answer is a single numeric
                                   particularly in DA and ADA tasks, outperforming the tra-                                                                                                    value. Specifically, for each question, the model’s prediction
                                   ditional TCoT approach. This demonstrates the potential                                                                                                     is deemed correct if and only if it precisely matches the
                                   of the ICoT paradigm in handling table reasoning tasks. In                                                                                                  referencenumericvalue,withnodiscrepanciesinformatting
                                   fact, the TCoT and ICoT modes differ fundamentally in how                                                                                                   or variations in representation. For example, if the ground
                                   they handle table content: TCoT directly inputs the table                                                                                                   truth is 42.0, predictions such as 42 or 42.00 would be
                                   in Markdown or HTML format, while ICoT enables the                                                                                                          acceptedascorrectduetotheirequivalenceinnumericvalue,
                                   model to actively explore the table content through iterative                                                                                               but predictions like 42.1 or forty-two would be marked as
                                   interactions. This distinction becomes critical when dealing                                                                                                incorrect. This metric enables a direct, unambiguous, and
                                   with large tables. Due to the context window limitations,                                                                                                   precise evaluation of model performance. Such number-
                                   TCoTstruggles to process the entire table content, whereas                                                                                                  only tasks typically require models to perform accurate cell
                                   ICoT, being independent of context size, is unaffected by                                                                                                   retrieval or numerical operations.
                                   table size and can dynamically query the table to retrieve                                                                                                  Theexperimental results are shown in Table 5. For number-
                                   relevant information.                                                                                                                                       only tasks, Deep Thinking LLMs consistently achieve aver-
                                   The right panel of Figure 2 focuses on performance eval-                                                                                                    ageperformancescoresabove50,outperformingothertypes
                                   uations for tasks requiring precise calculations.                                                                                 A no-                     of models. It is also observed that certain non-deep-thinking
                                                                                                                                                                                      11
