                         TReB:AComprehensiveBenchmarkforEvaluatingTableReasoningCapabilitiesofLargeLanguageModels
                Yang,A.,Zhang,B.,Hui,B.,Gao,B.,Yu,B.,Li,C.,Liu,D.,                     function calls and complex instructions. arXiv preprint
                  Tu, J., Zhou, J., Lin, J., Lu, K., Xue, M., Lin, R., Liu, T.,        arXiv:2406.15877, 2024.
                  Ren, X., and Zhang, Z. Qwen2.5-math technical report:
                  Towardmathematical expert model via self-improvement.
                  arXiv preprint arXiv:2409.12122, 2024b.
                Yang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B.,
                  Yu, B., Gao, C., Huang, C., Lv, C., et al. Qwen3 technical
                  report. arXiv preprint arXiv:2505.09388, 2025a.
                Yang,Q.A.,Yang,B.,Zhang,B.,Hui,B.,Zheng,B.,Yu,B.,
                  Li, C., Liu, D., Huang, F., Wei, H., Lin, H., Yang, J., Tu,
                  J., Zhang, J., Yang, J., Yang, J., Zhou, J., Lin, J., Dang, K.,
                  Lu, K., Bao, K., Yang, K., Yu, L., Li, M., Xue, M., Zhang,
                  P., Zhu, Q., Men, R., Lin, R., Li, T., Tang, T., Xia, T.,
                  Ren, X., Ren, X., Fan, Y., Su, Y., Zhang, Y., Wan, Y., Liu,
                  Y., Cui, Z., Zhang, Z., and Qiu, Z. Qwen2.5 technical
                  report. arXiv preprint arXiv:2412.15115, 2024c.
                Yang, Z., Chen, L., Cohan, A., and Zhao, Y. Table-r1:
                  Inference-time scaling for table reasoning. arXiv preprint
                  arXiv:2505.23621, 2025b.
                Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan,
                  K., and Cao, Y. React: Synergizing reasoning and act-
                  ing in language models. In International Conference on
                  Learning Representations (ICLR), 2023.
                Young, A., Chen, B., Li, C., Huang, C., Zhang, G., Zhang,
                  G., Wang, G., Li, H., Zhu, J., Chen, J., et al.           Yi:
                  Open foundation models by 01. ai.            arXiv preprint
                  arXiv:2403.04652, 2024.
                Yu, T., Zhang, R., Yang, K., Yasunaga, M., Wang, D., Li,
                  Z., Ma, J., Li, I., Yao, Q., Roman, S., et al. Spider: A
                  large-scale human-labeled dataset for complex and cross-
                  domainsemanticparsing and text-to-sql task. In Proceed-
                  ings of the 2018 Conference on Empirical Methods in
                  Natural Language Processing, pp. 3911–3921, 2018.
                Zhang, X., Wang, D., Dou, L., Zhu, Q., and Che, W. A
                  survey of table reasoning with large language models.
                  Frontiers of Computer Science, 19(9):199348, 2025.
                Zheng, L., Chiang, W.-L., Sheng, Y., Zhuang, S., Wu, Z.,
                  Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E., et al. Judging
                  llm-as-a-judge with mt-bench and chatbot arena. Ad-
                  vances in Neural Information Processing Systems, 36:
                  46595–46623, 2023.
                Zhu, B., Shi, X., Erickson, N., Li, M., Karypis, G., and
                  Shoaran, M. Xtab: Cross-table pretraining for tabular
                  transformers. In International Conference on Machine
                  Learning, pp. 43181–43204. PMLR, 2023.
                Zhuo, T. Y., Vu, M. C., Chim, J., Hu, H., Yu, W., Widyasari,
                  R., Yusuf, I. N. B., Zhan, H., He, J., Paul, I., et al. Big-
                  codebench: Benchmarking code generation with diverse
                                                                                19
