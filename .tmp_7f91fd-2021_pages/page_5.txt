                                                    Large-scale few-shot program induction and synthesis 
                                                        CONCODE         NAPS      SPoC     ARC  DreamCoder  SyGUS  PROGRES 
                       Programming language                 Java        UAST       C++       -         DSL          DSL         C++ 
                       Number of programs                2,184,310      17,477    18,356     -          215         829       274,612 
                       Lines per program                    4.4          21.7      14.7      -         14.1         20.0         3.3 
                       Additional input                documentation     –pseudocode–        -           -            -        context 
                       Number of induction tasks              -           485      784     1000         215         829       274,612 
                       Number of test cases (average)         -           7.5      38.6     4.3        15.0         100.0       235.1 
               Table 1. Comparison of PROGRESto other program-based datasets. Some datasets like CONCODE (Iyer et al., 2018), contain lots of 
               programs, but no tests for these programs. NAPS and SPoC, both based on CodeForces, have as many induction tasks as CodeForces 
               problems (not subproblems); it is worth noting, however, that they focus on going from pseudo-code to code, a more relevant description 
               than our context. Both ARC and DreamCoder have program induction tasks manually designed by humans, thus restricting their size. For 
               DreamCoder we estimated the numbers using the dataset of list functions, the dataset of towers and the dataset of physical equations. For 
               SyGus, we estimated the number of tasks looking at the largest competition in 2019 and the statistics on the programs described in Alur 
               et al. (2013). Finally, note that even though we standardize the programs to have 20 tests (10 train,10 test), we often have access to many 
               more, with an average of 235. 
               was satisfed or not. Note that these if/while conditionals        ing equivalence of programs that exhibit undefned behavior, 
               are often interesting quantities, and we also include them        as the C standard states e.g.: a program with integer overfow 
               as tasks, even though there is no explicit boolean variable       may exhibit any behavior. We hence use I/O equivalence, 
               created in the original program.                                  also called machine equivalence, where two programs are 
               We store these line by line executions for each input set to      equivalent if they have the same outputs for all inputs (on a 
               the overall program. These fles can then be parsed to gen-        specifc machine). 
               erate the tests for each subprogram. To keep the dataset to a     Slicing  when we extract a contiguous set of instructions 
               reasonable size and avoid very long inputs, we capped the         from the overall program, not all lines will affect the output 
               execution to 100KB of generated data and skipped programs         value of the intermediate variable of interest. We thus clean 
               generating lines of more than 1KB of data. This avoided           the unnecessary instructions to avoid making programs un-
               long programs of many executions and arrays of tens of            necessarily long and redundant; a process called slicing (Xu 
               thousands of integers, which are hard to process by most          et al., 2005; Tsantalis & Chatzigeorgiou, 2009). To slice, 
               ML methods and expensive to store for a dataset.                  we try removing lines from the bottom to the top, as well as 
               3.3. Finding equivalent programs                                  entire code blocks. If the code without those lines or code 
                                                                                 blocks still passes the test-cases, we remove them and keep 
                There are two type of equivalences in our dataset construc-      iterating until we cannot remove any more code. Going from 
               tion: subprogram equivalence implies the two implement            the bottom to the top allows us to remove pairs of redundant 
               the same function; program induction task equivalence im-         instructions where the bottom one depends on the top one. 
               plies that their programs are equivalent and they happen in 
               the same context (in our case, defned by the text represent-      Slicing and fnding classes of equivalent tasks  We frst 
               ing the overall problem). This difference is important, as in     partition tasks by CodeForces problem, since these will have 
               programming we often have to recognize the possibility of         different text context, as well as different input-output pairs. 
               reusing a known pattern in a new circumstance.                    To detect equivalent tasks within each CodeForces problem, 
                                                                                 we run the following steps: 
               Defning Program Equivalence  The same function can                  1.  We slice every program independently and standardize 
               be  implemented  by  many  different  programs.  As  the                the variables. 
               fnal step in the dataset construction,  we identify such            2.  We join programs that have the same implementation. 
               equivalence-classes of functions using a mixture of test-
               ing and theorem-proving. Programming language theorists             3.  We mark programs that pass each other test-cases as 
               have defned many notions of program equivalence. A clas-                potentially equivalent. This is an overapproximation 
               sic one, sometimes called “semantic equivalence," deems                 of the true equivalence relation. 
               two programs equivalent if they have the same preconditions         4.  We then cluster these candidates into programs proven 
               and, for all inputs satisfying these preconditions, they can            actually equivalent by using Yogo (Premtoon et al., 
               be proved to have the same output.                                      2020), a tool based on equality saturation (Tate et al., 
               Implementing this in an automated checker is a non-starter:             2009; Nelson & Oppen, 1980). This refnes the candi-
               the intended precondition of any subprogram is unknowable               date sets into an underapproximation of the true equiv-
               from the code alone. Further, this defnition disallows prov-            alence relation. 
