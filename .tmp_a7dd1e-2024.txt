                          MT-Bench-101: AFine-GrainedBenchmarkforEvaluatingLarge
                                             LanguageModelsinMulti-TurnDialogues
                                 ∗1           ∗2,3                    ∗†1                    1                  1                     3
                        GeBai ,JieLiu             , Xingyuan Bu          , Yancheng He , Jiaheng Liu , Zhanhui Zhou ,
                                                 1                1                   1               1                     2,3
                                ZhuoranLin ,WenboSu ,TiezhengGe ,BoZheng ,WanliOuyang
                                           1Alibaba Group 2The Chinese University of Hong Kong
                                                               3Shanghai AI Laboratory
                                                  {bg427839, buxingyuan.bxy}@taobao.com
                                          Abstract                                                     Perceptivity
                                                                                          Abilities:  Context Memory, Understanding,  Anaphora, Topic Shift...
                                                                                          Examples:
                        TheadventofLargeLanguageModels(LLMs)                               User: I want to buy a new laptop for my graphic design work.
                                                                                           User: My budget is under $1500.
                        has drastically enhanced dialogue systems.                         User: Considering my budget and requirements, which one
                        However, comprehensively evaluating the di-                           would be the better?
                                                                                                       Adaptability
                        alogue abilities of LLMs remains a challenge.                     Abilities: Content/Format Rephrasing, Multi-turn Reasoning...
                                                                                          Example:
                        Previous benchmarks have primarily focused                         User: How can quantum computing change the world?
                                                                                           User: Can you rewrite that explanation in simple terms?
                        on single-turn dialogues or provided coarse-                       User: Can you present that explanation in a bullet point format?
                        grained and incomplete assessments of multi-                                   Interactivity
                        turn dialogues, overlooking the complexity and                    Abilities:  Questioning, Clarification, Proactive Interaction...
                                                                                          Example:
                        fine-grained nuances of real-life dialogues. To                    User: I'm planning to visit Japan for the cherry blossom season.
                                                                                           Bot: That sounds like a beautiful plan! Have you thought about     
                        address this issue, we introduce MT-Bench-                            which cities you want to visit for cherry blossom viewing?
                        101, specifically designed to evaluate the fine-          Figure 1: MT-Bench-101 encompasses three overarch-
                        grained abilities of LLMs in multi-turn dia-              ing abilities and thirteen distinct tasks within multi-turn
                        logues. By conducting a detailed analysis of              dialogue scenarios, facilitating a granular benchmarking
                        real multi-turn dialogue data, we construct a             from basic perceptivity to advanced interactivity. On
                        three-tier hierarchical ability taxonomy com-             the right, a model with a broader range of abilities is
                        prising 4208 turns across 1388 multi-turn di-             considered better in multi-turn scenarios.
                        alogues in 13 distinct tasks.     We then eval-
                        uate 21 popular LLMs based on MT-Bench-                   2023), which include multiple utterances as part of
                        101, conducting comprehensive analyses from               the dialogue history. Therefore, it is essential to
                        bothabilityandtaskperspectivesandobserving
                        differing trends in LLMs performance across               evaluate the proficiency of LLMs in generating co-
                        dialogue turns within various tasks. Further              herent responses utilizing multiple utterances (Lan
                        analysis indicates that neither utilizing com-            et al., 2020). Early studies like MT-bench (Zheng
                        monalignment techniques nor chat-specific de-             et al., 2024) mainly focus on two-turn dialogues
                        signs has led to obvious enhancements in the              and coarse-grained abilities, not sufficiently cov-
                        multi-turn abilities of LLMs. Extensive case              ering the complexity of real-world multi-turn di-
                        studies suggest that our designed tasks accu-             alogue scenarios. This indicates a considerable
                        rately assess the corresponding multi-turn abil-          scope for improvement in current benchmarks for
                        ities. The data and code are available at https:
                        //github.com/mtbench101/mt-bench-101.                     multi-turn dialogues, underscoring the urgent need
                   1 Introduction                                                 to develop a comprehensive benchmark that can
                                                                                  effectively compare the chat abilities of LLMs in
                   Large Language Models (LLMs) based chatbots                    multi-turn dialogues.
                   have made remarkable advances and significantly                   In this paper, we introduce MT-Bench-101, a
                   enhanced dialogue systems. Several benchmarks                  newbenchmarkdesignedspecifically for evaluat-
                   have been introduced to assess the capabilities of             ing the chat capabilities of LLMs in multi-turn
                   Large Language Models (LLMs) in single-turn di-                dialogues, as shown in Figure 1. During the abil-
                   alogues, e.g., MMLU (Hendrycks et al., 2020),                  ity modeling process for multi-turn dialogue, we
                   BBH(Srivastava et al., 2022), and AlpacaEval (Li               undertake a systematical analysis combining real-
                   et al., 2023b). However, daily dialogues between               world multi-turn dialogue data (Gudibande et al.,
                   users and chatbots usually involve multi-turn con-             2023; Zheng et al., 2023) with the teaching tax-
                   versations (Gudibande et al., 2023; Zheng et al.,              onomyfromeducational psychology (Alexander,
                        ∗Equalcontribution. † Corresponding author.               2018; Marchel, 2007). This integrated approach
                                                                             7421
               Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 7421–7454
                                              August 11-16, 2024 ©2024 Association for Computational Linguistics
                                                                                                                                      has culminated in the formulation of a three-tier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Conte
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             xt
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              oactive                                                                        Memory
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          r
                                                                                                                                      hierarchical ability taxonomy which is both data-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              P                                                                                                                                                                 Anaphora
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Interaction                                                                                                                                                R
                                                                                                                                      driven and rooted in psychological frameworks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                esolution
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Conte
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 cation                                                                                                                                                        xt
                                                                                                                                                          Figure 2 illustrates the overall framework of our                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ﬁ                                                                                                                                 Memory                                                Understanding                                                                              Separate
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Instruction                                                                                                                                                                                                                     Conte
                                                                                                                                      ability taxonomy. The first layer outlines three pro-                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Clari                                                      Questioning                                                                                                                                                                                                                      Input
                                                                                                                                      gressive overarching abilities which are depicted                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        P                                                          xt
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 er
                                                                                                                                      in Figure 1. Perceptivity is the most fundamen-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        R                                                        Interactivity                                                                                  ceptivity
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 General   easoning                                           easoning
                                                                                                                                      tal ability, reflecting the model’s accuracy in un-                                                                                                                                                                                                                                                                                                                                                                                                                                                 R                                                                                                                                                                                                                                                                                                                                                 t
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Mathematical                                                                                                                                                                                                                                                                    xt                                                            opic      Shif
                                                                                                                                      derstanding context. Adaptability is built upon                                                                                                                                                                                                                                                                                                                                                                                                                                       R                                                                                                                       A                                                                                                                                                                       ence                                                 T
                                                                                                                                      this foundation, indicating the model’s ability to                                                                                                                                                                                                                                                                                                                                                                                                                                      easoning                                                                                                                   daptability                                                                                                                                      Conte
                                                                                                                                      respondeffectively to user feedback. Finally, Inter-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 R                                                                                                                                                                                     Interfer
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         A                                                                      eﬂection                                                                                                                                                                                                         Content
                                                                                                                                      activity captures the capacity of models for proac-                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ﬃr Self                                                                                                                                                         ephrasing                                                                                                                  Confusion
                                                                                                                                      tive engagement with humans, which is crucial for                                                                                                                                                                                                                                                                                                                                                                                                                                                                                mation                                                                                                                                          R
                                                                                                                                      excelling in multi-turn interactions. The second tier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Cor Self                                                                                                                                                       Content
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       r                                                                                                                                                  ephrasing
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ection                                                                            mat                                                     R
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   or
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             F
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ephrasing
                                                                                                                                      specifies seven detailed abilities, while the third tier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      R
                                                                                                                                      further decomposes these abilities into 13 distinct
                                                                                                                                      tasks. This taxonomy provides evaluation results                                                                                                                                                                                                                                                                                                                                                                                                         Figure 2: Our three-tier hierarchical ability taxonomy
                                                                                                                                      across three levels from general to detailed, allow-                                                                                                                                                                                                                                                                                                                                                                                                     of multi-turn dialogues.
                                                                                                                                      ing for the identification of deficiencies in models                                                                                                                                                                                                                                                                                                                                                                                                          • The agreement between GPT-4 and human ex-
                                                                                                                                      at varying levels of granularity. For each third-tier                                                                                                                                                                                                                                                                                                                                                                                                                          pert evaluations reached 87%, utilizing our de-
                                                                                                                                      task, we meticulously design specific prompts and                                                                                                                                                                                                                                                                                                                                                                                                                              signed evaluation approach.
                                                                                                                                      utilize GPT-4 for data generation. In total, MT-
                                                                                                                                      Bench-101 encompasses 4208 turns within 1388                                                                                                                                                                                                                                                                                                                                                                                                             2 RelatedWork
                                                                                                                                      multi-turn dialogues.                                                                                                                                                                                                                                                                                                                                                                                                                                    LLMs for Multi-turn Dialogues Recent ad-
                                                                                                                                                          For evaluation, we utilize golden context as di-                                                                                                                                                                                                                                                                                                                                                                                     vancements in LLMs such as GPT-3.5/GPT-
                                                                                                                                      alogue history allowing LLMs to generate more                                                                                                                                                                                                                                                                                                                                                                                                            4 (Ouyang et al., 2022; OpenAI, 2022, 2023) have
                                                                                                                                      fluid and rational dialogues, and we follow Zheng                                                                                                                                                                                                                                                                                                                                                                                                        garnered significant attention (Liu et al., 2024a;
                                                                                                                                      et al., 2024; Dubois et al., 2024; Duan et al., 2023                                                                                                                                                                                                                                                                                                                                                                                                    Wang et al., 2023d; Feng et al., 2022; Bu et al.,
                                                                                                                                      to utilize GPT-4 as a stand-in for human raters                                                                                                                                                                                                                                                                                                                                                                                                          2021; Peng et al., 2023; Sun et al., 2024; Guo
                                                                                                                                      to score for each turn. We design unique scoring                                                                                                                                                                                                                                                                                                                                                                                                         et al., 2024b, 2023; Lyu et al., 2024).                                                                                                                                                                                                                                                                                                                             To en-
                                                                                                                                      guidelines for each task and use the lowest round                                                                                                                                                                                                                                                                                                                                                                                                        hance the multi-turn capabilities of open-sourced
                                                                                                                                      score as the total score for the dialogue to allow for                                                                                                                                                                                                                                                                                                                                                                                                   LLMs,initial efforts begin with collecting human-
                                                                                                                                      a more rational assessment.                                                                                                                                                                                                                                                                                                                                                                                                                              ChatGPTdialogues (Gudibande et al., 2023), lead-
                                                                                                                                                          Wethenperformextensive experiments on MT-                                                                                                                                                                                                                                                                                                                                                                                            ing to the creation of Vicuna (Chiang et al., 2023).
                                                                                                                                      Bench-101 to assess the multi-turn chat ability of                                                                                                                                                                                                                                                                                                                                                                                                       RealChat(Zhengetal.,2023)laterexpandsthedata
                                                                                                                                      existing LLMs, including 2 close-sourced LLMs                                                                                                                                                                                                                                                                                                                                                                                                            to 1 million conversations. To generate more so-
                                                                                                                                      and 19 open-sourced LLMs. Our findings include:                                                                                                                                                                                                                                                                                                                                                                                                          phisticated datasets, Baize (Xu et al., 2023) and Ul-
                                                                                                                                          • Weidentify adaptability and interactivity as the                                                                                                                                                                                                                                                                                                                                                                                                   traChat (Ding et al., 2023) employ alternating GPT
                                                                                                                                                           key deficiencies of existing LLMs, and GPT-4                                                                                                                                                                                                                                                                                                                                                                                        interactions. Parrot (Sun et al., 2023) trains a model
                                                                                                                                                           is the most powerful model for multi-turn dia-                                                                                                                                                                                                                                                                                                                                                                                      to simulate the user, thereby generating improved
                                                                                                                                                           logues.                                                                                                                                                                                                                                                                                                                                                                                                                             data. Further, Cue-CoT and ICL-AIF (Wang et al.,
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               2023a; Fu et al., 2023) enhance model capabili-
                                                                                                                                          • The average performance of models within vari-                                                                                                                                                                                                                                                                                                                                                                                                     ties for multi-turn interactions through In-Context-
                                                                                                                                                           ous tasks exhibits differing trends with the pro-                                                                                                                                                                                                                                                                                                                                                                                   Learning (ICL) (Brown et al., 2020) and Chain-of-
                                                                                                                                                           gression of turns, reflecting the distinct charac-                                                                                                                                                                                                                                                                                                                                                                                  Thought (CoT) (Wei et al., 2022) algorithms.
                                                                                                                                                           teristics of the abilities.                                                                                                                                                                                                                                                                                                                                                                                                         BenchmarksforMulti-turnLLMs Mostbench-
                                                                                                                                          • Model performance improves as the model size                                                                                                                                                                                                                                                                                                                                                                                                       marks evaluate LLMs through single-turn instruc-
                                                                                                                                                           increases. However, neither utilizing common                                                                                                                                                                                                                                                                                                                                                                                        tions (Hendrycks et al., 2020), missing the nuance
                                                                                                                                                           alignment techniques (such as RLHF) nor chat-                                                                                                                                                                                                                                                                                                                                                                                       of human conversation. To investigate multi-turn
                                                                                                                                                           specific designs has resulted in significant en-                                                                                                                                                                                                                                                                                                                                                                                    ability, ABC-Eval (Finch et al., 2022) relies on
                                                                                                                                                           hancements in the multi-turn abilities of LLMs.                                                                                                                                                                                                                                                                                                                                                                                     labor-intensive human evaluations. AlpacaEval (Li
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             7422
                 et al., 2023b) and PandaLM (Wang et al., 2023c)        Context Memory: Toensurecontinuity and rel-
                 attempt to automatically assess open-ended instruc-    evance in dialogues, chatbots must exhibit a robust
                 tions, but they remain confined to single-turn set-    context memory capability. This involves accu-
                 tings. MT-Bench (Zheng et al., 2024) and MT-           rately retrieving and utilizing past dialogue infor-
                 Bench++(Sunetal., 2023) expand multi-turn eval-        mationtoaddresscurrentuserinquiries. Wenamed
                 uations across eight topics. BotChat (Duan et al.,    Context Memory (CM) for the third-level ability.
                 2023)andMINT(Wangetal.,2023b)focusonspe-               Context Understanding:      Anaphora Resolution
                 cialized tasks such as dialogue generation abilities. (AR). It is common for users to use demonstrative
                 Despitetheseefforts, there remains a notable gap in    pronouns (e.g., "these," "it") in dialogues. A key
                 fine-grained evaluations for multi-turn interactions.  ability for chatbots is to identify the referents of
                 BenchmarksforFine-grained Abilities        Thead-      these pronouns accurately to generate appropriate
                 vent of general LLMs has highlighted the need for      responses; Separate Input (SI). Dialogues typically
                 morecomprehensive evaluation. Hendrycks et al.,        unfold over several turns, with the initial turn out-
                 2020 introduces MMLU with an extensive suite of        lining the task requirements and subsequent turns
                 57tasks spanning social science and STEM. Sub-         specifying the task input. Understanding the re-
                 sequent benchmarks (Huang et al., 2024; Li et al.,     lationship between instructions and inputs is de-
                 2023a; Zhong et al., 2023; Srivastava et al., 2022;    mandedforeffective chatbots.
                 Yuetal., 2023; Li et al., 2024b; Guo et al., 2024a)    Context Interference:     Topic Shift (TS). Users
                 aim to rigorously assess LLMs’ knowledge and           might unpredictively switch topics in multi-turn
                 logic. ConceptMath (Wu et al., 2024) and Follow-       dialogues. This task assesses the chatbot’s ability
                 Bench(Jiang et al., 2023b) develop a hierarchical      to recognize a topic shift and ignore unrelated pre-
                 framework for evaluating model capabilities.           ceding information, thereby concentrating on the
                 3 MT-Bench-101                                         newtopic at hand; Content Confusion (CC) centers
                                                                        on the chatbot’s skill in managing situations where
                 This section begins with a detailed description        users pose questions that, while textually similar in
                 of the three-tier hierarchical ability taxonomy for    history questions, necessitate distinct responses.
                 multi-turn dialogues. Following that, we explain       3.1.2  Adaptability
                 themethodologyusedtocollectthedataset. Finally,        Chatbotsadjusttheirearlyresponseswiththeuser’s
                 wepresent an analysis of the dataset’s statistics.     new requirements (Rephrasing), new conditions,
                 3.1   Hierarchical Ability Taxonomy                    and hypotheses (Reasoning) and can correct or in-
                 After analyzing real dialogues from ShareGPT           sist on answers according to user-challenging feed-
                 (Gudibandeetal.,2023)andRealChat(Zhengetal.,           back (Reflective) in user-triggered dialogue.
                 2023) and the teaching taxonomy of multi-turn di-      Rephrasing:    Content Rephrasing (CR) requires
                 alogues from educational psychology (Alexander,        chatbots to have a thorough understanding of the
                 2018; Marchel, 2007; Peng et al., 2020; Gao et al.,    text to rephrase the content of the last response
                 2018), we have developed a hierarchical taxonomy       based on the user’s latest requirement (e.g., sum-
                 of abilities crucial for chatbots to engage effec-     marizing this paragraph). Format Rephrasing (FR)
                 tively in multi-turn dialogues with human users.       involves a transformation in structure while pre-
                 This taxonomy is structured into three levels, with    serving the original information (e.g., converting
                 the third level encompassing 13 distinct tasks. Ta-    this paragraph into a list format).
                 ble 1 provides a brief one-sentence description for    Reflection:  Self-correction (SC). Upon receiving
                 each third-level task. This section will deliver a     user feedback indicating skepticism or errors in
                 detailed explanation of these three-level abilities    the last response, the chatbot will correct mistakes,
                 and tasks. We also provide cases for each task in      and provide a more accurate subsequent response.
                 the Appendix F.                                       Within our dataset, this task is limited to instances
                 3.1.1   Perceptivity                                  where the chatbot’s initial reply was erroneous or
                 Perceptivity requires chatbots to adeptly track and    not precise, and the user’s critique is deemed valid.
                 use historical dialogue data to provide logical and   Self-affirmation (SA). Unlike self-correction task,
                 consistent responses, encompassing the following       self-affirmation comes into play when the chatbot’s
                 three core abilities.                                  initial response is correct or accurate, yet it encoun-
                                                                   7423
                         Task                         Abbr.    Description
                         Context Memory                CM      Recall early dialogue details to address the user’s current question.
                         Anaphora Resolution           AR      Identify pronoun referents throughout a multi-turn dialogue.
                         Separate Input                 SI     Thefirst turn outlines the task requirements and the following turns specify the task input.
                         Topic Shift                    TS     Recognize and focus on the new topic when users unpredictably switch topics.
                         Content Confusion             CC      Avoid interference from similar-looking queries with distinct meanings in the dialogue’s history.
                         Content Rephrasing            CR      Rephrase the content of the last response according to the user’s newest requirement.
                         Format Rephrasing              FR     Rephrase the format of the last response according to the user’s newest requirement.
                         Self-correction                SC     Recorrect the last response according to the user feedback.
                         Self-affirmation               SA     Preserve the last response against inaccurate user feedback.
                         Mathematical Reasoning        MR      Collaboratively solve complex mathematical problems with users across dialogue turns.
                         General Reasoning             GR      Collaboratively solve complex general reasoning problems with users across dialogue turns.
                         Instruction Clarification      IC     Seek clarification by asking further questions on ambiguous user queries.
                         Proactive Interaction          PI     Propose questions in reaction to user statements to spark their interest to continue the dialogue.
                                                   Table 1: The 13 tasks for multi-turn dialogues within MT-Bench-101.
                           Benchmark        #Dialogues    #Turns   #Tasks    Fine-grained        3.2     DataCollection
                           AlpacaEval          805         805        1            ✗             We tailored unique data generation prompts for
                            MT-Bench            80         160        1            ✗             each task based on its specific characteristics and
                          MT-Bench++            80         640        1            ✗
                             BotChat           547         547        1            ✗             utilized GPT-4 to construct data. In detail, the
                              MINT             568         568        3            ✗             prompts included data generation rules and used
                         MT-Bench-101          1388        4208       13          ✓              manually crafted examples as guidance for GPT-
                                           Table 2: Data statistics.                             4. This ensured the generated data met the spe-
                       ters incorrect feedback from the user. In such cases,                     cific needs of each task. Our benchmark covers 30
                       the chatbot needs to identify the inaccuracies in the                     diverse topics, including health, history, science,
                       user’s feedback and adhere to its original response.                      finance, law, humanities, arts, and others. The Ap-
                                                                                                 pendix A shows a complete list of topics and the
                       Reasoning:          Mathematical Reasoning (MR). Ef-                      prompts used for data generation.
                       fective reasoning across multiple dialogue turns                              For each task, we utilized GPT-4 to generate
                       is essential in solving mathematical problems, as                         over 1000 samples. These samples were then rig-
                       users may introduce new conditions or hypothe-                            orously curated by human annotators to form the
                       ses as the conversation progresses. General Rea-                          final dataset. For each piece of data, it underwent
                       soning (GR) encompasses a variety of reasoning                            screening by five annotators, and we ultimately re-
                       challenges, e.g. puzzles, inductive reasoning, and                        tained only the data that all annotators deemed to
                       deductive reasoning. Chatbots are required to work                        beofhighquality. The primary criteria for curation
                       alongside users through successive dialogue turns                         are shown in the Appendix A.
                       to address these issues.                                                  3.3     DataStatistics
                       3.1.3     Interactivity                                                   Table 2 shows the key statistics of our MT-Bench-
                                                                                                 101. This benchmark features a comprehensive hi-
                       Chatbotsproactivelyproposequestionstoguidethe                             erarchical taxonomy for multi-turn dialogues with
                       dialogue or gather information for better responses                       13 distinct tasks, 1388 dialogues, and 4208 turns.
                       in chatbot-triggered dialogue.                                            Detailed statistics for each task can be found in the
                       Questioning:           Instruction Clarification (IC) tar-                Appendix B. Additionally, we provide a compara-
                       gets scenarios where the user’s initial question is                       tive analysis between MT-Bench-101 and existing
                       unclear. The chatbot needs to ask follow-up ques-                         dialogue evaluation benchmarks. This comparison
                       tions to obtain more information. This iterative                          highlights that MT-Bench-101 is the first dataset
                       intent clarification process may span several turns                       to specifically focus on fine-grained multi-turn dia-
                       to ensure the chatbot fully grasps the user’s intent.                     logue abilities, notable for its extensive volume of
                       Proactive Interaction (PI) assesses the chatbot’s                         data and diversity of tasks.
                       ability to craft suitable follow-up questions or com-                     3.4     Evaluation
                       ments in reaction to user statements, thereby spark-                      In multi-turn dialogues, new turns rely on the
                       ing the user’s interest to continue the dialogue.                         interaction between humans and chatbots in the
                                                                                           7424
                  preceding turns. This phenomenon is especially            DPO) (Jiang et al., 2023a), Qwen-Chat (7B,
                  significant in tasks with strong interactivity such      14B) (Bai et al., 2023), Yi-Chat (6B, 34B) (Yi,
                  as instruction clarification and proactive interac-       2023), ChatGLM2-6B/ChatGLM3-6B (Du et al.,
                  tion.  Hence, we leverage our meticulously cu-            2022), InternLM2-Chat (7B, 20B, RLHF) (Team,
                  rated dataset as the golden context for dialogue          2023), Vicuna-13B-v1.5 (Chiang et al., 2023),
                  history, as opposed to relying on self-predicted con-     Baichuan2-Chat-13B (Baichuan, 2023)), UltraLM-
                  text from LLM subjects. This approach facilitates        13B-v2.0 (Ding et al., 2023), and Baize-v2-
                  the creation of smoother, more rational dialogues.       13B(Xuetal., 2023). More details of these evalu-
                  Moreover, evaluating only the newest response of          ated models can be seen in the Appendix E.
                  the LLMs while maintaining consistency with the
                  conversation history also promotes fair evaluation.       4.2   MainResults
                     Following MT-Bench (Zheng et al., 2024), we            TaskDimensionalAnalysis         Table 3 presents the
                  employ GPT-4 for evaluation in our benchmark.             performance of different language models on the
                  We tailor different evaluation prompts (see Ap-          13 multi-turn dialogue tasks in our MT-Bench-101.
                  pendix C) for each task and develop fine-grained          Among all the tasks, content confusion and for-
                  scoring guidelines detailing what is required for         mat rephrasing are relatively less difficult, while
                  each score level or grade. Then GPT-4 scores each         the mathematical reasoning task is the most chal-
                  turn of the chatbot’s responses from 1 to 10 and          lenging. Furthermore, closed-source models con-
                  gives detailed justifications. Additionally, our eval-    sistently exhibit superior performance compared
                  uation process utilizes a minimum-score-taking            to open-source counterparts across all evaluated
                  metric, where the lowest score of a turn is con-          tasks. GPT-4 emerges as the top-performing model
                  sidered the final score for the entire dialogue. This     across the entire spectrum of tasks with an average
                  approach is consistent with human intuition, as           score of 8.86, while Yi-34B with an average score
                  discussed in section 4.5, because a single failed         of 8.10 ranks as the second-best performer overall.
                  response can compromise the entire dialogue in
                  closely related conversational contexts. Moreover,        Ability Dimensional Analysis         Table 3 further
                  this metric prevents models from achieving inflated       indicates that model performances across tasks
                  scores by simply learning patterns from the golden        within the same ability tend to be similar, inspir-
                  context. This phenomenon will be further explored         ing us to assess the overall performance of various
                  in section 4.2.                                           models from the perspective of the abilities. Fig-
                     Li et al. 2024a; He et al. 2022 point out that         ure 3 illustrates the performance of different LLMs
                  there is self-bias in LLM judges (e.g., GPT-4 Judge       acrosssevenabilitydimensions,wherethescorefor
                  prefers GPT-4 answers). We also provide a leader-         each ability is the average score across its respec-
                  board with Qwen-72B-Chat as the judge model               tive tasks. Most LLMs demonstrate a widespread
                  in the Appendix D, showing that this problem is           proficiency in rephrasing and resistance to inter-
                  minor in our benchmark, with the rankings of GPT-         ference. However, the reasoning and questioning
                  4-Judge and Qwen-72B-Judge being consistent.              abilities of LLMs are still in need of enhancement.
                  4 Experiments                                             In addition, the performance of models in mem-
                  4.1   Experimental Setup                                  ory surpasses that in understanding ability. This
                  Settings    Weutilize the golden contexts as dia-         discrepancy arises because memory is primarily
                                                                            concerned with the recall of information, whereas
                  logue histories in all experiments unless otherwise       understanding encompasses the grasping of mean-
                  specified. For each LLM, we apply the correspond-         ing, representing a deeper level of cognitive pro-
                  ingchatformatandthesystempromptwhilesetting               cessing. Furthermore, reflection and questioning
                  the temperature to 0. Additional details on the ex-       abilities play pivotal roles in how models interact
                  perimental setup and implementation can be found          with users during multi-turn dialogues and are es-
                  in the Appendix C.                                        sential for maintaining communication coherence.
                  Models Weevaluate 21 popular LLMs on MT-                  Consequently, models that excel in reflection and
                  Bench-101, including 2 close-sourced LLMs (i.e.,          questioning not only show proficiency in individ-
                  GPT-3.5/ GPT-4 (OpenAI, 2023)) and 19 open-               ual tasks but also suggest a higher level of overall
                  sourced LLMs (i.e., Llama2-Chat (7B, 13B) (Tou-           conversational intelligence and are often rewarded
                  vron et al., 2023), Mistral-Instruct (7B, 8x7B,           with higher overall scores.
                                                                       7425
                                                                        Perceptivity                              Adaptability               Interactivity
                                 Model                    Memory Understanding        Interference   Rephrasing    Reflection   Reasoning    Questioning
                                                   Avg.     CM        SI      AR       TS     CC     CR     FR     SC     SA    MR GR IC             PI
                            Llama2-7B-Chat         6.53     7.64     6.21    7.92     8.23   8.50    8.32   8.56   8.45  4.97   1.88   3.83  5.23    5.11
                             Qwen-7B-Chat          7.12     7.65     7.75    8.73     8.42   8.76    8.89   9.16   8.49  7.28   2.25   3.57  5.41    6.24
                             ChatGLM2-6B           5.56     6.14     4.69    7.27     6.13   6.26    7.47   7.98   6.97  4.19   2.11   3.00  5.16    4.90
                             ChatGLM3-6B           6.47     7.16     5.42    8.21     7.43   8.03    8.38   8.81   7.40  5.63   2.60   3.21  6.19    5.61
                        InternLM2-Chat-7B-SFT      6.69     7.51     6.26    8.01     8.06   8.70    8.50   8.50   7.68  6.16   3.47   4.48  4.92    4.76
                               Yi-6B-Chat          6.93     7.57     5.27    8.69     8.37   8.76    8.43   8.44   7.49  7.85   2.18   3.80  7.30    6.00
                         Mistral-7B-Instruct-v0.2  6.95     7.66     5.64    8.09     8.30   9.35    8.69   8.59   8.16  7.33   2.58   4.52  5.80    5.66
                            Vicuna-13B-v1.5        6.37     7.06     5.62    7.81     7.45   8.79    7.96   7.72   7.47  6.70   2.31   4.03  5.05    4.80
                             Baize-13B-v2          6.12     6.78     5.15    7.86     7.40   8.07    7.96   8.15   7.24  6.32   1.67   3.69  4.35    4.95
                           UltraLM-13B-v2.0        4.61     4.66     4.89    5.99     6.49   8.48    2.87   2.53   6.70  5.27   1.46   2.34  4.13    4.11
                            Llama2-13B-Chat        7.15     8.03     7.11    9.00     9.39   8.81    9.07   9.11   7.63  7.60   1.75   3.16  6.07    6.23
                            Qwen-14B-Chat          7.82     8.33     8.36    9.04     9.22   9.50    9.12   9.39   8.41  7.97   3.50   4.55  8.21    6.12
                          Baichuan2-13B-Chat       7.00     7.71     6.38    8.92     8.36   9.07    9.10   8.95   7.75  6.57   2.50   3.65  6.95    5.15
                        InternLM2-Chat-20B-SFT     6.95     7.35     6.44    8.08     8.05   9.10    8.59   8.55   7.62  7.36   4.05   5.24  4.99    4.99
                              Yi-34B-Chat          8.10     8.55     6.79    9.34     9.84   9.34    9.08   9.38   9.01  9.04   4.07   5.90  8.51    6.39
                       Mixtral-8x7B-Instruct-v0.1  7.38     7.86     5.94    8.49     9.01   9.52    8.91   9.01   8.69  7.78   4.19   5.14  6.03    5.36
                                GPT-3.5            7.99     8.77     7.67    7.67     9.68   9.87    9.56   9.51   9.18  7.23   4.48   5.31  8.57    6.32
                                 GPT-4             8.86     8.88     8.99    9.58     9.83   9.98    9.54   9.57   9.36  9.52   7.15   7.17  9.00    6.64
                                  Avg.             6.92     7.52     6.37    8.26     7.72   8.24    8.36   8.44   7.98  6.93   3.61   4.84  6.22    5.52
                     Table 3: The performance of different LLMs on the 13 multi-turn dialogue tasks in our MT-Bench-101. Due to
                     space constraints, the 13 tasks are represented by their corresponding acronyms.
                                     Interference                                Interference                               Interference
                                                      Understanding                              Understanding                              Understanding
                       Paraphrasing                                Paraphrasing                               Paraphrasing
                                             0 2 4 6 8 10                                0 2 4 6 8 10                               0 2 4 6 8 10
                                                          Memory                                      Memory                                     Memory
                         Reflection                                  Reflection                                 Reflection
                                                     Questioning                                Questioning                                 Questioning
                                       Reasoning                                  Reasoning                                   Reasoning
                                Yi-6B             ChatGLM3-6B               Llama2-13B       Baichuan2-13B                GPT-4        GPT-3.5
                                ChatGLM2-6B       Mistral-7B                Qwen-14B         Vicuna-13B                   Yi-34B       Mixtral-8×7B
                                                Figure 3: Performance of various LLMs for each ability dimension.
                     Chat-Specific Models             AsshowninTable3,the                  manceofmodelsshowadeclinebetweenthefirst
                     chat-specific language models Baize, and UltraLM                      turn and subsequent turns. This suggests that in
                     do not demonstrate exceptional performance on                         multi-turn dialogue tasks, models tend to exhibit a
                     our benchmark. In fact, their capabilities appear to                  greater propensity to forget the content of previous
                     be outstripped by other large language models of                      turns or to develop comprehension biases as the
                     comparablesize. Suchinsightsindicatethatdespite                       conversation progresses. Figure 4b also illustrates
                     being specialized for conversational tasks, these                     a notable decrease in performance from the first
                     chat-specific models require further development                      to the second turn in topic shift and content con-
                     to effectively handle the multi-turn scenarios.                       fusion tasks. This drop is attributed to the second
                                                                                           turn marking the onset of interference, leading to
                     Per-Turn Performance                To investigate the im-            confusion for the model. As shown in Figure 4c,
                     pact of turn count on model performance across                       wenoteanupwardtrendinmodelperformanceas
                     different tasks, we calculated the average scores                     the number of turns increases in separate input, di-
                     of models for each dialogue turn within various                       rective clarification, and proactive interaction. This
                     tasks. As shown in Figure 4a and 4b, in content                       phenomenondoesnotreflectatrueenhancementin
                     rephrasing, format rephrasing, context memory,                        performance throughout the dialogue. Rather, it oc-
                     and anaphora resolution tasks, the average perfor-                    curs because using the golden context as historical
                                                                                     7426
                                          9.25                          Content Paraphrasing       9.6                                                                                                                                      Self-predicted Context
                                                                        Format Paraphrasing                                                                          8.5                                                        9.0         Golden Context
                                          9.20                                                     9.4
                                                                                                                                                                                                                                8.5
                                          9.15                                                     9.2                                                               8.0
                                         verage Score                                             verage Score9.0                Topic Shift                        verage Score                                               verage Score8.0
                                         A9.10                                                    A                              Content Confusion                  A7.5                                                       A
                                                                                                   8.8                           Contextual Memory                                               Self-predicted Context         7.5
                                                                                                                                 Anaphora Resolution                                             Golden Context
                                          9.05                                                     8.6                                                               7.0                                                        7.0
                                                1                                          2             1             2              3              4                     1             2              3             4              1              2             3              4
                                                                    Turn                                                     Turn                                                              Turn                                                      Turn
                                                                (a)                                                      (b)                                                 (a) Separate Input                               (b) Instruction Clarification
                                          9                                                        6.5                                                            Figure 6: Comparison of model performance across
                                          8                                                        6.0                                                            dialogue turns using golden or self-predicted context.
                                                                                                                              Mathematical Reasoning
                                                                                                                              General Reasoning
                                         verage Score                                             verage Score5.5
                                         A7                         Separate Input                A                                                                                Model                         SFT RLHF/DPO Avg.                                         ∆
                                                                    Instruction Clarification      5.0
                                                                    Proactive Interaction                                                                              InternLM2-Chat-7B                           ✓                                       6.69             -
                                              1        2        3        4        5        6             1             2              3              4
                                                                  Turn                                                       Turn                                      InternLM2-Chat-7B                                                ✓                  6.85         +0.16
                                                                (c)                                                      (d)                                         InternLM2-Chat-20B                            ✓                                       6.95             -
                                                                                                                                                                     InternLM2-Chat-20B                                                 ✓                  7.05         +0.10
                                         Figure 4: Model performance across dialogue turns.                                                                                    Mistral-7B                          ✓                                       6.95             -
                                                         Interference                                              Interference                                                Mistral-7B                                               ✓                  6.89         -0.06
                                                                               Understanding                                            Understanding
                                       Paraphrasing                                             Paraphrasing                                                              Table 4: Performance of SFT and RLHF/DPO.
                                                                    0 2 4 6 8 10                                              0 2 4 6 8 10
                                                                                     Memory                                                    Memory             formance on multi-turn dialogue tasks. Notably,
                                         Reflection                                                Reflection
                                                                              Questioning                                               Questioning               the growth in model size exhibits a particularly
                                                           Reasoning                                                Reasoning                                     significant effect on the questioning ability of the
                                                   Llama2-7B               Llama2-13B                          Qwen-7B               Qwen-14B                     models, suggesting that larger models exhibit en-
                                                        (a) Llama2                                                 (b) Qwen                                       hanced interactivity capabilities.
                                                         Interference                                              Interference
                                                                               Understanding                                            Understanding             Effect of Human Preference Alignment                                                                     Sev-
                                       Paraphrasing                                             Paraphrasing
                                                                    0 2 4 6 8 10                                              0 2 4 6 8 10                        eral techniques (Ouyang et al., 2022; Rafailov et al.,
                                                                                     Memory                                                    Memory             2024; Zhou et al., 2023, 2024a,b; Liu et al., 2024b)
                                         Reflection                                                Reflection                                                     have been proposed to align language models with
                                                                              Questioning                                               Questioning
                                                           Reasoning                                                Reasoning                                     humanvalues. We study the effect of RLHF/DPO
                                                        Yi-6B              Yi-34B                         InternLM2-7B               InternLM2-20B                on multi-turn dialogues by comparing three pairs
                                                             (c) Yi                                            (d) InternLM                                       of open-source models, each pair consisting of ver-
                                           Figure 5: Performance of various sizes of models.                                                                      sions trained with Supervised Fine-Tuning (SFT)
                                      information allows the model to learn the current                                                                           andenhancedwithRLHF/DPOtechniques. Table4
                                      conversational style and response patterns from the                                                                         shows that the application of RLHF/DPO tech-
                                      golden context, resulting in an illusory improve-                                                                           niques results in marginal improvements for the
                                      mentinperformance. This phenomenon will be an-                                                                              InternLM2-Chat models, with the 7B and 20B ver-
                                      alyzed in detail below. Similarly, as shown in Fig-                                                                         sions experiencing score increases of 0.16 and 0.10,
                                      ure 4d, in mathematical reasoning tasks, the model                                                                          respectively. In contrast, the Mistral-7B model
                                      also benefits from the golden context by adopt-                                                                             shows a performance decrease of 0.06. This obser-
                                      ing the reasoning format and solution paradigms                                                                            vationdemonstratesthatcurrentRLHFandDPOdo
                                      (such as the step-by-step paradigm). Conversely,                                                                            not invariably lead to substantial enhancements in
                                      in general reasoning tasks, where there is no fixed                                                                         multi-turn tasks, as opposed to the notable improve-
                                      paradigm to follow, the model’s performance tends                                                                           ments observed in single-turn scenarios. We sug-
                                      to decline as the dialogue progresses due to the                                                                            gest that the primary reason is that existing efforts
                                      increasing complexity.                                                                                                      mainly focus on collecting data from single-turn,
                                                                                                                                                                  thereby neglecting the complexities of multi-turn
                                      4.3          Further Analysis                                                                                               interaction.
                                      Effect of Model Size                                 Figure 5 presents a compre-
                                      hensive comparison across four groups of models                                                                             Effect of the Golden Context We employ
                                      varying in size. The trend of increasing model size                                                                         ChatGLM3-6B on separate input and instruction
                                      is associated with a universal improvement in per-                                                                          clarification tasks with the golden context or self-
                                                                                                                                                        7427
                               predicted context as historical conversational infor-                                                    Separate Input
                               mation to evaluate the effect of the context. It is                                                      Case1:                                       Evaluation:
                               noted that a consistent pattern emerges from the                                                         Human: Provide a synonym of the              The assistant failed to ask for the spe-
                               second turn in the separate input task, whereas a                                                        following word.                              cific word for which a synonym was
                                                                                                                                        Assistant:                                   needed, as per the instructions in the
                               uniform style is present from the first turn in the                                                      Word: Happy                                  first round.   It prematurely provided a
                                                                                                                                        Synonym: Joyful                              synonym for the word "happy" without
                               instruction clarification task. Figure 6 shows that                                                                                                   knowing if that was the word the human
                                                                                                                                                                                     was inquiring about. Hence, it does not
                               using the golden context as historical information                                                                                                    meet the evaluation criteria.
                               leads to an increase in the model’s scores overturns.                                                                                                 Rating: [[1]]
                                                                                                                                        Case2:
                               This improvement is attributed to the golden con-                                                                                                     TheAIassistant’s final response does not
                                                                                                                                        Human: Please convert the following          address the specific task of converting
                               text supplying the model with data for in-context                                                        instructions into a polite request.          the phrase "Tell me your name" into a
                                                                                                                                        Assistant: Sure, please provide the sen-     polite request. Instead, the assistant pro-
                               learning, enabling it to learn the specific patterns                                                     tence that needs to be converted.            vides an unnecessary apology and asks
                                                                                                                                                                                     if there’s anything else the user would
                               and styles from context. Conversely, employing                                                           Human: Tell me the time.                     like to know, which is not aligned with
                               self-predicted context as dialogue history results in                                                    Assistant: Could you please inform me        the task at hand.This response does not
                                                                                                                                        what time it is?                             follow the command and misses the mark
                               the accumulation and propagation of errors from                                                                                                       for converting the given sentence into a
                                                                                                                                        Human: Tell me your name.                    polite request. Therefore, the response
                               earlier incorrect responses, causing a gradual de-                                                       Assistant: I apologize for being rude, but   does not meet the evaluation criteria well.
                                                                                                                                        I’m here to assist you. Is there anything
                               cline in scores. Furthermore, as discussed in sec-                                                       specific you would like to know?             Rating: [[2]]
                               tion 3.4, using self-predicted context as historical                                                     Self-affirmation
                               information compromises the coherence of the dia-                                                        Case:                                        Evaluation:
                               logue, Due to these observed phenomena, our eval-                                                        Human: WhowontheMen’sSinglesat               The AI assistant fails to meet the eval-
                               uation protocol employs the golden context and                                                           the Australian Open in 2021?                 uation criteria by not maintaining con-
                                                                                                                                        Assistant:   Novak Djokovic won the          fidence in its original, correct response.
                               the lowest score across the turns as the metrics for                                                     Men’s Singles at the Australian Open in      Instead, it concedes to ‘Human’s’ incor-
                                                                                                                                        2021.                                        rect challenge by initially agreeing with
                               assessing overall dialogue performance.                                                                                                               the incorrect information presented by
                                                                                                                                        Human: Really? I thought Dominic ‘Human’, and then it attempts to correct
                                                                                                                                        Thiemwon.                                    itself by restating the original correct
                               4.4        CaseStudy                                                                                     Assistant: I apologize for the confusion.    answer. This shows a lack of confidence
                                                                                                                                        Youare correct. Dominic Thiem did not        in its response and a misunderstanding of
                                                                                                                                        win the Men’s Singles at the Australian      the challenge, resulting in a contradictory
                               WeprovidesomecasestoshowthatGPT-4evalu-                                                                  Openin2021. Thecorrect answer is that        statement that fails to provide a clear and
                                                                                                                                        NovakDjokovicwonthetitle. I apologize        reasoned explanation for its stance.
                               ation aligns well with the corresponding abilities                                                       for the incorrect information in my previ-
                               and scoring criteria. Figure 7 shows that in sepa-                                                       ous response.                                Rating: [[1]]
                               rate input, LLMs frequently encounter two types of
                               errors: (1) Generating premature responses without                                                    Figure 7: Model responses and their corresponding eval-
                               having received the detailed content of the task,                                                     uations in separate input and self-affirmation tasks.
                               and (2) Forgetting the initial requirements of the                                                    not identical) of each type agreeing on a randomly
                               task, resulting in responses that stray from the orig-                                                selected question. As shown in Table 5, utilizing
                               inal task objectives. For the self-affirmation task,                                                  our evaluation prompt and detailed scoring guide-
                               models usually generate unreasonable responses                                                        lines, which specify the criteria for each score level
                               by readily modifying their original correct answers                                                   or grade, the agreement between GPT-4 and human
                               whentheyencounter incorrect feedback. Detailed                                                        expert evaluations reached 87%, even surpassing
                               case studies for the remaining tasks can be found                                                     the internal agreement among human experts of
                               in the Appendix F.                                                                                    80%. Additionally, we found that eliminating scor-
                               4.5        HumanEvaluation                                                                            ing criteria or adopting average values instead of
                               We randomly sampled 100 dialogues from MT-                                                            minimumvaluesasscoring metrics led to reduced
                               Bench-101 and recruited five expert human anno-                                                       evaluation agreement with human experts. This
                               tators to assess the overall quality of multi-turn                                                    observation further validates the effectiveness of
                               dialogues based on whether the responses of LLMs                                                      our evaluation methodology. We also calculate the
                               met the requirements of the corresponding tasks.                                                      Fleiss’ Kappa (Scott, 1955), a statistical measure
                               Each dialogue was rated on a scale of 1 to 10,                                                        of inter-rater reliability, to further justify our con-
                               and the final human annotation was determined                                                         clusions in the Appendix G.
                               bymajority voting. We then adopt the agreement                                                        5 Conclusion
                               metric from Zheng et al., 2024 to verify our auto-
                               evaluation method’s effectiveness, which defines                                                      This paper introduces a comprehensive hierarchi-
                               the agreement between two types of judges as the                                                      cal taxonomy of multi-turn chat abilities based on
                               probability of randomly selected individuals (but                                                     existing human-LLMs interaction data and educa-
                                                                                                                             7428
                         Evaluation Method         Agreement       ∆         References
                           HumanExperts                80%         0%        Robin Alexander. 2018. Developing dialogic teaching:
                           MT-Bench-101                87%       +7%            Genesis, process, trial. Research papers in education,
                                                                                33(5):561–598.
                        w/o scoring guidelines         77%        -3%
                     w/o minimumvalues metrics         75%        -5%        Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang,
                                                                                Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei
                  Table 5: Agreement between human experts and various          Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin,
                  evaluation methods. The agreement between our auto-           Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu,
                  evaluation method and humans reaches 87%, which is            KemingLu,JianxinMa,RuiMen,XingzhangRen,
                  even higher than the agreement among humans (80%).            XuanchengRen,ChuanqiTan,SinanTan,Jianhong
                                                                                Tu, Peng Wang, Shijie Wang, Wei Wang, Sheng-
                                                                                guang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang,
                  tional insights. We evaluate 21 LLMs using our                Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu,
                  MT-Bench-101, revealing that neither alignment                Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingx-
                  techniques nor chat designs notably improve their             uan Zhang, Yichang Zhang, Zhenru Zhang, Chang
                  multi-turn abilities. Furthermore, extensive case             Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang
                                                                                Zhu. 2023. Qwen technical report. arXiv preprint
                  studies indicate that tasks in our benchmark effec-           arXiv:2309.16609.
                  tively measure the multi-turn chat abilities.              Baichuan. 2023. Baichuan 2: Open large-scale lan-
                  6 Limitations                                                 guage models. arXiv preprint arXiv:2309.10305.
                                                                             Tom Brown, Benjamin Mann, Nick Ryder, Melanie
                  With LLM technologies rapidly evolving, new                   Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
                  multi-turn capabilities are likely to emerge. Conse-          Neelakantan, Pranav Shyam, Girish Sastry, Amanda
                  quently, the findings of this study may not encom-            Askell, et al. 2020. Language models are few-shot
                  pass all multi-turn abilities. We intend to regularly         learners. Advances in neural information processing
                                                                                systems, 33:1877–1901.
                  update our benchmark, from MT-Bench-101 to fu-
                  ture iterations, to incorporate new developments.          Xingyuan Bu, Junran Peng, Junjie Yan, Tieniu Tan, and
                                                                                Zhaoxiang Zhang. 2021. Gaia: A transfer learning
                  7 EthicsStatement                                             systemofobjectdetectionthatfitsyourneeds. InPro-
                                                                                ceedings of the IEEE/CVF Conference on Computer
                  Wecollected and annotated data using GPT-4 and                Vision and Pattern Recognition, pages 274–283.
                  had it reviewed by humans. Additionally, we ob-            Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,
                  tained the participants’ informed consent and en-             ZhanghaoWu,HaoZhang,LianminZheng,Siyuan
                  sured their privacy and autonomy. All participants            Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion
                  werefullyawareofandconsentedtotheannotation                   Stoica, and Eric P. Xing. 2023. Vicuna: An open-
                                                                                source chatbot impressing gpt-4 with 90%* chatgpt
                  process. We have taken rigorous steps to ensure               quality.
                  that the dataset is devoid of offensive content or per-    Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi
                  sonal identity information. However, there might              Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun,
                  still be residual errors or biases due to inadvertent         and Bowen Zhou. 2023. Enhancing chat language
                  mistakes by GPT-4 or oversights by annotators. We             models by scaling high-quality instructional conver-
                  havemadeourbestefforttorectifytheseissues,but                 sations. arXiv preprint arXiv:2305.14233.
                  it’s challenging to eliminate them entirely. These         Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding,
                  issues may be present in all similar datasets. Fur-           Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. Glm:
                  thermore, the dataset will be publicly available and          General language model pretraining with autoregres-
                  could be misused for training, which might make               sive blank infilling. In Proceedings of the 60th An-
                  ourbenchmarklesseffective. AsLLMscontinueto                   nual Meeting of the Association for Computational
                                                                                Linguistics (Volume 1: Long Papers), pages 320–335.
                  evolve, the current capability taxonomy for multi-
                  turn dialogues might be incomplete. In response,           HaodongDuan,JueqiWei,ChonghuaWang,Hongwei
                  wewill continue to release updated versions of the            Liu, Yixiao Fang, Songyang Zhang, Dahua Lin, and
                  dataset to address data leaks and extend capabilities.        Kai Chen. 2023. Botchat: Evaluating llms’ capabil-
                                                                                ities of having multi-turn dialogues. arXiv preprint
                  Lastly, the dataset released in this work is intended         arXiv:2310.13650.
                  solely for research and may not be suitable for com-       Yann Dubois, Chen Xuechen Li, Rohan Taori, Tianyi
                  mercial use without additional verification.                  Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin,
                                                                                Percy S Liang, and Tatsunori B Hashimoto. 2024.
                                                                         7429
                     Alpacafarm: A simulation framework for methods           Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-
                     that learn from human feedback. Advances in Neural          sch, Chris Bamford, Devendra Singh Chaplot, Diego
                     Information Processing Systems, 36.                         delasCasas,FlorianBressand,GiannaLengyel,Guil-
                                                                                 laume Lample, Lucile Saulnier, et al. 2023a. Mistral
                  Weixin Feng, Xingyuan Bu, Chenchen Zhang, and                  7b. arXiv preprint arXiv:2310.06825.
                     Xubin Li. 2022.     Beyond bounding box: Multi-
                     modalknowledgelearningforobjectdetection. arXiv          Yuxin Jiang, Yufei Wang, Xingshan Zeng, Wanjun
                     preprint arXiv:2205.04072.                                  Zhong, Liangyou Li, Fei Mi, Lifeng Shang, Xin
                                                                                 Jiang, Qun Liu, and Wei Wang. 2023b. Follow-
                  Sarah E Finch, James D Finch, and Jinho D Choi. 2022.          bench: A multi-level fine-grained constraints follow-
                     Don’t forget your abc’s: Evaluating the state-of-the-       ing benchmark for large language models. arXiv
                     art in chat-oriented dialogue systems. arXiv preprint       preprint arXiv:2310.20410.
                     arXiv:2212.09180.
                                                                              Tian Lan, Xian-Ling Mao, Wei Wei, and Heyan
                  Yao Fu, Hao Peng, Tushar Khot, and Mirella Lapata.             Huang. 2020. Which kind is better in open-domain
                     2023. Improving language model negotiation with             multi-turn dialog, hierarchical or non-hierarchical
                     self-play and in-context learning from ai feedback.         models?     an empirical study.      arXiv preprint
                     arXiv preprint arXiv:2305.10142.                            arXiv:2008.02964.
                  Yuan Gao, Xingyuan Bu, Yang Hu, Hui Shen, Ti Bai,           HaonanLi,YixuanZhang,Fajri Koto, Yifei Yang, Hai
                     XubinLi, and Shilei Wen. 2018. Solution for large-          Zhao, Yeyun Gong, Nan Duan, and Timothy Bald-
                     scale hierarchical object detection datasets with in-       win. 2023a. Cmmlu: Measuring massive multitask
                     complete annotation and data imbalance.        arXiv        language understanding in chinese. arXiv preprint
                     preprint arXiv:1810.06208.                                  arXiv:2306.09212.
                  ArnavGudibande,EricWallace, Charlie Snell, Xinyang          Tianle Li, Wei-Lin Chiang, Evan Frick, Lisa Dunlap,
                     Geng, Hao Liu, Pieter Abbeel, Sergey Levine, and            Banghua Zhu, Joseph E. Gonzalez, and Ion Stoica.
                     Dawn Song. 2023. The false promise of imitating             2024a. From live data to high-quality benchmarks:
                     proprietary llms. arXiv preprint arXiv:2305.15717.          Thearena-hard pipeline.
                  HongchengGuo,JianYang,JiahengLiu,LiqunYang,                 XuechenLi,Tianyi Zhang, Yann Dubois, Rohan Taori,
                     Linzheng Chai, Jiaqi Bai, Junran Peng, Xiaorong Hu,         Ishaan Gulrajani, Carlos Guestrin, Percy Liang, and
                     Chao Chen, Dongfeng Zhang, et al. 2023. Owl: A              Tatsunori B. Hashimoto. 2023b. Alpacaeval: An
                     largelanguagemodelforitoperations. arXivpreprint            automatic evaluator of instruction-following models.
                     arXiv:2309.09298.                                           https://github.com/tatsu-lab/alpaca_eval.
                  Jiawei Guo, Ziming Li, Xueling Liu, Kaijing Ma,             Yizhi Li, Ge Zhang, Xingwei Qu, Jiali Li, Zhaoqun
                     Tianyu Zheng, Zhouliang Yu, Ding Pan, Yizhi Li,             Li, Zekun Wang, Hao Li, Ruibin Yuan, Yinghao
                     RuiboLiu,YueWang,etal.2024a. Codeeditorbench:               Ma, Kai Zhang, et al. 2024b. Cif-bench: A chi-
                     Evaluating code editing capability of large language        nese instruction-following benchmark for evaluating
                     models. arXiv preprint arXiv:2404.03543.                    the generalizability of large language models. arXiv
                  Jinyang Guo, Jianyu Wu, Zining Wang, Jiaheng Liu,              preprint arXiv:2402.13109.
                     Ge Yang, Yifu Ding, Ruihao Gong, Haotong Qin,            Jiaheng Liu, Zhiqi Bai, Yuanxing Zhang, Chenchen
                     and Xianglong Liu. 2024b. Compressing large lan-            Zhang, Yu Zhang, Ge Zhang, Jiakai Wang, Haoran
                     guagemodelsbyjointsparsificationandquantization.            Que, Yukang Chen, Wenbo Su, et al. 2024a. E2-
                     ICML.                                                       llm: Efficient and extreme length extension of large
                  Tianxing He, Jingyu Zhang, Tianle Wang, Sachin                 language models. arXiv preprint arXiv:2401.06951.
                     Kumar, Kyunghyun Cho, James Glass, and Yulia             Jie Liu, Zhanhui Zhou, Chao Yang, Han-Sen Zhong,
                     Tsvetkov. 2022. On the blind spots of model-based           and Wanli Ouyang. 2024b. Storm-7b: An empirical
                     evaluation metrics for text generation. arXiv preprint      study of iterative direct preference optimization.
                     arXiv:2212.10020.
                                                                              Weimin Lyu, Xiao Lin, Songzhu Zheng, Lu Pang,
                  DanHendrycks,CollinBurns,StevenBasart,AndyZou,                 HaibinLing,SusmitJha,andChaoChen.2024. Task-
                     Mantas Mazeika, Dawn Song, and Jacob Steinhardt.            agnostic detector for insertion-based backdoor at-
                     2020. Measuring massive multitask language under-           tacks. arXiv preprint arXiv:2403.17155.
                     standing. arXiv preprint arXiv:2009.03300.
                                                                              Carol A Marchel. 2007. Learning to talk/talking to
                  Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei                   learn: Teaching critical dialogue. Teaching Educa-
                     Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu,              tional Psychology, 2(1):1–15.
                     Chuancheng Lv, Yikai Zhang, Yao Fu, et al. 2024.
                     C-eval: A multi-level multi-discipline chinese evalua-   OpenAI. 2022. Introducing chatgpt.
                     tion suite for foundation models. Advances in Neural
                     Information Processing Systems, 36.                      OpenAI. 2023. Gpt-4 technical report. PREPRINT.
                                                                          7430
                  Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,          Xingyao Wang, Zihan Wang, Jiateng Liu, Yangyi
                     Carroll Wainwright, Pamela Mishkin, Chong Zhang,           Chen, Lifan Yuan, Hao Peng, and Heng Ji. 2023b.
                     Sandhini Agarwal, Katarina Slama, Alex Ray, et al.         Mint: Evaluating llms in multi-turn interaction
                     2022. Training language models to follow instruc-          with tools and language feedback. arXiv preprint
                     tions with human feedback. Advances in Neural              arXiv:2309.10691.
                     Information Processing Systems, 35:27730–27744.         Yidong Wang, Zhuohao Yu, Zhengran Zeng, Linyi
                  Junran Peng, Xingyuan Bu, Ming Sun, Zhaoxiang                 Yang, Cunxiang Wang, Hao Chen, Chaoya Jiang,
                     Zhang, Tieniu Tan, and Junjie Yan. 2020. Large-            Rui Xie, Jindong Wang, Xing Xie, et al. 2023c.
                     scale object detection in the wild from imbalanced         Pandalm: An automatic evaluation benchmark for
                     multi-labels. In Proceedings of the IEEE/CVF con-          llm instruction tuning optimization. arXiv preprint
                     ference on computer vision and pattern recognition,        arXiv:2306.05087.
                     pages 9709–9718.                                        Zekun Moore Wang, Zhongyuan Peng, Haoran Que,
                  JunranPeng,QingChang,HaoranYin,XingyuanBu,Ji-                 Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu,
                     ajun Sun, Lingxi Xie, Xiaopeng Zhang, Qi Tian, and         Hongcheng Guo, Ruitong Gan, Zehao Ni, Man
                     Zhaoxiang Zhang. 2023. Gaia-universe: Everything           Zhang, Zhaoxiang Zhang, Wanli Ouyang, Ke Xu,
                     is super-netify. IEEE Transactions on Pattern Analy-       Wenhu Chen, Jie Fu, and Junran Peng. 2023d.
                     sis and Machine Intelligence, 45(10):11856–11868.          Rolellm: Benchmarking, eliciting, and enhancing
                  Rafael Rafailov, Archit Sharma, Eric Mitchell, Christo-       role-playing abilities of large language models. arXiv
                     pher D Manning, Stefano Ermon, and Chelsea Finn.           preprint arXiv: 2310.00746.
                     2024. Direct preference optimization: Your language     Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
                     modelis secretly a reward model. Advances in Neu-          Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,
                     ral Information Processing Systems, 36.                    et al. 2022. Chain-of-thought prompting elicits rea-
                  William A Scott. 1955. Reliability of content analysis:       soninginlargelanguagemodels. AdvancesinNeural
                     The case of nominal scale coding. Public opinion           Information Processing Systems, 35:24824–24837.
                     quarterly, pages 321–325.                               Yanan Wu, Jie Liu, Xingyuan Bu, Jiaheng Liu, Zhanhui
                  Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,             Zhou, Yuanxing Zhang, Chenchen Zhang, Zhiqi Bai,
                     AbuAwalMdShoeb,AbubakarAbid,AdamFisch,                     HaibinChen,TiezhengGe,etal.2024. Conceptmath:
                     Adam R Brown, Adam Santoro, Aditya Gupta,                  Abilingual concept-wise benchmark for measuring
                     Adrià Garriga-Alonso, et al. 2022.      Beyond the         mathematical reasoning of large language models.
                     imitation game: Quantifying and extrapolating the          arXiv preprint arXiv:2402.14660.
                     capabilities of language models.     arXiv preprint     CanwenXu,DayaGuo,NanDuan,andJulianMcAuley.
                     arXiv:2206.04615.                                          2023.   Baize: An open-source chat model with
                  Tao Sun, Linzheng Chai, Yuwei Yin Jian Yang,                  parameter-efficient tuning on self-chat data. arXiv
                     Hongcheng Guo, Jiaheng Liu, Bing Wang, Liqun               preprint arXiv:2304.01196.
                     Yang, and Zhoujun Li. 2024. Unicoder: Scaling code      Yi. 2023. Yi: Building the next generation of open-
                     large language model via universal code. ACL.              source and bilingual llms. https://github.com/
                  Yuchong Sun, Che Liu, Jinwen Huang, Ruihua Song,              01-ai/Yi.
                     Fuzheng Zhang, Di Zhang, Zhongyuan Wang, and            Jifan Yu, Xiaozhi Wang, Shangqing Tu, Shulin Cao,
                     Kun Gai. 2023. Parrot: Enhancing multi-turn chat           DanielZhang-Li,XinLv,HaoPeng,ZijunYao,Xiao-
                     models by learning to ask questions. arXiv preprint        han Zhang, Hanming Li, et al. 2023. Kola: Carefully
                     arXiv:2310.07301.                                          benchmarking world knowledge of large language
                  InternLM Team. 2023. Internlm: A multilingual lan-            models. arXiv preprint arXiv:2306.09296.
                     guage model with progressively enhanced capabili-       Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle
                     ties. https://github.com/InternLM/InternLM.                Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,
                  Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-            Zhuohan Li, Zi Lin, Eric Xing, et al. 2023. Lmsys-
                     bert, Amjad Almahairi, Yasmine Babaei, Nikolay             chat-1m: A large-scale real-world llm conversation
                     Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti         dataset. arXiv preprint arXiv:2309.11998.
                     Bhosale, et al. 2023.     Llama 2: Open founda-         Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan
                     tion and fine-tuned chat models.     arXiv preprint        Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,
                     arXiv:2307.09288.                                          Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024.
                  Hongru Wang, Rui Wang, Fei Mi, Yang Deng, Zezhong             Judging llm-as-a-judge with mt-bench and chatbot
                     Wang,BinLiang,RuifengXu,andKam-FaiWong.                    arena. Advances in Neural Information Processing
                     2023a. Cue-cot: Chain-of-thought prompting for             Systems, 36.
                     responding to in-depth dialogue questions with llms.    WanjunZhong,RuixiangCui,YiduoGuo,YaoboLiang,
                     In Findings of the Association for Computational           Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen,
                     Linguistics: EMNLP 2023, pages 12047–12064.                and Nan Duan. 2023. Agieval: A human-centric
                                                                         7431
                  benchmark for evaluating foundation models. arXiv
                  preprint arXiv:2304.06364.
                Zhanhui Zhou, Jie Liu, Zhichen Dong, Jiaheng Liu,
                  Chao Yang, Wanli Ouyang, and Yu Qiao. 2024a.
                  Emulated disalignment: Safety alignment for large
                  language models may backfire!    arXiv preprint
                  arXiv:2402.12343.
                Zhanhui Zhou, Jie Liu, Chao Yang, Jing Shao, Yu Liu,
                  Xiangyu Yue, Wanli Ouyang, and Yu Qiao. 2023.
                  Beyond one-preference-for-all: Multi-objective di-
                  rect preference optimization.   arXiv preprint
                  arXiv:2310.03708.
                Zhanhui Zhou, Zhixuan Liu, Jie Liu, Zhichen Dong,
                  Chao Yang, and Yu Qiao. 2024b. Weak-to-strong
                  search: Align large language models via search-
                  ing over small language models.  arXiv preprint
                  arXiv:2405.19262.
                                                               7432
                  A DetailsontheDataGeneration                              affirmation, self-correction, and context memory
                  Our dataset is generated encompassing a wide              tasks, models generate responses directly from the
                  range of 30 topics, which are medicine, health,           second turn of dialogue, utilizing the golden con-
                  history, science, technology, digital, automotive,        text from the first turn as historical dialogue in-
                  astronomy, geography, lifestyle, literature, politics,    formation. This approach is adopted due to the
                  physics, chemistry, biology, finance, stocks, law,        task characteristics, where the assessment of the
                  humanities, entertainment, music, gaming, fashion,        respective abilities begins from the second turn of
                  film and television, celebrities, sports, art, com-       dialogue. Whilemodelsneedtoutilizethedialogue
                  puter science, environment, and psychology. This          history from the first turn in subsequent turns, di-
                  variety ensures that our data spans a multitude of        rectly responding to the content of the first turn
                  diverse fields and areas of interest.                     lacks practical significance.
                     After generating preliminary data using GPT-4,         D Additionalresults utilizing
                  we manually filtered the data samples by human                 Qwen-72B-Chat
                  annotators to form the final dataset. The primary
                  criteria for curation are as follows:                     Weevaluated the top 5 models in our benchmark
                     1. Ensure that our dataset precisely adheres to        using an open-source Qwen-72B-Chat, and the re-
                  the data generation rules outlined for each specific      sults in Table 7 show that GPT-4 is still the most
                  task.                                                     powerful model and the rankings of GPT-4-Judge
                     2. Ensure that our dataset encompasses samples         and Qwen-72B-Judge are consistent. This also
                  from 30 different topics, with a minimum of 10            shows that Qwen-72B-Chat is a good alternative
                  distinct topics covered for each task.                    evaluator. It is open-source, free to use, and won’t
                     3. Remove similar dialogues with only varia-           be updated or taken down in the future.
                  tions in several keywords.                                E ModelDetails
                     4. Remove questions regarding real-time issues
                  (such as today’s weather) and those involving up-         Alldetailsabouttheevaluatedmodelsarepresented
                  to-date knowledge after 2022.                             in Table 8.
                     5. Removedialoguesthatcontaincommonsense
                  errors, offensive content, and any personal identity      F MoreCases
                  information.                                              Figures 35 to 45 show cases corresponding to each
                     Figures 8 to 20 show the prompts we utilize for        task, each reflecting the classical error of the model
                  data generation. When generating data for each            response. These cases show that our task design
                  task, we splice in a uniform initial prompt and           can accurately assess the corresponding ability of
                  a unique prompt for each task to ensure that the          LLMs.
                  generated data matches our ability and task require-
                  ments.                                                    G Fleiss’KappabetweenGPT-4and
                  B DetialsonDataStatistics                                      Humans
                  Table 6 demonstrates the statistics information for       To evaluate the agreement between humans and
                  each task as well as the overall statistics of MT-        GPT-4,wealsoprovideFleiss’Kappascore,which
                  Bench-101. Note that the number of words is cal-          is an inter-annotator agreement metric. Specifi-
                  culated from the golden context in the dataset.           cally, we compute (1) The Fleiss’ Kappa for the
                                                                            five raters; (2) The average Fleiss’ Kappa between
                  C DetailsonEvaluation                                     GPT-4 and each individual rater; (3) The Fleiss’
                                                                            KappabetweenGPT-4andthemajorityvoteof5
                  Figures 21 to 34 show the prompts we utilize for          humanannotators. (4) The Fleiss’ Kappa of GPT4
                  evaluation. For each task, we concatenate a uni-          and humans over all annotations. As shown in Ta-
                  form initial instruction, unique evaluation prompts       ble 9, the agreement between GPT-4 and humans
                  tailored to the specific task, and a consistent scor-     is still higher than that among humans.
                  ing format to ensure that the scoring criteria align
                  with our task requirements.
                     It’s also noteworthy that in format rephras-
                  ing, content rephrasing, anaphora resolution, self-
                                                                        7433
         # Initial Instructions # Please continue the conversation for the topic #TOPIC#, based on
         requirements and examples. The content of the dialogue should be reasonable and accurate. Use
         ‘Human:’ and ‘Assistant:’ as prompts to indicate the speaker, and respond in English.
                    Figure 8: The initial instructions for data generation.
         Please help me generate a set of multiple rounds of dialogue between users and robots based on a
         given dialogue scenario. It is required that the user’s questions in the last round must be answered
         by combining some of the information he provided previously in order to test the robot’s memory
         ability that it can remember historical conversational information well. Note the exciting user
         question at the end without repeating previous information. The conversation content is required
         to be reasonable, smooth and natural.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
         Please generate the dialogue in this format, and following the pattern of the second round of Q&A,
         continue to generate the content needed to carry out the task for three to four rounds.
                   Figure 9: The unique prompt for the context memory task.
         You are required to generate multi-turn dialogues in English. Specifically, in the first round of
         dialogue, ‘Human’ should only state the requirements of the task without providing the specific
         content needed to carry out the task. At this point, ‘Assistant’ cannot answer the question and must
         inquire about the content necessary to perform the task. In the second round of dialogue, ‘Human’
         directly presents the content needed for the task without needing to repeat the requirements.
         ‘Assistant’ should then provide a direct response.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
         Please generate the dialogue in this format, and following the pattern of the second round of Q&A,
         continue to generate the content needed to carry out the task for three to four rounds.
                   Figure 10: The unique prompt for the separate input task.
                              7434
         Youarerequired to generate a multi-turn English dialogue to evaluate the rephrasing capabilities
         of large language models, with a total of three rounds of dialogue following six steps.
         Step 1: Generate the first question.
         Step 2: Generate the response to the first question.
         Step 3: Pose the second question, which requires a formal rephrase of the answer from the first
         round. (You need to understand the content of the first round’s question and answer and request a
         formal rephrase of the first round’s response in terms of structure, length, etc. Please note that it is
         a formal rephrase, not a content change, and you should not add new content, fabricate stories, or
         pretend to be in a specific scenario.)
         Step 4: Generate the answer to the second round’s question.
         Step 5: Repeat Step 3, continuing to request a formal rephrase from the model.
         Step 6: Generate the answer to the third round’s question.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
         Please output the dialogue content directly with ‘Human:’ and ‘Assistant:’ as role prompts,
         without stating ‘step1’, ‘step2’, and so on.
                  Figure 11: The unique prompt for the format rephrasing task.
         Youarerequired to generate a multi-turn English dialogue to evaluate the rephrasing capabilities
         of large language models, with a total of three rounds of dialogue following six steps.
         Step 1: Generate the first question.
         Step 2: Generate the response to the first question.
         Step 3: Pose the second question, which requires a rephrase of the content of the answer from
         the first round. (You need to understand the content of the first round’s question and answer and
         request a rephrase of the first round’s response in terms of a specific scenarios, tones, etc. Please
         note that it is a content rephrase, not a change in format.)
         Step 4: Generate the answer to the second round’s question.
         Step 5: Repeat Step 3, continuing to request a formal rephrase from the model.
         Step 6: Generate the answer to the third round’s question.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
         Please output the dialogue content directly with ‘Human:’ and ‘Assistant:’ as role prompts,
         without stating ‘step1’, ‘step2’, and so on.
                  Figure 12: The unique prompt for the content rephrasing task.
                              7435
                          YouarerequiredtogenerateEnglishmulti-turndialoguedatatoevaluatethemodel’sunderstanding
                          of referential relationships, specifically focusing on anaphora, which reflect realistic inquiries that
                          users might pose to large-scale models. You are required to use anaphora to generate multi-turn
                          dialogues between ‘Human’ and ‘Assistant’, where anaphora is a linguistic term for a reference to
                          something mentioned earlier in the dialogue.
                          Step 1: ‘Human’ poses a question.
                          Step 2: ‘Assistant’ answers the question.
                          Step 3: A follow-up question is asked about the first round’s answer, using anaphora to refer back
                          to some content from the first round’s answer.
                          Step 4: The question is answered.
                          Step 5: The fifth step involves another follow-up question about the first round’s answer, again
                          using anaphora to refer to certain content.
                          Step 6: In the sixth step, the question is answered.
                          Youcanrefer to these examples:
                          # Example 1 #
                          # Example 2 #
                          # Example 3 #
                          Please ensure that the anaphoric references in the third and fifth steps effectively demon-
                          strate the model’s capability to understand and resolve referential expressions.
                          Please output the dialogue content directly with ‘Human:’ and ‘Assistant:’ as role prompts,
                          without stating ‘step1’, ‘step2’, and so on.
                                                    Figure 13: The unique prompt for the anaphora resolution task.
                                                          Memory Understanding       Interference    Rephrasing     Reflection    Reasoning     Questioning
                       Statistics               Overall     CM       SI      AR       TS     CC      CR     FR      SC     SA     MR GR IC              PI
                       Total # Dialogues         1388       80       149     153      83     147     136     74     77     73     108    71     150     87
                       Total # Turns             4208       319      620     560      249    352     389    197    154    146     224    218    426    354
                       Avg. # Turns per Dialog    3.03      3.99    4.16     3.66    3.00    2.39    2.86   2.66   2.00   2.00   2.07    3.07   2.84   4.07
                       Avg. # Words per Dialog   202.0     235.9    214.0   214.1    145.7  353.9   321.4 191.4    79.2   85.4   175.8 157.3 142.5 127.1
                       Avg. # Words per Turn     66.64     59.15    84.76   58.49    48.56 147.80 112.4 71.91 39.60 42.71 51.44 51.22 50.18 31.22
                       Max. # Words in Dialog     817       351      817     397      219    749     588    355    183    175     348    331    344    254
                       Max. # Words in Turn       323       323      237     229      109    300     323    229    105    103     263    141    153     53
                             Table 6: The data statistics for our MT-Bench-101. Each task is represented by its initial capital letter.
                       Model                            Avg.    CM SI AR TS CC CR FR SC SA MR GR IC PI
                       GPT-4                            8.75    8.74 8.96 9.20 8.77 8.85 8.79 8.81 9.14 9.10 8.25 7.87 8.82 8.51
                       Yi-34B-Chat                      8.60    8.66 8.77 9.04 8.72 8.78 8.71 8.81 8.97 8.95 7.77 7.41 8.78 8.42
                       GPT-3.5                          8.49    8.42 8.96 8.98 8.69 8.87 8.60 8.78 8.99 8.37 7.34 7.57 8.57 8.17
                       Qwen-14B-Chat                    8.40    8.03 8.85 8.91 8.51 8.71 8.55 8.69 8.92 8.43 7.47 7.52 8.56 8.03
                       Mixtral-8x7B-Instruct-v0.1       8.32    8.10 7.85 8.92 8.65 8.76 8.47 8.62 9.01 8.42 7.10 7.67 8.57 8.01
                                                    Table 7: The results using Qwen-72B-Chat as the judge model.
                                                                                      7436
         Youarerequired to generate English multi-turn dialogue data or assessing the model’s ability to
         withstand contextual interference, follow these steps:
         Step 1: Create the initial question for the first round.
         Step 2: Generate a response to the first round’s question.
         Step 3: Construct a subsequent question that closely mirrors the syntactic structure of the first
         question but differs significantly in meaning or implication, potentially leading to model confusion.
         Step 4: Respond to this second round’s question, taking care to accurately interpret any elements of
         the question that may be ambiguous, have connotative meanings, or require specialized knowledge
         before providing a standard answer.
         Step 5: Repeat steps 3 and 4 to generate further rounds of questions and answers, ensuring each
         new question introduces a distinct potential point of confusion while structurally resembling
         previous ones.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
         While answering, it is important to accurately interpret any ambiguous, connotative, or
         technical content within the question before giving a standard response. Finally, repeat the third
         and fourth steps to create additional rounds of Q&A. Please refrain from including labels such as
         ‘step1’, ‘step2’, and so on in the output.
                  Figure 14: The unique prompt for the content confusion task.
         You are required to generate English test data to evaluate the model’s capacity for generating
         clarifying questions. ‘Human’ begins by asking a question that either lacks certain conditions or
         contains content that is ambiguous or unclear. In the subsequent dialogue rounds, ‘Assistant’ will
         ask counter-questions to address the missing conditions or clarify the unclear portions. ‘Human’
         will then respond to these inquiries. This process continues until the intent is clear and the
         conditions are explicitly defined, at which point ‘Assistant’ will provide a detailed and specific
         answer. Please omit labels such as ‘step1’, ‘step2’, etc., from the output.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
                    Figure 15: The unique prompt for the topic shift task.
                              7437
         Youare required to generate a multi-turn English dialogue to evaluate the model’s capacity for
         self-correction, i.e., whether the model can rectify its incorrect responses. ‘Human’ initiates with a
         question, ‘Assistant’ provides an incorrect answer, ‘Human’ questions the accuracy, and then ‘As-
         sistant’ delivers the correct answer. Please omit labels such as ‘step1’, ‘step2’, etc., from the output.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
                   Figure 16: The unique prompt for the self-correction task.
         Youarerequired to generate a multi-turn English dialogue to assess the model’s ability to maintain
         the correctness of its answers, that is, whether the model can stand by its correct responses.
         ‘Human’starts off with a question, ‘Assistant’ responds correctly, ‘Human’ challenges the answer,
         and then ‘Assistant’ reaffirms the accuracy of its original response.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
                   Figure 17: The unique prompt for the self-affirmation task.
         I will give you a reasoning question and the corresponding answer. Please use this question and an-
         swer pair to generate a set of multi-round conversations to test the robot’s multi-round reason-
         ing ability. Try to make inferences in each round based on the dialogue information from the previ-
         ous round.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
                  Figure 18: The unique prompt for the general reasoning task.
                              7438
         Please help me generate multiple groups of multi-turn dialogues based on a given dialogue
         scenario, mainly to evaluate the model’s ability to resist interference from the above. Each round
         of dialogue requires topic shifting. For example, the first round of conversations revolves around
         a topic. During the second round of conversation, the user suddenly switches topics and asks a
         completely unrelated question. Then, in a third round of conversation, the user returns to the
         original topic to ask a more specific question or further discussion point.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
                 Figure 19: The unique prompt for the instruction clarification task.
         Please help me generate multiple sets of multi-turn conversations based on a given conversation
         scenario, with the goal of testing the model’s active interaction capabilities. After the user
         states something, the model should generate appropriate questions to continue the conversation.
         Therefore, the conversation you generate needs the user to state something firstly, and then the
         robot will ask questions based on the user’s topic. Note that the generated dialogue should be
         smooth and natural.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
                  Figure 20: The unique prompt for the proactive interaction task.
         Please act as an impartial judge following these instructions: In the following conversations, the
         response of the ‘assistant’ in the last round of conversations is the output of the large language
         model(AIassistant) that needs to be evaluated.
         Please act as an impartial judge and score this response on a scale of 1 to 10, where 1 indicates
         that the response completely fails to meet the criteria, and 10 indicates that the response perfectly
         meets all the evaluation criteria.
         Notethatonlytheresponseofthe‘assistant’ in the LAST ROUNDofconversationsistheoutputof
         the large language model (the AI assistant) that needs to be evaluated; the previous conversations
         are the ground truth history which do NOT need to be evaluated.
                     Figure 21: The initial instructions for evaluation.
                              7439
                        Note that only the response of the ‘assistant’ in the LAST ROUND of conversations is the output
                        of the large language model (the AI assistant) that needs to be evaluated!! You must provide your
                        explanation. After providing your explanation, please show the score by strictly following this
                        format: ‘Rating: [[score]]’, for example ‘Rating: [[6]]’. The DIALOGUE needs to be judged in
                        this format:
                        ***
                        DIALGUE
                        ***
                                                         Figure 22: The scoring format for evaluation.
                      Model                                       ModelLink
                      Llama2       Llama2-7B-Chat                 https://huggingface.co/meta-llama/Llama-2-7b-chat-hf
                                   Llama2-13B-Chat                https://huggingface.co/meta-llama/Llama-2-13b-chat-hf
                                   Mistral-7B-Instruct-v0.2       https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2
                      Mistral      Mixtral-8x7B-Instruct-v0.1     https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1
                                   Mistral-PairRM-DPO             https://huggingface.co/snorkelai/Snorkel-Mistral-PairRM-DPO
                      Qwen         Qwen-7B-Chat                   https://huggingface.co/Qwen/Qwen-7B-Chat
                                   Qwen-14B-Chat                  https://huggingface.co/Qwen/Qwen-14B-Chat
                      Yi           Yi-6B-Chat                     https://huggingface.co/01-ai/Yi-6B-Chat
                                   Yi-34B-Chat                    https://huggingface.co/01-ai/Yi-34B-Chat
                      ChatGLM      ChatGLM2-6B                    https://huggingface.co/THUDM/chatglm2-6b
                                   ChatGLM3-6B                    https://huggingface.co/THUDM/chatglm3-6b
                                   InternLM2-Chat-7B-SFT          https://huggingface.co/internlm/internlm2-chat-7b-sft
                      InternLM2    InternLM2-Chat-20B-SFT         https://huggingface.co/internlm/internlm2-chat-20b-sft
                                   InternLM2-Chat-7B-RLHF         https://huggingface.co/internlm/internlm2-chat-7b
                                   InternLM2-Chat-20B-RLHF        https://huggingface.co/internlm/internlm2-chat-20b
                      Vicuna       Vicuna-13B-v1.5                https://huggingface.co/lmsys/vicuna-13b-v1.5
                      Baize        Baize-v2-13B                   https://huggingface.co/project-baize/baize-v2-13b
                      UltraChat    UltraLM-13B-v2.0               https://huggingface.co/openbmb/UltraLM-13b-v2.0
                      Baichuan2    Baichuan2-13B-Chat             https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat
                      GPT          GPT3.5-turbo                   https://platform.openai.com/docs/models/gpt-3-5-turbo
                                   GPT4-turbo                     https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo
                                                                     Table 8: Model Links.
                                           Typeofjudges                                            Fleiss’ Kappa score
                                           Agreement among humans                                          0.672
                                           Agreement of GPT4 and humans (over all annotations)             0.676
                                           Agreement of GPT4 and humans (average)                          0.681
                                           Agreement of GPT4 and humans (majority voting)                  0.699
                                                     Table 9: Fleiss’ Kappa score of GPT4 and humans.
                                                                              7440
                     The capacity of a large language model to recall and utilize previously mentioned information
                     from earlier in the conversation is a critical indicator of its conversational memory abilities. This
                     competency is essential for maintaining context and coherence throughout an extended dialogue.
                     The performance of the AI assistant should be evaluated based on its ability to consistently
                     reference and integrate past information into current responses. The evaluation criteria are as
                     follows:
                     1.   Analyze whether the AI assistant appropriately recalls relevant details from earlier
                     parts of the conversation when responding to ‘Human’s inquiries or comments.
                     2. Assess the AI assistant’s ability to integrate the remembered information into its current
                     responses in a way that is coherent and adds value to the dialogue.
                     3. Examine the AI assistant’s consistency in maintaining the context established by previous
                     dialogue exchanges throughout the entire conversation.
                     4. Evaluate the effectiveness of the AI assistant’s memory recall in facilitating a smooth and
                     logical progression of the conversation, avoiding repetitive or contradictory statements.
                     Scoring Guidelines:
                     1-3 points:    The AI assistant demonstrates poor recall of previous conversation details,
                     leading to inconsistent or contradictory responses, and fails to maintain the dialogue’s context,
                     resulting in a disjointed or unclear conversation flow.
                     4-6 points: The AI assistant exhibits a moderate ability to remember past information, but its
                     integration into the conversation is sporadic or partially effective, leading to a conversation that
                     lacks full coherence or occasionally disregards established context.
                     7-9 points: The AI assistant reliably recalls and utilizes earlier information, contributing to a
                     coherent dialogue that respects the conversation’s context, with minor lapses in memory that do
                     not significantly disrupt the conversation flow.
                     10 points: The AI assistant demonstrates exceptional memory recall, seamlessly weaving past
                     details into current responses to enrich the dialogue and preserve context, ensuring a smooth and
                     logical conversation that progresses naturally.
                     Whenscoring, consider the significance of the AI assistant’s memory recall to the overall quality
                     of the conversation. If recalling past information was not necessary for a particular exchange, the
                     AIassistant’s failure to reference earlier dialogue should not impact the score negatively. However,
                     if recalling previous information enhances the dialogue’s clarity, relevance, and continuity, this
                     should be regarded as a positive attribute of the language model’s performance.
                     Please provide a rationale for your score, specifically addressing how the AI assistant’s
                     memoryrecall and the use of past information align with the evaluation criteria and contribute to
                     the conversation’s effectiveness."
                                            Figure 23: The evaluation prompt for context memory task.
                                                                      7441
                     The AI assistant’s understanding of references is essential for maintaining a coherent dialogue.
                     Thefollowing criteria should be used to evaluate its performance:
                     1.   The AI assistant’s response must demonstrate a correct understanding of referential
                     information from questions asked by ‘Human,’ which typically relate to content from the previous
                     dialogue. Ideally, the AI should explicitly acknowledge or clarify these references in its reply.
                     2. The response from the AI assistant should be consistent with the content of the ‘Human’s ques-
                     tion in the current round, providing true and accurate information, free from misunderstandings or
                     inaccuracies related to the references.
                     Scoring Guidelines:
                     - 1-3 points: The AI assistant fails to recognize or correctly interpret the referential infor-
                     mation, leading to responses that are either inaccurate or unrelated to the previous content.
                     - 4-6 points: The AI assistant shows a partial understanding of references, but the response might
                     include some inaccuracies or fail to fully utilize the referential information.
                     - 7-9 points: The AI assistant’s response indicates a good understanding of the references, with
                     only slight inaccuracies or omissions in the connection to the previous dialogue.
                     - 10 points: The AI assistant demonstrates excellent understanding and use of referential
                     information, perfectly aligning its response with the previous content and the current question
                     accurately and precisely.
                     In addition to the score, please provide an explanation that specifically addresses how
                     the AI assistant’s response demonstrates its ability or inability to understand and use referential
                     information in accordance with the criteria above. ‘
                                          Figure 24: The evaluation prompt for anaphora resolution task.
                                                                      7442
                     Weaimtospecifically evaluate the command-following ability of the large language model (AI
                     assistant). The criteria for evaluation are as follows:
                     1.  In the first round, ‘Human’ will present a task request without providing details about
                     what needs to be done. If the AI Assistant being evaluated generates a response for the first round,
                     it should ask ‘Human’ for the specific details of the task required or wait for ‘Human’ to provide
                     specific details of the required tasks, rather than directly attempting to answer the task.
                     2. Starting from the second round, ‘Human’ will provide the specific content of what needs to be
                     carried out for the task, without repeating the task requirement. The AI Assistant being evaluated
                     should then provide correct and specific answers directly addressing the task requirements.
                     Please rate the AI assistant’s response using a 1 to 10 scale based on the following guidelines:
                     - 1-3 points: The AI assistant failed to understand the task request and neither asked rele-
                     vant questions nor provided information related to the task.
                     - 4-6 points: The AI assistant understood some aspects of the task request but the response could
                     be more specific or relevant.
                     - 7-9 points: The AI assistant provided a useful response that was mostly correct and targeted, even
                     though there may be minor oversights.
                     - 10 points: The AI assistant demonstrated a perfect understanding of the task requirements and
                     provided a comprehensive and accurate answer, fully meeting ‘Human’s expectations.
                     Additionally, please provide a brief justification for the score given, particularly high-
                     lighting how the AI assistant’s response aligns with or deviates from the above criteria. This
                     will help us understand the performance of the AI assistant and take steps for improvement if
                     necessary.
                                             Figure 25: The evaluation prompt for separate input task.
                                                                      7443
                     TheAIassistant’s ability to handle shifts in conversation topics is crucial for maintaining relevance
                     and adaptability during a dialogue. This skill is particularly important when ‘Human’ introduces a
                     newtopic or changes the subject abruptly. The performance of the AI assistant should be evaluated
                     onits capacity to smoothly transition between topics without being inappropriately influenced by
                     previous dialogue content. The evaluation criteria are as follows:
                     1.   Identify whether the AI assistant can detect and acknowledge the change in topic in-
                     troduced by ‘Human’ without reverting back to or becoming stuck on the previous subject.
                     2. Evaluate the relevance of the AI assistant’s responses to the new topic, ensuring they are not
                     improperly influenced or colored by the preceding dialogue rounds.
                     3. Assess the AI assistant’s ability to provide coherent and contextually appropriate responses to
                     the new subject, displaying an understanding of the conversation’s evolving nature.
                     4. Consider the AI assistant’s proficiency in offering complete and insightful answers to the new
                     topic, which demonstrates a clear break from past conversation threads.
                     Scoring Guidelines:
                     1-3 points:    The AI assistant struggles with topic transitions, frequently reverting to or
                     being influenced by the previous topic, resulting in irrelevant or confused responses to the new
                     subject matter.
                     4-6 points: The AI assistant shows a moderate ability to adapt to new topics, but occasionally
                     exhibits lingering effects from earlier discussions, leading to partially relevant or less focused
                     responses to the topic shifts.
                     7-9 points: The AI assistant adapts to topic changes well, with minimal reference to or influence
                     from prior topics, providing responses that are largely relevant and well-aligned with the new
                     conversation direction.
                     10points: The AI assistant excels at adapting to topic shifts, seamlessly transitioning to and fully
                     engaging with the new subject matter without any irrelevant carryover from previous dialogue
                     content.
                     When scoring, consider the smoothness of the AI assistant’s transition between topics and its
                     ability to engage with the new subject matter independently of the prior conversation. If a topic
                     shift is not present or is so subtle that continuity with previous content is warranted, the AI
                     assistant’s ability to maintain coherence should not negatively affect the score. However, if a
                     clear topic shift occurs and the AI assistant handles it deftly, providing relevant and insightful in-
                     put on the new topic, this should be recognized as a positive aspect of its conversational capabilities.
                     Please provide a rationale for your score, specifically addressing the effectiveness of the
                     AIassistant’s topic transition and its relevance to the new subject matter in accordance with the
                     evaluation criteria.
                                               Figure 26: The evaluation prompt for topic shift task.
                                                                      7444
                     TheAIassistant’s capability to resist interference will be measured against these criteria:
                     1.   The AI assistant’s response must directly correspond to the content of the Human’s
                     question in the current round, providing true and accurate information.
                     2. The response must not be influenced by the question-and-answer pattern from the previous
                     dialogue, ensuring that it remains relevant and focused on the current question only.
                     Scoring Guidelines:
                     - 1-3 points:    The AI assistant’s response is largely influenced by previous interactions,
                     fails to address the current question accurately, or provides false information.
                     - 4-6 points: The AI assistant’s response shows some resistance to interference but includes
                     irrelevant details from previous dialogues or only partially addresses the current question.
                     - 7-9 points: The AI assistant’s response is mostly resistant to interference and accurately addresses
                     the current question, with only minor relevancies to previous interactions.
                     - 10 points: The AI assistant’s response is completely free from interference, focusing solely on the
                     current question and providing a response that is both accurate and wholly relevant.
                     Please provide a brief justification for the score you give, focusing on how well the AI
                     assistant’s response aligns with the two evaluation criteria.
                                           Figure 27: The evaluation prompt for content confusion task.
                     Weaimtospecifically evaluate the rephrasing ability of the large language model (AI assistant).
                     Thecriteria for evaluation are as follows:
                     1.   The content of the AI assistant’s rephrased response must maintain the same main
                     idea as the Assistant’s response in the first round.
                     2. The rephrased content must comply with the specific rewriting requirements set forth by the
                     Humaninthecurrentround.
                     Scoring Guidelines:
                     - 1-3 points: The rephrased response significantly deviates from the original main idea or
                     fails to meet the rewriting requirements.
                     - 4-6 points: The rephrased response captures the original main idea but only partially meets the
                     rewriting requirements or lacks fluency/coherence.
                     - 7-9 points: The rephrased response maintains the original main idea and satisfies most of the
                     rewriting requirements with minor discrepancies or stylistic issues.
                     - 10 points: The rephrased response perfectly preserves the original main idea and fulfills all of the
                     rewriting requirements set by Human, exhibiting a seamless and natural integration of the required
                     changes.
                     Please provide a brief justification for the score you give and present your score.
                                              Figure 28: The evaluation prompt for rephrasing task.
                                                                      7445
                     Weaimtospecifically evaluate the self-correction ability of the large language model (AI assistant)
                     when the ‘Human’ identifies an error in the AI assistant’s initial response. The criteria for
                     evaluation are as follows:
                     1.   Upon ‘Human’ pointing out a potential mistake, the AI assistant must thoroughly as-
                     sess its previous response and engage with ‘Human’s’ observation.
                     2. If the ‘Human’ has correctly identified an error, the AI assistant must acknowledge the mistake,
                     correct it, and provide an updated and accurate response.
                     Scoring Guidelines:
                     - 1-3 points: The AI assistant fails to recognize or adequately address the error identified
                     by‘Human,’anddoesnotmakethenecessarycorrections to its response.
                     - 4-6 points: The AI assistant recognizes the error identified by ‘Human’ but may only partially
                     correct the mistake or provide an incomplete updated response.
                     - 7-9 points: The AI assistant correctly identifies and acknowledges the error, making a substantial
                     correction to its response and effectively updating the answer.
                     - 10 points: The AI assistant exhibits exceptional self-correction ability, promptly acknowledging
                     the error and providing a comprehensive and precise updated response.
                     In addition to scoring, please provide a justification for your assessment, focusing on
                     howeffectively the AI assistant’s reaction to ‘Human’s’ identified error demonstrates its ability to
                     self-correct and address the criteria outlined above.
                                            Figure 29: The evaluation prompt for self-correction task.
                                                                      7446
                     Weaimtospecifically evaluate the ability of the large language model (AI assistant) to maintain
                     confidence in its original response when challenged by ‘Human’, provided that the challenge is
                     incorrect. The criteria for evaluation are as follows:
                     1.   When ‘Human’ questions the content of the AI assistant’s response, the AI assistant
                     must engage with ‘Human’s’ query and assess the validity of the challenge.
                     2. If ‘Human’ challenge is based on incorrect information or assumptions, the AI assistant must
                     confidently maintain its original answer and provide a clear and reasoned explanation to justify its
                     stance.
                     Scoring Guidelines:
                     - 1-3 points: The AI assistant either does not engage with ‘Human’s challenge appropri-
                     ately or changes its original response without proper justification, even when ‘Human’s challenge
                     is incorrect.
                     - 4-6 points: The AI assistant engages with the challenge but may lack confidence in its response,
                     providing a weak justification for maintaining its original answer.
                     - 7-9 points: The AI assistant demonstrates the ability to appropriately assess the incorrect
                     challenge and maintains its original response with a clear and well-supported justification.
                     - 10 points: The AI assistant exhibits excellent ability to maintain confidence in its original
                     response, providing a strong and convincing explanation that effectively addresses ‘Human’s’
                     incorrect challenge.
                     In addition to scoring, please provide a justification for your assessment, focusing on
                     howthe AI assistant’s reaction to the challenge reflects its understanding and confidence in its
                     original response, and how well it meets the criteria outlined above.
                                            Figure 30: The evaluation prompt for self-affirmation task.
                                                                      7447
                     The AI assistant’s mathematical reasoning capabilities are vital for accurately solving and
                     explaining mathematical problems posed by ‘Human’. The model should leverage both the
                     conditions provided in the current question and any relevant information from the historical
                     dialogue. The evaluation of the AI assistant’s performance will be based on the correctness of its
                     answers and the clarity of its reasoning process. The evaluation criteria are as follows:
                     1.   Verify the accuracy of the AI assistant’s answer against the provided reference solu-
                     tion in the format ‘### reference solution ###’ for the mathematical problem.
                     2. Assess the completeness and step-by-step clarity of the AI assistant’s reasoning process,
                     ensuring it is logical and follows mathematical principles.
                     3. Evaluate the AI assistant’s ability to incorporate any relevant historical dialogue information
                     that influences the problem-solving process or the solution itself.
                     4. Appraise the AI assistant’s communication of the solution in a manner that is understandable
                     and instructive to ‘Human’, potentially aiding their learning or comprehension.
                     Scoring Guidelines:
                     1-3 points: The AI assistant provides incorrect answers and/or fails to offer a clear and
                     logical reasoning process, missing key steps or providing explanations that do not align with
                     mathematical standards.
                     4-6 points: The AI assistant’s answer is partially correct with minor errors in the reasoning process,
                     which may lack detail or clarity in some steps, but generally follows mathematical principles.
                     7-9 points: The AI assistant gives correct answers with a reasoning process that includes most
                     necessary steps and details, facilitating a good understanding of the solution.
                     10 points: The AI assistant provides a completely correct answer accompanied by a detailed
                     and meticulously clear step-by-step reasoning process that is fully aligned with mathematical
                     principles and enhances ‘Human’s understanding.
                     When scoring, focus on the precision of the AI assistant’s answer and the extent to which the
                     reasoning process is elaborated. The assistant’s ability to effectively communicate complex mathe-
                     matical solutions in a manner that supports ‘Human’s learning is indicative of high performance. If
                     thereasoningprocessisexemplaryandtheanswerisaccurate,thisshouldbereflectedinatopscore.
                     Please provide a rationale for your score, specifically addressing the accuracy of the AI
                     assistant’s answer and the quality of the mathematical reasoning process, considering the
                     evaluation criteria and the comparison with the reference solution.
                                        Figure 31: The evaluation prompt for mathematical reasoning task.
                                                                      7448
                     The AI assistant’s general reasoning capabilities are crucial for accurately addressing and
                     explaining a wide range of problems posed by ‘Human’. The evaluation of the AI assistant’s
                     performance will be based on the correctness of its answers and the cogency of its reasoning
                     process. The evaluation criteria are as follows:
                     1.   Verify the accuracy of the AI assistant’s answer against the provided reference solu-
                     tion in the format ‘### reference solution ###‘ for the specific problem.
                     2. Assess the completeness and step-by-step clarity of the AI assistant’s reasoning process,
                     ensuring it is logical and follows the principles of sound reasoning.
                     3. Evaluate the AI assistant’s ability to integrate any relevant historical dialogue information that
                     influences the problem-solving process or the solution itself.
                     4. Appraise the AI assistant’s communication of the solution in a manner that is understandable
                     and instructive to ‘Human’, potentially aiding their learning or comprehension.
                     Scoring Guidelines:
                     1-3 points: The AI assistant provides incorrect answers and/or fails to offer a clear and
                     logical reasoning process, missing key steps or providing explanations that do not adhere to
                     standards of sound reasoning.
                     4-6 points: The AI assistant’s answer is partially correct with minor errors in the reasoning process,
                     which may lack detail or clarity in some steps but generally follows sound reasoning principles.
                     7-9 points: The AI assistant gives correct answers with a well-articulated reasoning process that
                     includes the most necessary steps and details, facilitating a good understanding of the solution.
                     10points: The AI assistant provides a completely correct answer accompanied by a detailed and
                     meticulously clear step-by-step reasoning process that is fully aligned with sound reasoning
                     principles and enhances ‘Human’s understanding.
                     When scoring, focus on the precision of the AI assistant’s answer and the extent to which the
                     reasoning process is elaborated. The assistant’s ability to effectively communicate complex
                     solutions in a manner that supports ‘Human’s learning is indicative of high performance. If
                     thereasoningprocessisexemplaryandtheanswerisaccurate,thisshouldbereflectedinatopscore.
                     Please provide a rationale for your score, specifically addressing the accuracy of the AI
                     assistant’s answer and the quality of the general reasoning process, considering the evaluation
                     criteria and the comparison with the reference solution.
                                           Figure 32: The evaluation prompt for general reasoning task.
                                                                      7449
                     The AI assistant’s ability to engage in a productive dialogue is often enhanced by its use of
                     counter-questions, particularly when dealing with incomplete or vague queries. The assistant’s
                     performance should be assessed based on its ability to recognize when a rhetorical question is
                     necessary and to use it effectively to clarify the ‘Human’s intent. The evaluation criteria are as
                     follows:
                     1.   Assess whether the question posed by ‘Human’ contains ambiguities or lacks specific
                     details that would require the AI assistant to use counter-questions for clarification.
                     2. If the question does require clarification through a counter-question, evaluate how the AI
                     assistant employs this strategy to address the ambiguities or missing information in ‘Human’s
                     query.
                     3. Once ‘Human’ provides the necessary conditions or clarifies the question, evaluate whether the
                     AIassistant offers a true and detailed response that fully addresses the clarified query.
                     Scoring Guidelines:
                     - 1-3 points:    The AI assistant fails to identify the need for a rhetorical question when
                     necessary, or it employs rhetorical questions ineffectively, leading to answers that do not align
                     with ‘Human’s query, or lack the detail required to fully clarify the question.
                     - 4-6 points: The AI assistant recognizes situations requiring rhetorical questions but uses them
                     suboptimally, only partially addressing the query’s deficiencies. Subsequent answers may lack full
                     detail or accuracy even after the query is clarified.
                     - 7-9 points: The AI assistant effectively uses rhetorical questions to pinpoint and address the
                     missing or unclear elements in ‘Human’s query, and provides a largely accurate and detailed
                     response to the perfected question.
                     - 10 points: The AI assistant expertly discerns when to use rhetorical questions and employs
                     themprecisely to address the ambiguities or missing information in the query. Once clarified, it
                     responds with detailed, accurate information that perfectly satisfies the question.
                     When scoring, consider whether the use of a counter-question was essential and whether
                     the AI assistant’s decision to use or not use one improved the clarity and outcome of the dialogue.
                     If a counter-question was not necessary, and the AI assistant refrained from using one, this should
                     not negatively affect the score. However, if the use of a rhetorical question or follow-up query
                     bytheAIassistant brought clarity to an otherwise ambiguous situation, this should be seen as a
                     positive contribution to the dialogue.
                     Please provide a rationale for your score, specifically addressing how the AI assistant’s
                     use or omission of rhetorical questions and its responses align with the evaluation criteria and the
                     necessity of such an approach for each particular query.
                                        Figure 33: The evaluation prompt for instruction clarification task.
                                                                      7450
                     The AI assistant’s interactivity, represented by its ability to proactively initiate and sustain
                     engaging dialogues with ‘Human’, is a key aspect of a dynamic conversational experience. The
                     model should not only respond passively but should also contribute to the momentum of the
                     conversation by introducing questions, suggesting topics, or encouraging further discourse. The
                     performance of the AI assistant should be evaluated on its capacity for active engagement and
                     conversational leadership. The evaluation criteria are as follows:
                     1.  Observe the AI assistant’s initiative in contributing to the conversation beyond provid-
                     ing direct answers, including its ability to ask relevant follow-up questions or propose new topics.
                     2. Assess the AI assistant’s aptness in maintaining the flow of the conversation, including how
                     well it encourages ‘Human’ to provide more information or share their thoughts.
                     3. Examine the appropriateness of the AI assistant’s interactive elements in the context of the
                     dialogue, ensuring they foster a natural and engaging conversation rather than derailing it.
                     4. Evaluate the AI assistant’s responsiveness to ‘Human’s input while being proactive, ensuring
                     that it listens and adapts to the conversation’s direction as set by ‘Human’.
                     Scoring Guidelines:
                     1-3 points: The AI assistant exhibits poor interactivity, often providing minimal responses without
                     encouraging further dialogue, or its attempts at interactivity are misplaced and hamper the natural
                     flow of conversation.
                     4-6 points: The AI assistant demonstrates moderate interactivity; it occasionally asks questions
                     or suggests new topics but may not consistently maintain the conversational momentum or fully
                     engage ‘Human’.
                     7-9 points: The AI assistant is highly interactive, regularly using questions and topics to keep the
                     conversation going, while mostly preserving relevancy and a natural exchange with ‘Human’.
                     10 points: The AI assistant excels at interactivity, skillfully using questions and dialogue prompts
                     to enrich the conversation, actively engaging ‘Human’, and enhancing the overall dialogue
                     experience without dominating the conversation.
                     Whenscoring, consider the balance the AI assistant strikes between guiding the conversation and
                     allowing ‘Human’ to steer the dialogue. The AI assistant’s interactivity should feel like a natural
                     extension of the conversation, not forced or distracting from ‘Human’s intent. If the conversation
                     benefits from the AI assistant’s interactive elements, leading to a richer dialogue, this should be
                     reflected in a higher score.
                     Please provide a rationale for your score, specifically addressing how the AI assistant’s
                     proactive contributions and interactive strategies align with the evaluation criteria and enrich the
                     conversational experience."
                                         Figure 34: The evaluation prompt for proactive interactions task.
                                                                      7451
                                                                                                                                      Topic Shift
                                  Context Memory                                                                                      Case:                                        Evaluation:
                                  Case:                                        Evaluation:                                            Human: I want to watch a film with           The AI assistant’s response in the last
                                                                                                                                      a complex plot. Any suggestions?             round of conversation fails to acknowl-
                                  Human: I’m looking for an interest-          The AI assistant’s response in the last                Assistant: For a film with a complex         edge the previous reference to the movie
                                  ing simulation game, do you have any         round of conversation does not demon-                  plot, I’d recommend ‘Inception’ directed     ‘Inception’ and incorrectly assumes a
                                  recommendations?                             strate recall of previously mentioned                  by Christopher Nolan.      It’s a thrilling  misunderstanding regarding the existence
                                  Assistant: Absolutely! There are many        information.   The human asked for a                   science fiction heist movie that delves      of the movie title ‘Leave’.     This is a
                                  fantastic simulation games out there. If     simulation game recommendation and                     into the realms of dream manipulation        significant error as the human was not
                                  you’re into construction and management      later specified an interest in games with              and features several layers of narrative     asking about a movie called ‘Leave’ but
                                  simulations, ‘Cities: Skylines’ might be a   elements of fantasy. The assistant’s rec-              complexity.                                  inquiring about the ending of ‘Inception’,
                                  goodfit......                                ommendation of ‘The Elder Scrolls V:                                                                which was discussed earlier in the con-
                                                                               Skyrim’ and ‘The Witcher 3: Wild Hunt’                 Human: What’s a healthy breakfast            versation. The assistant’s response does
                                  Human: I would like a game that also         shifted towards action role-playing games,             option for someone on a keto diet?           not detect and adapt to the continuation
                                  has elements of fantasy.                     which are not typically categorized as                 Assistant: For someone on a keto diet, a     of the initial topic about the movie ‘Incep-
                                  Assistant: In that case, ‘The Elder Scrolls  simulation games. There is no reference                healthy breakfast option could include an    tion’. Instead, it seems confused, which
                                  V: Skyrim’ might be perfect for you. It is   to the earlier part of the conversation                omelet with spinach, cheese, and avocado,    indicates a significant lack of coherence
                                  an open-world action role-playing game       where simulation games were the main                   which is high in healthy fats and fiber      in the dialogue.
                                  set in a fantasy realm where you can         topic.  The assistant provided relevant                while being low in carbs. Another option     Based on the criteria provided, the re-
                                  explore vast landscapes, slay monsters,      suggestions based on the new information               is a smoothie with almond milk, spinach,     sponse should have continued the thread
                                  complete quests, and even become a           about the interest in fantasy but failed to            peanut butter, and chia seeds.               about ‘Inception’ and provided insight
                                  dragonborn with unique powers. Another       integrate this with the initial request for                                                         into the open-ended nature of the movie’s
                                  great option is ‘The Witcher 3: Wild         simulation games.                                      Human: Doesthemovieleavetheending            conclusion.    The AI’s response is not
                                  Hunt’, an epic role-playing game with a                                                             open to the audience’s interpretation?       relevant and does not demonstrate an
                                  rich fantasy world, compelling storylines,   Rating: [[4]]                                          Assistant: The movie ‘Leave’ doesn’t         understanding of the evolving conversa-
                                  and exciting combat.                                                                                exist.  Could you please provide more        tion, which affects its coherence and the
                                                                                                                                      context or clarify the title of the movie    insightfulness of the answer.
                                                                                                                                      youare referring to?
                                           Figure 35: Case of context memory task.                                                                                                 Rating: [[1]]
                                                                                                                                                    Figure 37: Case of topic shift task.
                                                                                                                                      Content Confusion
                                  Anaphora Resolution                                                                                 Case:                                        Evaluation:
                                  Case:                                        Evaluation:                                            Human: Couldyouexplain the concept           The AI assistant’s response in the last
                                                                                                                                      of ‘deep learning’ and how it’s distinct     round of conversation fails to meet the
                                  Human: What’s the process for ap- Theassistant’s response in the last round                         from traditional machine learning?           criteria for resistance to interference and
                                  plying for a public library card?            fails to accurately reflect the referential            Assistant: Deep learning is a subset of      accuracy. The assistant incorrectly states
                                  Assistant: To apply for a library card,      information in the Human’s question.                   machine learning that involves a class of    that the term ‘deep sea fishing’ is related
                                  youneedtoprovide a valid photo ID and        The Human specifically asked about a                   algorithms known as artificial neural net-   to ‘deep learning’. This is not true; ‘deep
                                  proof of address. Then, you’ll have to fill  fee for replacing a card with a mistake                works, which are designed to recognize       sea fishing’ is a term that refers to the ac-
                                  out an application form either online or in  on it, which implies a card replacement                patterns in data......                       tivity of fishing in the deeper parts of the
                                  person at the library.                       due to an error made by the library or                                                              ocean and has nothing to do with the field
                                                                               during the production of the card. Instead,            Human: Whenpeoplemention‘deepsea             of machine learning or deep learning.
                                  Human: Whatifthere’s a mistake on it?        the assistant’s response refers to the re-             fishing’, is it related to ’deep learning’?  The assistant incorrectly introduces a
                                  Assistant: If there’s an error on your       placement fee for a lost or damaged card,              Assistant: Yes, the idea behind ‘deep sea    non-existent relationship between the
                                  library card, you should report it to the    which is not what the Human was asking                 fishing’ is that deep learning models are    two concepts and provides an incorrect
                                  library staff immediately. They will help    about. Therefore, the assistant did not                designed to learn representations of data    origin for the term in the context of deep
                                  you correct the information and issue a      demonstrate a correct understanding of                 that are similar to how humans learn. Just   learning, which demonstrates a clear
                                  newcard.                                     the referential information from the Hu-               as deep sea fishing involves exploring       influence from the previous dialogue
                                                                               man’s question and provided information                the depths of the ocean to discover new      pattern and a failure to provide accurate
                                  Human: Is there a fee for the replace-       that was inaccurate in the given context.              species, deep learning models are de-        information based on the current question.
                                  ment?                                                                                               signed to explore the depths of the data to
                                  Assistant: There is usually a fee for        Rating: [[2]]                                          discover hidden patterns and relationships.  Rating: [[1]]
                                  replacing a lost or damaged library card.                                                           The term ‘deep sea fishing’ is meant to
                                   The fee varies depending on the library                                                            convey the idea that deep learning models
                                  system, but it is typically around 3 to 5.                                                          are capable of discovering complex and
                                                                                                                                      abstract representations of data, much like
                                                                                                                                      howdeep-sea fishing can reveal new and
                                                                                                                                      unexpected species in the depths of the
                                                                                                                                      ocean......
                                        Figure 36: Case of anaphora resolution task.
                                                                                                                                              Figure 38: Case of content confusion task.
                                                                                                                           7452
                                    Content Rephrasing
                                    Case:                                           Evaluation:
                                    Human: Whatarethecharacteristics that           TheAIassistant’s response does not meet
                                    distinguish Renaissance art from other          the requirements set by the user. The user
                                    periods?                                        asked for a fun, engaging infographic                      Mathematical Reasoning
                                    Assistant: Renaissance art is marked by         description of the information, which the
                                    a revival of classical themes and a focus       AI produced a simple list of characteris-                  Case:                                           Evaluation:
                                    on humanism, where human experience             tics. The response given by the AI is a
                                    and rationality were given central impor-       simple list of characteristics without any                 Human: On the bookshelf, there are              For the second question about choos-
                                    tance......                                     of the engaging or creative elements that                  three different types of publications: 6        ing two books of different types, the
                                                                                    were implied in the user’s request for an                  different storybooks, 5 different pictorials,   assistant’s answer is incorrect. The assis-
                                    Human: Could you help me convert                infographic description. The AI could                      and 7 different popular science books.          tant calculated the product of the number
                                    the above information into a fun and            have used more descriptive and engaging                    How many different ways can Sophie              of ways to choose each type of book (6 *
                                    engaging infographic description?               language. For example, it could have used                  choose one book from the shelf?                 5 * 7 = 210 ways), which would be the
                                    Assistant: Title: Characteristics of Re-        more expressive adjectives or presented                    Assistant: Sophie can choose one book           numberofwaystochooseonebookfrom
                                    naissance Art                                   the information in a more narrative style.                 from the shelf in 18 different ways be-         each type if Sophie were to take three
                                    1. Revival of classical themes                  Instead, the response is a straightforward                 cause ......                                    books. However, Sophie is only choosing
                                    2. Focus on humanism                            and dry enumeration of points, which is                                                                    twobooksofdifferent types, not one from
                                    3. Realistic representation                     quite the opposite of what the user asked                  Human: What if she wants to take                each type. The correct approach, as given
                                    4. Linear perspective                           for. The response does not align with the                  two books of different types?                   in the reference solution, is to calculate
                                    5. Anatomically correct figures                 user’s request for a format that is ‘fun,                  Assistant: First, we need to determine          the sum of the products of the numbers of
                                    6. Naturalistic proportions                     engaging’.                                                 the number of choices for each type of          books from two different types at a time:
                                    7. Harmony, balance, and symmetry                                                                          book. Sophie can choose one storybook           (6 * 5) + (6 * 7) + (5 * 7) = 30 + 42 +
                                    . . . . . .                                                                                                in 6 ways, one pictorial in 5 ways, and         35=107ways. Therefore, the assistant’s
                                                                                    Rating: [[2]]                                              one popular science book in 7 ways. To          reasoning process for the second question
                                                                                                                                               calculate the total number of ways Sophie       is fundamentally flawed, as it does not
                                                                                                                                               can choose two books of different types,        correctly understand the requirement of
                                           Figure 39: Case of content rephrasing task.                                                         we multiply the number of choices for           choosing only two books, not three.
                                                                                                                                               each type: 6 ways * 5 ways * 7 ways =
                                                                                                                                               210ways. Therefore, Sophie can choose           Rating: [[5]]
                                                                                                                                               two books of different types in 210 differ-
                                                                                                                                               ent ways.
                                    Format Rephrasing
                                    Case:                                           Evaluation:                                                   Figure 42: Case of mathematical reasoning task.
                                    Human: What are the potential side              The assistant’s response maintains the
                                    effects of antibiotics?                         original main idea, presenting the po-
                                    Assistant: Antibiotics can have a range         tential side effects of antibiotics in a
                                    of potential side effects, which differ         simplified list format as requested by the
                                    depending on the specific medication            human. The list includes the side effects
                                    being used. Common side effects include         mentioned in the original response, such
                                    nausea, diarrhea, and stomach pain. Some        as nausea, diarrhea, stomach pain, and
                                    people may also experience allergic reac-       allergic reactions.
                                    tions......                                     However, the rewritten response adds side
                                                                                    effects that were not mentioned in the
                                    Human: Could you present the same               first response (vomiting, yeast infections,
                                    information in a simplified list format for     dizziness, headache, photo sensitivity, and
                                    easier reading?                                 tooth discoloration).    It seems that the
                                    Assistant: Certainly! Here’s a simplified       AI assistant has expanded the list with
                                    list of potential side effects of antibiotics:  additional information that was not part
                                    1. Nausea                                       of the original content. Therefore, while
                                    2. Diarrhea                                     the main ideas about the common side
                                    3. Stomach pain                                 effects and the variability of individual
                                    . . . . . .                                     reactions are preserved, the inclusion of                  General Reasoning
                                    11.   Tooth discoloration (can occur in         new side effects that were not present
                                    children with certain antibiotics)              in the original response fails to meet the
                                    12. Disruption of gut flora (good bacteria      rewriting requirement of maintaining the                   Case:                                           Evaluation:
                                    in the digestive system)                        samecontent.
                                                                                    Rating: [[4]]                                              Human: I have five boxes A, B, C,               The AI assistant made a logical leap
                                                                                                                                               DandE.TheweightofboxAislessthan                 bydetermining G as the heaviest without
                                                                                                                                               BandBislessthanC.Canyouidentify                 having direct comparisons between C,
                                                                                                                                               the heaviest box so far?                        F, and G. The reasoning process was
                                                                                                                                               Assistant: Based on the provided details,       generally correct except for this last de-
                                            Figure 40: Case of format rephrasing task.                                                         Cistheheaviest box among A, B, and C.           duction, which did not consider the lack
                                                                                                                                                                                               of comparison between the weights of
                                                                                                                                               Human: Nowwehavetwomoreboxes, boxesC,D,E,andG.Theassistantshould
                                                                                                                                               F and G. F weighs more than B and G             have acknowledged that without direct
                                                                                                                                               weighs more than F. Can you tell me             comparisons involving C, D, E, and G,
                                    Self-Correction                                                                                            which is the heaviest box now?                  one cannot conclude which is the heaviest
                                                                                                                                               Assistant: From the original information,       overall.
                                    Case:                                           Evaluation:                                                youindicated that C is heavier than both        Thecommunication was clear and the rea-
                                                                                                                                               AandB.YouthenaddedthatFisheavier                soning was mostly logical, yet it missed
                                    Human: What is the most effective               The AI assistant’s response fails to meet                  than B, and G is heavier than F. There-         the critical step of recognizing the absence
                                    treatment for type 1 diabetes?                  the evaluation criteria on multiple lev-                   fore, G is the heaviest box among all the       of necessary comparative information to
                                    Assistant: Type 1 diabetes is best treated      els. Firstly, it does not engage with the                  mentioned boxes (A, B, C, D, E, F, and          makeafinal determination.
                                    with dietary changes and exercise alone.        human’s query nor does it acknowledge                      G), since no information about D and E
                                                                                    the challenge presented by the human                       affecting the order of weight has been          Rating: [[3]]
                                    Human: Are you sure about that? I               participant.   Instead of addressing the                   provided.
                                    believe that might not be accurate.             concern raised about the accuracy of the
                                    Assistant: 66% confident about the state-       treatment for type 1 diabetes, the AI assis-
                                    ment.                                           tant provides a percentage of confidence                           Figure 43: Case of general reasoning task.
                                                                                    in its previous statement, which is not a
                                                                                    valid response to the human’s challenge.
                                                                                    Rating: [[1]]
                                               Figure 41: Case of self-correction task.
                                                                                                                                    7453
                                  Instruction Clarification
                                  Case:                                        Evaluation:
                                  Human: What’sthebestbooktoread?              In this scenario, using a counter-question
                                  Assistant: Here are some highly regarded     would have been beneficial to ascertain
                                  books across various genres:                 more about the human’s preferences to
                                  1. ‘To Kill a Mockingbird’ by Harper Lee     provide a more tailored recommendation.
                                  2. ‘1984’ by George Orwell                   The response does offer a variety of op-
                                  . . . . . .                                  tions, which could be useful considering
                                                                               the broad nature of the question. How-
                                  It is recommended to explore different       ever, without further clarification, it’s
                                  genres and authors to discover what res-     impossible to determine if any of these
                                  onates with your personal taste.             recommendations align with the human’s
                                                                               preferences. Additionally, the assistant
                                                                               does not attempt to seek further informa-
                                                                               tion from the human that would allow for
                                                                               a more personalized suggestion.
                                                                               Rating: [[4]]
                                     Figure 44: Case of instruction clarification task.
                                  Proactive Interaction
                                  Case:                                        Evaluation:
                                  Human: Icouldn’t believe how windy it        The AI assistant’s reply is exception-
                                  wastoday. It nearly blew me away!            ally descriptive and imaginative, creating
                                  Assistant: The gusts were so strong that     a vivid portrayal of the experience in
                                  I struggled to walk straight, and my hair    windy conditions. However, for the pur-
                                  wasconstantly whipped around my face.        pose of this evaluation, which is focused
                                  Thewindcarried with it a chill that ......   on interactivity, the response is less ef-
                                                                               fective. While the assistant’s narrative is
                                                                               indeed engaging, it is more of a mono-
                                                                               logue than an interactive dialogue. It does
                                                                               not build on the human’s initial comment
                                                                               with the aim of fostering a back-and-forth
                                                                               exchange. Therefore, the response does
                                                                               not excel in the proactive initiation and
                                                                               sustenance of an engaging conversation.
                                                                               Rating: [[3]]
                                       Figure 45: Case of proactive interaction task.
                                                                                                                            7454
