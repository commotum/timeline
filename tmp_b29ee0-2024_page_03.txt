                                                                                              SegPoint       3
                               Module that extracts local semantics from point clouds, seamlessly incorporat-
                               ing this geometric insight into the feature extraction process. Furthermore, a
                               Geometric-guided Feature Propagation is designed to utilize semantic flows de-
                               rived from geometric priors and the LLM’s hidden embeddings, facilitating the
                               generation of fine-grained, high-quality features for accurate dense prediction
                               tasks. Unlike previous attempts at 2D field [8,28,50], we do not depend on
                               additional costly pre-trained segmentation models like SAM [26].
                                   Moreover, we introduce a benchmark named Instruct3D, designed to advance
                               research in the field of segmentation driven by implicit and complex instruc-
                               tions. Understanding these nuanced instructions necessitates reasoning abilities
                               and extensive knowledge of the world. It includes a total of 2,565 diverse pairs
                               of instructions and point clouds for tuning and evaluation. Our comprehensive
                               experiments demonstrate the benchmark’s utility in evaluating the model’s ca-
                               pability of segmentation based on human-like instructions.
                                   Taking advantage of a multi-modal LLM and task-specific prompts, SegPoint
                               is capable of generating segmentation masks for a wide range of tasks in a uni-
                               fied model: 1) 3D instruction segmentation, 2) 3D referring segmentation, 3) 3D
                               semantic segmentation, and 4) 3D open-vocabulary semantic segmentation, as
                               depicted in Fig. 1. SegPoint achieves competitive results on established bench-
                               marks like ScanRefer [4] for referring segmentation and ScanNet [7] for semantic
                               segmentation while showing remarkable performance on the Instruct3D dataset.
                                   In summary, our main contributions are as follows:
                                 – We propose SegPoint, the first 3D segmentation model that can compre-
                                   hend human intentions and address multiple segmentation tasks within one
                                   framework by harnessing the Large Language Model’s reasoning capabilities.
                                 – We present a Geometric Enhancer Module that integrates comprehensive
                                   scene information into the process of 3D scene understanding. Besides, A
                                   Geometric-guided Feature Propagation is designed to achieve accurate and
                                   fine-grained segmentation. These two modules supplement the missing local
                                   information and grasp fine-grained features for dense prediction tasks.
                                 – We introduce a new task called 3D instruction segmentation and construct
                                   a new dataset Instruct3D, which necessitates a model’s self-reasoning to
                                   interpret implicit instructions for segmenting the target object.
                                 – Our experimental findings reveal that SegPoint not only competes strongly
                                   in 3D semantic, referring, and open-vocabulary semantic segmentation but
                                   also excels in 3D instruction segmentation, showcasing its versatility and
                                   effectiveness across a spectrum of segmentation challenges.
                               2    Related Work
                               2.1   Multi-modal Large Language Model
                               Inspired by the exceptional reasoning abilities of Large Language Models, re-
                               searchers are delving into transferring these capabilities into the vision realm [9,
