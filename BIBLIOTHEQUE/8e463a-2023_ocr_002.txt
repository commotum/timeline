(long-lasting).

There are several possible solutions to the above
challenges. One option is to always use the most
updated data such as the news of the day (temporal
knowledge). However, this is both labor-intensive
to race against the LLM training and unclear about
the lifetime of the proposed data. Another option is
to keep the benchmark closed-source, with an au-
thoritative committee managing the data and users
calling API when evaluating, thus preventing using
them for training LLMs . To reach this point further
requires community coordination.

To better address these challenges, we propose
an approach to GENerate new KNOWledge conve-
niently (KnowGen) based on the structured repre-
sentation of existing entity knowledge by making
reasonable changes to entity attributes and rela-
tionships. There are differences and associations
between artificial entities and existing entities. Par-
ticularly, we apply KnowGen with structured bi-
ological taxonomic information data to rationally
create a group of organisms that do not exist in
the world. To test the model’s ability in face of
new knowledge, we construct a variety of ques-
tions about these artificial entities that can examine
the model’s ability to understand new knowledge
(Knowledge Understanding), distinguish between
model’s internal knowledge and new knowledge
(Knowledge Differentiation) and make multi-hop
reasoning by linking model’s internal and new
knowledge (Knowledge Association). We use
the ArtificialLy ConstrUcted kNowledge to Assess
LLMs as a benchmark (ALCUNA).

We evaluate and analyze several popular large
models based on ALCUNA, including ChatGPT!,
Alpaca, Vicuna, and ChatGLM with vanilla, CoT
(Chain-of-Thought), Zero-Shot and Few-Shot set-
tings (Brown et al., 2020; Kojima et al., 2023; Wei
et al., 2023). We find that neither ChatGPT nor
other models perform very well in face of new
knowledge. ChatGPT does a good job of under-
standing and differentiating new knowledge, but
almost all models fail to reason between the new
knowledge and the internal knowledge. This re-
minds us to remain cautious when large models
encounter new scenarios and knowledge. In addi-
tion, we explore the impact of entity similarity on
the model’s understanding of entity knowledge, the
impact of contextual entities, etc.

The contributions of our work are listed below:

'https://chat.openai.com/chat

1) we propose a new method KnowGen to generate
new knowledge for simulating real scenarios. 2)
we apply our method to produce an artificial bio-
logical entity knowledge dataset, ALCUNA, as a
benchmark for evaluating the performance of mod-
els in face of new knowledge. 3) we evaluate and
analyze several popular large models and obtain
insightful observations and conclusions.

Our benchmark has been released to the commu-
nity to facilitate future research *.

Algorithm 1: Knowledge Generation
input :One Class C
output : Property Set T(é) of é
e? < RandomSelect(C) ;
EP*> — sib(e?)
// Get the triplet set for heredity, variation, dropout
and extension
Th, 78,74 < RandomSplit(Tr(e”))
Th TR, TH + RandomSplit(T7a(e?))
T° < RandomSample (7 (E?*"))

// Heredity and Dropout
Tr(@) — Tr(C) UTE
Ta(é) + Ta(C) UTA
// Variation: replacing the object with an entity from
the same class

for (e?,r, e’) in Tg do

E’®> & sib(e’)

e's» — RandomSelect (E’*”)

Ta(@) + Tal@) U{E,r,€)}
// Variation: add gaussian noise to the value or copy

from EPs”

for (e?,a,v) in TX do

if isnum(v) then

| ®ev+N(0,v/10)
else
| e?*> < RandomSelect (E”*”)
0 < GetValue (e?®’, a)

Ta(é) + Ta(é) U {(E, a, 6) }
// Extension and get final property
T(é) + Ta(é) U Tr(é) UT®

2 KnowGen: Knowledge Generation

In this section, we begin by presenting our inspira-
tion, then formally introduce our knowledge gener-
ation method KnowGen.

2.1 Inspiration

According to the ontological form (Sowa, 1995;
Noy et al., 2001), we can represent most knowledge

*https: //gi thub.com/Arvid-pku/ALCUNA
