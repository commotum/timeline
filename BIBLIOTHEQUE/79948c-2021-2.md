# CoAtNet: Marrying Convolution and Attention for All Data Sizes (2021)
Source: 79948c-2021.pdf

## Core reasons
- The paper targets computer vision and discusses Transformers in the context of image recognition compared to ConvNets.
- It introduces CoAtNet, a hybrid ConvNet-Transformer architecture that combines convolution and self-attention blocks.

## Evidence extracts
- "Transformers have attracted increasing interests in computer vision, but they still fall behind state-of-the-art convolutional networks." (p. 1)
- "Based on these insights, we propose a simple yet effective network architecture named CoAtNet, which enjoys the strengths from both ConvNets and Transformers." (p. 2)

## Classification
Class name: Increasing Transformer's Dimensions
Class code: 2

$$
\boxed{2}
$$
