              1538                                G.Hinton,S.Osindero,andY.-W.Teh
              is possible for log p(v0) to fall even though the lower bound on it increases,
              butlog p(v0)canneverfallbelowitsvalueatstep2ofthegreedyalgorithm
              because the bound is tight at this point and the bound always increases.
                 Thegreedyalgorithmcanclearlybeappliedrecursively,soifweusethe
              full maximum likelihood Boltzmann machine learning algorithm to learn
              each set of tied weights and then we untie the bottom layer of the set from
              the weights above, we can learn the weights one layer at a time with a
              guarantee that we will never decrease the bound on the log probability of
              thedataunderthemodel.4 Inpractice,wereplacethemaximumlikelihood
              Boltzmannmachinelearningalgorithmbycontrastivedivergencelearning
              becauseitworkswellandismuchfaster.Theuseofcontrastivedivergence
              voids the guarantee, but it is still reassuring to know that extra layers
              are guaranteed to improve imperfect models if we learn each layer with
              sufﬁcient patience.
                 Toguaranteethatthegenerativemodelisimprovedbygreedilylearning
              morelayers, it is convenient to consider models in which all layers are the
              same size so that the higher-level weights can be initialized to the values
              learned before they are untied from the weights in the layer below. The
              samegreedyalgorithm, however, can be applied even when the layers are
              different sizes.
              5 Back-Fitting with the Up-Down Algorithm
              Learningtheweightmatricesonelayeratatimeisefﬁcientbutnotoptimal.
              Once the weights in higher layers have been learned, neither the weights
              nor the simple inference procedure are optimal for the lower layers. The
              suboptimality produced by greedy learning is relatively innocuous for su-
              pervisedmethodslikeboosting.Labelsareoftenscarce,andeachlabelmay
              provide only a few bits of constraint on the parameters, so overﬁtting is
              typically more of a problem than underﬁtting. Going back and reﬁtting the
              earlier models may therefore cause more harm than good. Unsupervised
              methods, however, can use very large unlabeled data sets, and each case
              maybeveryhigh-dimensional, thus providing many bits of constraint on
              a generative model. Underﬁtting is then a serious problem, which can be
              alleviated by a subsequent stage of back-ﬁtting in which the weights that
              were learned ﬁrst are revised to ﬁt in better with the weights that were
              learned later.
                 Aftergreedilylearninggoodinitialvaluesfortheweightsineverylayer,
              we untie the “recognition” weights that are used for inference from the
              “generative” weights that deﬁne the model, but retain the restriction that
              theposteriorineachlayermustbeapproximatedbyafactorialdistribution
              in which the variables within a layer are conditionally independent given
                 4 The guarantee is on the expected change in the bound.
