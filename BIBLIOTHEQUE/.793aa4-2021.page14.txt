                Shifting Pattern Learned from Absolute Positional Attention  Usingrelative position encoding gives
                generally better results despite smaller improvement scale compared to moving feature encoding per-head.
               Tounderstand this, we visualize the attention pattern of the absolute positional attention and found two
                representative patterns in DIET-ABS in Figure 7. We observe that even given absolute position features,
                the model learns a “shifting pattern” for the most part. Different from Wang and Chen (2020) which
                claimed absolute position only learns local patterns, we show the position attention can actually attend
                to longer context. However, the shifting pattern can be modeled directly by relative position. Thus,
                DIET-REL can be a better model choice with fewer parameters and more accurate inductive bias in some
                applications.
                           (a) Attend to Forward Neighbors                  (b) Attend to Previous Tokens
                Figure 7: Sampled position attention score patterns for the DIET-ABS model. We can see a clear shifting patterns
                generated by the model. Such patterns can be modeled better by relative positional scalar encodigs.
                Rank of Positional Attention Matrices   In Figure 8, we present a comparison of rank of position
                attention matrices for a BERTBASE model with absolute position embeddings at input (P W W>P>)
                                                                                                 Q   Q    K K
               v.s. absolute position embeddings per-head (DIET-ABS (1), (P P>), where P ,P     ∈Rn×dp). With
                                                                           Q K            Q   K
                additive positional embedding at input, position attention matrices have much lower rank, limiting the
                representative power. This is alleviated by DIET-ABS.
                                            Figure 8: Rank of positional attention matrices
                                                             2987
