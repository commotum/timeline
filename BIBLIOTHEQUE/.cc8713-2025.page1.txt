                     Self-Improving Language Models for Evolutionary Program Synthesis:
                                                      ACaseStudyonARC-AGI
                                            Julien Pourcel1 Cédric Colas*12 Pierre-Yves Oudeyer*1
                                      Abstract                                search through the space of possible programs, using meth-
                   Manyprogramsynthesistasksprovetoochalleng-                 ods like genetic programming or sequential Bayesian infer-
                   ing for even state-of-the-art language models to           ence (Koza, 1994; Liang et al., 2010). These approaches
                   solve in single attempts. Search-based evolution-          generate initial candidates based on task constraints, then
                   ary methods offer a promising alternative by ex-           iteratively refine them through mutation and crossover op-
                   ploring solution spaces iteratively, but their effec-      erations. However, their effectiveness depends heavily on
                   tiveness remain limited by the fixed capabilities          having intelligent program generators and mutation opera-
                   of the underlying generative model. We propose             tors—without these, algorithms must expend massive com-
                   SOAR,amethodthatlearnsprogramsynthesisby                   putation, blindly exploring the space of possible solutions.
                   integrating language models into a self-improving          Large language models (LLMs) have marked a new turn in
                   evolutionary loop. SOAR alternates between (1)             program synthesis by acting as powerful program genera-
                   an evolutionary search that uses an LLM to sam-            tors (Roziere et al., 2023; Guo et al., 2024), solving many
                   ple and refine candidate solutions, and (2) a hind-        tasks in a single attempt (Li & Ellis, 2024). For harder
                   sight learning phase that converts search attempts         problems, they can serve as intelligent operators for evolu-
                   into valid problem-solution pairs used to fine-tune        tionary search, proposing targeted modifications to existing
                   theLLM’ssamplingandrefinementcapabilities—                 solutions (Lehman et al., 2023; Olausson et al., 2023; Mey-
                   enabling increasingly effective search in subse-           erson et al., 2024). But these approaches face a fundamental
                   quent iterations. On the challenging ARC-AGI               limitation: the capabilities of the model used for sampling
                   benchmark, SOAR achieves significant perfor-               and refinement remain fixed, and simply sampling more
                   mance gains across model scales and iterations,            candidates or trying more refinements yields diminishing
                   leveraging positive transfer between the sampling          returns. This paper introduces a system that learns to sample
                   and refinement finetuning tasks. These improve-            and refine programs from past synthesis attempts, enabling
                   ments carry over to test-time adaptation, enabling         sustained performance improvements beyond the limits of
                                                             1
                   SOARtosolve52%ofthepublictestset.                          search-based methods.
                                                                              WeproposeSelf-improving Operators for Automated pro-
              1. Introduction                                                 gram Refinements (SOAR), a framework that integrates
              Program synthesis promises to transform how humans inter-       language models into a self-improving evolutionary loop.
              act with computers by automatically discovering programs        SOARalternates between two phases: first, using an LLM
              that satisfy their intent. Instead of writing precise instruc-  to sample and refine candidate programs through evolution-
              tions, users can express their goals through constraints, ex-   ary search (Sample&Refine phase), then using these search
              amples, or natural language, letting synthesis algorithms       traces to fine-tune the model’s sampling and refinement ca-
              figure out the implementation details. However, finding a       pabilities. This creates a virtuous cycle—better models
              programthatsatisfies all constraints may be challenging due     enable more effective search, which in turn provides bet-
              to the vast space of possible implementations.                  ter training data for further model improvements. Unlike
                                                                              previous approaches that rely on human-engineered domain-
              Traditional program synthesis approaches rely on iterated       specific languages to scaffold search, or human-generated
                 *                 1      2                                   solutions to finetune program generators, SOAR learns to
                  Equal supervision Inria MIT. Correspondence to: Julien      synthesize programs in Python, learning solely from its own
              Pourcel <julien.pourcel@inria.fr>.                              synthesis attempts, including both successes and failures.
              Proceedings of the 42nd International Conference on Machine     Wedemonstrate SOAR’s effectiveness on the Abstraction
              Learning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025     and Reasoning Corpus (ARC), a program synthesis bench-
              bythe author(s).                                                markspecifically designed to challenge AI models’ core rea-
                  1Our code is open-sourced at: github.com/flowersteam/SOAR
                                                                           1
