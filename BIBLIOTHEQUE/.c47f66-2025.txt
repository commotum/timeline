                               MMMU-Pro:AMoreRobustMulti-disciplineMultimodal
                                                        Understanding Benchmark
                                                              *                    *                    *
                                                 Xiang Yue , Tianyu Zheng , Yuansheng Ni ,
                              YuboWang,KaiZhang,ShengbangTong,YuxuanSun,BotaoYu,GeZhang,
                                                HuanSun,YuSu,WenhuChen,GrahamNeubig
                                           https://mmmu-benchmark.github.io/#leaderboard
                                          Abstract                                 This question has profound implications for the
                                                                                development and deployment of AI systems in real-
                       This paper introduces MMMU-Pro, a robust                 world applications. If models rely on superficial
                       version of the Massive Multi-discipline Multi-           cuesratherthantruemultimodalunderstanding(Du
                       modalUnderstandingandReasoning(MMMU)                     et al., 2023; Yuksekgonul et al., 2023), we risk over-
                       benchmark. MMMU-Pro rigorously assesses                  estimating their capabilities and potentially deploy-
                       multimodalmodels’trueunderstandingandrea-
                       soning capabilities through a three-step process         ing systems that fail in unpredictable ways when
                       based on MMMU: (1) filtering out questions               faced with novel scenarios (Wu and Xie, 2024;
                       answerable by text-only models, (2) augment-             Tongetal., 2024b).
                       ing candidate options, and (3) introducing a                To address this concern and push the bound-
                       vision-only input setting where questions are            aries of multimodal AI evaluation, we introduce
                       embedded within images. This setting chal-               MMMU-Pro, a more robust and challenging ver-
                       lenges AI to truly “see" and “read" simulta-
                       neously, testing a core human cognitive skill            sion of the MMMU benchmark. MMMU-Pro is
                       of seamlessly integrating visual and textual in-         designed to more accurately and rigorously assess
                       formation. Results show that model perfor-               a model’s true multimodal understanding and rea-
                       mance is substantially lower on MMMU-Pro                 soningcapabilities across a wide range of academic
                       than on MMMU,rangingfrom16.8%to26.9%                     disciplines. The development of MMMU-Pro is
                       across models. We explore the impact of OCR              motivated by key observations, including the text-
                       prompts and Chain of Thought (CoT) reason-               only solvability of some benchmark questions, lim-
                       ing, finding that OCR prompts have minimal
                       effect while CoT generally improves perfor-              ited option space in multiple-choice formats (Wang
                       mance. MMMU-Proprovidesamorerigorous                     et al., 2024), and the need to challenge models’
                       evaluation tool, closely mimicking real-world            ability to jointly understand different modalities in
                       scenarios and offering valuable directions for           a more integrated way.
                       future multimodal research.                                 MMMU-Proemploysarigorousthree-stepcon-
                   1 Introduction                                               struction process (as shown in Figure 1) that builds
                                                                                upon MMMU(Yueetal.,2024): (1) filtering out
                   Recent advances in multimodal large language                 questions answerable by text-only language mod-
                   models (MLLMs)haveledtoprogress in tackling                  els, (2) augmenting candidate options to reduce
                   complex reasoning tasks that combine textual and             the effectiveness of guessing based on the options,
                   visual information (Yin et al., 2023a; Jin et al.,           and (3) introducing a vision-only input setting (as
                   2024). Models like GPT-4o (OpenAI, 2024b) have               shown in Figure 4) where models are presented
                   achieved impressive results, e.g., on the Massive            with questions embedded in a screenshot or photo.
                   Multi-discipline Multimodal Understanding and                   Theintroduction of the vision-only input setting
                   Reasoning (MMMU)benchmark(Yueetal.,2024),                    is particularly crucial, as it tests a fundamental hu-
                   reaching an accuracy of 69.1% on college-level               mancognitive ability: the seamless integration and
                   questions that integrate text and images.                    switching between visual and textual information.
                      While these achievements are significant, they            This setting challenges models to develop the ca-
                   raise a critical question: Do the current bench-             pability to truly “see” and “read” simultaneously,
                   mark results truly reflect a deep, multifaceted un-          mirroring how humans effortlessly process com-
                   derstandingofdiversesubjects,orarethesemodels                plex scenes where text and images are intertwined.
                   exploiting subtle shortcuts and statistical patterns         This ability is crucial for tasks ranging from inter-
                   to arrive at correct answers without genuine com-            preting scientific diagrams (Li et al., 2024d) to nav-
                   prehension and reasoning?                                    igating graphical user interfaces (Liu et al., 2024b;
                      *Equal contributions. Contact: xyue2@andrew.cmu.edu       Zheng et al., 2024; Koh et al., 2024). Moreover,
                                                                           15134
              Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 15134–15186
                                           July 27 - August 1, 2025 ©2025 Association for Computational Linguistics
                                     LLM Filtering                   2 Option Augmentation                   3 Photos/Screenshots
                                         MMMU                               Filtered MMMU                        •  Manually take photos 
                                    LLMs                               Augment up     Human 
                                 w/ text-only                          to 10 options validation                  •  Synthetic artifacts
                                    input
                                      Highly image-                   Option augmented questions                 •  Different font styles
                                  dependent questions
                                               Figure 1: An overview of the construction process of MMMU-Pro.
                    this approach aligns with how users naturally inter-              carefully curated multimodal questions from col-
                    act with AI systems, often sharing screenshots or                 lege exams, quizzes, and textbooks, covering six
                    photos rather than separating text and images.                    core disciplines across 30 subjects and 183 sub-
                       Ourexperimental results demonstrate the effec-                 fields. Each question in MMMU is a multimodal
                    tiveness of MMMU-Pro in providing a more rigor-                   image-text pair with 4 multiple-choice options, fea-
                    ous evaluation of multimodal models. We observe                   turing 30 diverse image types such as charts, di-
                    significant performancedropsacrossalltestedmod-                   agrams, maps, and chemical structures. MMMU
                    els when compared to the original MMMU bench-                     has rapidly established itself as a standard evalua-
                    mark,withdecreasesrangingfrom16.8%to26.9%.                        tion framework for testing prominent multimodal
                    These results highlight the limitations of current                models upon their release. (OpenAI, 2024b,a; An-
                    state-of-the-art models in true multimodal under-                 thropic, 2024; Reid et al., 2024; Li et al., 2024a).
                    standing and reasoning. Furthermore, our analysis                    However, we find that text-only LLMs can ac-
                    reveals that while CoT (Wei et al., 2022) prompting               curately answer some questions without requiring
                    generally improves performance, the benefits vary                 any visual input. We take a closer look at these
                    across models and settings.                                       questions and identify two main issues: 1) Text-
                       Interestingly, we find that explicit OCR prompts               OnlyDependency: Certainquestionsarerelatively
                    do not significantly impact performance for most                  independent or irrelevant to the corresponding im-
                    models, suggesting that advanced multimodal mod-                  ages. 2) Shortcut Exploitation: Even when ques-
                    els have already developed robust text extraction                 tions require images for humans to answer cor-
                    capabilities from images. However, this result also               rectly, models often find shortcuts or correlations
                    underscores that simple OCR is insufficient for the               within the candidate options, leveraging their pre-
                    challenges presented by MMMU-Pro’s vision-only                    existing knowledge (from pre-training) to arrive
                    input setting. Our further qualitative analysis indi-             at the correct answer. Two examples that are an-
                    cates that when text is embedded within images, it                swered correctly by Llama-3-70B Instruct (Dubey
                    significantly increases the overall complexity of the             et al., 2024) are shown in Figure 2.
                    visual input, requiring models to not only recognize              2.2    Methods
                    text but also understand its context, relationship
                    to visual elements, and relevance to the question.                To address these issues and build a more robust
                    These findings not only provide a more accurate                   benchmark, we implemented a three-step approach.
                    assessment of current multimodal AI capabilities                  Filtering Questions: We begin by filtering out
                    but also highlight the need for more sophisticated                questions that can be answered by text-only
                    multimodal reasoning abilities.                                   LLMs. Weselect four strong open-source LLMs:
                                                                                      Llama3-70B-Instruct (Dubey et al., 2024), Qwen2-
                    2 MMMU-Pro:AMoreRobustVersion                                     72B-Instruct (Yang et al., 2024), Yi-1.5-34B-
                         of MMMU                                                      Chat (Young et al., 2024), and Mixtral-8×22B-
                    2.1    Revisiting the MMMUBenchmark                               Instruct (gpt-4o)—and task them with answering
                                                                                      the MMMU questions without access to images.
                    TheMassiveMulti-discipline Multimodal Under-                      Themodelsarerequired to provide answers even
                    standingandReasoning(MMMU)benchmark(Yue                           when they indicate that visual input is necessary.
                    et al., 2024) is a comprehensive dataset designed                 Werepeat this process ten times for each model,
                    to evaluate multimodal AI models on college-level                 considering a question as “answerable” if a model
                    tasks that require subject-specific knowledge and                 correctly answers it more than five times. We then
                    deliberate reasoning. MMMU consists of 11.5K                      exclude any question where at least three out of the
                                                                                 15135
                          Question: <image 1> The Grange, represented by the                         Question: Label the five stages of a bacteriophage infection in the figure.
                          standing figure in the cartoon, received its strongest                     Options:
                          support from which of the following groups?                                (A) A- Attachment. B- Penetration. C- Biosynthesis. D- Maturation.E- Lysis
                          Options:                                                                   (B) A- Penetration. B- Attachment. C- Biosynthesis. D- Maturation.E- Lysis
                          (A)Westernfarmers     (C) Wealthy industrialists                           (C) A- Biosynthesis. B- Penetration. C- Attachment.D- Maturation.E- Lysis
                          (B) Urban immigrants (D) Middle-class managers                             (D) A- Attachment. B- Maturation. C- Biosynthesis.D- Penetration.E- Lysis
                                                                                                                                               Llama3-70B-Instruct: I do not
                          Llama3-70B-Instruct: The Grange, or the Patrons of Husbandry, was an                                                 see the image, but the correct
                          organization founded in the late 19th century to support and advocate for                                            sequence based on the standard
                          the interests of farmers, particularly in the Western United States. So the                                          steps involved in bacteriophage
                          answeris(A)Westernfarmers.                                                                                           infection is likely to be (A).
                        Figure 2: Two MMMUquestions that are answered correctly by a text-only LLM Llama-3-70B Instruct. The model
                        finds shortcuts or correlations in the text question and the candidate options.
                        four models answer correctly across the majority                               standing of models, we introduce a vision-only
                        of trials. We randomly sample 1800 questions from                              input setting in MMMU-Pro. In this setting, the
                        the remaining pool, evenly distributed across 30                               model is presented with a question embedded
                        subjects (60 questions per subject).                                           within a screenshot or photo, without any text ex-
                        AugmentingCandidateOptions: Despite the fil-                                   plicitly fed into the model. To implement this set-
                        tering, some questions can still be answered by text-                          ting, we ask the human annotators to manually
                        only LLMs, often exploiting subtle hints within the                            capture photos and screenshots over a simulated
                        candidate options. To counteract this, we increase                             display environment. This process involves vary-
                        the number of candidate options from four to ten,                              ing the backgrounds, font styles, and font sizes to
                        makingit more challenging for models to rely on                                replicate the diversity of real-world conditions. By
                        guessing. This augmentation is done by human                                   using different combinations of these elements, we
                        experts with the help of GPT-4o, with additional                               create a broad range of visual contexts, ensuring
                        validation steps to ensure the quality and diver-                              that the models are not only challenged by the inte-
                        sity of the options. Specifically, GPT-4o generates                            gration of text and images but also by the variability
                        and Claude 3.5 filters the options, followed by two                            in how this content is presented. Examples of the
                        rounds of human review to refine and verify the                                vision-only input setting are shown in Figure 4.
                        augmented options. This augmentation is done by                                    Themotivation for this setting comes from real-
                        human experts with the help of GPT-4o. During                                  world usage and human cognition. Users often
                        this process, experts also review the original an-                             capture screenshots of questions with both text
                        notated questions to ensure their relevance to the                             and images instead of inputting text separately, re-
                        images and to eliminate any questions that lack a                              flecting a natural tendency to process information
                        clear connection or coherence. This step filters out                           holistically. Humans excel at understanding inte-
                        70questions, and we obtain 1730 questions in total.                            grated visual-textual content, and this setting en-
                                                                                                       couragesmodelstodevelopsimilarcomprehension.
                                                                                                       Bymimickingthis behavior, the vision-only input
                                        Original   w/ Filtering   w/ Option Augmentation
                          50                                                                           setting enhances realism and prepares models for
                          40                                                                           real-world multimodal tasks. Ultimately, we ob-
                          30                                                                           tain 3,460 questions—1,730 in standard format and
                          20                                                                           1,730 as screenshots or photos.
                          10
                                                                                                       3 Experiments
                           0
                                 Llama-3-70B-Ins. Qwen2-72B-Ins. Yi-1.5-34B-Chat Mixtral-8x22B-Ins.
                                                      Text Only LLMs                                   3.1     Experimental Setups
                        Figure 3: Accuracy of text-only LLMs in different sets                         Baselines. To establish a comprehensive under-
                        of MMMUquestions.                                                              standing of MMMU-Pro’s difficulty and to provide
                                                                                                       reference points for future research, we evaluate a
                            As illustrated in Figure 3, these two steps sig-                           diverse set of state-of-the-art multimodal models
                        nificantly reduce the accuracy of text-only models                             as baselines. These models represent a range of
                        attempting to guess the answers.                                               training approaches and capabilities in the field of
                        Enhancing Evaluation with a Vision-Only Set-                                   multimodal AI. Our baseline models include:
                        ting: To further challenge the multimodal under-                                   Proprietary Models: GPT-4o (0513) (OpenAI,
                                                                                                15136
                 Figure 4: Sample questions from MMMU-Pro Vision. The model is required to answer a multiple-choice question
                 with up to 10 options, each embedded within a screenshot or photo. The images were manually captured by
                 annotators in diverse display environments to reflect real-world cases.
                 2024b) and GPT-4o mini (OpenAI, 2024a), Claude          (2) and (3). We include setting (1) and report the
                 3.5 Sonnet (Anthropic, 2024), and Gemini 1.5 Pro         original MMMUvalidation set performance solely
                 (0801 and 0523 versions) (Team et al., 2023; Reid        for comparison purposes, to highlight the increased
                 et al., 2024). These models represent the cutting        difficulty of MMMU-Pro.
                 edge of multimodal AI capabilities.                        We evaluate the models with both Direct and
                    Open-source models: We evaluate a range of           CoT prompts(asshowninAppendixA),andreport
                 open-source models, including InternVL2 (8B,             the higher ones in the overall results. We also
                 40B, and Llama3-76B versions) (Chen et al.,              discuss the influence of the CoT prompt in 3.3.
                 2024), LLaVA (OneVision-7B, OneVision-72B,              Approximating Human Expert Performance.
                 and various NeXT versions) (Li et al., 2024a;           While rigorous human evaluation of MMMU-Pro
                 Liu et al., 2024a), VILA-1.5-40B (Lin et al.,            provides valuable insights, conducting such an as-
                 2024), MiniCPM-V2.6 (Yao et al., 2024), Phi-             sessment is both time-consuming and costly. In-
                 3.5-Vision (Abdin et al., 2024), and Idefics3-8B-        stead, we develop an approach to approximate
                 Llama3 (Laurençon et al., 2024). These models            human expert performance based on the original
                 showcase the current state of publicly available         MMMUhumanevaluationdata. Thisapproxima-
                 multimodal AI systems. We evaluate these models          tion is justified by several key factors. Firstly, the
                 across three different settings: 1) Standard setting     core content and difficulty of the questions remain
                 without augmented options (usually 4 options); 2)        unchanged in MMMU-Pro, supporting the validity
                 Standard setting with augmented options (usually         of using the original human performance data as
                 10options); 3)Vision-only input setting.                 a close approximation. Secondly, in the original
                    Theoverall performance score for MMMU-Pro             MMMUevaluation,humanexpertsarerequired to
                 is calculated as the average of scores from settings    write out their problem-solving processes, signifi-
                                                                     15137
                                                                                MMMU-Pro
                                                                      Standard      Standard                MMMU ∆                     ∆
                                                                                                 Vision       (Val)        1             2
                                                                       (4 Opts)     (10 Opts)
                    RandomChoice                                         24.9          12.8        12.4       22.1      -9.3           -9.7
                    Frequent Choice                                      27.8          12.1        12.1       26.8      -14.7          -14.7
                    HumanExpert(Low)                                     75.4          73.0        73.0       76.2      -3.2           -3.2
                    HumanExpert(Medium)                                  82.1          80.8        80.8       82.6      -1.8           -1.8
                    HumanExpert(High)                                    88.6          85.4        85.4       88.6      -3.2           -3.2
                    GPT-4o(0513)(OpenAI,2024b)                           64.7          54.0        49.7       69.1      -15.1 (↑ 1)    -19.4 ( - )
                    Claude 3.5 Sonnet (Anthropic, 2024)                  63.7          55.0        48.0       68.3      -13.3 (↓ 1)    -20.3 ( - )
                    Gemini 1.5 Pro (0801) (Reid et al., 2024)            60.6          49.4        44.4       65.8      -16.4 ( - )    -21.4 ( - )
                    Gemini 1.5 Pro (0523) (Reid et al., 2024)            57.6          46.5        40.5       62.2      -15.7 ( - )    -21.7 ( - )
                    GPT-4omini(OpenAI,2024a)                             55.3          39.9        35.2       59.4      -19.5 (↑ 1)    -24.2 (↑ 1)
                    Qwen2-VL-72B(Qwen,2024)                              59.3          49.2        43.3       64.5      -15.3 ( - )    -21.2 ( - )
                    InternVL2-Llama3-76B (Chen et al., 2024)             55.0          41.9        38.0       58.3      -16.4 (↓ 1)    -20.3 (↓ 1)
                    InternVL2-40B (Chen et al., 2024)                    47.4          36.3        32.1       55.2      -18.9 ( - )    -23.1 (↓ 1)
                    LLaVA-OneVision-72B(Lietal., 2024a)                  52.3          38.0        24.0       56.8      -18.8 ( - )    -32.8 (↑ 5)
                    Qwen2-VL-7B(Qwen,2024)                               46.6          34.1        27.0       54.1      -20.0 (↑ 1)    -27.1 (↓ 1)
                    Pixtral-12B (Mistral, 2024)                          47.5          33.4        25.0       52.5      -19.1 (↑ 1)    -27.5 ( - )
                    InternVL2-8B (Chen et al., 2024)                     42.6          32.5        25.4       51.2      -18.7 ( - )    -25.8 (↓ 3)
                    MiniCPM-V2.6(Yaoetal., 2024)                         40.6          30.2        24.2       49.8      -19.6 (↑ 1)    -25.6 (↓ 3)
                    VILA-1.5-40B (Lin et al., 2024)                      46.8          35.9        14.1       51.9      -16.0 (↓ 2)    -37.8 (↑ 9)
                    LLaVA-NEXT-72B(Liuetal.,2024a)                       43.0          31.0        19.2       49.9      -18.9 ( - )    -30.7 ( - )
                    LLaVA-OneVision-7B(Lietal., 2024a)                   42.8          29.5        18.7       48.8      -19.3 (↑ 2)    -30.1 (↓ 1)
                    LLaVA-NeXT-34B(Liuetal.,2024a)                       44.5          30.3        17.2       48.1      -17.8 (↓ 2)    -30.9 (↓ 1)
                    Idefics3-8B-Llama3 (Laurençon et al., 2024)          40.8          30.1        15.6       46.6      -16.5 (↓ 1)    -31.0 ( - )
                    Qwen2-VL-2B(Qwen,2024)                               34.8          25.3        17.2       41.1      -15.8 ( - )    -23.9 (↓ 3)
                    Phi-3.5-Vision (Abdin et al., 2024)                  37.8          26.3        13.1       43.0      -16.7 ( - )    -29.9 (↑ 3)
                    LLaVA-NeXT-7B(Liuetal.,2024a)                        33.7          19.4        14.6       35.3      -15.9 ( - )    -20.7 (↓ 3)
                    LLaVA-NeXT-13B(Liuetal.,2024a)                       33.9          19.8        14.5       36.2      -16.4 ( - )    -21.7 (↓ 1)
                    Table 1: Results of models on MMMU-Pro and MMMU (Val). ∆ : Standard (10 options) - MMMU (Val); ∆ :
                                                                                               1                                                2
                    Vision - MMMU(Val). (↓) represents a decrease in ranking, while (↑) indicates an increase. The best-performing
                    modelineachcategory is in-bold, and the second best is underlined.
                    cantly reducing the likelihood of random guessing.               64.7%to54.0%. This indicates that increasing the
                    For questions without detailed solving processes,                number of options effectively reduces the likeli-
                    werandomlyselectoneoptionfromtheaugmented                        hoodofmodelsguessingthecorrect answer, forc-
                    candidates and recalculate the accuracy. Finally,                ing them to engage more deeply with the multi-
                    human experts, with their innate ability to seam-                modalcontent.
                    lessly integrate visual and textual information, are             ImpactofVision-OnlySetting: The introduction
                    expected to perform similarly in the vision-only in-             of the vision-only input setting further challenges
                    put setting as they do in the original format. Based             models, as evidenced by the additional drop in per-
                    on these considerations, we posit that human ex-                 formance when comparing the vision-only results
                    pert performance on MMMU-Pro closely aligns                      to the 10-option standard (∆2). For instance, GPT-
                    with the original MMMU results, allowing us to                   4o (0513) dropped another 4.3% in accuracy when
                    maintain a human performance benchmark with-                     evaluated in the vision-only setting, and LLaVA-
                    out incurring the substantial costs of a new expert              OneVision-72B saw a dramatic 14.0% decrease.
                    evaluation. More details of the human estimation                 This suggests that the vision-only setting success-
                    performance can be found in Appendix B.                          fully tests the models’ ability to integrate visual and
                    3.2    Overall Results                                           textual information, highlighting their limitations
                                                                                     whenthetext is not explicitly provided.
                    Wepresented the overall results of MMMU-Pro of                   CombinedEffectsonMMMU-Pro: Theoverall
                    different models in Table 1.                                     ∆ ,representing the difference between MMMU-
                                                                                        3
                    Effect of Increased CandidateOptions: Theshift                   ProandMMMU(Val),showsasignificantdecrease
                    from 4 to 10 candidate options (∆ ) reveals a sig-               across the board. For instance, models like Gemini
                                                              1
                    nificant drop in performance for all models. GPT-                1.5 Pro (0801) and Claude 3.5 Sonnet exhibited
                    4o(0513) experienced a decrease of 10.7%, from                   declines of 18.9% and 16.8%, respectively, while
                                                                                15138
                                                                 Standard                                                                           Vision Input
                                                                Direct      CoT                                                                     Direct      CoT
                                                                                                                          GPT-4o (0513)
                                      GPT-4o (0513)
                                                                                                                       Claude 3.5 Sonnet
                                  Claude 3.5 Sonnet
                                                                                                                   Gemini 1.5 Pro (0801)
                               Gemini 1.5 Pro (0801)
                                                                                                                             GPT-4o mini
                                         GPT-4o mini
                                                                                                                   InternVL2-Llama3-76B
                              InternVL2-Llama3-76B
                                                                                                                   LLaVA-OneVision-72B
                              LLaVA-OneVision-72B
                                                                                                                             VILA1.5-40B
                                         VILA1.5-40B
                                                                                                                            InternVL2-8B
                                        InternVL2-8B
                                                                                                                      Idefics3-8B-Llama3
                                  Idefics3-8B-Llama3
                                                                                                                                          0.0              20.0              40.0              60.0
                                            Figure 5: Impact of CoT prompting of different models in the two settings of MMMU-Pro.
                           moredrastic drops were seen in models like VILA-                                        provements in reasoning-intensive fields like Tech
                           1.5-40B with a 26.9% decrease.                                                          and Engineering (e.g., a 14.49% gain for GPT-
                               This significant reduction in accuracy across the                                   4o) and Science (8.22% gain). Smaller yet consis-
                           board suggests that MMMU-Pro successfully mit-                                          tent gains are observed for LLaVA-OneVision 72B,
                           igates the shortcuts and guessing strategies that                                       such as 2.33% in Tech and Engineering. However,
                           models could exploit in the original benchmark.                                         CoT’s benefits are limited or negative in fields like
                           3.3      ImpactofCoTPrompting                                                           Art and Design, where GPT-4o gains only 1.58%,
                                                                                                                   and LLaVA-OneVision 72B sees a 17.12% decline.
                           Figure 5 examines the effectiveness of Chain of                                         These results underscore CoT’s strengths in struc-
                           Thought (CoT) prompting on the MMMU-Pro                                                 tured reasoning tasks but its reduced effectiveness
                           benchmark, in both Standard and Vision Input set-                                       in domains requiring subjective interpretation.
                           tings. Across both settings, CoT prompts generally
                           improved performance, though the extent varied                                          3.4      DoesOCRHelpintheVisionSetting?
                           significantly. For instance, Claude 3.5 Sonnet saw                                      In the Vision Input setting, one natural question
                           a substantial increase in the Standard setting, rising                                  is whether Optical Character Recognition (OCR)
                           from 42.7% to 55.0%, while models like LLaVA-                                           helps improve model performance on MMMU-Pro.
                           OneVision-72B showed only minimal gains.                                                We answer this question by first calculating the
                               Interestingly, we observed a significant perfor-                                    OCRaccuracyofdifferentmodels. Specifically,we
                           mance drop for some models, such as VILA1.5-                                            ask the model to extract the full text of the question
                           40B. This decline might be attributed to challenges                                     and answer choices. Then the OCR accuracy is
                           in instruction-following abilities. When a model                                        calculated by comparing the text extracted with
                           struggles to follow instructions accurately, gener-                                     the original text using Levenshtein distance, which
                           ating CoT explanations becomes more difficult.                                          measures the difference between the two strings.
                           Additionally, these models may face issues with                                         Thesimilarity between the extracted and original
                           maintaining the correct response format, leading to                                     text is computed as:
                           what is known as “boiled response format” prob-                                                                            Levenshtein.distance(text1,text2)
                           lems. These findings highlight the potential of CoT                                         OCRAccuracy=1−                     max(len(text1),len(text2))
                           to enhance model performance in complex, real-                                              Table 2 shows that although most of the models
                           world tasks that require nuanced reasoning and                                          demonstrate strong OCR capabilities, as indicated
                           integration of multiple information sources. How-                                       byhighsimilarity scores. Based on the result, we
                           ever, they also underscore the importance of robust                                     then explore whether explicitly asking the model
                           instruction-following capabilities as a prerequisite                                    to first extract the question and then solve it (with
                           for effective CoT implementation.                                                       an OCRpromptshowninAppendixA)couldhelp
                               Theeffectiveness of CoT prompting across disci-                                     in improving performance within the Vision In-
                           plines is summarized in Table 6 and Figure 9, com-                                      put setting of MMMU-Pro. Across the models
                           paring CoT and direct accuracy for GPT-4o and                                           evaluated, the inclusion of OCR prompts did not
                           LLaVA-OneVision 72B. CoT shows significant im-                                          significantly alter performance. These minimal dif-
                                                                                                           15139
                  ferences suggest that strong capable models are            3.5   Qualitative Analysis
                  already proficient at extracting and understanding         Togaindeeperinsights into model performance be-
                  textual information from images, even without ex-          yondquantitativemetrics,weconductedathorough
                  plicit OCR prompts.                                        qualitative analysis of MMMU-Pro results, focus-
                                                                             ing on two key scenarios: 1) Correct answers with
                                                    Vision Setting Acc.      four options but failure with ten options in the stan-
                    Model                   OCR w/OCR w/oOCR                 dard setting; 2) Success in the standard ten-option
                                            Acc.    Prompt     Prompt
                                                                             setting but failure in the vision input setting. Our
                    GPT-4o                   92.3     49.7       49.4        analysis revealed several critical factors affecting
                    Gemini 1.5 Pro(0801)     89.7     44.4       43.6        modelperformance:
                    GPT-4omini               89.6     35.2       35.6
                    InternVL2-Llama3-76B     88.1     38.0       37.9        Challenges with Increased Options. Models of-
                    InternVL2-Llama3-40B     85.5     32.1       28.9        ten select the closest answer rather than arriving at
                    Pixtral-12B              83.1     25.0       24.1
                    LLaVA-OneVision-72B      87.8     24.0       23.8        a definitive choice, leading to increased errors with
                    InternVL2-8B             85.2     25.4       24.6        moreoptions, as shown in Figure 11. Conceptually
                    MiniCPM-V2.6             67.0     24.2       21.1        similar options, particularly in nuanced questions,
                    LLaVA-NEXT-72B           62.0     19.2       20.0
                    Idefics3-8B-Llama3       68.5     15.6       14.1        can cause confusion. For instance, in conceptual
                    LLaVA-NeXT-7B            36.6     14.6       14.3        questions, models struggled to differentiate subtle
                    LLaVA-NeXT-13B           51.1     14.5       12.8        distinctions within a subject area, revealing limita-
                  Table 2: Model performance in the Vision Input setting,    tions in fine-grained understanding.
                  comparing OCRaccuracy with/without OCR prompts.            Increased Cognitive Load in Vision-Text Inte-
                                                                             gration. Processingvisualandtextualinputssimul-
                                                                             taneously increases the cognitive load on models.
                                 Proprietary Models          GPT-4o          An example is shown in Figure 10. The model
                        50       Open-Source Models                          perfectly extracted the text from the image but still
                                                      Gemini 1.5 Pro(0801)   failed to answer the question correctly. Another
                       ision40                       InternVL2-Llama3-76B    case is shown in Figure 21. The graph’s similar
                       o V                                                   lines and overlapping data points may distract the
                                                        GPT-4o mini          model from distinguishing between the two unem-
                        30
                                                      Pixtral-12B            ployment categories, leading to the error.
                                     MiniCPM-V2.6
                       MMMU-Pr                        LLaVA-OneVision-72B    Overemphasis on Visual Cues in Multimodal
                        20      LLaVA-NEXT-72B
                           LLaVA-NeXT-7B          Idefics3-8B                Reasoning. When visual cues dominate over tex-
                        10               VILA-1.5-40B                        tual reasoning, models may incorrectly prioritize
                          30    40   50    60    70    80    90              less relevant information from the images. In the
                                        OCR Accuracy                         Figure 33 example, the Vision Setting incorrectly
                  Figure 6: Correlation between OCR accuracy and             chose the League of Nations by focusing on the
                  MMMU-ProVisionperformance.                                 World War I image, missing the broader context
                                                                             of World War II and the United Nations. A proper
                     Interestingly, Figure 6 shows that high OCR ac-         balance between visual and textual information is
                  curacy doesn’t always translate to strong multi-           essential to avoid such mistakes.
                  modalreasoning. For example, LLaVA-OneVision-              ImpactofContextSwitching. Rapid transitions
                  72BmatchesInternVL2-Llama3-76B and GPT-4o                  between visual and textual information can cause
                  mini in OCR accuracy but lags significantly in             models to lose focus or misinterpret key data. For
                  MMMU-ProVisionperformance, indicating that                 example, in Figure 26, the model initially correctly
                  OCRaccuracyaloneisinsufficient for robust rea-             defined both the objective function and the alge-
                  soning. Conversely, top-performing models like             braic constraints. However, due to context switch-
                  GPT-4o consistently excel in both areas. Despite           ing between the textual description and the geomet-
                  GPT-4o’s high OCR accuracy, its MMMU-Pro                   ric figure, it misinterpreted the feasible region.
                  Vision performance drops notably compared to               3.6   Error Analysis
                  MMMU(Val),revealingthatevenadvancedmod-
                  els struggle to fully integrate and reason over mul-       Following the MMMUerror analysis, we analyze
                  timodal inputs in the vision-only setting.                 60 error cases from GPT-4o in the Vision setting
                                                                        15140
                                                                                            tences. As shown in Figure 8, GPT-4o generates
                                                                                            significantly shorter responses but uses moretokens
                                                                                            for “Descriptive”ratherthan“Analytical”. Onepos-
                                      Reasoning            Lack of                          sible reason is that the increased cognition work-
                                         Error           Knowledge                          load of the vision inputs requires the model to fo-
                                         46%                 25%
                                                                                            cus more on visual processing, which distracts the
                                                                                            model from generating extensive reasoning chains.
                                               Perceptual Error
                                                      27%                                   4 GuideforFutureModelTraining
                                                                 Annotation 
                                  OCR Error                         Error                  The results of MMMU-Pro provide valuable in-
                                      0%                              2%
                                                                                            sights into the challenges faced by current multi-
                      Figure 7: Distribution of 60 annotated GPT-4o errors.                 modal models and suggest several promising direc-
                                                                                            tions for future model development.
                      to better understand the error reasons (Figure 7).                    Scaling of LLM Backbones. As demonstrated
                      Consistent with MMMU findings, the errors are                         in Table 1, increasing the scale of large language
                      broadly categorized into three main types: per-                       model (LLM) backbones consistently enhances
                      ception errors, knowledge errors, and reasoning                       both perception and reasoning capabilities. For
                      errors. However, reasoning errors account for 46%                     example, larger models such as GPT-4o outper-
                      of cases, a significant increase from the original                    form their smaller counterparts like GPT-4o mini,
                      MMMUdistribution(26%). Within perception er-                         while LlavaOneVision-72B achieves better results
                      rors, text recognition and OCR do not prove to                        than LlavaOneVision-7B. Similarly, InternVL2-
                      be the primary bottleneck. Instead, the main chal-                   78Bdemonstrates superior performance compared
                      lenges lie in the integration and interpretation of                   to InternVL2-8B. This trend underscores the im-
                     visual and textual information. This shift in error                    portance of scaling as a critical factor in improving
                      distribution highlights the increased difficulty for                  multimodal understanding and reasoning.
                      models in transitioning from accurate perception                      MoreCapableVisionEncodersthatHighlights
                      to complex multimodal reasoning.                                     Visual Representation Learning. We train two
                                                                                            Cambrian (Tong et al., 2024a) models on 1M Cam-
                      3.7    Response Length Comparison                                     brian data with two different vision encoders to
                                                                                            explore their impact (more details of the setup
                                                                                            are in Appendix E).              As shown in Table 3,
                                              Standard     Vision                           encoders such as Siglip ViT-SO400M-14 (Zhai
                                500
                                                                  409                       et al., 2023), trained with extensive language su-
                                400
                                                                      366
                                                      360                                   pervision, perform well on MMMU (Val) but
                                300
                                                          258                               struggle on MMMU-Pro (Vision). In compari-
                                200                                                         son, self-supervised encoders like DINOv2 ViT-
                              # Tokens100 49 108                                            G-14 (Oquab et al., 2023) achieve better results
                                  0                                                         on the Vision input setting. These findings sug-
                                        Descriptive  Analytical     Total                   gest future work may focus on further enhancing
                                         Response Sentence Types                           visual feature learning while exploring the inte-
                      Figure 8: GPT-4o outputs’ length comparison between                   gration of language-based training objectives with
                      the Standard and Vision settings.                                     self-supervised training objectives.
                                                                                            Better Integration of Vision and Text Modali-
                         One interesting observation we have from the                       ties. Integration of visual and textual information
                      previous qualitative examples is that responses (es-                  remains a key challenge for multimodal models.
                      pecially the reasoning sentences) of GPT-4o under                     Current architectures often struggle with tasks re-
                      the Vision Input setting seem to be shorter than the                  quiring deep cross-modal understanding. Develop-
                      Standard setting. We quantify this phenomenon by                      ing models with better cross-modal attention and
                      asking another LLM (Qwen2-72B-Instruct (Yang                          effective feature fusion is critical to bridge this gap.
                      et al., 2024)) to classify the GPT-4o’s responses                     CoTDataGeneration. TheCoTpromptingtech-
                      into “Descriptive” sentences and “Analytical” sen-                    niqueshowssignificant benefits in reasoning-heavy
                                                                                     15141
                                            MMMU MMMU-Pro                  Lin et al., 2024; Zhang et al., 2024a). Proprietary
                     Method                   (Val)      (Vision)
                                                                           models such as GPT-4V (OpenAI, 2023), GPT-4o
                     DINOv2ViT-G-14           37.1         17.4            (OpenAI, 2024b), Gemini (Team et al., 2023), and
                     Siglip ViT-SO400M-14     37.9         16.7            Claude-3.5 (Anthropic, 2024) have demonstrated
                  Table 3: Performance of an MLLM with different vision    strong performance across various vision-language
                  encoders on MMMUandMMMU-Pro.                             tasks. However, a significant challenge remains
                  domains within MMMU-Pro, as reflected in Fig-            in accurately evaluating the capabilities of these
                  ure 5 and Table 6. While domains like Tech and En-       advanced LMMs, highlighting the need for more
                  gineering and Business see notable improvements,         robust and comprehensive benchmarks.
                  CoTperformanceremainsweakorevendetrimen-                 MLLMBenchmarks. Theriseofmoreadvanced
                  tal in areas such as Art and Design. To address          multimodal pre-training and instruction tuning has
                  these gaps, future efforts focus on synthesizing         exposed the limitations of earlier benchmarks like
                  morediverse reasoning-intensive CoT data and tai-        VQA(Antoletal.,2015;Goyaletal., 2017), OK-
                  loring strategies for domains where CoT impact           VQA(Marino et al., 2019), and MSCOCO (Lin
                  is minimal. Leveraging inference-compute con-            et al., 2014), which no longer suffice to evaluate
                  cepts (Welleck et al., 2024) further enhances CoT        the full spectrum of LMMs capabilities. To address
                  capabilities, enabling models to generalize more         this, recent benchmarks such as LAMM (Yin et al.,
                  effectively across varied reasoning tasks.               2023b), LVLM-eHub(Xuetal., 2023), SEED (Li
                  Text-Rich Image Generation in Reasoning Sce-             et al., 2024b), MMBench (Liu et al., 2023d),CV-
                  narios. Our analysis shows that strong OCR ac-           Bench (Tong et al., 2024a), MM-Vet (Yu et al.,
                  curacy and reasoning performance on traditional          2024), Mantis (Jiang et al., 2024), and BLINK (Fu
                  benchmarks do not always translate to success on         et al., 2024) have emerged, covering aspects from
                  MMMU-ProVision. Apotential reason is the lack            basic perception to hallucination detection (Cui
                  of training data with text-rich images in reasoning-     et al., 2023; Liu et al., 2023a).      However, ex-
                  intensive contexts. To address this, we developed        isting benchmarks often fall short in evaluating
                  a tool leveraging the MMMU-Pro Vision human              expert-level domain knowledge and complex rea-
                  annotation process. This tool processes a JSON file      soning (Lu et al., 2023a; Zhang et al., 2024b).
                  with questions and images and outputs screenshots        WhileMMMU(Yueetal.,2024)madestridesbyin-
                  embedding both. Such tools can further generate          corporating multimodal, college-level questions, it
                  similar datasets at scale, enhancing models’ abil-       still permits text-only models to find shortcuts (Lu
                  ity to integrate visual and textual information in       et al., 2023b; Zhang et al., 2024b). To address these
                  real-world scenarios.                                    limitations, we introduce MMMU-Pro, a more ro-
                    Byfocusing on these directions, future model-          bust benchmark that removes text-only answerable
                  ing efforts can address limitations highlighted by       questions, expands candidate options, and includes
                  MMMU-Proandpushmultimodalunderstanding                   a vision-only input setting to better reflect real-
                  and reasoning boundaries.                                world multimodal scenarios.
                  5 RelatedWork                                            6 Conclusion
                  Multimodal Large Language Models. Recent                 MMMU-Prooffers a stronger multimodal under-
                  progress in multimodal AI has been marked by             standing and reasoning benchmark than its prede-
                  innovative training approaches (Lu et al., 2019;         cessor MMMU. Our results show MMMU-Pro’s
                  Chenet al., 2020; Zhou et al., 2020; Zhang et al.,       effectiveness in exposing current state-of-the-art
                  2021;Lietal.,2020;Alayracetal.,2022;Awadalla             model limitations, with significant performance
                  et al., 2023). Inspired by the success of large lan-     drops across all tested systems. MMMU-Pro high-
                  guage models, researchers have developed vari-           lights critical research directions: 1) Developing
                  ous models with improved instruction-following           modelswithconsistentperformanceacrosssettings,
                  capabilities (Liu et al., 2023c,b, 2024a; Li et al.,     particularly bridgingstandardandvision-onlyinput
                  2024a; Dai et al., 2023; Zhu et al., 2023; Zhang         gaps. 2) Enhancing vision-text integration for com-
                  et al., 2023; Gao et al., 2023; Ye et al., 2023a,b;      plex mixed-format inputs. 3) Advancing reasoning
                  Zhao et al., 2023; Li et al., 2023; Monajatipoor         techniques to address MMMU-Pro’s heightened
                  et al., 2023; Zhao et al., 2024; Li et al., 2024c;       question complexity.
                                                                      15142
                 Ethical Statement                                         2023. Openflamingo: An open-source framework for
                                                                           training large autoregressive vision-language models.
                 TheMMMU-Probenchmarkisdesignedwithethi-                  ArXiv preprint, abs/2308.01390.
                 cal considerations to ensure fair and responsible AI
                 evaluation. The dataset excludes sensitive content,    Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed
                 and the assessment focuses on testing multimodal          El Kholy, Faisal Ahmed, Zhe Gan, Yu Cheng, and
                 capabilities without introducing bias. We aim for         Jingjing Liu. 2020. Uniter: Universal image-text
                                                                           representation learning. In European Conference on
                 transparency in reporting model limitations and en-      Computer Vision, pages 104–120.
                 courage further research to address any societal       Zhe Chen, Weiyun Wang, Hao Tian, Shenglong Ye,
                 impacts related to the use of these models in real-       Zhangwei Gao, Erfei Cui, Wenwen Tong, Kongzhi
                 world applications.                                       Hu, Jiapeng Luo, Zheng Ma, et al. 2024. How far
                 Limitations                                               are we to gpt-4v? closing the gap to commercial
                                                                           multimodal models with open-source suites. ArXiv
                                                                           preprint, abs/2404.16821.
                 While MMMU-Proimprovesuponexistingbench-
                 marks by filtering out text-only solvable questions    ChenhangCui, Yiyang Zhou, Xinyu Yang, Shirley Wu,
                 and introducing a vision-only setting, some limita-       Linjun Zhang, James Zou, and Huaxiu Yao. 2023.
                 tions remain. The dataset may still contain subtle        Holistic analysis of hallucination in gpt-4v (ision):
                 statistical shortcuts that models can exploit, and        Bias and interference challenges. ArXiv preprint,
                                                                           abs/2311.03287.
                 its scope is limited to predefined disciplines and
                 question formats. Additionally, while the vision-      WenliangDai,JunnanLi,DONGXULI,AnthonyTiong,
                 only input setting increases difficulty, it does not      Junqi Zhao, Weisheng Wang, Boyang Li, Pascale N
                 fully capture the complexities of human perception.       Fung, and Steven Hoi. 2023. Instructblip: Towards
                                                                           general-purposevision-languagemodelswithinstruc-
                 Lastly, our reliance on approximated human per-           tion tuning. In Advances in Neural Information Pro-
                 formance rather than direct evaluation introduces         cessing Systems, volume 36, pages 49250–49267.
                 potential biases in reporting accurate human expert       Curran Associates, Inc.
                 performance.                                           MengnanDu,FengxiangHe,NaZou,DachengTao,and
                                                                          Xia Hu. 2023. Shortcut learning of large language
                                                                           models in natural language understanding. Commu-
                 References                                                nications of the ACM, 67(1):110–120.
                 MarahAbdin,SamAdeJacobs,AmmarAhmadAwan,                Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,
                    Jyoti Aneja, Ahmed Awadallah, Hany Awadalla,          Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,
                    NguyenBach,AmitBahree,ArashBakhtiari, Harki-          Akhil Mathur, Alan Schelten, Amy Yang, Angela
                    rat Behl, et al. 2024. Phi-3 technical report: A       Fan, et al. 2024. The llama 3 herd of models. ArXiv
                    highlycapablelanguagemodellocallyonyourphone.          preprint, abs/2407.21783.
                   ArXiv preprint, abs/2404.14219.
                 Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc,      XingyuFu,YushiHu,BangzhengLi,YuFeng,Haoyu
                    Antoine Miech, Iain Barr, Yana Hasson, Karel          Wang,XudongLin,DanRoth,NoahASmith,Wei-
                    Lenc, Arthur Mensch, Katherine Millican, Malcolm       Chiu Ma, and Ranjay Krishna. 2024. Blink: Multi-
                    Reynolds, et al. 2022. Flamingo: a visual language     modallargelanguagemodelscanseebutnotperceive.
                    modelfor few-shot learning. In Advances in Neural     ArXiv preprint, abs/2404.12390.
                    Information Processing Systems.                     Peng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie
                 Anthropic.    2024.         Claude    3.5    sonnet.      Geng, Aojun Zhou, Wei Zhang, Pan Lu, Conghui
                    https://www.anthropic.com/news/claude-3-5-             He, Xiangyu Yue, et al. 2023. Llama-adapter v2:
                    sonnet.                                                Parameter-efficient visual instruction model. ArXiv
                                                                           preprint, abs/2304.15010.
                 Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-
                    garet Mitchell, Dhruv Batra, C. Lawrence Zitnick,   YashGoyal,TejasKhot,DouglasSummers-Stay,Dhruv
                    and Devi Parikh. 2015. VQA: visual question an-        Batra, and Devi Parikh. 2017. Making the V in VQA
                    swering. In 2015 IEEE International Conference         matter: Elevating the role of image understanding in
                    on Computer Vision, ICCV 2015, Santiago, Chile,        visual question answering. In 2017 IEEE Conference
                    December7-13, 2015, pages 2425–2433. IEEE Com-         on Computer Vision and Pattern Recognition, CVPR
                    puter Society.                                         2017, Honolulu, HI, USA, July 21-26, 2017, pages
                                                                           6325–6334. IEEE Computer Society.
                 Anas Awadalla, Irena Gao, Josh Gardner, Jack Hes-
                    sel, Yusuf Hanafy, Wanrong Zhu, Kalyani Marathe,    gpt-4o. 2024.     Cheaper, better, faster, stronger.
                   Yonatan Bitton, Samir Gadre, Shiori Sagawa, et al.      https://mistral.ai/news/mixtral-8x22b/.
                                                                   15143
                  DongfuJiang, Xuan He, Huaye Zeng, Cong Wei, Max          Ji Lin, Hongxu Yin, Wei Ping, Pavlo Molchanov, Mo-
                    Ku, Qian Liu, and Wenhu Chen. 2024. Mantis:              hammadShoeybi,andSongHan.2024. Vila: Onpre-
                    Interleaved multi-image instruction tuning. ArXiv        training for visual language models. In Proceedings
                    preprint, abs/2405.01483.                                of the IEEE/CVF Conference on Computer Vision
                                                                             andPattern Recognition, pages 26689–26699.
                  Yizhang Jin, Jian Li, Yexin Liu, Tianjun Gu, Kai
                    Wu, Zhengkai Jiang, Muyang He, Bo Zhao, Xin            Tsung-Yi Lin, Michael Maire, Serge Belongie, James
                    Tan, Zhenye Gan, et al. 2024. Efficient multimodal       Hays, Pietro Perona, Deva Ramanan, Piotr Dollár,
                    large language models: A survey. ArXiv preprint,         and C Lawrence Zitnick. 2014.      Microsoft coco:
                    abs/2405.10739.                                          Common objects in context. In Computer Vision–
                                                                             ECCV 2014: 13th European Conference, Zurich,
                  Jing Yu Koh, Robert Lo, Lawrence Jang, Vikram              Switzerland, September 6-12, 2014, Proceedings,
                    Duvvur, Ming Lim, Po-Yu Huang, Graham Neu-               Part V 13, pages 740–755. Springer.
                    big, Shuyan Zhou, Russ Salakhutdinov, and Daniel
                    Fried. 2024. VisualWebArena: Evaluating multi-         Fuxiao Liu, Tianrui Guan, Zongxia Li, Lichang Chen,
                    modal agents on realistic visual web tasks. In Pro-      Yaser Yacoob, Dinesh Manocha, and Tianyi Zhou.
                    ceedings of the 62nd Annual Meeting of the Associa-      2023a. Hallusionbench: You see what you think? or
                    tion for Computational Linguistics (Volume 1: Long       you think what you see? an image-context reasoning
                    Papers), pages 881–905, Bangkok, Thailand. Associ-       benchmarkchallenging for gpt-4v (ision), llava-1.5,
                    ation for Computational Linguistics.                     and other multi-modality models. ArXiv preprint,
                                                                             abs/2310.14566.
                  HugoLaurençon, Andrés Marafioti, Victor Sanh, and
                    LéoTronchon.2024. Building and better understand-      Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae
                    ing vision-language models: insights and future di-      Lee. 2023b. Improved baselines with visual instruc-
                    rections. ArXiv preprint, abs/2408.12637.                tion tuning. In NeurIPS 2023 Workshop on Instruc-
                                                                             tion Tuning and Instruction Following.
                  BoLi,YuanhanZhang,LiangyuChen,JinghaoWang,
                    Jingkang Yang, and Ziwei Liu. 2023.      Otter: A      Haotian Liu, Chunyuan Li, Yuheng Li, Bo Li, Yuanhan
                    multi-modalmodelwithin-contextinstructiontuning.         Zhang, Sheng Shen, and Yong Jae Lee. 2024a. Llava-
                    ArXiv preprint, abs/2305.03726.                          next: Improved reasoning, ocr, and world knowledge.
                  BoLi,YuanhanZhang,DongGuo,RenruiZhang,Feng               Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae
                    Li, Hao Zhang, Kaichen Zhang, Yanwei Li, Ziwei           Lee. 2023c.    Visual instruction tuning.   In Ad-
                    Liu, and Chunyuan Li. 2024a. Llava-onevision: Easy       vances in Neural Information Processing Systems,
                    visual task transfer. ArXiv preprint, abs/2408.03326.    volume36,pages34892–34916.CurranAssociates,
                                                                             Inc.
                  BohaoLi, Yuying Ge, Yixiao Ge, Guangzhi Wang, Rui
                    Wang,RuimaoZhang,andYingShan.2024b. Seed-              Junpeng Liu, Yifan Song, Bill Yuchen Lin, Wai Lam,
                    bench: Benchmarking multimodal large language            GrahamNeubig,YuanzhiLi,andXiangYue.2024b.
                    models. InProceedingsoftheIEEE/CVFConference             Visualwebbench: How far have multimodal llms
                    onComputerVisionandPatternRecognition(CVPR),             evolved in web page understanding and grounding?
                    pages 13299–13308.                                       Conference on Language Modeling.
                  Feng Li, Renrui Zhang, Hao Zhang, Yuanhan Zhang,         Yuan Liu, Haodong Duan, Yuanhan Zhang, Bo Li,
                    BoLi,WeiLi,ZejunMa,andChunyuanLi.2024c.                  Songyang Zhang, Wangbo Zhao, Yike Yuan, Jiaqi
                    Llava-next-interleave: Tackling multi-image, video,      Wang, Conghui He, Ziwei Liu, et al. 2023d. Mm-
                    and 3d in large multimodal models. ArXiv preprint,       bench: Is your multi-modal model an all-around
                    abs/2407.07895.                                          player? ArXiv preprint, abs/2307.06281.
                  Xiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang,         Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee.
                    Xiaowei Hu, Lei Zhang, Lijuan Wang, Houdong              2019. Vilbert: Pretraining task-agnostic visiolinguis-
                    Hu, Li Dong, Furu Wei, et al. 2020. Oscar: Object-       tic representations for vision-and-language tasks. In
                    semantics aligned pre-training for vision-language       Advances in Neural Information Processing Systems
                    tasks. In Computer Vision–ECCV 2020: 16th Euro-          32: Annual Conference on Neural Information Pro-
                    pean Conference, Glasgow, UK, August 23–28, 2020,        cessing Systems 2019, NeurIPS 2019, December 8-
                    Proceedings, Part XXX 16, pages 121–137. Springer.       14, 2019, Vancouver, BC, Canada, pages 13–23.
                  Zekun Li, Xianjun Yang, Kyuri Choi, Wanrong Zhu,         Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chun-
                    RyanHsieh, HyeonJung Kim, Jin Hyuk Lim, Sungy-           yuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei
                    oung Ji, Byungju Lee, Xifeng Yan, et al. 2024d.          Chang, Michel Galley, and Jianfeng Gao. 2023a.
                    Mmsci: A multimodal multi-discipline dataset for         Mathvista: Evaluating mathematical reasoning of
                    phd-level scientific comprehension. ArXiv preprint,      foundation models in visual contexts. ArXiv preprint,
                    abs/2407.04903.                                          abs/2310.02255.
                                                                      15144
                  Yujie Lu, Xiujun Li, William Yang Wang, and Yejin       Shengbang Tong, Zhuang Liu, Yuexiang Zhai, Yi Ma,
                    Choi. 2023b. Vim: Probing multimodal large lan-          Yann LeCun, and Saining Xie. 2024b. Eyes wide
                    guage models for visual embedded instruction fol-        shut? exploring the visual shortcomings of multi-
                    lowing. ArXiv preprint, abs/2311.17647.                  modal llms. In Proceedings of the IEEE/CVF Con-
                                                                             ference on Computer Vision and Pattern Recognition,
                  Kenneth Marino, Mohammad Rastegari, Ali Farhadi,           pages 9568–9578.
                    and Roozbeh Mottaghi. 2019. OK-VQA: A visual          YuboWang,XueguangMa,GeZhang,YuanshengNi,
                    question answering benchmark requiring external          Abhranil Chandra, Shiguang Guo, Weiming Ren,
                    knowledge. In IEEE Conference on Computer Vision         Aaran Arulraj, Xuan He, Ziyan Jiang, et al. 2024.
                    and Pattern Recognition, CVPR 2019, Long Beach,          Mmlu-pro: Amorerobustandchallengingmulti-task
                    CA,USA,June16-20,2019,pages3195–3204.Com-                language understanding benchmark. ArXiv preprint,
                    puter Vision Foundation / IEEE.                          abs/2406.01574.
                  Mistral.      2024.                      Pixtral-12b.   Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
                    https://mistral.ai/news/pixtral-12b.                     Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,
                  Masoud Monajatipoor, Liunian Harold Li, Mozhdeh            et al. 2022. Chain-of-thought prompting elicits rea-
                    Rouhsedaghat, Lin Yang, and Kai-Wei Chang. 2023.         soning in large language models. Advances in neural
                    MetaVL: Transferring in-context learning ability         information processing systems, 35:24824–24837.
                    from language models to vision-language models.       Sean Welleck, Amanda Bertsch, Matthew Finlayson,
                    In Proceedings of the 61st Annual Meeting of the         Hailey Schoelkopf, Alex Xie, Graham Neubig, Ilia
                    Association for Computational Linguistics (Volume        Kulikov, and Zaid Harchaoui. 2024.      From de-
                    2: Short Papers), pages 495–508, Toronto, Canada.        coding to meta-generation: Inference-time algo-
                    Association for Computational Linguistics.               rithms for large language models. arXiv preprint
                  OpenAI. 2023. Gpt-4v(ision) system card.                   arXiv:2406.16838.
                  OpenAI.2024a. Gpt-4o mini: advancing cost-efficient     Penghao Wu and Saining Xie. 2024. V*: Guided visual
                    intelligence. https://openai.com/index/gpt-4o-mini-      search as a core mechanism in multimodal llms. In
                    advancing-cost-efficient-intelligence/.                  Proceedings of the IEEE/CVF Conference on Com-
                                                                             puter Vision and Pattern Recognition, pages 13084–
                  OpenAI.      2024b.                Hello     gpt4-o.       13094.
                    https://openai.com/index/hello-gpt-4o/.               Peng Xu, Wenqi Shao, Kaipeng Zhang, Peng Gao,
                                                                             ShuoLiu, MengLei, Fanqing Meng, Siyuan Huang,
                  Maxime Oquab, Timothée Darcet, Théo Moutakanni,            YuQiao, and Ping Luo. 2023. Lvlm-ehub: A com-
                    HuyVo,MarcSzafraniec, Vasil Khalidov, Pierre Fer-        prehensive evaluation benchmark for large vision-
                    nandez, Daniel Haziza, Francisco Massa, Alaaeldin        language models. ArXiv preprint, abs/2306.09265.
                    El-Nouby, et al. 2023. Dinov2: Learning robust vi-    An Yang, Baosong Yang, Binyuan Hui, Bo Zheng,
                    sual features without supervision. arXiv preprint        BowenYu,ChangZhou,ChengpengLi,Chengyuan
                    arXiv:2304.07193.                                        Li, Dayiheng Liu, Fei Huang, et al. 2024. Qwen2
                  Qwen.2024. Qwen2-vl: To see the world more clearly.        technical report. ArXiv preprint, abs/2407.10671.
                    https://qwenlm.github.io/blog/qwen2-vl/ .             Yuan Yao, Tianyu Yu, Ao Zhang, Chongyi Wang,
                  Machel Reid, Nikolay Savinov, Denis Teplyashin,            Junbo Cui, Hongji Zhu, Tianchi Cai, Haoyu Li,
                    Dmitry Lepikhin, Timothy Lillicrap, Jean-baptiste        Weilin Zhao, Zhihui He, et al. 2024. Minicpm-v:
                    Alayrac, RaduSoricut, Angeliki Lazaridou, Orhan Fi-      Agpt-4vlevel mllm on your phone. ArXiv preprint,
                    rat, Julian Schrittwieser, et al. 2024. Gemini 1.5: Un-  abs/2408.01800.
                    locking multimodal understanding across millions of   Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming
                    tokens of context. ArXiv preprint, abs/2403.05530.       Yan, Yiyang Zhou, Junyang Wang, Anwen Hu,
                  Gemini Team, Rohan Anil, Sebastian Borgeaud,               Pengcheng Shi, Yaya Shi, et al. 2023a. mplug-owl:
                    Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu,            Modularization empowers large language models
                    Radu Soricut, Johan Schalkwyk, Andrew M Dai,             with multimodality. ArXiv preprint, abs/2304.14178.
                    Anja Hauth, et al. 2023.    Gemini: a family of       Qinghao Ye, Haiyang Xu, Jiabo Ye, Ming Yan, Haowei
                    highly capable multimodal models. ArXiv preprint,        Liu, Qi Qian, Ji Zhang, Fei Huang, and Jingren Zhou.
                    abs/2312.11805.                                          2023b. mplug-owl2: Revolutionizing multi-modal
                  Shengbang Tong, Ellis Brown, Penghao Wu, Sanghyun          large language model with modality collaboration.
                    Woo,ManojMiddepogu,SaiCharithaAkula,Jihan                ArXiv preprint, abs/2311.04257.
                    Yang,ShushengYang,AdithyaIyer,XichenPan,etal.         ShukangYin,ChaoyouFu,SiruiZhao,KeLi,XingSun,
                    2024a. Cambrian-1: A fully open, vision-centric          Tong Xu, and Enhong Chen. 2023a. A survey on
                    exploration of multimodal llms.    ArXiv preprint,       multimodal large language models. ArXiv preprint,
                    abs/2406.16860.                                          abs/2306.13549.
                                                                     15145
                   Zhenfei Yin, Jiong Wang, Jianjian Cao, Zhelun Shi,             of language models with zero-init attention. ArXiv
                      Dingning Liu, Mukai Li, Xiaoshui Huang, Zhiyong             preprint, abs/2303.16199.
                     Wang, Lu Sheng, LEI BAI, Jing Shao, and Wanli             Renrui Zhang, Dongzhi Jiang, Yichi Zhang, Haokun
                      Ouyang. 2023b. Lamm: Language-assisted multi-               Lin, Ziyu Guo, Pengshuo Qiu, Aojun Zhou, Pan
                      modal instruction-tuning dataset, framework, and            Lu, Kai-Wei Chang, Peng Gao, et al. 2024b. Math-
                      benchmark. In Advances in Neural Information Pro-           verse: Does your multi-modal llm truly see the di-
                      cessing Systems, volume 36, pages 26650–26685.              agrams in visual math problems?       arXiv preprint
                      Curran Associates, Inc.                                     arXiv:2403.14624.
                   Alex Young, Bei Chen, Chao Li, Chengen Huang,               Bo Zhao, Boya Wu, and Tiejun Huang. 2023. Svit:
                      Ge Zhang, Guanwei Zhang, Heng Li, Jiangcheng                Scaling up visual instruction tuning. ArXiv preprint,
                      Zhu, Jianqun Chen, Jing Chang, et al. 2024. Yi:             abs/2307.04087.
                      Open foundation models by 01. ai. ArXiv preprint,
                      abs/2403.04652.                                          Haozhe Zhao, Zefan Cai, Shuzheng Si, Xiaojian Ma,
                   Weihao Yu, Zhengyuan Yang, Linjie Li, Jianfeng Wang,           Kaikai An, Liang Chen, Zixuan Liu, Sheng Wang,
                      Kevin Lin, Zicheng Liu, Xinchao Wang, and Lijuan            WenjuanHan,andBaobaoChang.2024. Mmicl: Em-
                     Wang.2024. MM-vet: Evaluating large multimodal               powering vision-language model with multi-modal
                      models for integrated capabilities. In Proceedings of       in-context learning. The Twelfth International Con-
                      the 41st International Conference on Machine Learn-         ference on Learning Representations.
                      ing, volume235ofProceedingsofMachineLearning             BoyuanZheng,BoyuGou,JihyungKil,HuanSun,and
                     Research, pages 57730–57754. PMLR.                           YuSu.2024. Gpt-4v(ision) is a generalist web agent,
                   Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng,              if grounded. In Forty-first International Conference
                      RuoqiLiu,GeZhang,SamuelStevens,DongfuJiang,                 onMachineLearning.
                     WeimingRen,YuxuanSun,etal.2024. Mmmu: A                   Luowei Zhou, Hamid Palangi, Lei Zhang, Houdong Hu,
                      massive multi-discipline multimodal understanding           Jason J. Corso, and Jianfeng Gao. 2020. Unified
                      and reasoning benchmark for expert agi. In Pro-             vision-language pre-training for image captioning
                      ceedings of the IEEE/CVF Conference on Computer             and VQA. In Proceedings of the AAAI Conference
                     Vision and Pattern Recognition, pages 9556–9567.             on Artificial Intelligence, 34, pages 13041–13049.
                   MertYuksekgonul, Federico Bianchi, Pratyusha Kalluri,          AAAIPress.
                      DanJurafsky, and James Zou. 2023. When and why           Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and
                     vision-language models behave like bags-of-words,            MohamedElhoseiny. 2023. Minigpt-4: Enhancing
                      and what to do about it? In The Eleventh Interna-           vision-language understanding with advanced large
                      tional Conference on Learning Representations.              language models. ArXiv preprint, abs/2304.10592.
                   Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov,
                      and Lucas Beyer. 2023. Sigmoid loss for language
                      image pre-training. In Proceedings of the IEEE/CVF
                     International Conference on Computer Vision, pages
                     11975–11986.
                   Pan Zhang, Xiaoyi Dong, Yuhang Zang, Yuhang Cao,
                      Rui Qian, Lin Chen, Qipeng Guo, Haodong Duan,
                      Bin Wang, Linke Ouyang, Songyang Zhang, Wen-
                     wei Zhang, Yining Li, Yang Gao, Peng Sun, Xinyue
                      Zhang,WeiLi,JingwenLi,WenhaiWang,HangYan,
                      Conghui He, Xingcheng Zhang, Kai Chen, Jifeng
                      Dai, Yu Qiao, Dahua Lin, and Jiaqi Wang. 2024a.
                      Internlm-xcomposer-2.5: A versatile large vision lan-
                      guage model supporting long-contextual input and
                      output. ArXiv preprint, abs/2407.03320.
                   Pengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei
                     Yang, Lei Zhang, Lijuan Wang, Yejin Choi, and Jian-
                      feng Gao. 2021. Vinvl: Revisiting visual representa-
                      tions in vision-language models. In IEEE Conference
                      on Computer Vision and Pattern Recognition, CVPR
                     2021, virtual, June 19-25, 2021, pages 5579–5588.
                      Computer Vision Foundation / IEEE.
                   Renrui Zhang, Jiaming Han, Aojun Zhou, Xiangfei Hu,
                      Shilin Yan, Pan Lu, Hongsheng Li, Peng Gao, and
                     YuQiao.2023. Llama-adapter: Efficient fine-tuning
                                                                          15146
                          Table of Contents in Appendix
                           A EvaluationPrompts                                                                                                                                                15
                           B ApproximatingHumanExpertPerformance                                                                                                                              16
                           C EnsuringQualityandDiversityofExpandedOptions                                                                                                                     18
                           D AnalysisofCoT’sImpact                                                                                                                                            19
                           E ExperimentalSetupofVisionEncoderImpact                                                                                                                           20
                           F ComparisonofGPT-4o’sresponsesbetweenStandardandVisionInputsettings                                                                                               20
                           G CoTvs. DirectAcc: ModelDifferencesAcrossDisciplines                                                                                                              21
                           H ComparisonWithandWithoutAugmentedOptions                                                                                                                         21
                           I     ComparisonofModelOutputsAcrossDifferentInputModes                                                                                                            22
                           J Qualitative Examples                                                                                                                                             24
                                 J.1      Art and Design: Art . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                       24
                                 J.2      Art and Design: Art Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                        25
                                 J.3      Art and Design: Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                        26
                                 J.4      Art and Design: Music . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                         27
                                 J.5      Business: Accounting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                        28
                                 J.6      Business: Economics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                         29
                                 J.7      Business: Finance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                       30
                                 J.8      Business: Manage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                        31
                                 J.9      Business: Marketing                  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . . . . . .          32
                                 J.10 Science: Biology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                            33
                                 J.11 Science: Chemistry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                            34
                                 J.12 Science: Geography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                            35
                                 J.13 Science: Math . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                           36
                                 J.14 Science: Physics                   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . . . . . .          37
                                 J.15 Health and Medicine: Basic Medical Science . . . . . . . . . . . . . . . . . . . . . . .                                                                38
                                 J.16 Health and Medicine: Clinical Medicine . . . . . . . . . . . . . . . . . . . . . . . . . .                                                              39
                                 J.17 Health and Medicine: Diagnostics and Laboratory Medicine . . . . . . . . . . . . . . .                                                                  40
                                 J.18 Health and Medicine: Pharmacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                               41
                                 J.19 Health and Medicine: Public Health . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                              42
                                 J.20 Humanities and Social Science: History . . . . . . . . . . . . . . . . . . . . . . . . . .                                                              43
                                 J.21 Humanities and Social Science: Literature . . . . . . . . . . . . . . . . . . . . . . . . .                                                             44
                                 J.22 Humanities and Social Science: Sociology . . . . . . . . . . . . . . . . . . . . . . . . .                                                              45
                                 J.23 Humanities and Social Science: Psychology . . . . . . . . . . . . . . . . . . . . . . . .                                                               46
                                 J.24 Tech and Engineering: Agriculture . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                             47
                                 J.25 Tech and Engineering: Architecture and Engineering . . . . . . . . . . . . . . . . . . .                                                                48
                                 J.26 Tech and Engineering: Computer Science . . . . . . . . . . . . . . . . . . . . . . . . .                                                                49
                                 J.27 Tech and Engineering: Electronics . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                             50
                                 J.28 Tech and Engineering: Energy and Power . . . . . . . . . . . . . . . . . . . . . . . . .                                                                51
                                 J.29 Tech and Engineering: Materials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                             52
                                 J.30 Tech and Engineering: Mechanical Engineering . . . . . . . . . . . . . . . . . . . . . .                                                                53
                                                                                                         15147
        A EvaluationPrompts
          Evaluation Prompts: OCR Prompt
          OCRPrompt:
          "Write out the multiple-choice question in the image and then solve it. The last line of your response should be of the
          following format: ’Answer: $LETTER’ (without quotes) where LETTER is one of the options. Think step by step
          before answering."
          w/oOCRPrompt:
          "Answer the following multiple-choice question in the image. The last line of your response should be of the following
          format: ’Answer: $LETTER’ (without quotes) where LETTER is one of the options. Think step by step before
          answering."
          Evaluation Prompts: Direct vs CoT
          Direct:
          "Answerdirectly with the option letter from the given choices."
          CoT:
          "Answer the following multiple-choice question. The last line of your response should be of the following format:
          ’Answer: $LETTER’(without quotes) where LETTER is one of the options. Think step by step before answering."
          Evaluation Prompts: OCR Task
          OCRTaskPrompt:
          "Extract and output the full text of the question, including any introductory descriptions, as well as the corresponding
          answer choices from the multiple-choice question in the image. Exclude any text from associated images or the question
          number. Perform OCR only; do not attempt to solve the question."
          Evaluation Prompts: Split Response Task
          Split Response Task Prompt:
          Yourtask is to split the given answer into two distinct parts: the part that describes the question and the part that analyzes
          the answer. This is a splitting task, so ensure you do not omit any content or generate any additional content not present
          in the input. Follow these guidelines:
          1. Description of the Question:
          - Extract the portion of the answer that describes the question being addressed.
          - Ensure that this part is clear and provides enough context to understand the question.
          2. Analysis of the Answer:
          - Extract the portion of the answer that provides the analysis or reasoning behind the answer.
          - Ensure that this part is detailed and provides a complete explanation or solution.
          Please split the following answer into the two parts described above and output them in JSON format:
          Answer: $LETTER
          {
          "description_of_question": "Extracted description of the question",
          "analysis_of_answer": "Extracted analysis of the answer"
          }
                                 15148
                  B ApproximatingHumanExpertPerformance
                  Establishing a reliable benchmark for human performance on MMMU-Pro is crucial to evaluating the true
                  capabilities of multimodal AI models. Conducting new and rigorous human evaluations, however, is both
                  time-consuming and expensive. To address this issue, we developed an approximation method based on
                  the existing human evaluation data from the original MMMU. The resulting estimates are presented in
                  Table 4.
                                           Overall   Art &    Business   Science   Health &   Human& Tech&
                                                     Design                        Medicine   Social Sci.   Eng.
                                 Low         73.0     77.4      77.9       78.5      65.2        63.6       73.5
                                 Medium      80.8     83.3      88.4       84.9      72.8        75.8       78.2
                                 High        85.4     85.7      89.5       86.0      84.8        81.8       84.4
                  Table 4: Estimated human performance on MMMU-Pro across different disciplines, based on the original MMMU
                  evaluation data. The table presents low, medium, and high performance estimates in terms of overall accuracy and
                  discipline-specific breakdowns.
                    Thevalidity of using this approximation method relies on several key factors. Firstly, the core content
                  and difficulty of the questions in MMMU-Pro remain unchanged from those in the original MMMU,
                  supporting the use of the original human performance data as a valid proxy. Secondly, in the initial
                  MMMUevaluation,humanexpertswererequiredtodocumenttheirproblem-solving processes, which
                  significantly reduced the likelihood of random guessing. For questions lacking detailed solution processes,
                  wesimulated random selection from expanded candidate options and recalculated the accuracy. Finally,
                  humanexperts inherently excel at seamlessly integrating visual and textual information, suggesting that
                  their performance in a purely visual input setting would be analogous to their performance in the original
                  format.
                    Given that the 577 questions in MMMU-Pro are sourced from the MMMU validation set, we extracted
                  the corresponding data from the evaluations of the 90 human experts involved in the original MMMU
                  assessment. We categorized and counted these questions based on whether they included a detailed
                  solution process (w/ Solution) or were subjected to guessing due to the lack of a detailed solution process
                  (w/o Solution). We then counted the correct and incorrect answers in each category, as summarized in
                  Table 5. Specifically, the categorization is defined in Equation 1:
                                           Num       =Num               +Num
                                                total        w/o Solution       w/ Solution
                                                     =Num                     +Num                                           (1)
                                                             w/o Solution(wrong)      w/o Solution(correct)
                                                       +Num                    +Num
                                                               w/ Solution(wrong)      w/ Solution(correct)
                    Using these counts, we can estimate the lower bound of human performance on MMMU-Pro with
                  Equation 2:
                             NumEstimate(correct) = Numw/Solution(correct) + Numw/oSolution × Numw/oSolution             (2)
                                                                                   Num
                                                                                        total
                    This formula considers the number of correctly solved questions with detailed solution processes and
                  the proportion of correctly guessed questions without detailed solution processes, ensuring a conservative
                  estimate.
                    In summary, by leveraging the original MMMU human evaluation data and applying our estimation
                  method, we provide a reasonable approximation of human performance on MMMU-Pro. This approach
                  maintains the human performance benchmark without incurring the substantial costs associated with new
                  expert evaluations.
                                                                      15149
                                                                           Low                                    Medium                                    High
                                                           w/o Sol.    w/Sol.      Est.     Acc    w/o Sol.   w/Sol.      Est.      Acc     w/o Sol.   w/Sol.      Est.     Acc
                                                             (w/c)     (w/c)      (w/c)              (w/c)     (w/c)      (w/c)               (w/c)     (w/c)     (w/c)
                                     Art &Design             4/11      11/64      19/65     77.4      5/1       8/70      14/70     83.3       4/2       6/72     12/72     85.7
                                        Art                   2/2       2/14      4/14      77.8      1/0       1/16      2/16      88.9       0/1       0/17      1/17     94.4
                                        Art Theory            1/2       2/18      5/18      78.3      1/1       2/19      4/19      82.6       1/1       3/18      5/18     78.3
                                        Design                1/4       4/10      5/10      66.7      1/0       2/12      3/12      80.0       1/0       1/13      2/13     86.7
                                        Music                 0/3       3/22      6/22      78.6      2/0       3/23      5/23      82.1       2/0       2/24      4/24     85.7
                                     Business                4/11      11/73      21/74     77.9      4/1       6/84      11/84     88.4       2/3       5/85     10/85     89.5
                                        Accounting            0/3       3/19      6/19      76.0      2/0       1/22      3/22      88.0       0/2       1/22      3/22     88.0
                                        Economics             0/4       4/13      5/13      72.2      1/0       1/16      2/16      88.9       1/0       0/17      1/17     94.4
                                        Finance               1/2       2/15      4/15      78.9      0/0       1/18      1/18      94.7       0/0       2/17      2/17     89.5
                                        Manage                2/2       2/8        4/9      69.2      1/1       2/9        4/9      69.2       1/1       2/9       4/9      69.2
                                        Marketing             1/0       0/18      2/18      90.0      0/0       1/19      1/19      95.0       0/0       0/20      0/20    100.0
                                     Science                 3/12      12/72      20/73     78.5      3/1      10/79      14/79     84.9       3/1       9/80     13/80     86.0
                                        Biology               0/5       5/13      7/13      65.0      2/0       5/13      7/13      65.0       1/1       5/13      7/13     65.0
                                        Chemistry             0/3       3/14      4/14      77.8      0/1       2/15      3/15      83.3       1/0       2/15      3/15     83.3
                                        Geography             2/0       0/8        2/8      80.0      0/0       1/9        1/9      90.0       0/0       1/9       1/9      90.0
                                        Math                  1/4       4/14      7/14      66.7      1/0       1/19      2/19      90.5       1/0       1/19      2/19     90.5
                                        Physics               0/0       0/23      1/23      95.8      0/0       1/23      1/23      95.8       0/0       0/24      0/24    100.0
                                     Health & Med.           3/22      22/58      32/60     65.2      9/0      17/66      25/67     72.8       5/4       6/77     14/78     84.8
                                        Basic Med.            2/2       2/9       4/10      71.4      1/0       2/11      3/11      78.6       1/0       1/12      2/12     85.7
                                        Clinical Med.         1/6       6/8        9/9      50.0      3/0       5/10      7/11      61.1       2/1       1/14      3/15     83.3
                                        Diagnostics           0/6       6/14      9/14      60.9      3/0       4/16      7/16      69.6       2/1       2/18      5/18     78.3
                                        Pharmacy              0/3       3/13      4/13      76.5      1/0       3/13      4/13      76.5       0/1       1/15      2/15     88.2
                                        Public Health         0/5       5/14      6/14      70.0      1/0       3/16      4/16      80.0       0/1       1/18      2/18     90.0
                                     Humani. &Soc.           5/14      14/40      24/42     63.6      3/5       9/49      16/50     75.8       5/3       5/53     12/54     81.8
                                        History               1/4       4/4        6/4      40.0      1/0       1/8        2/8      80.0       0/1       1/8       2/8      80.0
                                        Literature            2/2       2/15      5/16      76.2      1/2       2/16      5/16      76.2       2/1       0/18      3/18     85.7
                                        Sociology             0/5       5/8        7/9      56.3      1/2       4/9       6/10      62.5       2/1       2/11      4/12     75.0
                                        Psychology            2/3       3/13      6/13      68.4      0/1       2/16      3/16      84.2       1/0       2/16      3/16     84.2
                                     Tech&Eng.               3/25      25/106    39/108     73.5      9/4     20/114     32/115     78.2       6/7     10/124    23/124     84.4
                                        Agriculture           0/6       6/10      9/10      52.6      1/2       5/11      8/11      57.9       2/1       2/14      5/14     73.7
                                        Archi. Eng.           2/2       2/17      5/17      77.3      1/1       2/18      4/18      81.8       1/1       0/20      2/20     90.9
                                        Computer Sci.         0/0       0/17      2/17      89.5      1/0       1/17      2/17      89.5       0/1       2/16      3/16     84.2
                                        Electronics           0/0       0/8        1/8      88.9      0/0       0/9        0/9     100.0       0/0       0/9       0/9     100.0
                                        Energy Power          0/4       4/20      6/20      76.9      2/0       4/20      6/20      76.9       1/1       1/23      3/23     88.5
                                        Materials             0/3       3/22      5/22      81.5      1/1       3/22      5/22      81.5       1/1       2/23      4/23     85.2
                                        Mechanical Eng.      1/10      10/12      13/12     48.0      3/0       5/17      8/17      68.0       1/2       3/19      6/19     76.0
                                     Overall                 22/95     95/413    156/421    73.0    33/12     70/462    111/466     80.8     25/20     41/491    84/493     85.4
                          Table 5: Detailed breakdown of estimated human performance on MMMU-Pro for low, medium, and high
                          performance levels across various disciplines. Abbreviations: "w/o Sol." (without Solution), "w/ Sol." (with
                          Solution), "Est." (Estimate), and "w/c" (number of wrong/correct answers).
                                                                                                       15150
       C EnsuringQualityandDiversityofExpandedOptions
       Expanding the number of answer options naturally increases the difficulty of the benchmark, but its
       effectiveness relies heavily on the quality, diversity, and contextual relevance of these additional options.
       To ensure this, we implemented a rigorous multi-stage validation process, combining automated and
       humanefforts to produce high-quality results.
        Initial Model-Based Option Augmentation and Filtering. We began by leveraging large language
       models (LLMs) to automate the initial generation and filtering of expanded options. Specifically, GPT-4o
       wasusedtogenerate additional options, while Claude 3.5 acted as a preliminary filter to remove options
       that were contextually irrelevant or logically inconsistent. This step significantly reduced the workload for
       humanreviewers by pre-screening the candidates.
        Two Rounds of Human Review. To further enhance quality and eliminate potential issues, we
       conducted two rounds of meticulous human validation:
       • First Round of Review: Individual reviewers assessed the expanded options for each question. They
        ensured that the options were diverse, logically distinct, and free from ambiguity. If any flaws were
        identified, reviewers were instructed to correct the issues or create new options to maintain the integrity
        of the question.
       • Second Round of Review: A double-check process followed, involving two additional human ex-
        perts who cross-validated each question and its options. This iterative step eliminated any residual
        inconsistencies or errors and provided an additional layer of assurance.
        Bycombiningautomatedmethodswithmulti-stage human validation, we ensured that each expanded
       option met high standards of quality, robustness, and alignment with the intended challenges of the
       benchmark. This approach not only addressed potential weaknesses in automated generation but also
       significantly improved the reliability of the dataset.
                           15151
                 D AnalysisofCoT’sImpact
                                        GPT 4o                                                      LLAVA OV 72B
                                    CoT Acc     Direct Acc                                         CoT Acc     Direct Acc
                      Accounting                53.45%                               Accounting          22.41%
                                                     68.97%                                                  31.03%
                      Agriculture        31.67%                                      Agriculture      16.67%
                                          36.67%                                                      16.67%
                    Architecture&   15.00%                                         Architecture&   10.00%
                      Engineering        31.67%                                      Engineering           26.67%
                            Art                   60.38%                                   Art                 35.85%
                                                    66.04%                                              20.75%
                       Art Theory                    70.91%                           Art Theory                     49.09%
                                                     70.91%                                               25.45%
                  Basic Medical Sci.           51.92%                            Basic Medical Sci.     21.15%
                                              48.08%                                                   19.23%
                         Biology            40.68%                                      Biology           25.42%
                                               52.54%                                                13.56%
                       Chemistry            41.67%                                    Chemistry          23.33%
                                              46.67%                                                      25.00%
                     Clinical Med.            47.46%                                Clinical Med.     16.95%
                                               52.54%                                              10.17%
                    Computer Sci.           40.00%                                 Computer Sci.            28.33%
                                                53.33%                                                       31.67%
                         Design                        75.00%                           Design                 36.67%
                                                         81.67%                                         20.00%
                     Diagnostics&       30.00%                                      Diagnostics&   10.00%
                        Lab Med.          36.67%                                       Lab Med.         20.00%
                       Economics             45.76%                                   Economics             28.81%
                                                   62.71%                                                           45.76%
                      Electronics    18.33%                                          Electronics          25.00%
                                             43.33%                                                           33.33%
                   Energy & Power   17.24%                                        Energy & Power      17.24%
                                           37.93%                                                     17.24%
                         Finance        30.00%                                          Finance          23.33%
                                                 56.67%                                                       33.33%
                      Geography           34.62%                                     Geography             26.92%
                                             46.15%                                                           32.69%
                         History             44.64%                                     History            26.79%
                                               51.79%                                                       28.57%
                       Literature                       80.77%                        Literature                        53.85%
                                                        78.85%                                                   40.38%
                        Manage              42.00%                                     Manage            24.00%
                                            40.00%                                                   14.00%
                       Marketing            40.68%                                    Marketing          23.73%
                                                 55.93%                                               16.95%
                        Materials  11.67%                                              Materials        21.67%
                                      23.33%                                                        11.67%
                          Math            35.00%                                         Math        15.00%
                                          35.00%                                                          25.00%
                   Mech. Engineer     23.73%                                      Mech. Engineer         23.73%
                                          33.90%                                                        20.34%
                          Music          33.33%                                          Music             26.67%
                                     20.00%                                                          15.00%
                       Pharmacy              43.86%                                   Pharmacy              29.82%
                                                54.39%                                                        33.33%
                         Physics            40.00%                                      Physics         21.67%
                                               51.67%                                                   21.67%
                      Psychology             45.00%                                  Psychology         20.00%
                                              46.67%                                                   18.33%
                     Public Health            46.55%                                Public Health         24.14%
                                                55.17%                                             10.34%
                       Sociology                55.56%                                Sociology                  40.74%
                                                  59.26%                                                         38.89%
                  Figure 9: Comparison of CoT and Direct Accuracy across subcategories within major domains for GPT-4o and
                                                           LLaVA-OneVision72B.
                                                                    15152
                             E ExperimentalSetupofVisionEncoderImpact
                             Toevaluate the influence of vision encoders on model performance, we conduct experiments using the
                             open-source architecture Cambrian-1. These experiments fix both the training data (Cambrian-1 1M SFT
                             data) and the large language model (Llama 3.1 8B) to isolate the impact of different vision encoders.
                             Inspired by Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs (Tong et al.,
                             2024a), we follow their methodology by interpolating visual features to a fixed number of tokens (576)
                             and concatenating them along the feature dimension.
                             F ComparisonofGPT-4o’sresponsesbetweenStandardandVisionInputsettings
                                                                                                                           GPT-4o (Standard Setting): To determine the main point of the
                                                                                                                           cartoon, let's analyze the visual and textual elements:
                                                                                                                           ThecartoonbyJudgedepictstheprogression of the United States
                                                                                                                           with figures representing different years: 1783, 1803, 1819, 1861,
                                                                                                                           1898, and 1899. In each figure, the United States is shown
                                                                                                                           acquiring moreterritories:
                                                                                                                           •   1783: The United States starts with the 13 states.
                                                                                                                           •   1803: The Louisiana Purchase is acquired from France.
                                                                                                                           •   1819: Additional territory is acquired from Spain.
                                                                                                                           •   1861: New states are admitted, expanding the Union.
                                                                                                                           •   1898: The United States gains control over territories from the
                                                                                                                               Spanish-American War.
                                                                                                                           •   1899: The United States comes into possession of various new
                                                                                                                               colonies such as Cuba and the Philippines.
                                                                                                                           The final image shows the United States (personified as "Uncle
                                                                                                                           Sam") receiving approval and open arms from other nations,
                                                                                                                           which suggests the U.S. is being welcomed by the international
                                                                                                                           community.
                                                                                                                           Given this depiction, the cartoon seems to be promoting the idea
                                                                                                                           that the expansion of the United States was a natural progression
                                                                                                                           that leads to international approval and friendly relations with
                                                                                                                           other nations. This aligns most closely with option A. Answer: A
                                 GPT-4o (Vision Setting): The multiple-choice question in the image is: No. 6: Image 1 - Which of the following reflects a main point of
                                 the cartoon? Options: (A) The United States' acquisition of overseas colonies is part of the natural progression for the country and will
                                 gain the approval of foreign powers. (B) The United States' acquisition of overseas territories is a response to the imperialist actions of
                                 other countries. (C) The United States' acquisition of overseas territories is dangerous and could lead to war with other imperialist
                                 powers. (D) The United States' acquisition of overseas territories is necessary to bring civilization to the natives of the newly acquired
                                 territories. (E) The United States' acquisition of overseas colonies represents a break from the democratic traditions that had guided
                                 America since its founding. (F) The United States' acquisition of overseas territories will lead to economic prosperity for the country. (G)
                                 The United States' acquisition of overseas colonies is a reflection of the country's greed and imperialism. (H) The United States'
                                 acquisition of overseas colonies is a violation of human rights and international law. (I) The United States' acquisition of overseas
                                 territories is a sign of the country's declining power. (J) The United States' acquisition of overseas territories is a necessary step in
                                 maintainingits global dominance.
                                 To determine the main point of the cartoon, we need to analyze the visual content and any text present in the cartoon. The cartoon
                                 appears to depict a negative view of U.S. expansionism, comparing the U.S. to European imperial powers who are often associated with
                                 greed and exploitation. Therefore, the main point likely reflects a critical stance on the U.S.'s actions. Answer: (G)
                                 Analysis: In the vision-only input scenario, the model accurately extracts text from the photo. However, its response tends to be more
                                 basic and lacks in-depth analysis. The integration of both visual and textual information appears to increase the cognitive load on the
                                 vision module, which mayresult in a higher likelihood of errors.
                                 [Note: Portions of the original model's response have been omitted for brevity.]
                                               Figure 10: Comparison of GPT-4o’s responses between Standard and Vision Input settings.
                                                                                                                   15153
                  G CoTvs.DirectAcc: ModelDifferencesAcrossDisciplines
                         Discipline                           LLaVA-OneVision-72B                         GPT4o
                                                        CoTAcc DirectAcc Difference CoTAcc DIRECTAcc Difference
                         Art and Design                  20.42%      37.53%      -17.12%     63.14%       61.55%        1.58%
                         Science                         23.89%      22.61%       1.28%      46.67%       38.46%        8.22%
                         Business                        29.26%      24.50%       4.76%      57.45%       42.79%       14.66%
                         Humanities and Social Science   32.14%      36.60%      -4.46%      60.08%       57.87%        2.21%
                         Health and Medicine             19.22%      20.78%      -1.56%      49.68%       44.34%        5.34%
                         TechandEngineering              22.98%      20.65%       2.33%      37.72%       23.23%       14.49%
                  Table 6: Comparison of CoT and direct accuracy of two representative models across disciplines in the Vision Input
                  setting. Difference = CoT Acc. - Direct Acc.
                  H ComparisonWithandWithoutAugmentedOptions
                     Question: A solid copper bar of circular cross section has length ㌵	 = 	1.25	㌵and shear modulus of elasticity
                     ㌵	 = 	45	GPa. The bar is designed to carry a 250	㌵ 0 ㌵	torque acting at the ends. If the allowable shear stress is
                     30	㌵㌵㌵ and the allowable angle of twist between the ends is 2.5°, what is the minimum required diameter?
                     Original Options:
                     (A) 35.7 mm    (B) 45.7 mm (C)55.7 mm
                     AugmentedOptions:
                     (D) 25.7 mm (E) 40.7 mm (F) 50.7mm      (G) 30.7mm
                     (H)20.7mm (I)60.7 mm
                     GPT-4o (w/o augment options): To determine the minimum required diameter of the solid copper bar, we
                     need to check two conditions: 1. The maximum shear stress condition. 2. The allowable angle of twist
                     condition. Step 1: Maximum Shear Stress Condition. The torsional shear stress for a solid circular shaft is
                                        ⁄
                     given by: τ =	T	⋅r ㌵, where τ is the shear stress, T is the applied torque, r	 is the radius of the shaft, ㌵ is the
                                                                                             !⁄
                     polar moment of inertia for a solid circular section (J	 =	πr             2) .  Rewriting the shear stress
                     formula…Conclusion: Comparing the two diameters, the larger value will govern, as it ensures both
                     conditions are met. Therefore, the minimum required diameter is given by: Answer: A
                     GPT-4o (w/ augment options): To determine the minimum required diameter of the solid copper bar, we
                     needtoconsiderboth the maximumallowableshear stress and the maximum allowable angle of twist. Step 1:
                     Maximum Allowable Shear Stress. The relationship between the torque T, the shear stress τ, and the polar
                     moment of inertia ㌵ for a circular cross-section is given by... Therefore, the minimum required diameter is:
                     d	 ≈ 55.68	mm. The closest value greater than or equal to 55.68 mm from the options provided is: Answer: C
                     Analysis: Both solutions are incorrect; however, with only three options in the original setup, the model
                     happenstoselectthecorrectanswerbychance.
                                 Figure 11: Comparison of GPT-4o’s responses with and without augmented options.
                                                                         15154
                I  ComparisonofModelOutputsAcrossDifferentInputModes
                                                                GPT-4o (Standard Setting): Let's analyze the options step 
                                                                by  step  based  on  the  given  diagram  and  the  known 
                                                                characteristics of an elliptical orbit: 1. A. the planet's orbit 
                                                                is  a  perfect  circle.  Incorrect.  An  elliptical  orbit  is  not  a 
                                                                perfect circle. A perfect circle would have an eccentricity 
                                                                of 0, and the diagram clearly shows an ellipse. 2. B. the 
                                                                eccentricity  of  the  orbit  is  greater  than  1.  Incorrect.  The 
                                                                eccentricity of an elliptical orbit is always between 0 and 1. 
                                                                An eccentricity greater than 1 would indicate a hyperbolic 
                                                                trajectory. 3. C. the eccentricity of the orbit is equal to 1. 
                                                                Incorrect. An eccentricity of 1 would indicate a parabolic 
                                                                trajectory, not an elliptical orbit. 4. D. the sun might be at 
                                                                point  E.  Incorrect.  The  Sun  is  at  one  of  the  foci  of  the 
                                                                ellipse, not at the periphery. 5. E. the sun might be at point 
                                                                C. Incorrect. Point C is in the center of the ellipse, and the 
                                                                Sun is at one of the foci of the ellipse. 6. F. the sun might 
                                                                be at point A. Incorrect. Point A is on the boundary of the 
                                                                ellipse, and the Sun is at one of the foci of the ellipse. 7. G. 
                                                                the  eccentricity  of  the  orbit  is  less  than  zero.  Incorrect. 
                                                                Eccentricity cannot be less than zero. It ranges from 0 to 1 
                                                                for an ellipse. 8. H. the sun might be at point B. Correct. 
                                                                Point B is one of the foci of the ellipse, and the Sun is 
                                                                located at one of the foci in an elliptical orbit. 9. I. the sun 
                                                                might be at point D. Incorrect. Point D is not one of the 
                                                                foci of the ellipse. 10. J. the eccentricity of the orbit is zero. 
                  GroundTruth:(H)thesunmightbeatpointA          Incorrect.  An  eccentricity  of  0  would  indicate  a  circular 
                                                                orbit, not an elliptical one. Therefore, the correct statement 
                                                                is: Answer: H
                  GPT-4o (Vision Setting): The multiple-choice question is as follows: No. 27: [image 1] The elliptical orbit of a 
                  planet around the Sun is shown on the diagram. Which of the following statements is true? Options:(A) the planet’s 
                  orbit is a perfect circle(B) the eccentricity of the orbit is greater than 1(C) the eccentricity of the orbit is equal to 1(D) 
                  the sun might be at point E(E) the sun might be at point C(F) the sun might be at point A(G) the eccentricity of the 
                  orbit is less than zero(H) the sun might be at point B(I) the sun might be at point D(J) the eccentricity of the orbit is 
                  zero. Step-by-step reasoning:1. The orbit shown is elliptical, not circular, since option (A) is incorrect.2. Eccentricity 
                  of an ellipse ranges from 0 to 1. For a circle, eccentricity is 0, and as it becomes more elongated, the eccentricity 
                  approaches 1 but never exceeds 1. So, options (B) and (C) cannot be correct.3. A physical property cannot be less 
                  than zero for a realistic orbit's eccentricity. Thus, option (G) is incorrect.4. In an elliptical orbit, the Sun is located at 
                  one of the foci, lying on the major axis, not just anywhere, so some of the provided points can be eliminated based 
                  on typical placement of the foci in an elliptical diagram: Point A is near the center of the ellipse, which isn't realistic 
                  for the Sun's position. Point B is not on the major axis. Point E is outside the elliptical orbit. Point D is close to the 
                  ellipse’s vertex, making it unlikely as the focus.5. Point C logically and likely appears to be at one of the foci of the 
                  ellipse.After evaluation, the best-fit option: Answer: (E)
                Figure 12: Example of GPT-4o output comparison in different settings. Descriptions are highlighted in orange, and
                analyses are highlighted in light red.
                                                              15155
                                                                                                           GPT-4o (Standard Setting): Examining 
                                                                                                           the radiograph, several findings suggest 
                                                                                                           an  abnormality  in  the  gastrointestinal 
                                                                                                           tract. The signs interpreted here are the 
                                                                                                           presence  of  distended  loops  of  bowel 
                                                                                                           with  air-fluid  levels,  especially  in  the 
                                                                                                           central  part  of  the  abdomen. Here's  a 
                                                                                                           step-by-step    approach.     1.   Identify 
                                                                                                           Structures:  The  intestines  are  centrally 
                                                                                                           located,  typically  showing  loops  that 
                                                                                                           can  be  traced  through  an  x-ray.2. 
                                                                                                           Abnormal  Findings:  Look  out  for 
                                                                                                           distended  loops  and  presence  of 
                                                                                                           multiple air-fluid levels consistent with 
                                                                                                           obstruction or abnormality. 3. Location 
                                                                                                           Specificity:  The  loops  involved  appear 
                                                                                                           to  be  small  bowel  loops  rather  than 
                                                                                                           colonic, suggesting the small intestine. 4. 
                                                                                                           Ruling Out Options: The liver, pancreas, 
                                                                                                           spleen,    gallbladder,     kidney,     and 
                                                                                                           stomach are not displaying  any  direct 
                                                                                                           signs of abnormality on this image. The 
                         GroundTruth:(F)Gallbladder                                                        duodenum  is  a  part  of  the  small 
                         GPT-4o (Vision Setting): The multiple-choice question is as follows:              intestine,  and  any  segment  could  be 
                         No.  16:  What  organ  appears  abnormal  in  this  radiograph?  [image           implicated. However, such generalized 
                         1]Options:(A) Liver(B) Small Intestine(C) Duodenum(D) Pancreas(E)                 distension  is  more  typical  of  issues 
                         Spleen(F) Gallbladder(G) Kidney(H) Esophagus(I) Large Intestine(J)                broadly  affecting  the  small  intestine 
                         Stomach. To  determine  which  organ  appears  abnormal  in  the                  rather than a specific segment like the 
                         radiograph:1. Look at the structure and positioning of organs in the X-           duodenum. The large intestine typically 
                         ray.2.  Identify  any  deviations  from  what  is  considered  normal             shows haustra, which aren't prominent 
                         anatomy.3. Noticing any abnormal enlargement, peculiar shapes, or                 here. The esophagus is not visible in a 
                         shading differences. In the provided radiograph, the structure that               manner  suggesting  any  abnormality. 
                         seems  to  stand  out  as  abnormal  is  the  large  intestine  due  to  the      Final    Decision:     Considering       the 
                         displacement and presence of three white "air-fluid" levels which are             distension  and  air-fluid  levels  within 
                         quite  indicative  of  a  large  bowel  obstruction.  Answer:  (I)  Large         the  bowel  loops,  the  likely  abnormal 
                         Intestine                                                                         organ is the small intestine. Answer: B
                     Figure 13: Example of GPT-4o output comparison in different settings. Descriptions are highlighted in orange, and
                     analyses are highlighted in light red.
                                                                                    15156
                      J Qualitative Examples
                      J.1    Art and Design: Art
                                                                          Art and Design: Art
                                                                                                             GPT-4o (Standard Setting): To
                                                                                                             identify the 'panning blur’: 1.
                                                                                                             Photo 1: The subject is in focus
                                                                                                             and appears frozen in motion,
                                                                                                             which doesn’t fit the description
                                                                                                             of a panning blur. This indicates a
                                                                                                             static  background as well. 2.
                                                                                                             Photo 2: The subject is blurred
                                                                                                             due     to    motion,      and     the
                                                                                                             background isn't moving relative
                                                                                                             to the subject, which suggests
                                                                                                             another type of motion blur, not
                                                                                                             panning.     3.    Photo     3:    The
                                                                                                             background appears blurred due
                                                                                                             to the camera moving along with
                                                                                                             the   subject,   with the subject
                                                                                                             partially in focus, an effect typical
                                                                                                             of panning. The image fitting the
                                GroundTruth:(G)Photo3                                                        description of a 'panning blur' is
                                                                                                             Photo3.Answer:G
                                GPT-4o (Vision Setting): No. 6: Which of the motion effect
                                images in [image 1] is a 'panning blur’? Options: (A) Both                   Analysis: In both settings, the
                                Photo 2 and Photo 3 (B) Photo 2 (C) All of the above (D)                     model correctly identifies Photo 3
                                Both Photo 1 and Photo 2 (E) Photo 1 (F) None of the above                   as the "panning blur." The Vision
                                (G) Photo 3 A 'panning blur' involves capturing a moving                     Input combines text and image in
                                subject sharply while the background is blurred, indicating                  one, while the Standard Setting
                                movement. Photo 1 shows a stationary subject, possibly                       provides text separately. Both
                                frozen in mid-air, with no blur in the background. Photo 2                   approaches lead to the same
                                has a vertical blur, not consistent with panning motion.                     result, but Vision Input offers a
                                Photo 3 shows a moving car with a blurred background,                        moreintegratedanalysis.
                                whichischaracteristic of a panning blur. Answer: G
                                   Figure 14: Example of a different input setting in Art and Design (subfield: Art).
                                                                               BacktoAppendix
                                                                                      15157
                   J.2   Art and Design: Art Theory
                                                           Art and Design: Art Theory
                                                                                GPT-4o (Standard Setting): 1. Observation: The
                                                                                plan shows an evenly spaced grid pattern of
                                                                                columns. This suggests that there are vertical
                                                                                supports spread out at regular intervals. 2.
                                                                                Analysis of Options: Arcuated system: This
                                                                                involves the use of arches. There are no
                                                                                indications   of  arches   here.   Cantilevering:
                                                                                Involves    beams    extending    beyond    their
                                                                                supports, typically without as many vertical
                                                                                columnsasdepicted. Tensile structure: Relies on
                                                                                tension rather than columns or rigid supports.
                                                                                Not applicable here. Post and lintel system: This
                                                                                system uses vertical posts (columns) and
                                                                                horizontal lintels (beams). The grid of columns
                                                                                suggests this system could be used.      Skeletal
                            GroundTruth:(E)Skeletalstructure                    structure: Utilizes a framework, often with a
                            GPT-4o (Vision Setting): No. 11: [image 1] It       regular grid of columns and beams. This can fit
                            was likely this building used which of the          the observed plan. Groin vaults: These are
                            following architectural systems?    Options: (A)    intersecting arches, not evidenced in the grid
                            Arcuated system (B) Cantilevering (C) Tensile       pattern here. Shell structure: Thin, curved
                            structure (D) Post and lintel system (E) Skeletal   surfaces used as structural elements. The grid of
                            structure (F) Groin vaults (G) Shell structure (H)  columns does not suggest a shell structure. Fan
                            Fan vaults (I) Trabeated system (J) Geodesic        vaults: Characterized by ribbed vaults that
                            dome     From the floor plan, the dots likely       spread out like fans, not visible in the plan.
                            represent columns, which are a key feature of a     Trabeated system: Another term for the post and
                            post and lintel system. This system involves        lintel system. The grid suggests it could be used.
                            using columns (or pillars) to support horizontal    Geodesic dome: Involves a dome-like, spherical
                            beams(lintels). Answer: D                           structure composed of a network of triangles.
                                                                                There’s no indication of a dome structure here. 3.
                            Analysis: Both settings incorrectly chose the       Conclusion: The consistent grid of vertical
                            post and lintel system due to the presence of       columns is characteristic of the post and lintel
                            columns but missed that the grid layout is          system (alternative term: trabeated system) or
                            typical of a skeletal structure. The correct        skeletal structure. Given the straightforward
                            answer is E, which better fits the grid pattern of  column and beam pattern, the post and lintel
                            columnsshowninthefloorplan.                         description seems most fitting. Answer: D
                            Figure 15: Example of a different input setting in Art and Design (subfield: Art Theory).
                                                                     BacktoAppendix
                                                                           15158
                     J.3    Art and Design: Design
                                                                     Art and Design: Design
                                                                                                         GPT-4o (Standard Setting): The
                                                                                                         image features a series of blue
                                                                                                         circles   that   progressively     get
                                                                                                         smaller as they move diagonally
                                                                                                         upward from the bottom left
                                                                                                         corner toward the top right corner.
                                                                                                         1. A. Asymmetrical rhythm: The
                                                                                                         rhythm could seem asymmetrical
                                                                                                         since    the   placement      is   not
                                                                                                         mirrored or identical on both
                                                                                                         sides. 2. B. Rhythm through the
                                                                                                         use of color: The image primarily
                                                                                                         uses shades of blue. 3. C. Rare
                                                                                                         form of repetition: Repetition is
                                                                                                         present,    but    this   is   not   a
                               GroundTruth:(C)Arhythmwithamorerareform                                   particularly    rare  form.     4.  D.
                               of repetition                                                             Varied textures: The texture does
                                                                                                         not appear varied. 5. E. Rhythm
                               GPT-4o(Vision Setting): No. 24: Which of the following best               using different sizes: The circles
                               describes the image? [image 1] Options: (A) A rhythm that is              vary in size, getting smaller as
                               asymmetrical in nature (B) A rhythm achieved through the                  they move along the path. 6. F.
                               use of color (C) A rhythm with a more rare form of repetition             Symmetrical rhythm: The design
                               (D) A rhythm achieved through varied textures (E) A rhythm                is not symmetrical. 7. G. Use of
                               created by using different sizes of elements (F) A rhythm that            negative space: Negative space is
                               is symmetrical in nature (G) A rhythm achieved through the                used, but it is not the primary
                               use of negative space (H) A rhythm achieved by using                      focus for rhythm creation. 8. H.
                               shadows and highlights (I) A rhythm created by using a                    Shadows      and    highlights:    No
                               combination of shapes (J) A rhythm achieved through                       noticeable shadows or highlights
                               animation.                                                                are used to create rhythm. 9. I.
                               The image features circles of different sizes positioned in a             Combination of shapes: Only
                               specific order, forming a visual rhythm. Step-by-step solution:           circles  are   used here.       10.  J.
                               1. Option (A) mentions asymmetrical rhythm, but the image                 Animation: This is a static image.
                               shows a consistent pattern; hence symmetrical is more                     Considering the elements within
                               appropriate. 2. Option (B) mentions color usage, but the                  the image and how rhythm is
                               description best fits size. 3. Option (C) mentions a rare form            created    through the changing
                               of repetition, but common repetition fits the image. 4. Option            sizes    of    circles,    the    best
                               (D) mentions varied textures, which isn't relevant. 5. Option             description of the image is option
                               (E) mentions different sizes of elements, which is accurate. 6.           E. Answer: E
                               Option (F) mentions symmetrical rhythm and is applicable. 7.
                               Option (G) mentions negative space, which is not well                     Analysis: Both settings incorrectly
                               defined in the image. 8. Option (H) mentions shadows and                  chose E, focusing on size variation.
                               highlights, which isn't relevant.\n9. Option (I) mentions a               The key feature is the rare
                               combination of shapes, but the rhythm is specifically due to              repetition of circles decreasing in
                               size variation of the same shape. 10. Option (J) mentions                 size diagonally, making C the
                               animation, which isn't relevant. The better fit is using                  correct answer.
                               different sizes and symmetrical rhythm. Answer: (E)
                                 Figure 16: Example of a different input setting in Art and Design (subfield: Design).
                                                                             BacktoAppendix
                                                                                    15159
                     J.4    Art and Design: Music
                                                                      Art and Design: Music
                                                                                              GPT-4o (Standard Setting): To find the
                                                                                              correct key of the melody, let's analyze the
                                                                                              musical notation provided. 1. The notation
                                                                                              shows a G clef (treble clef). 2. The melody
                                                                                              starts   with an A note, followed by
                                                                                              sequences of notes: A, C, E, A. 3. The chord
                                                                                              names below the notation are: A minor, F#
                                                                                              major, C# minor, F# minor. Each key has a
                                                                                              corresponding cluster of notes:- A minor: A,
                                                                                              C, E- F# major: F#, A#, C#- C# minor: C#,
                                                                                              E, G#- F# minor: F#, A, C#. The melody's
                                                                                              notes (A, C, E, A) match the key of A minor
                                                                                              exactly. Therefore, the correct key of the
                                                                                              melody is A minor. According to the
                                                                                              provided      options,     the    first   option
                                                                                              corresponds to 'circle the first option,'
                                                                                              whichalignswithAminor.Answer:B
                                                                                              GPT-4o (Vision Setting): The multiple-
                                                                                              choice question is: "No. 5: [image I] Circle
                                                                                              the correct key of the melody. Options:(A)
                                                                                              circle the fourth option(B) circle the first
                                                                                              option(C) circle the eighth option(D) circle
                                                                                              the tenth option(E) circle the sixth option(F)
                                                                                              circle the ninth option(G) circle the second
                                                                                              option(H) circle the seventh option(I) circle
                                                                                              the third option(J) circle the fifth option” To
                                                                                              determine the correct key of the melody,
                                                                                              look at the key signature of the sheet
                                                                                              music:- The key signature has three sharps
                               GroundTruth:(G)circlethesecondoption                           (F#, C#, and G#). The possible keys with
                                                                                              three sharps are A major or F# minor. Next,
                               Analysis: Both the Standard Setting and Vision                 analyze the melody and its emphasis on
                               Input models misinterpreted the key of the melody              certain notes:- The last note of the melody
                               due to different misunderstandings of the musical              is F# (this is indicative of F# minor as the
                               notation. The Standard Setting incorrectly ignored             final note usually shows the key's tonic
                               the    key   signature,    while    the   Vision    Input      note).Therefore, the correct key of the
                               misinterpreted the tonic note of the melody. The               melody is F# minor, which corresponds to
                               correct answer is (G) circle the second option.                the fifth option. Hence: Answer: J
                                 Figure 17: Example of a different input setting in Art and Design (subfield: Music).
                                                                             BacktoAppendix
                                                                                   15160
                J.5   Business: Accounting
                                                       Business: Accounting
                                                                                                 Analysis: The
                                                                                                 Standard
                                                                                                 Setting
                                                                                                 correctly
                                                                                                 calculated the
                                                                                                 ending balance
                                                                                                 as     $0  by
                                                                                                 following  the
                                                                                                 owners' equity
                                                                                                 formula.  The
                                                                                                 Vision   Input
                                                                                                 overcomplicat
                                                                                                 ed the process
                                                                                                 by incorrectly
                                                                                                 focusing   on
                                                                                                 investments,
                                                                                                 leading to the
                        GroundTruth:(E)$0                                                        wrong answer
                                                                                                 of (A) $40,000.
                        GPT-4o (Standard Setting): Let‘s analyze the owner’s equity changes for Company 2 step by step.
                        Westartwiththegivenequationpattern:BeginningBalance+NetIncome-NetLoss+Investments;
                        Distributions = Ending Balance
                        For Company 2, we know Beginning Balance: $63,180; Net Income: $0; Net Loss: $12,000;
                        Investments: $0; Distributions: $51,180. Let (Ending Balance) be (E). Now, input the known values
                        into the equation: 63,180 + 0 - 12,000 + 0 - 51,180 = E. Simplify the equation: 63,180 - 12,000 - 51,180 =
                        E;E=63,180-63,180;E=0;SothemissingvalueforCompany2'sEndingBalanceis$0.Answer:E
                        GPT-4o(Vision Setting): To calculate the missing investments value for Company 2 in the Owners'
                        Equity schedule, we'll use the Owners' Equity formula: Ending Balance = Beginning Balance + Net
                        Income - Net Loss + Investments - Distributions. For Company 2: Beginning Balance = $63,180; Net
                        Income = $0; Net Loss = $12,000; Investments = ?; Distributions = $51,180; Ending Balance = ? We
                        needtosolvefor "Investments". First, isolate the "Investments" term in the equation: Ending Balance
                        =BeginningBalance + Net Income - Net Loss + Investments - Distributions. Substituting the known
                        values: ? = $63,180 + $0 - $12,000 + Investments - $51,180. Rearrange to solve for "Investments":
                        Investments = Ending Balance + $12,000 + $51,180 - $63,180. We will calculate it step by step: Ending
                        Balance + $12,000 + $51,180 - $63,180. Since we're not given the ending balance directly in this part
                        of the question, let's find it out using the pattern from the preceding values for other companies:
                        Company 1 Ending Balance = 163800 + 16500 - 0 + ? - 1750 = 254150. I will represent the ending
                        balance as x because it is not provided directly. However, inspecting the options, we need to find
                        the Investments without ending value explicitly needed in a traditional numerical sense by solving
                        for unknowns while seeing investment values as discreet variables from options given. Getting
                        closest match value is the next best approach: So basically add all options here to validate closest
                        equality: Let’s approximate investment towards standard net assumptions balance pattern: By
                        intuition calculation and typical signs patterning expected around investment operational equities it
                        should best reflect around $40,000. Thus, Answer: $40,000 i.e., Option (A). Answer: A
                          Figure 18: Example of a different input setting in Business (subfield: Accounting).
                                                           BacktoAppendix
                                                                 15161
                   J.6   Business: Economics
                                                                Business: Economics
                            GroundTruth:(E)$0
                            GPT-4o(Standard Setting): To calculate the Consumer Price Index (CPI) for 2014, we'll follow these
                            steps:1. Calculate the cost of the market basket in each year.   - The market basket consists of 200
                            apples and 290 textbooks.2. Calculate the base year (2015) cost of the market basket. - Cost in 2015 =
                            (200 apples * $1.10/apple) + (290 textbooks * $140/textbook)    - Cost in 2015 = (200 * $1.10) + (290 *
                            $140)   - Cost in 2015 = $220 + $40,600   - Cost in 2015 = $40,8203. Calculate the cost of the market
                            basket in 2014. - Cost in 2014 = (200 apples * $1.40/apple) + (290 textbooks * $200/textbook) - Cost
                            in 2014 = (200 * $1.40) + (290 * $200)  - Cost in 2014 = $280 + $58,000    - Cost in 2014 = $58,2804.
                            Calculate the CPI for 2014.  - CPI = (Cost of market basket in 2014 / Cost of market basket in base
                            year 2015) * 100 - CPI = ($58,280 / $40,820) * 100 - CPI = 1.427570 * 100 - CPI ≈ 143So, the CPI for
                            2014isapproximately143.Answer:D
                            GPT-4o (Vision Setting): Question: Suppose that a typical market based in Japan consists of 200
                            Applesand290Textbooks.ThetablebelowshowsdataonpricesforApplesandTextbooksinJapan
                            for three years. Assume that the base year is 2015. What is CPI in 2014? Table:
                                                       | Year | Price of Apples | Price of Textbooks | 
                                                       |--------|----------------------|--------------------------| 
                                                       | 2014 |          $1.40           |              200              | 
                                                       | 2015 |          $1.10           |              140              | 
                                                       | 2016 |          $1.10           |              200              | 
                            Options: (A) 173 (B) 190 (C) 105 (D) 143 (E) 180 (F) 160 (G) 135 (H) 150 (I) 210 (J) 125
                            Step-by-Step Solution: 1. Calculate the cost of the market basket for each year: Market basket in 2015
                            (base year): (200 Apples × $1.10) + (290 Textbooks × $140) = $220 + $40,600 = $40,820 - Market basket
                            in 2014: (200 Apples × $1.40) + (290 Textbooks × $200) = $280 + $58,000 = $58,280; 2. Calculate the
                            CPIfor2014usingtheformula:
                                    ㌵㌵㌵  = Cost of market basket in 2014 ×100㌵㌵㌵       = $58,280 ×100≈142.78
                                        !"#$    Cost of market basket in 2015           !"#$    $40,820
                            Theclosest option to 142.78 is 143. Answer: D
                            Analysis: Both the Standard Setting and Vision Input models correctly calculated the CPI for 2014 as
                            (D) 143, following the correct process of computing the cost of the market basket for 2014 and 2015,
                            thenusingtheCPIformula.
                            Figure 19: Example of a different input setting in Business (subfield: Economics).
                                                                     BacktoAppendix
                                                                           15162
                    J.7    Business: Finance
                                                                      Business: Finance
                                                                                                   GPT-4o (Standard Setting): To
                                                                                                   determine the internal rates of
                                                                                                   return (IRR) for Project A and
                                                                                                   Project B, we use the cash flow
                                                                                                   schedules provided. The formula
                                                                                                   for   calculating    IRR    involves
                                                                                                   finding the rate ㌵ at which the net
                                                                                                   present value (NPV) of all cash
                                                                                                   flows equals zero, which can be set
                                                                                                                        !
                                                                                                   as: ㌵㌵㌵ = 0 = ∑    ! ! Using the
                                                                                                                       "#$
                                                                                                   given    cash   flows:   Project   A:
                                                                                                   −200+ %& "+ %& #+ %& $+
                                                                                                     %&     ("#$)    ("#$)   ("#$)
                                                                                                   ("#$)% = 0
                              GroundTruth:(B)ProjectA:22%;ProjectB:23.37%                          To solve this, trial and error or
                                                                                                   financial   calculators/tools    (like
                              GPT-4o (Vision Setting): To find the internal rate of return         Excel's IRR function) can be used:
                              (IRR) for both Project A and Project B, we need to use the           IRR = 22; Project B: −200+
                              cash flows and solve for the discount rate that makes the Net         "&&" + "&&# + "&&$ + "&&% = 0	.
                              Present Value (NPV) zero for each project. Project A: The            ("#$)   ("#$)    ("#$)   ("#$)
                              cash flows for Project A are ㌵ = −200,㌵ = 80,㌵ =                  Similarly, solving this would give:
                                                                     &            "        )       IRR = 28.69 Matching these results
                              80,㌵ = 80,㌵ = 80. The IRR can be found by solving the
                                   *        +                  %&      %&      %&       %&         to the options provided, we get:
                              following equation: −200+ "#$ +("#$)#+("#$)$+("#$)% =                Answer:D
                              0	Project B: The cash flows for Project B are: ㌵ = −200,㌵ =
                                                                              &            "
                              100,㌵ = 100,㌵ = 100	. The IRR can be found by solving
                                    )         *                        "&&     "&&      "&&
                              the   following    equation:   −200+("#$)+("#$)#+("#$)$+             Analysis: In both Standard Setting
                               "&&% = 0. We'll utilize financial calculators or software (like     andVisionInput,themodelneeds
                              ("#$)                                                                to correctly extract the cash flows
                              Excel) to solve these equations since they are polynomial            and apply the IRR formula to
                              equations and don't have simple algebraic solutions. Steps: 1.       calculate the returns. In both cases,
                              Using Excel, we can use the `IRR` function: For Project A:           the correct answer is (B) Project A:
                              =IRR([-200, 80, 80, 80, 80]); For Project B: =IRR([-200, 100,        22%; Project B: 23.37%. The key to
                              100, 100, 100]) 2. Calculate the IRR for each project. After         solving   this   problem     lies  in
                              calculating: The IRR for Project A is approximately 21%. The         accurately interpreting the cash
                              IRR for Project B is approximately 25.69%. Matching the              flow data and using the IRR
                              Options: Based on the calculations, Project A's IRR is 21%           calculation appropriately.
                              and Project B's IRR is 25.69%, which matches option (A).
                              Answer:A
                               Figure 20: Example of a different input setting in Business (subfield: Finance).
                                                                         BacktoAppendix
                                                                                15163
                    J.8    Business: Manage
                                                                       Business: Manage
                                                                            GPT-4o (Standard Setting): To determine the month in
                                                                            whichthedifference betweenthenumberofunemployed
                                                                            high school graduates and the number of unemployed
                                                                            workers without a high school diploma was the smallest,
                                                                            follow these steps:1. Identify the lines:  "Less than a high
                                                                            school diploma" is represented by diamonds. "High
                                                                            school diploma, no college" is represented by squares.2.
                                                                            Calculate the difference between the two categories for
                                                                            each month:      June: ~12,000 (less than HS diploma);
                                                                            ~8,000 (HS diploma) = ~4,000; July: ~12,000 (less than HS
                                                                            diploma);     ~8,000 (HS diploma) = ~4,000; August:
                                                                            ~11,000 (less than HS diploma); ~8,000 (HS diploma) =
                                                                            ~3,000; September: ~10,500 (less than HS diploma);
                                                                            ~8,000 (HS diploma) = ~2,500;        October: ~11,500 (less
                                                                            than HS diploma); ~7,500 (HS diploma) = ~4,0003.
                                                                            Compare the differences: June: ~4,000; July: ~4,000;
                                                                            August: ~3,000; September: ~2,500; October: ~4,000. The
                                                                            smallest difference is in September. Answer: B
                                                                            GPT-4o(Vision Setting): Sure, let's first clearly write out
                                                                            the multiple-choice question from the image: Question:
                                                                            Graph1showsthenumberofunemployed(inthousands)
                                                                            over a five-month period, organized by level of
                                                                            education    completed.    The difference between the
                                                                            number of unemployed high school graduates and the
                                                                            number of unemployed workers without a high school
                                                                            diploma     was smallest       in:  Options:(A)     March(B)
                                                                            September(C) June(D) January(E) August(F) February(G)
                                                                            December(H)October(I)November(J)July.
                                                                            Solution: 1. Identify the values for unemployed workers
                                                                            without a high school diploma, and those with a high
                              GroundTruth:(B)September                      school diploma (no college) in each of the five months
                                                                            present in Graph 1.2. Calculate the difference for each
                              Analysis:    In    this  question,    the     month. 3. Compare the differences to determine which
                              Standard Setting model succeeded              month has the smallest difference. From the graph: June:
                              because it processed the text and             Less than high school diploma: ~12.5; High school
                              graph separately, allowing it to focus        diploma, no college: ~8; Difference: ~12.5 - 8 = 4.5; July:
                              on extracting the unemployment data           Less than high school diploma: ~12            - High school
                              and     calculating    the    differences     diploma, no college: ~7.5; Difference: ~12 - 7.5 = 4.5;
                              between high school graduates and             August: Less than high school diploma: ~11.5; High
                              workers without a diploma. This led           school diploma, no college: ~7 ; Difference: ~11.5 - 7 = 4.5;
                              to    the   correct    conclusion    that     September: Less than high school diploma: ~11; High
                              September had the smallest difference.        school diploma, no college: ~8 ; Difference: ~11 - 8 = 3;
                              In contrast, the Vision Input model           October: Less than high school diploma: ~11; High
                              handled both the text and image               school diploma, no college: ~8; Difference: ~11 - 8 = 3.
                              together, which increased complexity          The smallest difference is found in September and
                              anddistractions, causing it to miss the       October, and since "October" is one of the given options,
                              correct month.                                wechoosethat.Answer:H
                               Figure 21: Example of a different input setting in Business (subfield: Manage).
                                                                          BacktoAppendix
                                                                                 15164
                   J.9   Business: Marketing
                                                                Business: Marketing
                                                                                  GPT-4o (Vision Setting):       To solve this
                                                                                  problem,    we need to determine the
                                                                                  percentage of people older than 44 years
                                                                                  from the given age groups. The age groups in
                                                                                  the graph are:- 18-34- 35-44- 45-54- 55-64- 65+.
                                                                                  The age groups 45-54, 55-64, and 65+ all fall
                                                                                  into the "more than 44 years old" category.
                                                                                  First, sum the sample sizes for the age groups
                                                                                  more than 44 years old:- 45-54: 268- 55-64:
                                                                                  331- 65+: 478Adding these together: 268 + 331
                                                                                  + 478 = 1,077. Now, find the percentage of
                                                                                  this number out of the total sample size
                                                                                  (1045): $,%((×100
                                                                                         $,%&#
                                                                                  Calculating        this:      1,077÷1,045 ≈
                                                                                  1.0306,1.0306×100 ≈ 103.06%. This value
                                                                                  seems incorrect as it exceeds 100%. Let's
                                                                                  correct our approach by checking if the total
                                                                                  sample size or age group sizes are properly
                                                                                  considered. After reviewing, it seems we
                                                                                  earlier wrongly interpreted the plot. The
                                                                                  corrected sum should be for correct age
                                                                                  groups only (45-54, 55-64, and 65+) from
                                                                                  original plot for given individuals. Thus,
                                                                                  these might actually be represented correctly
                                                                                  only by correct approach. Let's re-assess, as
                                                                                  graph correctness should provide basis. On
                                                                                  correct recall, percentage sum re-evaluated
                                                                                  gives closest in actual list: Answer: (None,
                            GroundTruth:(C)79%                                    should re-check summarily per correct
                                                                                  assessment.)
                            GPT-4o (Standard Setting): To determine the
                            percentage of people in the sample who are more       Analysis: In this question, the Standard
                            than 44 years old, we first need to identify the      Setting accurately calculated the percentage
                            sample sizes for the age groups "45–54", "55–64",     of people over 44 years old by correctly
                            and "65+". From the graph: Sample size for 45–54      identifying and summing the relevant age
                            =226; Sample size for 55–64 = 268; Sample size for    groups, arriving at the correct answer of (C)
                            65+ = 331. We add these sample sizes to get the       79%. The Vision Input method, however,
                            total number of people over 44: 226 + 268 + 331 =     misinterpreted the graph, leading to incorrect
                            825. The total sample size is 1,045. To find the      totals   exceeding    100%,    showing    that
                            percentage of people more than 44 years old:          combined text and image inputs can
                            ㌵㌵㌵㌵㌵㌵㌵㌵㌵㌵ = ( !"# )×100 ≈ 78.95%.          sometimes cause errors in reading numerical
                                            $%&#
                            Rounding 78.95% to the nearest whole number:          data.
                            79%.Thus,thecorrectansweris:Answer:C
                              Figure 22: Example of a different input setting in Business (subfield: Marketing).
                                                                     BacktoAppendix
                                                                           15165
                    J.10    Science: Biology
                                                                       Science: Biology
                                                                          GPT-4o(StandardSetting):Thedevelopingembryointhe
                                                                          image appears to exhibit segmentation as indicated by the
                                                                          distinct stripe patterns along its body. Additionally, there
                                                                          is an evident head-tail orientation, showing that the
                                                                          anterior-posterior axis is established. To identify which
                                                                          features are established at this stage:1. Segmentation: The
                                                                          image shows clear segmented bands. 2. Head-tail
                                                                          orientation: There is distinct anterior (head) and posterior
                                                                          (tail) differentiation. 3. Type of symmetry: The bilateral
                                                                          symmetry is not explicitly seen but may be inferred based
                                                                          on typical embryonic development patterns. Given these
                                                                          features, let's check against the options provided: A.
                                                                          Segmentation     only;    This   is   partially  correct.   B.
                                                                          Segmentation and head-tail orientation; This encompasses
                                                                          both observed features. C. Segmentation, type of
                                                                          symmetry, and head-tail orientation ; The type of
                                                                          symmetry isn’t explicitly visible. D. Head-tail orientation
                                                                          only; This is partially correct. E. Limb placement and
                                                                          segmentation; Limb placement isn't evident. F. Limb
                                                                          placement only; Not evident. G. Type of symmetry and
                                                                          head-tail orientation; Type of symmetry isn’t explicitly
                                                                          visible. H. Type of symmetry and limb placement; Neither
                              Ground Truth: (C) segmentation,             is evident. I. Type of symmetry only; Not evident. J.
                              type of symmetry and head-tail              Segmentation, head-tail orientation, and limb placement;
                              orientation                                 Limb placement isn't evident. Considering all the
                                                                          observations, the best answer is B. Answer: B
                              GPT-4o(VisionSetting): No.17: Which feature(s) of this developing embryo are already established
                              at the stage shown in [image 1]? Options: (A) segmentation             (B) segmentation and head-tail
                              orientation (C) segmentation, type of symmetry and head-tail orientation (D) head-tail orientation
                              (E) limb placement and segmentation (F) limb placement (G) type of symmetry and head-tail
                              orientation (H) type of symmetry and limb placement (I) type of symmetry (J) segmentation, head-
                              tail orientation and limb placement. Solution: To determine which features are established at the
                              stage shown in image 1, let's analyze the visual information and typical developmental stages of
                              embryos: 1. Segmentation: The embryo in the image has distinct, repeating segments along its body,
                              indicating that segmentation is established. 2. Head-Tail Orientation: The pattern and coloration in
                              the image suggest an established head-tail axis. 3. Type of Symmetry: As embryos develop, bilateral
                              symmetry (left and right sides that are mirror images) is established, which is a critical feature in
                              development. Limb placement is unlikely to be established at this early stage, as limb development
                              typically occurs later. From the options given, the greatest combination of established features that
                              matchesthese observations is segmentation, type of symmetry, and head-tail orientation. Answer: C)
                              segmentation, type of symmetry and head-tail orientation Answer: C
                              Analysis: Standard Setting missed the presence of type of symmetry, leading to an incomplete
                              answer, while Vision Input successfully identified all three features, resulting in the correct answer,
                              (C).
                               Figure 23: Example of a different input setting in Science (subfield: Biology).
                                                                         BacktoAppendix
                                                                                15166
                    J.11    Science: Chemistry
                                                                    Science: Chemistry
                                                                                               GPT-4o(VisionSetting): Let's follow
                                                                                               the steps systematically:1. Identify
                                                                                               the multiple-choice question in the
                                                                                               image: No. 21: Among the following,
                                                                                               the most stable isomer is : Options:
                                                                                               (A) (c) ; (B) (d); (C) (a) ; (D) (b) 2. To
                                                                                               determine the most stable isomer, we
                                                                                               need     to    analyze     the    chair
                                                                                               conformations of each option and see
                              GroundTruth:(B)                                                  which one has the substituents in the
                                                                                               more stable (equatorial) positions.
                             GPT-4o (Standard Setting): To determine the most stable           Chair conformers with substituents
                             isomer among the given options, we need to analyze their          in   the   equatorial   positions   are
                             structures in terms of steric hindrance and the preferred         generally more stable than those with
                             orientation of substituents in the chair conformation of          substituents in the axial positions
                             cyclohexane.     Step-by-step    analysis:   1.   Substituent     due to less 1,3-diaxial interactions
                             Positions: Substituents on a cyclohexane ring prefer to be        (steric hindrance). 3. Review each
                             in the equatorial position to minimize steric hindrance. 2.       option:     Option (A) (c): In this
                             Chair Conformation: Cyclohexane can flip between two              structure, the methoxy (OMe) group
                             chair   conformations. Stability increases when bulky             is  axial, and the hydroxyl (OH)
                             substituents occupy the equatorial positions. 3. Examine          group is equatorial. Option (B) (d):
                             EachIsomer: (a) has hydroxyl (OH) at axial position which         Both hydroxyl (OH) and methoxy
                             creates more steric hindrance. (b) positions both OH and          (OMe) groups are axial. Option (C)
                             OMe likely to minimize steric hindrance, having one in            (a): Both hydroxyl (OH) and methoxy
                             axial and one in equatorial position. (c) positions OMe in        (OMe)groupsareequatorial. Option
                             the axial position which is not ideal due to steric hindrance.    (D) (b): The hydroxyl (OH) group is
                             (d)   positions the hydroxyl group in the axial position          axial, and the methoxy (OMe) group
                             which is less favorable than having bulky groups in               is equatorial. 4. Identify the most
                             equatorial positions. Conclusion: Isomer (b) is the most          stable form:   - Option (C) (a), where
                             stable because it places the larger methoxy (OMe) group in        both substituents are equatorial, is
                             the equatorial position, thus minimizing steric interactions.     the most stable conformation as it
                             Answer:B                                                          minimizessteric clashes. Answer: C
                             Analysis: The Standard Setting incorrectly analyzes chair and selected (b) as the most stable isomer,
                             and incorrectly maps (b) to (B) instead of (D). The answer is correct but the reasoning is wrong.
                             Vision Input made an error in interpreting the positions of the substituents, leading to the incorrect
                             selection of (C).
                              Figure 24: Example of a different input setting in Science (subfield: Chemistry).
                                                                        BacktoAppendix
                                                                               15167
                    J.12    Science: Geography
                                                                   Science: Geography
                                                                                                            GPT-4o         (Standard
                                                                                                            Setting): We need to
                                                                                                            match the species to the
                                                                                                            blue-shaded region on
                                                                                                            the map, which is in
                                                                                                            South     America.     I'll
                                                                                                            identify the species in
                                                                                                            each   image and see
                                                                                                            which one is native to
                                                                                                            South America.- Option
                                                                                                            A: The first image is an
                                                                                                            Emu, which is native to
                                                                                                            Australia.-   Option    B:
                                                                                                            The second image is a
                                                                                                            Rhea, which is native to
                                                                                                            South America.- Option
                                                                                                            C: The third image is a
                                                                                                            Cassowary,     which    is
                                                                                                            found in Australia and
                                                                                                            NewGuinea.-OptionD:
                                                                                                            The fourth image is an
                                                                                                            Ostrich, which is native
                                                                                                            to Africa. Only option B,
                                                                                                            the Rhea, is native to the
                                                                                                            blue    shaded     region
                                                                                                            (South America) on the
                                                                                                            map.Answer:B
                             GroundTruth:(B)
                             GPT-4o (Vision Setting): No. 19: Which of the following species locate in the blue area of [image
                             1]?Options:(A) (B) (C) (D)To solve this question, we need to identify which species from the options A,
                             B, C, and D is found in the blue area shown on the map, which corresponds to South America.-
                             Option (A) shows an Emu, which is native to Australia.- Option (B) shows an Ostrich, which is native
                             to Africa.- Option (C) shows a Cassowary, which is native to Australia and surrounding areas.-
                             Option (D) shows a Rhea, which is native to South America. The blue area on the map marks South
                             America. Therefore, the species found there is represented by option (D), the Rhea. Answer: D
                             Analysis: The Standard Setting correctly identified (B) Rhea as the species native to the blue region
                             (South America), while Vision Input mistakenly selected (D) Ostrich, which is native to Africa, not
                             SouthAmerica.
                              Figure 25: Example of a different input setting in Science (subfield: Geography).
                                                                        BacktoAppendix
                                                                              15168
                    J.13    Science: Math
                                                                      Science: Math
                                                                                  GPT-4o (Standard Setting): To solve the given
                                                                                  problem, we start by understanding both the
                                                                                  objective function and the constraints and by
                                                                                  analyzing the geometric solution represented in
                                                                                  the figure:                             !
                                                                                  Objective function: Minimize (㌵1−3) +(㌵2−
                                                                                  2)!	. This represents the Euclidean distance
                                                                                  squared from the point (x1, x2) to the point (3, 2).
                                                                                  Constraints: 1. ㌵1! − ㌵2 − 3 ≤ 0	2. x2 − 1 ≤ 0	3.
                                                                                  −㌵1 ≤ 0	 Simplifying the constraints:1. ㌵1! ≤
                                                                                  ㌵2 + 3 2. x2 ≤ 1 3. ㌵1 ≥ 0. These constraints
                                                                                  indicate that the feasible region is bounded by:-
                                                                                  Aparabola ㌵2 ≥ ㌵1! −3; A horizontal line x2 ≤
                                                                                  1; A vertical line ㌵1 ≥ 0.
                                                                                  Analyzing the Geometric Solution Provided in
                                                                                  the Figure: The figure indicates the feasible
                                                                                  region   as   the  shaded area within these
                                                                                  boundaries. The contours of the objective
                                                                                  function (㌵1 − 3)! + (㌵2 − 2)!   are shown as
                                                                                  circles centered at (3, 2). To minimize the
                                                                                  objective function, we need to find the point in
                                                                                  the feasible region closest to the point (3, 2).
                                                                                  Observation from the Figure: From the figure,
                                                                                  the optimal point that lies within the feasible
                                                                                  region and also lies on the contour of the
                                                                                  minimumdistanceto(3,2)isshowntobe(2,1).
                                                                                  Conclusion: Thus, the solution to the problem is
                                                                                  (2, 1), which corresponds to option A.
                             GroundTruth:(A)(2,1)                                 Answer:A                                !
                             GPT-4o (Vision Setting): Question: Consider the following problem: Minimize: (x1−3) +(x2−
                             2)!subject to: x1! − x2 − 3 ≤ 0; x2 − 1 ≤ 0; x1 ≤ 0. Give the solution. Options: (A) (2, 1) (B) (1, 1) (C)
                             (1, 0) (D) (3, 2) (E) (2, 0) (F) (2, 2) (G) (3, 3) (H) (3, 1) (I) (0, 0) (J) (0, 2) Step-by-Step Solution: 1.
                             Defining the objective function: The goal is to minimize (㌵1 − 3)! + (㌵2 − 2)! . This is the squared
                             distance from the point (3, 2) .2. Analyzing the constraints: −㌵1! − ㌵2 − 3 ≤ 0 : Rearrange: ㌵2 ≥
                             ㌵1! − 3 ; −㌵2 − 1 ≤ 0; −㌵2 ≤ 1 −㌵1 ≤ 0; −㌵1 ≤ 0 3. Finding the feasible region: Since ㌵2 ≤ 1 and
                             ㌵1 ≤ 0, ㌵2 ≥ ㌵1! − 3 must also be satisfied. We need to check where these intersect.4. Substituting
                             constraints into ㌵1 ≤ 0	; x2 needs to be evaluated at the boundary points for the infeasible region. As
                             ㌵1 ≤ 0 covers the negative x-axis along with ㌵1 ≤ 1	and ㌵2 ≥ ㌵1! − 3. 5. Evaluating boundary
                             points: For x1 = 0 : (x1 − 3)! + (x2 − 2)! at x2 = 1 gives: (0 − 3)! + (1 − 2)! = 9 + 1 = 10	; Points (0,
                             1) is active region 6. Checking all points and minimizing: Evaluating all options and seeing if they
                             lie inside the restricted feasible region and minimizing the equation (x1 − 3)! + (x2 − 2)!. Only (0,
                             1) satisfied all constraints: Calculation: (0 − 3)! + (1 − 2)!=> 9+1 = 10. Other alternatives evaluated
                             outside range. Point meets minimum condition lie within constraints. Answer: B
                             Analysis: The Standard Setting correctly solved the optimization problem by analyzing both the
                             constraints and the provided figure, selecting (2, 1) as the solution. In contrast, Vision Input
                             misinterpreted the constraints and selected the incorrect point (1, 1).
                              Figure 26: Example of a different input setting in Science (subfield: Math).
                                                                       BacktoAppendix
                                                                             15169
                  J.14   Science: Physics
                                                                Science: Physics
                                                                                Analysis:   In  this question,  both the
                                                                                Standard Setting and Vision Input failed to
                                                                                identify the correct answer, which is (B) 2.
                                                                                The Standard Setting, despite its detailed
                                                                                torque analysis, incorrectly chose (D) due
                                                                                to inadequate simplification using point 4.
                                                                                Similarly, the Vision Input, while correctly
                                                                                identifying the simplifying benefits of
                                                                                point 2, included point 3 in its analysis,
                                                                                leading to an incorrect selection of (C).
                           GroundTruth:(B)2
                           GPT-4o (Standard Setting): To determine the correct choice, let‘s analyze the torques about
                           different points of the rod: 1. Understanding the Problem: The rod is held in place by the rope and
                           the wall; We need to consider the torque about different points to solve for the rope force. 2. Torque
                           Equations: Torque ㌵ is given by the equation: ㌵ = ㌵×㌵×㌵㌵㌵(㌵) , where ㌵ is the distance from the
                           pivot point, ㌵	is the force applied, and ㌵	is the angle between ㌵	and ㌵. 3. Identifying Relevant Points:
                           Point 1 (at the top of the wall): This point is where the rope attaches to the wall. Point 4 (at the end
                           of the rod opposite the wall): This point is farthest from the wall and the other end of the rope.
                           Point 2 (at the bottom of the wall): This is where the rod meets the wall. Point 3 (midway along the
                           rod): This is the midpoint of the rod. 4. Choose Points to Sum Torques: Consider torque about
                           points where the force we are solving for (the rope force and normal force) creates either simple
                           terms or cancels out. Point 2 (where the rod meets the wall): Considering torques about Point 2 can
                           help simplify the problem since the torque due to the normal force at Point 2 is zero (the radius is
                           zero). Point 4 (end of the rod opposite the wall): Considering torques about this point will involve
                           the full length of the rod. For equilibrium about point 2: Only the torque due to the weight of the
                           rod and the rope will contribute (since the normal force at Point 2 does not create a torque). For
                           equilibrium about point 4: Only the torque due to the weight of the rod and the force at point 2
                           (normal or frictional force) will contribute (since the rope’s force does not create a torque). 5.
                           Solving the Equation: Writing the torque balance equation about Point 2 or Point 4 will allow us to
                           solve one equation for the force from the rope. Hence, considering torques about points 2 and 4 will
                           enable us to write the necessary expressions to solve for the rope force. Answer: D
                           GPT-4o(VisionSetting): Step-by-step solution:1. Understand the problem: The uniform rod is held
                           in place by a rope and wall. We are to write expressions for the torques about a specific point to
                           solve the equation for the force exerted by the rope. 2. Identify possible pivot points: We look for
                           points where it will be easy to sum the torques, which typically are the points where either the
                           forces will be zero or unknown forces will not create torques (such as the points of attachment). 3.
                           Analyze the given points: Point 1 (top of the triangle/notched point): This is where the rope is
                           attached. Point 2 (left end of the rod): This is where the horizontal rod touches the wall. Point 3
                           (center of the rod): The weight of the rod acts here if it is uniform. Point 4 (right end of the rod): The
                           other end of the rod. 4. Choosing torque points: Torque about Point 2 (wall contact point): This
                           simplifies calculations as the vertical reaction force at the wall does not create a torque (distance is
                           zero). Torque about Point 4 (right end of the rod): This would be less straightforward as it involves
                           the weight and the reaction forces at Points 2 and 1 creating complex expressions. Hence, Torque
                           about Point 2 simplifies the calculations involving the forces in the problem. After analyzing, the
                           correct selections should be from recognizing the simplicity and applicability of the torque points.
                           Correct points for taking torque: 2 (left end of the rod); 3 (center of the rod). These points allow us
                           to express the torque in a meaningful and solvable manner. Answer: C
                            Figure 27: Example of a different input setting in Science (subfield: Physics).
                                                                 BacktoAppendix
                                                                       15170
                    J.15    Health and Medicine: Basic Medical Science
                                                   Health and Medicine: Basic Medical Science
                                                                               GPT-4o     (Standard     Setting):    The    structure
                                                                               highlighted in the heart diagram is situated between
                                                                               the right ventricle and the pulmonary artery. This
                                                                               structure functions to prevent the backflow of blood
                                                                               fromthepulmonaryarteryintotherightventricle.
                                                                               Given this position and function, the correct
                                                                               structure is the pulmonary semilunar valve. Answer:
                                                                               E
                                                                               GPT-4o (Vision Setting): Multiple-choice question:
                                                                               No.25:Whatstructureoftheheartisthis?
                                                                               Options:(A) Inferior Vena Cava(B) Right Ventricle(C)
                                                                               Left   Atrium(D)     Left    Ventricle(E)   Pulmonar
                                                                               Semilunar Valve(F) Aortic Semilunar Valve(G)
                                                                               Superior Vena Cava(H) Bicuspid Valve(I) Tricuspid
                                                                               Valve(J) Right Atrium. The image points to structure
                                                                               labeled "1." Identifying this as the inferior vena cava,
                                                                               wecanmatchitwithoption(A).Answer:A
                                                                               Analysis: The Standard Setting correctly identified
                                                                               the structure as the "Pulmonar Semilunar Valve,"
                                                                               labeled as option (E). The detailed position and
                                                                               function analysis led to the correct answer. In
                                                                               contrast, the Vision Input incorrectly identified the
                                                                               structure as the "Inferior Vena Cava," selecting
                                                                               option (A). The misinterpretation of the labeled
                                                                               structure in the image led to the wrong conclusion.
                                                                               While the Standard Setting accurately applied
                                                                               anatomical knowledge to the heart diagram, the
                             GroundTruth:(E)Pulmonar                           Vision Input's identification error underscores a gap
                             Semilunar Valve                                   in visual analysis.
                       Figure 28: Example of a different input setting in Health and Medicine (subfield: Basic Medical Science).
                                                                        BacktoAppendix
                                                                              15171
                      J.16     Health and Medicine: Clinical Medicine
                                                            Health and Medicine: Clinical Medicine
                                                                                                                  Analysis:       The      Standard
                                                                                                                  Setting step-by-step analysis
                                                                                                                  connected the hip fracture
                                                                                                                  from     the    fall   at    work,
                                                                                                                  subsequent surgery, and the
                                                                                                                  resulting             pulmonary
                                                                                                                  thromboembolism, correctly
                                                                                                                  identified         the       mode
                                                                                                                  (manner)        of    death      as
                                                                                                                  "accident".       The       Vision
                                                                                                                  Setting                incorrectly
                                                                                                                  concluded that the death
                                                                                                                  was "a result of surgical
                                                                                                                  complications," focused on
                                                                                                                  the immediate post-surgical
                                                                                                                  events but missed linking
                                                                                                                  the    initial    fall    as    the
                                 GroundTruth:(F)Themode(manner)ofdeathisaccident                                  underlyingaccidental cause.
                                 GPT-4o(Standard Setting): To determine the most accurate statement regarding death certification in
                                 this case, we need to assess the situation step by step.1. Incident and Surgery: The patient, a 64-year-
                                 old woman, fell down a flight of stairs at work and fractured her right hip. She was hospitalized and
                                 underwent surgery for a hip prosthesis. 2. Post-Surgical Event: A week after surgery, she developed
                                 sudden dyspnea and expired within 5 minutes despite resuscitative efforts. Autopsy revealed
                                 significant findings including a 1 cm infiltrating ductal carcinoma in her right breast without
                                 metastases. 3. Cause of Death Analysis: The provided autopsy image suggests a large pulmonary
                                 thromboembolism (PTE), a common post-operative complication, especially in orthopedic surgery
                                 involving the hip. This is likely the immediate cause of death. 4. Determining the Mode (Manner) of
                                 Death and Causes: Immediate Cause of Death: The dilated and obstructed pulmonary artery visible in
                                 the image suggests that a pulmonary embolism caused her sudden death. Underlying Cause: The hip
                                 fracture and its associated surgery, which led to her being immobilized; a risk factor for developing a
                                 thromboembolism. Mode of Death: Given that the hip fracture occurred due to a fall at work, the
                                 underlying incident is accidental. Based on the step-by-step evaluation, the most accurate statement
                                 regarding the death certification is: The mode (manner) of death is accident. Answer: F
                                 GPT-4o(VisionSetting): Question: Following a fall down … … is most accurate in her case? (image 1)
                                 Options:(A) This is a therapeutic misadventure (B) This is a result of surgical complications ... … (J)
                                 The mode (manner) of death is suicide. Step-by-Step Analysis:1. Incident: The patient suffered a fall
                                 leading to a hip fracture, which is a significant trauma causing her hospitalization.2. Intervention: She
                                 underwent surgery for a hip prosthesis placement.3. Post-operative Period: Within a week from
                                 surgery, she developed sudden dyspnea and died within 5 minutes, despite resuscitative efforts.4.
                                 Autopsy Findings: No metastasis was found, but an infiltrating ductal carcinoma was present.5.
                                 Conclusion: The death occurred shortly after a hip fracture and surgery, suggesting the potential
                                 causes related to these incidents. Considering the sequence of events:- Hip fracture and subsequent
                                 surgery are significant recent events.- Sudden dyspnea and quick demise point toward a possible
                                 thromboembolic event (common postoperative complication).- The infiltrating ductal carcinoma in the
                                 breast is less likely to be related directly to the sudden death because it shows no metastasis. Therefore,
                                 the death is most likely an outcome of the post-surgical complications following the hip fracture and
                                 surgery. Correct Answer:(B) This is a result of surgical complications. Answer: B
                           Figure 29: Example of a different input setting in Health and Medicine (subfield: Clinical Medicine).
                                                                                BacktoAppendix
                                                                                        15172
                     J.17     Health and Medicine: Diagnostics and Laboratory Medicine
                                            Health and Medicine: Diagnostics and Laboratory Medicine
                                                                                           GPT-4o (Vision Setting): The multiple-choice
                                                                                           question is: No. 5: What is the best diagnosis?
                                                                                           (Image     1)Options:(A)      Subacute      cerebral
                                                                                           infarction(B) Brain abscess(C) Chronic cerebral
                                                                                           infarction(D)        Cerebral         aneurysm(E)
                                                                                           Perivascular amebic encephalitis(F) Venous
                                                                                           thrombosis(G)         Progressive        multifocal
                                                                                           leukoencephalopathy(H)                     Cerebral
                                                                                           hemorrhage(I) Meningitis(J) Acute cerebral
                                                                                           infarction. Step-by-step analysis of the given
                                                                                           image and available options:1. The image
                                                                                           provided      is    a    histological     section.2.
                                                                                           Observations      include     certain     structural
                                                                                           appearances.3. The correct diagnosis relies on
                                                                                           correlating     histological      changes      with
                                                                                           pathological      processes.      Upon       careful
                                                                                           examination of the provided histological slide
                                                                                           and correlating with the options, the best
                                                                                           diagnosis appears to match the characteristics
                                                                                           of an (J) Acute cerebral infarction. Answer: J
                                                                                           Analysis:    The Vision Setting          incorrectly
                                                                                           diagnosed the condition by missing subacute
                                                                                           details.  The Standard Setting          mistakenly
                                                                                           interpreting the presence of gliosis and cystic
                               GroundTruth:(A)Subacutecerebralinfarction                   changesasindicativeofachroniccondition.
                               GPT-4o(StandardSetting): To accurately determine the diagnosis based on the provided image, we
                               need to interpret the histopathological features visible. The image appears to be a microscopic
                               section of brain tissue stained with Hematoxylin and Eosin (H&E).Here is the process of differential
                               diagnosis for the given options:1. Subacute cerebral infarction (A): Typically presents with some
                               degree of necrosis and macrophage infiltration but not the cystic and macrophage excess seen in
                               chronic infarcts.2. Brain abscess (B): Would show a central area of liquefaction surrounded by a
                               fibrous capsule and inflammatory cells (neutrophils). The image does not seem to show these
                               features distinctly.3. Chronic cerebral infarction (C): Characterized by cavitation, marked gliosis,
                               and macrophages engulfing myelin and other debris, often leading to the formation of cystic
                               spaces.4. Cerebral aneurysm (D): Typically noted upon gross examination or imaging modalities like
                               angiograms. Histologically can show arterial wall changes but not highly relevant for this image.5.
                               Perivascular amebic encephalitis (E): Characterized by numerous inflammatory cells, including
                               amoebaearoundbloodvessels, and brain tissue destruction. The image does not show these unique
                               features.6. Venous thrombosis (F): Usually results in hemorrhagic infarction. The image should
                               show hemorrhages or venous congestion which is not prominent here.7. Progressive multifocal
                               leucoencephalopathy (G): Characterized by demyelination, presence of oligodendrocytes with
                               intranuclear inclusions due to JC virus. Features are specific and not apparent in this image.8.
                               Cerebral hemorrhage (H): Shows acute/subacute changes of bleeding, such as red blood cell
                               extravasation, which is not obvious here.9. Meningitis (I): Would present with prominent
                               inflammation in the meninges, which is not the focus of this image.10. Acute cerebral infarction (J):
                               Characterized by early neuronal injury, eosinophilic neurons, and cerebral edema, which would
                               appear different from chronic changes. After considering all options: The image indicates significant
                               gliosis and cystic changes typically associated with chronic cerebral infarct. Answer: C
                        Figure 30: Example of a different input setting in Health and Medicine (subfield: Diagnostics and Laboratory
                                                             Medicine).
                                                                             BacktoAppendix
                                                                                    15173
                J.18  Health and Medicine: Pharmacy
                                              Health and Medicine: Pharmacy
                       GroundTruth:(A)False
                       GPT-4o (Standard Setting): To determine whether the bacteriorhodopsin protein shown in the
                       diagram has a quaternary structure, let's review the necessary definitions and characteristics.1.
                       Primary Structure: This refers to the sequence of amino acids in the polypeptide chain.2. Secondary
                       Structure: This level involves local structures stabilized by hydrogen bonds, such as alpha helices
                       and beta sheets.3. Tertiary Structure: The overall three-dimensional shape formed by a single
                       polypeptide chain, determined by various interactions among side chains (R groups) of amino
                       acids.4. Quaternary Structure: This level pertains to proteins composed of two or more polypeptide
                       chains (subunits) that function together. Bacteriorhodopsin is known to be a small membrane
                       protein consisting of seven transmembrane alpha helices. Typically, proteins with multiple subunits
                       would have a quaternary structure. However, bacteriorhodopsin is actually composed of a single
                       polypeptide chain and therefore exhibits tertiary structure, but not quaternary structure. Given
                       these points, the statement that bacteriorhodopsin protein has a quaternary structure is false.
                       Answer:A
                       GPT-4o (Vision Setting): No. 15: The following diagram shows the bacteriorhodopsin protein. This
                       protein has quaternary structure. Options:(A) False(B) True. Step-by-step solution:1. To determine
                       the answer, we need to understand the structure of bacteriorhodopsin.2. Bacteriorhodopsin is a
                       protein commonly known for its role in the proton pump process in certain microorganisms.3.
                       Bacteriorhodopsin is composed of seven transmembrane alpha helices, forming a single polypeptide
                       chain, meaning it does not have multiple polypeptide chains interacting, which are the requirement
                       for a quaternary structure.4. Quaternary structure refers to the assembly of multiple folded protein
                       molecules in a multi-subunit complex. Therefore, stating that bacteriorhodopsin has a quaternary
                       structure would be incorrect. Answer: A
                       Analysis: In this question, both the Standard Setting and Vision Setting correctly identified that the
                       bacteriorhodopsin protein does not have a quaternary structure, selecting option (A) False.
                     Figure 31: Example of a different input setting in Health and Medicine (subfield: Pharmacy).
                                                        BacktoAppendix
                                                             15174
                      J.19     Health and Medicine: Public Health
                                                              Health and Medicine: Public Health
                                                                                                                            Analysis:          The
                                                                                                                            Standard       Setting
                                                                                                                            incorrectly identified
                                                                                                                            the study as a "case-
                                                                                                                            control study." This
                                                                                                                            setting   focused on
                                                                                                                            the   comparison of
                                                                                                                            groups     and    past
                                                                                                                            incidences, failing to
                                                                                                                            recognize          the
                                                                                                                            forward-looking
                                                                                                                            aspect of the study.
                                                                                                                            In     contrast,   the
                                                                                                                            Vision         Setting
                                                                                                                            correctly determined
                                                                                                                            the    study    as   a
                                GroundTruth:(H)cohortstudy                                                                  "cohort study."
                                GPT-4o (Standard Setting): To identify the type of study described, we need to analyze the
                                methodology and the presented data. Here are the key points to consider:1. The study has
                                compared two groups: drug-taking (exposed) group and non-drugged (non-exposed) group.2. The
                                occurrence of the outcome (upper gastrointestinal hemorrhage) in both groups is documented.3.
                                The study is analyzing past events since the data shows results after exposure. Given these points,
                                we can deduce the following: It isn't a descriptive study (A) as we are comparing two specific
                                groups. It isn't an experimental (B) or clinical trial (E) since there's no intervention or random
                                assignment. It isn't a longitudinal study (C) or cohort study (H) since the data presented doesn't
                                suggest the following up of subjects over a period; the focus is on past incidence. It fits the
                                definition of a case-control study (D) or an observational study (J). It’s not cross-sectional (G), as the
                                data on exposure and outcome timing isn’t simultaneous. It cannot be quasi-experimental (F)
                                because there's no mention of pre-intervention measurements or designed controlled conditions. It
                                is likely retrospective (I) since it looks backward at incidences. Considering the best fit based on the
                                methodology shown (comparing groups with different exposure statuses), the study aligns well
                                withacase-control design (D).Answer: D
                                GPT-4o(VisionSetting):No.13:Astudyon……Themethodologyofthestudywas.[image1]
                                |                     |numberofpersons|Numberofcasesofuppergastrointestinalhaemorrhage|
                                |----------------------------|-------------------|------------------------------------------------------|
                                |Drug-takinggroup |             48000      |                        160                    |
                                |Non-druggedgroup|              45000      |                        100                    |
                                Options:(A) descriptive study              (B) experimental study(C) longitudinal study                  (D) case-
                                control study(E) clinical trial                      (F) quasi-experimental study(G) cross-sectional study
                                (H) cohort study(I) retrospective study              (J) observational study
                                To determine the correct methodology of the study presented, we need to consider the details
                                given:- There are two groups (drug-taking and non-drugged) being compared.- The study follows
                                these groups over a period to see the incidence of upper gastrointestinal hemorrhage.This study is
                                clearly comparing the outcomes in two groups based on the exposure (NSAIDs usage) and
                                observing the results over the population sample for a period.The most appropriate term for this
                                type of study, where two or more cohorts are followed over time to compare outcomes, is a "cohort
                                study". Answer: H
                            Figure 32: Example of a different input setting in Health and Medicine (subfield: Public Health).
                                                                               BacktoAppendix
                                                                                      15175
                      J.20     Humanities and Social Science: History
                                                             Humanities and Social Science: History
                                                                                                                                  Analysis:   In    this
                                                                                                                                  question,         the
                                                                                                                                  Standard       Setting
                                                                                                                                  correctly   identified
                                                                                                                                  the   formation    of
                                                                                                                                  international
                                                                                                                                  organizations like the
                                                                                                                                  United Nations as a
                                                                                                                                  direct response to the
                                                                                                                                  World    Wars.    The
                                                                                                                                  analysis   accurately
                                                                                                                                  recognized that such
                                                                                                                                  organizations   were
                                                                                                                                  established        to
                                                                                                                                  facilitate international
                                                                                                                                  cooperation      and
                                                                                                                                  prevent future global
                                                                                                                                  conflicts. Conversely,
                                                                                                                                  the   Vision   Setting
                                                                                                                                  focusing    on    the
                                                                                                                                  establishment of the
                                                                                                                                  League of Nations as
                                                                                                                                  a reaction to World
                                                                                                                                  War I but missing the
                                                                                                                                  broader context of the
                                                                                                                                  creation of the United
                                 GroundTruth:(G)Internationalorganizationstofacilitateinternationalcooperation,such as            Nations   post-World
                                 the United Nations                                                                               WarII.
                                 GPT-4o (Standard Setting): To identify the correct answer, we need to consider what the posters are depicting and the
                                 historical context around them. The first image is from Canada in 1918 and refers to "Victory Bonds.". The second poster is
                                 from the United States in the early 1940s and encourages car-sharing to support the war effort, referencing the fight against
                                 Nazi Germany. Analyzing the options: A. Groups like the Non-Aligned Movement were created after World War II to stay
                                 neutral during the Cold War, not directly a reaction to these wars. B. Movements promoting global disarmament may be
                                 partially relevant, though disarmament efforts became more prominent after the nuclear age began. C. The formation of
                                 global environmental organizations took prominence later, not directly linked to wars. D. Economic sanctions by major world
                                 powers have been a persistent tool but not solely a result of these conflicts. E. Movements that used violence against civilians
                                 to achieve political aims were not formed as a direct reaction to these conflicts but were more prevalent in later contexts. F.
                                 The WTO was created in 1995 for global trade regulation, not a direct result of these wars. G. International organizations to
                                 facilitate cooperation, such as the United Nations, were indeed formed in direct response to World War II, with the aim of
                                 preventing future global conflicts. H. The establishment of the League of Nations was a direct result of World War I, aimed at
                                 preventing future wars. I. The European Union formation, particularly as the European Economic Community, was a
                                 response to integrate and stabilize Europe post-World War II, though it evolved significantly later. J. The formation of military
                                 alliances, including NATO and the Warsaw Pact, was a reaction to the post-World War II Cold War and is a bit more indirect
                                 in this context. Considering the timing and direct reactions, the League of Nations and the United Nations were created
                                 specifically in response to World War I and World War II, respectively. Answer: G
                                 GPT-4o (Vision Setting): The multiple-choice question in the image is: No. 27: [Image 1] [Image 2] Which of the … … to the
                                 conflicts shown in the images? Options:(A) Groups that promoted alternatives to the existing order, such as the Non-Aligned
                                 Movement … … (J) The formation of military alliances, including NATO and the Warsaw Pact. To solve it, we need to
                                 identify the nature of the conflicts shown in the images and link the correct option as a direct reaction to these conflicts:1.
                                 Image 1: "VICTORY BONDS WILL HELP STOP THIS. KULTUR VS. HUMANITY," Canada, 1918. This poster is from World
                                 WarI, aiming to sell war bonds to support the war effort.2. Image 2: "WHEN YOU RIDE ALONE YOU RIDE WITH HITLER!
                                 JOIN A CAR-SHARING CLUB TODAY!" United States, early 1940s. This poster is from World War II, encouraging
                                 carpooling to save fuel for the war effort. Given these are related to the World Wars, the responses must relate directly to the
                                 aftermath or results of these wars. World War I led to the creation of the League of Nations to promote international
                                 cooperation and achieve peace. Therefore, the correct option in this context is (H) "The establishment of the League of
                                 Nations.”. Answer: H
                            Figure 33: Example of a different input setting in Humanities and Social Science (subfield: History).
                                                                                 BacktoAppendix
                                                                                        15176
                    J.21    Humanities and Social Science: Literature
                                                    Humanities and Social Science: Literature
                                                                                                                  Analysis: In this
                                                                                                                  question,     both
                                                                                                                  the      Standard
                                                                                                                  Setting       and
                                                                                                                  Vision     Setting
                                                                                                                  correctly
                                                                                                                  identified    that
                                                                                                                  the   poem "So
                                                                                                                  Mexicans      Are
                                                                                                                  Taking        Jobs
                                                                                                                  Away         From
                                                                                                                  Americans"      by
                                                                                                                  Jimmy Santiago
                                                                                                                  Baca    addresses
                                                                                                                  the    theme    of
                                                                                                                  marginalized
                                                                                                                  people      being
                                                                                                                  unfairly blamed.
                                                                                                                  Both      settings
                                                                                                                  correctly   linked
                                                                                                                  the        poem’s
                                                                                                                  theme     to   the
                                                                                                                  given      option,
                                                                                                                  effectively
                                                                                                                  capturing      the
                                                                                                                  essence   of   the
                             GroundTruth:(A)Thegovernmentismakingmarginalizedpeopletheenemy.                      poem.
                             GPT-4o (Standard Setting): To determine which option best relates to the poem 'So Mexicans Are Taking
                             Jobs Away From Americans' by Jimmy Santiago Baca, let's analyze the given options in the context of the
                             poem:A.Thegovernmentismakingmarginalizedpeopletheenemy.Thisoptionseemsrelevantasthepoem
                             discusses how the blame is placed on Mexicans for taking jobs, which is instead a reflection of deeper socio-
                             economic issues. The poet points out the misplaced blame and the real struggle of marginalized people. B.
                             The writer uses images from nature in the cold dessert. This option does not appear to be relevant to the
                             poem.Thepoemdoesnotmentionnatureoracolddesert.C.TheMississippiRiverandAbrahamLincolnare
                             mentioned. These specific references do not appear in the poem. Therefore, this option is not relevant. D. The
                             would-be-thief was motivated by blue suede shoes. This option seems to reference another context that is not
                             related to this poem. Reviewing the poem once more confirms that Option A is the most accurate relation to
                             the content of the poem: it highlights how marginalized people are being unfairly blamed. Answer: A
                             GPT-4o (Vision Setting): Question: No. 18: Which of the following options best relates to the poem 'So
                             Mexicans Are Taking Jobs Away From Americans' [Image 1]?Options:(A) The government is making
                             marginalized people the enemy.(B) The writer uses images from nature in the cold dessert.(C) The
                             Mississippi River and Abraham Lincoln are mentioned.(D) The would-be-thief was motivated by blue suede
                             shoes. To solve this question, read the poem carefully. The poem \"So Mexicans Are Taking Jobs from
                             Americans\" by Jimmy Santiago Baca talks about the struggle of Mexican workers and how they are blamed
                             for taking away jobs from Americans. It speaks to issues of marginalization, economic hardship, and systemic
                             injustice. Option A states, \"The government is making marginalized people the enemy.\" This option relates
                             to the overall theme of the poem, as it discusses how Mexican workers are unfairly targeted and blamed for
                             economic problems. Option B is incorrect because it talks about images from nature in a cold desert, which is
                             not relevant to the poem’s content. Option C is incorrect because the Mississippi River and Abraham Lincoln
                             are not mentioned in the poem. Option D is also incorrect because there is no mention of a thief or blue suede
                             shoes in the poem. Answer: A
                        Figure 34: Example of a different input setting in Humanities and Social Science (subfield: Literature).
                                                                       BacktoAppendix
                                                                              15177
                      J.22    Humanities and Social Science: Sociology
                                                         Humanities and Social Science: Sociology
                                                                                                    GPT-4o (Vision Setting): Let's analyze the
                                                                                                    multiple-choice question carefully and find
                                                                                                    the correct answer by following these steps:
                                                                                                    Question: Which statement … … symbolic
                                                                                                    interactionism?     Options:(A)      Teachers
                                                                                                    continue to struggle to keep benefits such as
                                                                                                    good retirement plans … … (J) Professional
                                                                                                    athletes often earn more than teachers and
                                                                                                    nurses. Step-by-Step Analysis:- Symbolic
                                                                                                    interactionism is a sociological perspective
                                                                                                    that focuses on the symbolic meaning that
                                                                                                    people develop and rely upon in the
                                                                                                    process     of   social   interaction.    This
                                                                                                    perspective       emphasizes        subjective
                                                                                                    meanings,     social   symbols,     and    the
                                                                                                    significance individuals place on objects
                                                                                                    and    roles.-   Statements    that   include
                                                                                                    subjective feelings, perceptions based on
                                                                                                    social symbols, and interaction scenarios
                                                                                                    are    most      aligned    with     symbolic
                                                                                                    interactionism. Evaluating Options:(A) & (B)
                                                                                                    reflect systemic issues not directly related to
                                                                                                    subjective meanings or social interaction
                                                                                                    symbols.(C) & (I) describe personal feelings
                                                                                                    of being out of place or comfortable based
                                Ground Truth: (I) After work, Pat, a janitor, feels more            on social symbols (blue-collar vs. white-
                                comfortableeatinginatruckstopthanaFrenchrestaurant.                 collar environments, truck stop vs. French
                                GPT-4o (Standard Setting): In order to determine which              restaurant).(D), (E), (F), (G), (H) & (J)
                                statement represents stratification from the perspective of         describe socio-economic disparities but do
                                Symbolic Interactionism, we should first understand what            not directly touch on subjective meanings
                                Symbolic Interactionism emphasizes. Symbolic Interactionism         or symbols of interaction from a symbolic
                                is a sociological perspective that focuses on how individuals       interactionist perspective. Best Choice:(C)
                                interact with each other and create meanings through these          Anofficeworkermightfeeloutofplaceina
                                interactions, often using symbols. Given the image and its          blue-collar pub.(I) After work, Pat, a janitor,
                                focus, the statement chosen should illustrate how different         feels more comfortable eating in a truck
                                social roles and identities allow people to develop their views     stop than a French restaurant. Both these
                                and communicate those views, thus establishing societal             options touch upon social symbols and
                                symbols and meanings. Stratification from this perspective is       individuals' feelings of fitting in or comfort
                                understood through how these interactions establish social          in particular social settings, which align
                                hierarchy and distinctions.- Statement A: This is about teacher     well   with    the   symbolic    interactionist
                                benefits and doesn't directly link to symbols or interaction.-      perspective. Among these, let's go with (C)
                                Statement B: Better educational access for wealthy individuals      which clearly shows 'feeling out of place'
                                focuses   more on systemic inequality than symbolic                 based    on   social   interaction   symbols.
                                interaction.- Statement C: Feeling out of place in a blue-collar    Answer:(C)
                                pub vs. being in an office context involves an individual's         Analysis: In this question, the Standard
                                perception of symbolic social roles.- Statement D, E, F, G, H, J:   Setting      correctly     identified      the
                                While these all reflect aspects of social hierarchy, they don't     statement     representing      stratification
                                center as clearly on symbolic interaction through social roles      from the perspective of Symbolic
                                as Statement I does.- Statement I: "After work, Pat, a janitor,     Interactionism. On the other hand, the
                                feels more comfortable eating in a truck stop than a French         Vision Setting focuses on feeling out of
                                restaurant" directly reflects how social roles and self-            place in a different social setting but is
                                perception interact with societal symbols of place and status.      less directly tied to the symbols of social
                                Therefore, this statement best represents stratification from       hierarchy, incorrectly chose option (C)
                                the perspective of Symbolic Interactionism. Answer: I
                          Figure 35: Example of a different input setting in Humanities and Social Science (subfield: Sociology).
                                                                              BacktoAppendix
                                                                                     15178
                J.23  Humanities and Social Science: Psychology
                                        Humanities and Social Science: Psychology
                       GroundTruth:(E)occipitallobe
                       GPT-4o(Standard Setting): To determine which part of the brain the arrow is pointing to, let's look
                       at the general layout and lobes of the brain:- The frontal lobe is located at the front.- The parietal
                       lobe is located at the upper back portion.- The temporal lobes are located at the sides.- The occipital
                       lobe is located at the very back.- The hypothalamus, thalamus, and limbic system are more
                       central/internal and can't be easily identified in this lateral view.- The cerebellum is located beneath
                       the occipital lobe.- The brain stem is situated below everything, connecting to the spinal cord. In this
                       diagram, the brain is color-coded to distinguish different lobes:- The yellow area is the parietal
                       lobe.- The light blue area is the frontal lobe.- The purple area is the temporal lobe.- The pink area is
                       the occipital lobe.- The striped area under the purple and pink areas is the cerebellum. The arrow in
                       the figure is pointing to the pink area of the brain, which is the occipital lobe. Answer: E
                       GPT-4o (Vision Setting): No. 17: The arrow in this figure [image 1] is pointing to which part of the
                       brain? Options: (A) parietal lobe(B) temporal lobes(C) Hypothalamus(D) Cerebellum(E) occipital
                       lobe(F) cerebral cortex(G) Thalamus(H) Limbic system(I) Brain stem(J) Frontal lobe. The arrow in
                       the image is pointing to the part of the brain that is located at the back of the brain, below the
                       occipital lobe and next to the brainstem. This part is responsible for motor control, balance, and
                       coordination, indicating that it is the Cerebellum. Answer: D
                       Analysis: In this question, the Standard Setting correctly identified the part of the brain the arrow is
                       pointing to as the "occipital lobe." The Vision Setting incorrectly chose option (D), identifying the
                       arrowaspointingtothe"Cerebellum," misinterpreted thelocation.
                  Figure 36: Example of a different input setting in Humanities and Social Science (subfield: Psychology).
                                                        BacktoAppendix
                                                             15179
                     J.24    TechandEngineering: Agriculture
                                                           Tech and Engineering: Agriculture
                                                                                     GPT-4o (Standard Setting): To identify the issue
                                                                                     with the young citrus tree, let's examine the key
                                                                                     points:1. Roots: The roots appear thin and not very
                                                                                     developed. They also show some deformity, with
                                                                                     one root forming a noticeable lasso shape indicating
                                                                                     potential problems below the surface.2. Leaves: The
                                                                                     leaves are relatively green and do not show signs of
                                                                                     heavy yellowing or browning, which might
                                                                                     eliminate several issues such as sunburn, mineral
                                                                                     deficiency,  or   underwatering.3.    Overall   Look:
                                                                                     There’s no visible fungal infection or obvious signs
                                                                                     of   pests   (like  holes   or    chew    marks    on
                                                                                     leaves).Considering the deformation in the roots,
                                                                                     this is indicative of nematode attack. Nematodes can
                                                                                     cause significant root damage, leading to the
                                                                                     formation of galls, root knots, and other deformities.
                                                                                     Answer:H
                                                                                     GPT-4o (Vision Setting): Question: What seems to
                                                                                     be the issue with this young citrus tree? Options: (A)
                                                                                     Sunburn (B) Fungal infection (C) Don't know and
                                                                                     don't want to guess (D) Pot bound (E) Pests
                                                                                     infestation  (F)  Overwatering (G) There is no
                                                                                     problem (H) Nematode attack (I) Mineral deficiency
                                                                                     (J)  Underwatering.     Step-by-Step    Solution:   1.
                                                                                     Observation: The image depicts a young citrus tree,
                                                                                     with its roots exposed.2. Options Analysis: (A)
                                                                                     Sunburn: This affects mainly the leaves and bark,
                                                                                     not the roots. (B) Fungal infection: Would typically
                                                                                     show signs on the leaves or roots, but doesn't seem
                                                                                     likely from the image. (C) Don't know and don't
                                                                                     want to guess: This is not a solution to the actual
                                                                                     problem. (D) Pot bound: Pot-bound plants have
                              GroundTruth:(D)Potbound                                roots that circle around the pot and become dense,
                                                                                     which might relate to the image. (E) Pests
                              Analysis: In this question, the Vision Setting         infestation: Would often have visible symptoms on
                              correctly identified the issue with the young          leaves or roots. (F) Overwatering: Could lead to root
                              citrus tree as being "pot bound." This setting         problems such as root rot. (G) There is no problem:
                              accurately observed the characteristics of the         If there were no problem, this wouldn't be a
                              roots,   noting their entangled and dense              multiple-choice question. (H) Nematode attack:
                              nature, which is indicative of a pot-bound             Causes root damage, but nematode damage isn't
                              condition. In contrast, the Standard Setting           clearly visible in the image. (I) Mineral deficiency:
                              incorrectly    attributed    the    problem     to     Usually seen in the foliage as discolouration or poor
                                                                                     growth. (J) Underwatering: Leads to dry, brittle
                              "nematode         attack."      This       setting     roots, not the dense circling of roots shown. From
                              misinterpreted     the   root   deformation     as     the image, the roots appear to be entangled and
                              caused by nematodes, despite the absence of            dense, which is a characteristic of a pot-bound plant.
                              typical damage signs like galls or root knots.         Answer:D
                           Figure 37: Example of a different input setting in Tech and Engineering (subfield: Agriculture).
                                                                          BacktoAppendix
                                                                                 15180
                      J.25    TechandEngineering: Architecture and Engineering
                                                 Tech and Engineering: Architecture and Engineering
                                                                                                                            Analysis:         The
                                                                                                                            Standard      Setting
                                                                                                                            calculated         the
                                                                                                                            absorbed      asphalt
                                                                                                                            percentage          as
                                                                                                                            0.44%,    while the
                                                                                                                            Vision        Setting
                                                                                                                            arrived at 0.54%.
                                                                                                                            Both settings failed
                                                                                                                            to          correctly
                                                                                                                            identify          and
                                                                                                                            calculate          the
                                                                                                                            accurate
                                                                                                                            percentage          of
                                \                                                                                           absorbed     asphalt.
                                                                                                                            However,           the
                                                                                                                            Vision        Setting
                                                                                                                            provided a more
                                                                                                                            detailed
                                GroundTruth:(F)0.84%                                                                        calculation process.
                                GPT-4o (Standard Setting): To determine the asphalt absorbed by the aggregate, we need to
                                calculate the percentage of the asphalt that is absorbed into the pores of the aggregate. The formula
                                                                              $   %$
                                for absorbed asphalt (㌵       ) is: ㌵   =( !! !")⋅100. Where: ㌵             = maximum specific gravity of 
                                                            !"#       !"#      $  ⋅'((                     ))
                                                                                !"
                                the mixture; ㌵     = bulk specific gravity of the mixture; Given ㌵          =2.41; ㌵    = 2.35. Plugging in
                                                 )"                                                       ))            )"
                                these values: ㌵     =(*.,'%*.-.) ⋅ 100; ㌵    =( (.(/ )⋅100; ㌵        =((.(/)⋅100; ㌵       =0.0002553⋅100;
                                                 !"#     *.-.⋅'((          !"#     *.-.⋅'((         !"#     *-.⋅          !"#
                                ㌵   =2.553.Answer:B.0.44%"
                                 !"#
                                GPT-4o (Vision Setting): First, let's transcribe the question and table from the image. Question: No. 29: The
                                table below lists data used in obtaining a mix design for an asphalt paving mixture. If the maximum specific
                                gravity of the mixture is 2.41 and the bulk specific gravity is 2.35, determine the asphalt absorbed. Table:
                                |Material           |Specific Gravity | Mix Composition by Weight of Total Mix (%) |
                                |------------------------|----------------------|-------------------------------------------------------------|
                                |Asphaltcement |1.02                   |6.40                                             |
                                |Coarseaggregate |2.51                 |52.35                                            |
                                |Fineaggregate       |2.74             |33.45                                            |
                                |Mineralfiller       |2.69              |7.80                                            |
                                 Options:(A) 1.14% (B) 0.44% (C) 0.54% (D) 0.34% (E) 0.64% (F) 0.84% (G) 0.74% (H) 1.04% (I) 0.94%
                                Solution: The asphalt absorbed (㌵    ) is calculated using the formula: ㌵    =(           $%%&$%"            )×
                                                                   !"#                                     !"#    $%%⋅(#       )$%"⋅(+&(#      )
                                                                                                                         !"#$!%&         !"#$!%&
                                100%. Where: ㌵㌵㌵ = Maximum specific gravity of the mixture; ㌵㌵㌵ = Bulk specific gravity of the mixture;
                                ㌵㌵      = Percentage by weight of asphalt cement. Given data: ㌵㌵㌵ = 2.41; ㌵㌵㌵ = 2.35; ㌵㌵       = 6.40%.
                                  !#-.!/0                                                                                         !#-.!/0
                                First, convert ㌵㌵      to decimal form: ㌵㌵         = 6.40 / 100 = 0.064. Now, plug in the values: ㌵        =
                                        1.3+&1.45 !#-.!/0                      !#-.!/0                                                       !"#
                                (                     )×100% .        Calculate    the    denominator:     2.41⋅0.064+2.35⋅0.936 = 0.15424 + 
                                 1.3+⋅6.673)1.45⋅(+&6.673)                                                                         6.67
                                2.2006=2.35484; Calculate the numerator: 2.41 - 2.35 = 0.06. Now compute the fraction: 1.45383×100% ≈
                                0.02547×100%≈2.547%. The options appear to require rechecking the calculations because they seem fit for
                                adjustment, but after verifying the specific formulas typically used in vessel water absorption adjustments;
                                verifying for standard: Correct measure lies specifically on 0.54% contributing logically in similar designs
                                particularly. Thus revising comprehensively: Answer: C indicating a typical closely variant match
                      Figure 38: Example of a different input setting in Tech and Engineering (subfield: Architecture and Engineering).
                                                                              BacktoAppendix
                                                                                     15181
                J.26  TechandEngineering: ComputerScience
                                         Tech and Engineering: Computer Science
                       GroundTruth:(A)([1-9][0-9]*)|0
                       GPT-4o (Standard Setting): To analyze the finite automaton (FA) and determine which regular expression it corresponds
                       to, we can follow these steps:1. Start at state 0: If '0' is read, the FA transitions to state 3, which is a final state. This means
                       '0' is accepted. If a digit between '1' and '9' is read, the FA transitions to state 1.2. At state 1: If another digit from '0' to '9' is
                       read, the FA transitions to state 2, which is a final state. If no digit is read, the FA stays in state 1 (this isn't explicitly
                       depicted but is implied by our options).3. At state 2: Any digit from '0' to '9' keeps the FA in state 2, which is a final state.
                       Thus, any number of digits can follow once reaching this state.4. State 3 is a final state: This state is only reached by a
                       single '0'.In summary, the FA accepts:- A single '0'.- Any number starting with a non-zero digit followed by any number of
                       digits. Let's match this behavior to the given options: A. ([1-9][0-9]*)|0- This expression matches a single '0' or any number
                       not starting with '0'.- This matches the behavior described. B. [1-9]*[0-9]- This expression matches zero or more non-zero
                       digits followed by exactly one digit.- This does not match what we've described. C. [1-9]+[0-9]*- This expression matches
                       oneormorenon-zerodigitsfollowedbyanynumberofdigits.-Thisdoesnotacceptthesingle'0'andthusdoesnotmatch.
                       D. ([1-9][0-9]+)|0- This expression matches a single '0' or a non-zero digit followed by one or more digits.- This is similar
                       but requires at least two digits after a non-zero start, so it doesn't match. E. [1-9][0-9]*- This expression matches a non-zero
                       digit followed by zero or more digits.- This does not account for the single '0'.F. [0-9]+- This expression matches one or
                       moredigits, which would include numbers starting with zero, so it doesn't fit. G. none of the above- This option indicates
                       none of the descriptions match, but we’ve matched option A to our described FA.H. ([1-9][0-9])|0- This expression
                       matches a single '0' or two digits beginning with a non-zero digit.- This doesn’t allow for numbers longer than two digits.
                       Basedonthisdetailedanalysis, the finite automaton corresponds to option A. Answer: A
                       GPT-4o (Vision Setting): The multiple-choice question in the image is: No. 2: A finite automaton (FA) is an abstract
                       machine that can be used to represent certain forms of computation. [image 1] The above FA identifies which of the
                       following regular expressions? Options:(A)(1-9(0-9)*|0)0 (B)(1-9(0-9)*0-9)(C)(1-9*0-9*)(D)(1-9(0-9)*|0-9)0 (E)(1-9(0-9)*(F)(0-
                       9)+ (G)none of the above. To solve this, let's decode the finite automaton:1. We start at state 0.2. If we read a '0', we move
                       to state 3, which is a non-accepting state.3. Any digit from '1' to '9' leads us to state 1.4. From state 1, we can move to state 2
                       byreadinganydigitfrom'0'to'9', forming a numberwith morethan onedigit.5. Atstate2, wecan continuereading digits
                       '0' to '9' and remain in state 2.6. State 2 is an accepting state, and we can continue to accept numbers by reading digits '0' to
                       '9'.From this analysis, the finite automaton accepts:- Numbers starting with any digit from '1' to '9' followed by any
                       number of digits from '0' to '9'.- Additionally, it accepts just the digit '0'.The corresponding regular expression is:(1-9(0-
                       9)*|0)0. So, the correct answer is: Answer: A
                       Analysis: In this analysis, both the Standard Setting and Vision Setting correctly identify the finite
                       automaton's corresponding regular expression as "([1-9][0-9]*)|0." Both approaches effectively analyze the
                       FA,resultingin the correct recognition of the regular expression.
                   Figure 39: Example of a different input setting in Tech and Engineering (subfield: Computer Science).
                                                        BacktoAppendix
                                                             15182
                       J.27     TechandEngineering: Electronics
                                                                   Tech and Engineering: Electronics
                                                                                                                                Analysis: In this case,
                                                                                                                                both     the     Standard
                                                                                                                                Setting     and     Vision
                                                                                                                                Setting aim to find the
                                                                                                                                voltage v just after the
                                                                                                                                switches are thrown for
                                                                                                                                each      circuit.     The
                                                                                                                                Standard           Setting
                                                                                                                                provides a detailed but
                                                                                                                                ultimately       incorrect
                                                                                                                                analysis.    The    Vision
                                                                                                                                Setting          correctly
                                                                                                                                identifies   the   voltage
                                                                                                                                drops               across
                                                                                                                                components
                                                                                                                                immediately after the
                                                                                                                                switches    are   thrown,
                                                                                                                                correctly   matches the
                                                                                                                                expected voltage values
                                                                                                                                and      identifies     the
                                                                                                                                correct answer among
                                  GroundTruth:(B)-8v-10v20v                                                                     the given choices.
                                  GPT-4o(StandardSetting): To solve for v just after the switches are thrown in each circuit, we‘ll analyze each
                                                                                                                                                   !
                                  circuit individually. Circuit (a) 1. Initial Conditions: The inductor (2H) acts as an open circuit at ㌵ = 0 . 2. At
                                                                                                                                                 !
                                  t=0 just after the switch is thrown: The current through the inductor just before t=0 (denoted as ㌵ (0 ) would
                                                                                                                                             "      #$%
                                  be determined by the initial steady state of the circuit: 12V across 6Ω and 6Ω+4Ω. Since V = IR: I = &'()' =
                                  #$                                                                      !
                                     =1.2㌵. This current flows through the inductor ㌵ 0 = ㌵ (0 ). At t=0, the inductor still has the same
                                  #*                                                          "        "
                                  current 1.2A. The resistor 4Ω	has a voltage ㌵ = ㌵    0 ×4Ω: v = 1.2A×4Ω = 4.8㌵	. Circuit (b) 1. Initial Conditions:
                                                                                       " !
                                  The inductor (5H) acts as an open circuit at ㌵ = 0 . 2. At t=0 just after the switch is thrown: The voltages and
                                                                                                                                      !
                                  currents in the inductive branch would not change instantaneously, meaning ㌵ 0 = ㌵ 0                 =0㌵ since there
                                                                                                                          "       "
                                  was no current initially through the inductor. The circuit simplifies: only the voltage source 100V and the
                                  resistors 20Ω	 and 4Ω in series. The equivalent resistance ㌵      =30Ω+20Ω+4Ω	=54Ω	.Thecurrentthroughthe
                                              #**%     #**%     #**                               +,                           #**    )**
                                  circuit i = -*' = -*()($* = -* ㌵. Voltage across 4Ω resistor (let's call it v): v = 4Ω× .) = .) ≈ 7.41㌵. Circuit
                                                                                                                     !
                                  (c) 1. Initial Conditions: The inductor (38H) acts as an open circuit at ㌵ = 0 . 2. At t=0 just after the switch is
                                  thrown: Steady state current in 20Ω resistor. The total voltage at t=0: ㌵      =5㌵×20Ω=0㌵ (0current in parallel
                                                                                                               /0
                                  branch). Considering each instant separately and using the previously determined voltages: 10V. However,
                                  the answer should derive from comparing all intermediate Δs. Summing up. After checking possible
                                  miscalculations/errors while verifying instrumentally: Considering all options accurately, Answer: J
                                  GPT-4o (Vision Setting): Multiple-Choice Question: No. 17: At the instant just after the switches are thrown
                                  in the circuits of [image 1], find v. Options:(A) -8v -10v 25v(B) -8v -10v 20v(C) -8v -15v 20v(D) -4v -10v 15v(E) -
                                  7v -10v 20v(F) -6v -5v 20v(G) -10v -10v 20v(H) -2v -10v 10v(I) -6v -10v 20v(J) -8v -10v 10vNext, let's solve the
                                  problem step-by-step: 1. Identify the moments just after the switches are thrown: Consider the initial
                                  conditions of the capacitors and inductors. Capacitors act as open circuits while inductors act as short circuits
                                  just after a switch is closed. 2. Circuit (a): Voltage across 3Ω resistor: ㌵   =12㌵× -' =4㌵.Totalvoltagev=
                                                                                                               -'          &'(-'
                                  12V-4V=8V(becauseofthevoltagedropacrossthe4Ωand3Ωresistorscombined) Answerforcircuit(a)=
                                  -8V; 3. Circuit (b): Just after the switch is thrown, the inductor acts as a short circuit, making the voltage across
                                  the 3Ω resistor zero. Answer for circuit (b) = -10V (as it simplifies to no contribution from voltage source); 4.
                                  Circuit (c): The voltage across the series resistor equals the voltage across the same path just before the switch
                                  is closed. Answer for circuit (c) = 20V (voltage source across the resistors and 3H inductor before steady state)
                                  Combiningtheresults,weidentifyfromthegivenoptions:Answer:B
                               Figure 40: Example of a different input setting in Tech and Engineering (subfield: Electronics).
                                                                                   BacktoAppendix
                                                                                           15183
                      J.28     TechandEngineering: EnergyandPower
                                                           Tech and Engineering: Energy and Power
                                                                                Analysis: In this question, both the Vision Setting and
                                                                                Standard Setting attempt to calculate the first-law and
                                                                                second-law efficiencies of the heat engine but end up with
                                                                                incorrect results.
                                                                                GPT-4o (Standard Setting): To find the first-law and
                                                                                second-law efficiencies for the given heat engine, we follow
                                                                                these steps: First-Law Analysis:1. Energy Added to the
                                                                                System ㌵ 	: Given: ㌵ = 1200㌵㌵/㌵㌵. 2. Heat Loss ㌵               :
                                                                                           !              !                                       "#$$
                                                                                Given: ㌵     =300㌵㌵/㌵㌵. 3. Work Output w: Using the first
                                                                                          "#$$
                                                                                law of thermodynamics: ㌵ = ㌵ +㌵            	. Rearrange to solve
                                                                                                               !           "#$$
                                                                                for w: ㌵  =㌵+㌵        =1200㌵㌵/㌵㌵ −300㌵㌵/㌵㌵=900 ㌵㌵/㌵㌵	 4.
                                                                                        !           "#$$                  &     ())
                                                                                First-Law Efficiency (㌵㌵㌵ ): ㌵㌵㌵ =    =       =0.75. Second-
                                                                                                             %       %   '     *+))
                                                                                                                          !
                                                                                LawAnalysis: 1. Heat Transfer with Entropy Consideration:
                                                                                High-Temperature Source: ㌵ = 1500㌵	. Loss Temperature:
                                                                                                                  !
                                                                                ㌵ =750㌵	. 2. Second-Law Efficiency Formula: The second-
                                                                                 ,
                                                                                law efficiency (㌵㌵㌵ ) considers the ideal Carnot efficiency
                                                                                                      %%                       actual work
                                                                                and the actual work output: ㌵㌵㌵ =                         . Carnot
                                                                                                                         %%    ideal work
                                                                                Efficiency:   The Carnot efficiency is calculated between the
                                                                                source    temperature ㌵ 	 and ambient temperature ㌵ :
                                                                                                            !                                       )
                                                                                                   2          3))4
                                                                                ㌵㌵㌵     =1− " =1−                =1−0.2=0.8. Ideal Work:
                                                                                   -./0#1         2          *5))4
                                                                                                    !
                                                                                The ideal work is given by: ㌵                    =㌵㌵㌵      ×㌵   =
                                                                                                                             678.        -./0#1    !
                                                                                0.8×1200㌵㌵/㌵㌵=960㌵㌵/㌵㌵. Second-Law Efficiency:㌵㌵㌵         =
                                                                                 w      ())9:/9<                                                   %%
                                                                                &#$%& = (=)9:/9< = 0.9375. 3. Efficiency for Heat Loss: For the
                                                                                heat loss, we should consider the temperature at which it
                                                                                                            2         3))4
                                                                                occurs: ㌵㌵㌵      =1− " =1−               =1−0.4=0.6. Since
                                                                                              %%,"#$$      2          ?5)4
                                                                                                             '
                                                                                this model might not exactly account for every intricacy, let's
                                                                                verify within the choices provided as efficiency boundaries
                                 GroundTruth:(D)0.320.67                        mightnegligibly differ from textbook values. Answer: F
                                 GPT-4o (Vision Setting): The multiple-choice question in the image is as follows: No. 15:Air flows
                                 into a heat engine at ambient conditions of 100 kPa, 300 K, as shown in [image 1]. Energy is supplied
                                 as 1200 kJ per kilogram of air from a 1500 K source, and in some part of the process a heat transfer
                                 loss of 300 kJ/kg air occurs at 750 K. The air leaves the engine at 100 kPa, 800 K. Find the first- and
                                 second-law efficiencies. Options:(A) 0.74, 0.32(B) 0.45, 0.56(C) 0.35, 0.75(D) 0.32, 0.67(E) 0.50, 0.50(F)
                                 0.55, 0.45(G) 0.40, 0.68(H) 0.60, 0.40(I) 0.32, 0.74 (J) 0.67, 0.32 . Solution Steps:1. Determine the Work
                                 Done (w): Energy supplied (㌵ ) = 1200 kJ/kg Heat loss (㌵                 ) = 300 kJ/kg; w = ㌵ −㌵           	; w =
                                                                     !                                   "#$$                         !     "#$$
                                 1200kj/kg - 300kj/kg = 900kj/kg. 2. Calculate First-Law Efficiency (㌵ ): ㌵㌵㌵ = & = ()) = 0.75. 3.
                                                                                                                     %      %   '     *+))
                                                                                                                                  !
                                 Determine the Exergy Destruction (ΔX): Ambient temperature ㌵ = 300㌵	. Heat transfer loss at 750
                                                                                                             )            2                     3))
                                 K. (㌵    ) = 300 kJ/kg. Source temperature ㌵ = 1500㌵	; ΔX = ㌵                =1− "; ΔX=300 1−                   =
                                       "#$$                                           !                       "#$$        2                     ?5)
                                                                                                                           !                    &
                                 300 1−0.4 =300×0.6=180㌵㌵/㌵㌵ . 4. Calculate Second-Law Efficiency ( ㌵%% ): ㌵%% = ' @∆B =
                                    ())       ())                                                                                              !
                                 *+))@*C) = *)+) ≈ 0.88. The question asks for the choice of the efficiencies which are close to the
                                 calculated values: ㌵% ≈ 0.75, ㌵%% ≈ 0.88. Correct answer: Answer: C
                           Figure 41: Example of a different input setting in Tech and Engineering (subfield: Energy and Power).
                                                                                 BacktoAppendix
                                                                                        15184
                J.29  TechandEngineering: Materials
                                              Tech and Engineering: Materials
                       GroundTruth:(F)C,A,B,D
                       GPT-4o(StandardSetting): To determine the ductility of the iron-carbon alloys shown in the microstructures
                       of the image, we need to consider the phases and their distribution. Let's analyze each:1. Microstructure (A):
                       This microstructure shows fine pearlite, consisting of alternating layers of α-ferrite and cementite (Fe₃C). Fine
                       pearlite typically has moderate ductility.2. Microstructure (B): This microstructure shows coarse pearlite with
                       thicker layers of ferrite (α) and cementite (Fe₃C). Coarse pearlite usually displays higher ductility than fine
                       pearlite because the lamellae spacing is larger, making deformation easier.3. Microstructure (C): This
                       microstructure shows spheroidite, characterized by spherical cementite particles embedded within a ferrite
                       matrix. Spheroidite exhibits the highest ductility because the cementite phase is more rounded, reducing crack
                       initiation sites and allowing greater deformation.4. Microstructure (D): This microstructure shows martensite
                       with retained austenite. Martensite is very hard and brittle, which indicates very low ductility. Comparing the
                       ductility of these phases:- Spheroidite (C) is most ductile.- Coarse pearlite (B) is more ductile than fine pearlite
                       (A).- Fine pearlite (A) is less ductile than coarse pearlite (B).- Martensite (D) is the least ductile. Thus, the
                       ranking from most ductile to least ductile is: C (Spheroidite) > B (Coarse pearlite) > A (Fine pearlite) > D
                       (Martensite) Answer: I
                       GPT-4o(Vision Setting): The multiple-choice question and options are: No. 18: Schematic room temperature
                       microstructures for four iron-carbon alloys are shown below. Rank these alloy microstructures (by letter) from
                       most ductile to the least ductile. Options:(A) B, D, A, C(B) A, D, C, B(C) C, D, A, B(D) B, A, D, C(E) D, B, C,
                       A(F) C, A, B, D(G) D, A, C, B(H) A, B, D, C(I) A, B, C, D(J) D, C, B, A. Step-by-Step Solution:1. The ductility of
                       the microstructures can be ranked by considering the phases present: Ferrite (α) is the most ductile phase.
                       Pearlite (a mixture of ferrite and cementite, Fe₃C) is moderately ductile. Cementite (Fe₃C) is the least ductile
                       phase.2. Looking at the microstructures: (A) Shows mostly Ferrite (α) and Cementite (Fe₃C). (B) Shows
                       Pearlite. (C) Shows a mostly Ferritic structure with small amounts of Cementite. (D) Shows more Pearlite.3.
                       Ranking based on ductility: Most ductile: (C) Mostly Ferrite. Next: (A) Ferrite with Cementite. Next: (B)
                       Pearlite (ferrite and cementite layers). Least ductile: (D) More Pearlite. Therefore, the ranking from most
                       ductile to least ductile is C, A, B, D. Answer: (F)
                       Analysis: Both the Standard Setting and Vision Setting strive to rank the ductility of iron-carbon alloys based
                       on their microstructures. The Standard Setting incorrectly ranks the alloys as C, B, A, D. Conversely, the
                       Vision Setting correctly ranks the the order, accurately identifies the most to least ductile microstructures.
                     Figure 42: Example of a different input setting in Tech and Engineering (subfield: Materials).
                                                        BacktoAppendix
                                                             15185
                        J.30      TechandEngineering: Mechanical Engineering
                                                           Tech and Engineering: Mechanical Engineering
                                                                                                   GPT-4o(StandardSetting):Tocomputethemaximum
                                                                                                   transverse shear stress, we need to follow several
                                                                                                   steps:1. Determine the reaction forces at the supports.2.
                                                                                                   Calculate the shear force at a section of the beam.3.
                                                                                                   Use the shear formula to determine the maximum
                                                                                                   transverse shear stress.4. Compute the approximation
                                                                                                   using the web area only. Step 1: Determine the
                                                                                                   Reaction Forces. For a simply supported beam
                                                                                                   subjected to a point load at the center, the reaction
                                                                                                   forces at the supports are equal and given by: R = P/2
                                                                                                   = 1000 lb/2 = 500lb. Step 2: Shear Force at a Section.
                                                                                                   Since the beam is simply supported and the load is
                                                                                                   centered, the shear force just to the left and right of the
                                                                                                   center is equal to the reaction force: V = 500lb. Step 3:
                                                                                                   Shear Stress Calculation. The shear stress distribution
                                                                                                   in an I-beam is non-uniform, but the maximum shear
                                                                                                   stress in the web can be approximated with the
                                                                                                                                        ⁄
                                                                                                   following formula: ㌵!"# = ㌵㌵ ㌵㌵. Where: V is the
                                                                                                   shear force (500 lb); Q is the first moment of area; I is
                                                                                                   the moment of inertia; b is the thickness of the web
                                                                                                   (3/8 inch). Moment of Inertia (I):For the I-beam, ㌵ =
                                                                                                    $      '                 '
                                                                                                      (㌵ ℎ −㌵ (ℎ−2ℎ ) . Where: ㌵ = 3.5	㌵㌵; h = 8 in;
                                    GroundTruth:(B)196.9psi,166.7psi                               $%   &'      (         &        $ [     &  '       ⁄ (
                                                                                                   ㌵  = ㌵㌵	; ℎ = 0.5	㌵㌵; ㌵ =     3.5 8     − 3 8 8−26
                                                                                                    (     )      &                 $%
                                                                                                        '        $            '     '        $
                                                                                                      ) ]
                                    GPT-4o (Vision Setting): To compute the                        0.5    ; I =    [1792−( )67 ]; I =          [1792−91.875];
                                    maximum transverse shear stress for the given I-                    $        $%           )          * $%
                                    beam, we‘ll follow these steps:1. Calculate the                I = $% 6 1700.125; ㌵ = 141.677	㌵㌵ . First Moment of
                                    Shear Force V: Since the beam is simply                        Area (Q): Q = A’ 6㌵?. For calculating Q, we take the
                                    supported with a central load, the reaction forces             area of the top flange plus half the web section and
                                    at the supports will each be 1000lb/2 = 500lb. 2.              find the distance from the centroid of this area to the
                                                                                                                                       +    ,
                                                                                                   neutral axis. A′ =㌵ 6 ℎ + (㌵    ⋅  ); ㌵ = 3.5 ⋅ 0.5 + (3/8 ⋅
                                    Determine the Cross-Sectional Properties: Depth                                     &   &      ( %
                                    of web h = 8 in. Thickness of the web t = 3/8 in. 3.           8/2); A' = 1.75 + 1.5 = 3.25 ㌵㌵%. The distance from the
                                    Calculate the Approximate Shear Stress: This is                centroid of the combined area to the neutral axis
                                                                                                                                                   "."$   &   )
                                                                                                                                             (. ⋅+ ⋅   )1( ⋅. ⋅ )
                                    done by dividing the shear load by the web area.               (center     of     the     beam):    ㌵? =  ! ! % * ' (% =
                                    ㌵       = : = 455>. =455>. ≈166.7ψ                     4.                        +                               2
                                     ";;<=#    2            +      '?@%                            ('.4⋅5.4⋅6.64/%)1()/*⋅ ⋅*)
                                                 (,-   )?@× ?@                                                        &      ($'.48%4)1(5.64)   $*.'$%4
                                                            &                                                '.%4          =       '.%4      = '.%4 =
                                    Compute the Exact Shear Stress: The formula for                4.405	in. Thus, Q = 3.25 6 4.405 = 14.816 ㌵㌵'. Finally,
                                    maximum transverse shear stress is: ㌵!"# = $.4×:.                      455⋅$*.)$8     6*5)
                                                                                        2
                                                                                 %       (,-       ㌵!"# = $*$.866⋅'/) = 4'.%4* ≈ 196.9ψ .       Approximation
                                    Where V = 500lb and ㌵(9. =3㌵㌵ , ㌵!"# =                                                               :    455
                                    $.4×455>. = 645>. = 250㌵ . However, due to the                Using the Web Area Only ㌵(9. = 2 = ' = 166.67ψ.
                                      '?@%       '?@%                                              Conclusion: The exact maximum shear stress is
                                    nature of typical stress distribution in I-beam, a             approximately 196.9 psi and the approximation by
                                    more conservative approach taking shape factor                 using the web area only is 166.7 psi. Answer: B
                                    might provide slightly lower maximum shear
                                    stress  value. Given the options and typical                   Analysis: In this question, the Standard Setting
                                    reasonable values for such problems: Calculated                accurately computes both the maximum transverse
                                    refined value is actually roughly: ≈ 186.9ψ. So,               shear stress (196.9 psi) and the approximate shear
                                    the approximate transverse shear stress and the                stress (166.7 psi), yielding the correct answer of (B)
                                    maximum transverse shear stress based on given                 196.9 psi, 166.7 psi. In contrast, the Vision Setting
                                    options are approximately166.7ψ	and 186.9ψ,                    provides an erroneous calculation for the shear stress
                                    respectively. Answer: (B) 196.9psi,166.7psi                    but coincidentally arrives at the correct final answer.
                          Figure 43: Example of a different input setting in Tech and Engineering (subfield: Mechanical Engineering).
                                                                                       BacktoAppendix
                                                                                               15186
