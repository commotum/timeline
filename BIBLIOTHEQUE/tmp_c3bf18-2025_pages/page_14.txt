m=
oO
Nae)
ms
G
aa]

100 100

High-Level (2_H)

80 80

60 60

40 40 “

Participation Ratio (PR)
Participation Ratio (PR)

20 20

20 40 60 80 100 20 40 60 80 100
(d) Number of Trajectories Number of Trajectories

®

100 £9.95 100

80 80

60 60

42.09 40.75
40 30.22 40

20 20

Participation Ratio (PR)
Participation Ratio (PR)

0 20 40 Low-Level High-Level Low-Level High-Level
Position in the hierarchy Gy) @H) Gy) (ZH)

Figure 8: Hierarchical Dimensionality Organization in the HRM and Mouse Cortex. (a,b) are
adapted from Posani et al.”*. (a) Anatomical illustration of mouse cortical areas, color-coded by
functional modules. (b) Correlation between Participation Ratio (PR), a measure of effective neural
dimensionality, and hierarchical position across different mouse cortical areas. Higher positions in
the hierarchy (e.g., MOs, ACAd) exhibit significantly higher PR values compared to lower sensory
areas (e.g., SSp-n), with a Spearman correlation coefficient of » = 0.79 (P = 0.0003). (c,d) Trained
HRM. (c) PR scaling of the trained HRM with task diversity. The dimensionality of the high-
level module (z;;) scales with the number of unique tasks (trajectories) included in the analysis,
indicating an adaptive expansion of its representational capacity. In contrast, the low-level module’s
(zr) dimensionality remains stable. (d) PR values for the low-level (zz, PR = 30.22) and high-
level (zy, PR = 89.95) modules of the trained HRM, computed from neural activity during 100
unique Sudoku-solving trajectories. A clear dimensionality hierarchy is observed, with the high-
level module operating in a substantially higher-dimensional space. (e,f) Analysis of Untrained
Network. To verify that the dimensionality hierarchy is an emergent property of training, the same
analyses were performed on an untrained HRM with random weights. (e) In contrast to the trained
model’s scaling in (c), the dimensionality of both modules in the untrained model remains low and
stable, failing to scale with the number of tasks. (f) Similarly, contrasting with the clear separation
in (d), the PR values for the untrained model’s modules (zz, PR = 42.09; zy, PR = 40.75) are
low and nearly identical, showing no evidence of hierarchical separation. This confirms that the
observed hierarchical organization of dimensionality is a learned property that emerges through
training, not an artifact of the model’s architecture.

14
