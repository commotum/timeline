# Point Transformer (Not specified in the paper.)
Source: 821c59-2021.pdf

## Core reasons
- The paper develops a self-attention layer specifically for 3D point cloud processing, indicating a transformer-style model adapted to 3D data.
- It constructs Point Transformer networks for point cloud classification and dense prediction as backbones for 3D scene understanding, showing a shift from 1D/2D tasks to 3D domains.

## Evidence extracts
- "We flesh out this intuition and develop a self-attention
layer for 3D point cloud processing." (p. 1)
- "Based on the Point Transformer layer, we construct
high-performing Point Transformer networks for clas-
sification and dense prediction on point clouds. These
networks can serve as general backbones for 3D scene
understanding." (p. 2)

## Classification
Class name: Increasing Transformer's Dimensions
Class code: 2

$$
\boxed{2}
$$
