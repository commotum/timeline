# SWE-Bench: Can Language Models Resolve Real-World GitHub Issues? (2024)
Source: ae28ee-2024.pdf

## Core reasons
- The paper introduces SWE-bench as a benchmark built from real GitHub issues and pull requests, making the dataset/benchmark the main contribution.
- It specifies benchmark evaluation metrics for task resolution, emphasizing measurement infrastructure.

## Evidence extracts
- "SWE-bench is a benchmark featuring GitHub issues from popular repositories that report bugs or request new features, and pull requests that make changes to the repository to resolve these issues." (p. 2)
- "The metric for our benchmark is the percentage of task instances that are resolved." (p. 3)

## Classification
Class name: Data, Benchmarks & Measurement
Class code: 4

$$
\boxed{4}
$$
