                         PublishedasaconferencepaperatICLR2019
                         UNIVERSALTRANSFORMERS
                                            ∗                      ∗
                           MostafaDehghani †        StephanGouws              OriolVinyals
                           UniversityofAmsterdam    DeepMind                  DeepMind
                           dehghani@uva.nl          sgouws@google.com         vinyals@google.com
                           JakobUszkoreit           ŁukaszKaiser
                           GoogleBrain              GoogleBrain
                           usz@google.com           lukaszkaiser@google.com
                                                               ABSTRACT
                                 Recurrent neural networks (RNNs) sequentially process data by updating their
                                 state with each newdatapoint,andhavelongbeenthedefactochoiceforsequence
                                 modeling tasks. However, their inherently sequential computation makes them
                                 slow to train. Feed-forward and convolutional architectures have recently been
                                 showntoachievesuperiorresultsonsomesequencemodelingtaskssuchasmachine
                                 translation, with the added advantage that they concurrently process all inputs in
                                 thesequence,leadingtoeasyparallelizationandfastertrainingtimes. Despitethese
                                 successes, however, popular feed-forward sequence models like the Transformer
                                 fail to generalize in many simple tasks that recurrent models handle with ease, e.g.
                                 copyingstringsorevensimplelogicalinferencewhenthestringorformulalengths
                                 exceed those observed at training time. We propose the Universal Transformer
                                 (UT), a parallel-in-time self-attentive recurrent sequence model which can be
                                 cast as a generalization of the Transformer model and which addresses these
                                 issues. UTscombinetheparallelizabilityandglobalreceptiveﬁeldoffeed-forward
                                 sequencemodelsliketheTransformerwiththerecurrentinductivebiasofRNNs.
                                 Wealsoaddadynamicper-positionhaltingmechanismandﬁndthatitimproves
                                 accuracy on several tasks. In contrast to the standard Transformer, under certain
                                 assumptionsUTscanbeshowntobeTuring-complete. Ourexperimentsshowthat
                                 UTsoutperformstandardTransformersonawiderangeofalgorithmicandlanguage
                                 understanding tasks, including the challenging LAMBADA language modeling
                                 taskwhereUTsachieveanewstateoftheart,andmachinetranslationwhereUTs
                                 achievea0.9BLEUimprovementoverTransformersontheWMT14En-Dedataset.
                         1   INTRODUCTION
        arXiv:1807.03819v3  [cs.CL]  5 Mar 2019Convolutional and fully-attentional feed-forward architectures like the Transformer have recently
                         emerged as viable alternatives to recurrent neural networks (RNNs) for a range of sequence
                         modeling tasks, notably machine translation (Gehring et al., 2017; Vaswani et al., 2017). These
                         parallel-in-time architectures address a signiﬁcant shortcoming of RNNs, namely their inherently
                         sequentialcomputationwhichpreventsparallelizationacrosselementsoftheinputsequence,whilst
                         still addressing the vanishing gradients problem as the sequence length gets longer (Hochreiter et al.,
                         2003). TheTransformermodelinparticularreliesentirelyonaself-attentionmechanism(Parikhetal.,
                         2016; Lin et al., 2017) to compute a series of context-informed vector-space representations of the
                         symbolsinitsinputandoutput,whicharethenusedtopredictdistributionsoversubsequentsymbolsas
                         themodelpredictstheoutputsequencesymbol-by-symbol. Notonlyisthismechanismstraightforward
                         to parallelize, but as each symbol’s representation is also directly informed by all other symbols’
                         representations, this results in an effectively global receptive ﬁeld across the whole sequence. This
                         standsincontrasttoe.g.convolutionalarchitectureswhichtypicallyonlyhavealimitedreceptiveﬁeld.
                         Notably,however,theTransformerwithitsﬁxedstackofdistinctlayersforegoesRNNs’inductivebias
                         towardslearningiterativeorrecursivetransformations. Ourexperimentsindicatethatthisinductive
                            ∗ Equalcontribution,alphabeticallybylastname.
                            † WorkperformedwhileatGoogleBrain.
                                                                    1
