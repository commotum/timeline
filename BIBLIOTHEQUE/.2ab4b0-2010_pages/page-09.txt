                                                                                                                                                                                                   REVIEWS
                                                            ab
                                                                    The mountain car problem                                    Loss functions (priors)                                Conditional expectations
                                                               0.7                                                          5                                                    30
                                                               0.6                                                          0                                                    25                                  −c(t)
                                                               0.5                                                         –5                                                   es20
                                                                                                                                                                                t
                                                                                                                                                                                a
                                                               0.4                                                       e–10                           c(x)                       15
                                                                                                                         c
                                                                                                                         or–15                                                  ted st
                                                             Height0.3   ϕ(x)                                            F                                                        10
                                                               0.2                                                       –20                                                    Estima   5
                                                                                                                                                                                                                          x
                                                                                                                                                                                                                      μ(t)
                                                                0.1                                                       –25                                                      0
                                                                 0                                                        –30                                                    –5
                                                                   -2        -1         0          12 –2 –1 012    0 20 40 60 80 100120
                                                                                  Position (x)                                                Position (x)                                          Time (seconds)
                  Principle of optimality
                  An optimal policy has                             Equations of motion                                         Trajectories                                           Action
                  the property that whatever the 
                  initial state and initial decision,                    ˙x             x′                                   2                                                     3
                  the remaining decisions must                      f == 1                                               x′
                                                                         ˙x′    −∇ϕ −  ⁄8 x′ + σ(a)                                                                                2
                  constitute an optimal policy                                     x
                  with regard to the state                                                                                   1                                                   l                             a(t)
                  resulting from the first decision.                                                                                                                                1
                  Exploration–exploitation                                                                                   0                                                   ol signa0
                                                                                                                         elocity
                  trade-off                                                                                              V                                                       ontr
                  Involves a balance between                                                                                                                                     C–1
                  exploration (of uncharted                                                                                 –1
                                                                                                                                                                                  –2
                  territory) and exploitation (of 
                  current knowledge). In                                                                                   –2                                                     –3
                  reinforcement learning, it has                                                                              –2         –1          012    0 20 40 60 80 100120
                  been studied mainly through                                                                                                 Position (x)                                          Time (seconds)
                  the multi-armed bandit 
                  problem.                                 Figure 3 | solving the mountain car problem with prior expectations. a | How paradoxical but adaptive behaviour (for 
                                                                                                                                                                                          Nature Reviews | Neuroscience
                                                           example, moving away from a target to ensure that it is secured later) emerges from simple priors on the motion of hidden 
                  Dynamical systems theory                 states in the world. Shown is the landscape or potential energy function (with a minimum at position x = –0.5) that exerts 
                  An area of applied                       forces on a mountain car. The car is shown at the target position on the hill at x =1, indicated by the red circle. The equations 
                  mathematics that describes               of motion of the car are shown below the plot. Crucially, at x = 0 the force on the car cannot be overcome by the agent, 
                  the behaviour of complex                 because a squashing function –1≤σ≤1 is applied to action to prevent it being greater than 1. This means that the agent can 
                  (possibly chaotic) dynamical             access the target only by starting halfway up the left hill to gain enough momentum to carry it up the other side. b | The 
                  systems as described by                  results of active inference under priors that destabilize fixed points outside the target domain. The priors are encoded in a 
                  differential or difference               cost function c(x) (top left), which acts like negative friction. When ‘friction’ is negative the car expects to go faster (see 
                  equations.
                                                           Supplementary information S5 (box) for details). The inferred hidden states (upper right: position in blue, velocity in green 
                  Synergetics                              and negative dissipation in red) show that the car explores its landscape until it encounters the target, and that friction then 
                  Concerns the self-organization           increases (that is, cost decreases) dramatically to prevent the car from escaping the target (by falling down the hill). The 
                  of patterns and structures in            ensuing trajectory is shown in blue (bottom left). The paler lines provide exemplar trajectories from other trials, with 
                  open systems far from                    different starting positions. In the real world, friction is constant. However, the car ‘expects’ friction to change as it changes 
                  thermodynamic equilibrium. It            position, thus enforcing exploration or exploitation. These expectations are fulfilled by action (lower right).
                  rests on the order parameter 
                  concept, which was generalized 
                  by Haken to the enslaving 
                  principle: that is, the dynamics             In summary, optimal control and decision (game)                                   Conclusions and future directions
                  of fast-relaxing (stable) modes          theory start with the notion of cost or utility and try to                            Although contrived to highlight commonalities, this 
                  are completely determined by 
                  the ‘slow’ dynamics of order             construct value functions of states, which subsequently                               Review suggests that many global theories of brain 
                  parameters (the amplitudes of            guide action. The free-energy formulation starts with                                 function can be united under a Helmholtzian percep-
                  unstable modes).                         a free-energy bound on the value of states, which is                                  tive of the brain as a generative model of the world it 
                                                                                                                                                             18,20,21,25
                  Autopoietic                              specified by priors on the motion of hidden environ-                                  inhabits                (FIG. 4); notable examples include the 
                  Referring to the fundamental             mental states. These priors can incorporate any cost                                  integration of the Bayesian brain and computational 
                  dialectic between structure              function to ensure that costly states are avoided. states                             motor control theory, the objective functions shared 
                  and function.                            with minimum cost can be set (by learning or evolu-                                   by predictive coding and the infomax principle, 
                  Helmholtzian                             tion) in terms of prior expectations about motion and                                 hierarchical inference and theories of attention, the  
                  Refers to a device or scheme             the attractors that ensue. In this view, the problem of                               embedding of perception in natural selection and  
                  that uses a generative model to          finding sparse rewards in the environment is nature’s                                 the link between optimum control and more exotic 
                  furnish a recognition density            solution to the problem of how to minimize the entropy                                phenomena in dynamical systems theory. The constant 
                  and learns hidden structures in          (average surprise or free energy) of an agent’s states: by                            theme in all these theories is that the brain optimizes 
                  data by optimizing the                   ensuring they occupy a small set of attracting (that is,                              a (free-energy) bound on surprise or its complement, 
                  parameters of generative 
                  models.                                  rewarding) states.                                                                    value. This manifests as perception (so as to change 
                  NATuRE REvIEWs | NeuroscieNce                                                                                                                                  voluME 11 | FEBRuARy 2010 | 135
                                                                                        © 2010 Macmillan Publishers Limited. All rights reserved
