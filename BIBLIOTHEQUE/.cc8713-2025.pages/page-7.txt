                                    Learning program synthesis with self-improving language models: A case study on ARC-AGI
                 improve refinement capabilities substantially, with diverse                          80
                 sampling performing marginally better (42.88% when refin-
                 ing solutions sampled by a non-finetuned model).                                     70
                                                                                                      60
                                            Sample-3k acc      Sample&Refine
                                                                                                      50                                 QC-7B
                           nofinetuning          29.67               34.83                           -train score (%)                    QC-14B
                      finetune: uniform                              42.67                            40                                 QC-32B
                                                                                                     ARC                                 Q-72B
                       finetune: diverse                             42.88                                                               Mistral-Large
                                                                                                      30                                 all models
                                                                                                                                         oracle (all models)
                 Table 3. Refinement finetuning: ARC-train performance of Sam-                    SOAR(base-model)       1             2             3
                 ple&Refine search methods (6k budget) using a non-finetuned                                            Training iteration
                 Qwen-2.5-Coder-14B model in the sampling step before refining             Figure 2. Iterated self-improvement on training problems. ARC-
                 sampled solutions with different Qwen-2.5-Coder-14B models                train performance across training iterations. Training iteration 0:
                 finetuned for program refinement (% solved).                              search with base models. All: score achieved by applying majority
                                                                                           voting on the combined generated solutions of the five models.
                 Positive synergy between sample and refine tasks.                         with better search capabilities, with the >32B models out-
                 Should we train separate models for sampling and refine-                  performing smaller variants at iteration 0; (2) smaller mod-
                 ment, or can a single model learn both effectively? Table 4               els show steeper improvements in early iterations; (3) all
                 shows that joint finetuning outperforms both base models                  modelsizes continue to benefit from further training itera-
                 and task-specific finetuning—for both sampling and search                 tions, though gains may slow down in later iterations; and
                 performance. This indicates a clear synergy: learning to                  (4) relative improvements are largest for smaller models,
                 sample helps refinement, and vice versa. The results sug-                 with the 7B model nearly doubling its performance.
                 gest that both tasks benefit from shared representations of
                 program structure and transformation patterns. Rather than                Wefoundthatpoolingdatafromthesearchtracesofourfive
                 splitting effort between specialized models, joint learning of-           models before performing majority voting (5 × 6k samples
                 fers a more efficient and effective path. Appendix E presents             per task) significantly outperformed all of them (see brown
                 moredetailed experiments supporting this result.                          line on Fig. 2)—suggesting that different model sizes may
                                                                                           solve problems in complementary ways. However, majority
                                                                        Sample&            voting is not an ideal aggregation strategy; we observed
                    Samplemodel        Refine model      Sample-3k      Refine-6k          an average score gap of 9.5% between majority voting and
                          base              base           29.67          34.83            oracle performance across our models, where the oracle
                       fine-samp          fine-ref         36.46          43.88            is defined as a task being solved if at least one solution
                       fine-both         fine-both         39.79          44.42            produces the correct output. This gap indicates room for
                                                                                           improvement in developing better ensembling methods.
                 Table 4. ARC-train accuracy using different combinations of               Since pooled data from multiple models and iterations con-
                 models for the Sample (col 1) and Refine (col 2) phases.                  sistently yielded better performance during search (see Fig-
                 fine-samp/ref/both refers to Qwen-2.5-Coder-14B finetuned for             ure 2), we trained a series of base models on a subset of
                 sampling, refinement, or both, respectively.        Sample-3k and         the combined dataset of all training iterations and model
                 Sample&Refine-6k (cols 2, 3) indicate the ARC-train accuracy
                 after sampling (3k solutions) and after search (3k samples + 3k           sizes (as described in Section 3.4). These models, trained
                 refinements).                                                             on a greater diversity of programs and refinement strategies,
                                                                                           significantly outperform models trained on their own data
                 4.3. Learning to search with iterated self-improvement                    only (Table 5). We use these models called SOAR(all train)
                                                                                           as starting points for test-time training steps.
                 Having established effective methods for self-improvement,
                 we now examine how improvements compound through                                 Modelsize           SOAR(3train)       SOAR(all train)
                 iterations and scale with model size.                                              QC-7B                  19.9                33.0
                                                                                                   QC-14B                  24.5                39.1
                 Self-improvement on ARC-train problems.                   Figure 2                QC-32B                  28.0                41.1
                 shows substantial gains across iterations for all model sizes,                     Q-72B                  34.6                39.8
                                                                                             Mistral-Large-123B            28.5                40.1
                 solving an extra +27% (7B), +24% (14B), +20% (32B),                       Table 5. ARC-test accuracy after training base models on a subset
                +19%(72B) and +22% (Mistral) problems on ARC-train.                        of 1) the data obtained at the 2nd SOAR iteration using that same
                 The relationship between model size and performance re-                   model size, SOAR(3 train); 2) all data collected by all models and
                 veals several interesting patterns: (1) larger models start               all previous train iterations SOAR(all train).
                                                                                        7
