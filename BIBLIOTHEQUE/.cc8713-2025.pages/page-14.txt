                         Learning program synthesis with self-improving language models: A case study on ARC-AGI
                                  60                                  SOAR (base-model)
                                                                      SOAR (base-model, 12.6k)
                                  50                                  SOAR (1-train)
                                                                      SOAR (2-train)
                                                                      SOAR (3-train)
                                  40
                                  30
                                 -train score (%) 20
                                 ARC10
                                   0              SampleRefine
                                       0    2000 4000 6000 8000 10000 12000
                                                     Number of Samples
            Figure 7. Scaling laws of iterated self-improvement on training problems. ARC-train performance across training iterations (gen-0 base
            model) for Qwen-2.5-Coder-7b. We increased the number of generation zero samples to 12,600 to match the total FLOPS usage of
            generation two, including both training and inference.
                                                           14
