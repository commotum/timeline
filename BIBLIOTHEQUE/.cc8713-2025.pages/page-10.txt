                             Learning program synthesis with self-improving language models: A case study on ARC-AGI
              Acknowledgments                                                C., Vikram, S., Lebron, F., Choy, P., Ramasesh, V., Web-
              This work benefitted from access to the HPC resources of       son, A., and Pope, R. How to scale your model. 2025.
              IDRISundertheallocation A0171011996 made by GENCI.             Retrieved from https://jax-ml.github.io/scaling-book/.
              It was also co-funded by AI Chair ANR DeepCuriosity         Balog, M., Gaunt, A. L., Brockschmidt, M., Nowozin, S.,
              ANR-19-CHIA-0004. Cédric Colas acknowledges funding            and Tarlow, D. Deepcoder: Learning to write programs.
              fromtheEuropeanUnion’sHorizon2020researchandinno-              arXiv preprint arXiv:1611.01989, 2016.
              vation programme under the Marie Skłodowska-Curie grant
              agreement No 101065949.                                     Bradley, H., Dai, A., Teufel, H., Zhang, J., Oostermeijer,
                                                                             K., Bellagente, M., Clune, J., Stanley, K., Schott, G., and
              ImpactStatement                                                Lehman,J. Quality-diversity through ai feedback. arXiv
                                                                             preprint arXiv:2310.13032, 2023.
              This work demonstrates how iterative model improvement      Butt, N., Manczak, B., Wiggers, A., Rainone, C., Zhang,
              can help overcome the performance plateaus typically en-       D. W., Defferrard, M., and Cohen, T. Codeit: Self-
              countered when scaling both model size and search budget.      improving language models with prioritized hindsight
              This finding suggests an important principle for developing    replay. In International Conference on Machine Learn-
              morecapable AI systems that could benefit society across       ing, 2024.
              numerous applications, from software development to sci-
              entific discovery.                                          Chollet, F. On the measure of intelligence. arXiv preprint
              However, the development of self-improving AI systems          arXiv:1911.01547, 2019.
              naturally raises safety considerations. While our results   Chollet, F. Arc prize website. "https://arcprize.o
              showclear performance slow downs rather than unbounded         rg/", 2024. ARC Prize Leaderboard.
              improvement, suggesting inherent limitations to our spe-
              cific approach, the general principle of systems improving  Chow, Y., Tennenholtz, G., Gur, I., Zhuang, V., Dai, B.,
              through self-directed learning could inspire future systems    Thiagarajan, S., Boutilier, C., Agarwal, R., Kumar, A.,
              with broader capabilities. This underscores the importance     and Faust, A. Inference-aware fine-tuning for best-of-
              of implementingappropriatesafeguardsandoversightmech-          n sampling in large language models. arXiv preprint
              anisms when developing such systems.                           arXiv:2412.15287, 2024.
              Wedemonstrate these results using open-source language      Colas, C., Karch, T., Sigaud, O., and Oudeyer, P.-
              models and will release our complete codebase upon publi-      Y. Autotelic agents with intrinsically motivated goal-
              cation. We believe this transparency is crucial for respon-    conditioned reinforcement learning: a short survey. Jour-
              sible development of increasingly capable AI systems, and      nal of Artificial Intelligence Research, 74:1159–1199,
              weencourage researchers building on this work to maintain      2022.
              similar standards of openness while carefully considering
              potential societal impacts.                                 Daniel, H., Michael, H., and team, U. Unsloth, 2023. URL
                                                                             http://github.com/unslothai/unsloth.
              References                                                  Dettmers,T.,Pagnoni,A.,Holtzman,A.,andZettlemoyer,L.
              Akyürek, E., Damani, M., Qiu, L., Guo, H., Kim, Y., and        Qlora: Efficient finetuning of quantized llms. Advances
                Andreas, J. The surprising effectiveness of test-time        in Neural Information Processing Systems, 36, 2024.
                training for abstract reasoning, 2024. Preprint.          Dong, K. and Ma, T. Beyond limited data: Self-play llm
              AlphaEvolve-team. AlphaEvolve: A Gemini-powered cod-           theorem provers with iterative conjecturing and proving.
                ing agent for designing advanced algorithms — deep-          arXiv preprint arXiv:2502.00212, 2025.
                mind.google. https://deepmind.google/disc                 Ellis, K., Wong, C., Nye, M., Sablé-Meyer, M., Morales, L.,
                over/blog/alphaevolve-a-gemini-power                         Hewitt, L., Cary, L., Solar-Lezama, A., and Tenenbaum,
                ed-coding-agent-for-designing-advance                        J. B. Dreamcoder: Bootstrapping inductive program
                d-algorithms/,2025.                                          synthesis with wake-sleep library learning. In Proceed-
              Andrychowicz, M., Wolski, F., Ray, A., Schneider, J., Fong,    ings of the 42nd acm sigplan international conference on
                R., Welinder, P., McGrew, B., Tobin, J., Pieter Abbeel, O.,  programming language design and implementation, pp.
                and Zaremba, W. Hindsight experience replay. Advances        835–850, 2021.
                in neural information processing systems, 30, 2017.       Gandhi,K.,Lee,D.,Grand,G.,Liu,M.,Cheng,W.,Sharma,
              Austin, J., Douglas, S., Frostig, R., Levskaya, A., Chen,      A., and Goodman,N.D. Streamofsearch(sos): Learning
                                                                       10
