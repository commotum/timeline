                                Learning program synthesis with self-improving language models: A case study on ARC-AGI
                 to search in language. arXiv preprint arXiv:2404.03683,        Kalajdzievski, D. A rank stabilization scaling factor for
                 2024.                                                             fine-tuning with lora. arXiv preprint arXiv:2312.03732,
               Gehring, J., Zheng, K., Copet, J., Mella, V., Carbonneaux,          2023.
                 Q., Cohen, T., and Synnaeve, G. Rlef: Grounding code           Koza, J. R. Genetic programming as a means for program-
                 llms in execution feedback with reinforcement learning.           mingcomputers by natural selection. Statistics and com-
                 arXiv preprint arXiv:2410.02089, 2024.                            puting, 4:87–112, 1994.
               Gendron, G., Bao, Q., Witbrock, M., and Dobbie, G. Large         Kumar,A.,Lu,C.,Kirsch,L.,Tang,Y.,Stanley,K.O.,Isola,
                 language models are not strong abstract reasoners. arXiv          P., and Ha, D. Automatingthesearchforartificiallifewith
                 preprint arXiv:2305.19555, 2023.                                  foundation models. arXiv preprint arXiv:2412.17799,
               Goldberg, e. a. Genetic algorithms and machine learning.            2024.
                 3(2):95–99. ISSN 1573-0565. doi: 10.1023/A:102260              Langdon, W. B. and Poli, R. Foundations of genetic pro-
                 2019183. URL https://doi.org/10.1023/A:                           gramming. Springer Science & Business Media, 2013.
                 1022602019183.
                                                                                LeGris, S., Vong, W. K., Lake, B. M., and Gureckis, T. M.
               Greenblatt, R. Draw more samples. "https://redwoo                   H-arc: Arobustestimateofhumanperformanceontheab-
                 dresearch.substack.com/p/getting-50-s                             straction and reasoning corpus benchmark. arXiv preprint
                 ota-on-arc-agi-with-gpt", 2024. Accuracy                          arXiv:2409.01374, 2024.
                 from ARCPrize Leaderboard.
                                                                                Lehman, J., Gordon, J., Jain, S., Ndousse, K., Yeh, C.,
               Guo, D., Zhu, Q., Yang, D., Xie, Z., Dong, K.,                      and Stanley, K. O. Evolution through large models. In
                 Zhang, W., Chen, G., Bi, X., Wu, Y., Li, Y., et al.               HandbookofEvolutionary Machine Learning, pp. 331–
                 Deepseek-coder: When the large language model meets               366. Springer, 2023.
                 programming–theriseofcodeintelligence. arXivpreprint
                 arXiv:2401.14196, 2024.                                        Li, W.-D. and Ellis, K. Is programming by example solved
                                                                                   byllms? arXiv preprint arXiv:2406.08316, 2024.
               Guo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R.,
                 Zhu, Q., Ma, S., Wang, P., Bi, X., et al. Deepseek-r1: In-     Li, W.-D., Hu, K., Larsen, C., Wu, Y., Alford, S., Woo, C.,
                 centivizing reasoning capability in llms via reinforcement        Dunn, S. M., Tang, H., Naim, M., Nguyen, D., Zheng,
                 learning. arXiv preprint arXiv:2501.12948, 2025.                  W.-L., Tavares, Z., Pu, Y., and Ellis, K. Combining
                                                                                   induction and transduction for abstract reasoning, 2024.
               Hodel, M. Arc-dsl. https://github.com/michael                       URLhttps://arxiv.org/abs/2411.02272.
                 hodel/arc-dsl,2023. [OnlineGitHubrepository].
                                                                                Li, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J.,
               Holland, J. H. Adaptation in Natural and Artificial Systems:        Leblond,R.,Eccles,T.,Keeling,J.,Gimeno,F.,DalLago,
                 An Introductory Analysis with Applications to Biology,            A., et al. Competition-level code generation with alpha-
                 Control, and Artificial Intelligence. The MIT Press. ISBN         code. Science, 378(6624):1092–1097, 2022.
                 978-0-262-27555-2. doi: 10.7551/mitpress/1090.001.00
                 01. URL https://direct.mit.edu/books/m                         Liang, P., Jordan, M. I., and Klein, D. Learning programs:
                 onograph/2574/Adaptation-in-Natural-a                             Ahierarchical bayesian approach. In ICML, volume 10,
                 nd-Artificial-SystemsAn.                                          pp. 639–646, 2010.
               Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang,    Liu, F., Tong, X., Yuan, M., Lin, X., Luo, F., Wang, Z.,
                 S., Wang, L., and Chen, W. Lora: Low-rank adaptation of           Lu, Z., and Zhang, Q. Evolution of heuristics: Towards
                 large language models. arXiv preprint arXiv:2106.09685,           efficient automatic algorithm design using large language
                 2021.                                                             model. arXiv preprint arXiv:2401.02051, 2024.
               Hui, B., Yang, J., Cui, Z., Yang, J., Liu, D., Zhang, L.,        Menon,A.,Tamuz,O.,Gulwani,S.,Lampson,B.,andKalai,
                 Liu, T., Zhang, J., Yu, B., Lu, K., et al. Qwen2. 5-coder         A. A machine learning framework for programming
                 technical report. arXiv preprint arXiv:2409.12186, 2024.          by example. In International Conference on Machine
               Jain, N., Han, K., Gu, A., Li, W.-D., Yan, F., Zhang, T.,           Learning, pp. 187–195. PMLR, 2013.
                 Wang,S., Solar-Lezama, A., Sen, K., and Stoica, I. Live-       Meyerson, E., Nelson, M. J., Bradley, H., Gaier, A., Moradi,
                 codebench: Holistic and contamination free evaluation             A., Hoover, A. K., and Lehman, J. Language model
                 of large language models for code. In The Thirteenth              crossover: Variation through few-shot prompting. ACM
                 International Conference on Learning Representations.             Transactions on Evolutionary Learning, 4(4):1–40, 2024.
                                                                             11
