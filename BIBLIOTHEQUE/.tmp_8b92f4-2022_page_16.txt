                             Under review as a conference paper at ICLR 2025
                    810      A VANILLAVITFAILUREANALYSIS
                    811
                    812
                    813                                  Input
                    814
                    815
                    816
                    817
                    818
                    819
                    820
                    821
                    822
                    823
                    824
                    825                             Expected Output                 Vanilla ViT Output
                    826
                    827
                    828      Figure 8: Failure case of ViT-Vanilla with NLP <pad> tokens. ViT-Vanilla with 2D padding and
                    829      NLP<pad>tokensfailstoaccountfortheactualinnergridsize,fillingtheentirehmax×wmax space.
                    830      Whenthe output is cropped to the true grid dimensions, the predictions within the valid region are
                    831      correct, underscoring the importance of proper boundary handling.
                    832
                    833      B TRAININGDETAILS
                    834
                    835
                    836      This section provides a comprehensive overview of the training setup, including hyperparameters,
                    837      hardware specifications, and other relevant details regarding the training process.
                    838      Our model consists of 3 layers with 8 attention heads and a hidden dimension of 128. The model
                    839      was trained on various single-core GPU nodes, including P100, V100, and T4, with a batch size of
                    840      8 for 1 epoch. The typical training time per task ranges from 6 to 10 hours (wall clock).
                    841      The dataset was generated using Hodel’s generators (Hodel, 2024), producing 1 million samples,
                    842      which were then split into training, validation, and test sets with 998,000, 1,000, and 1,000 in-
                    843      stances, respectively. The generation time varies between 3 and 12 hours, depending on the task.
                    844      A fixed random seed (1230) was used for both dataset generation and model training to ensure
                    845      reproducibility.
                    846      Duetocomputationalresourceconstraints,theablationstudywasperformedonarandomlysampled
                    847      subset of 100 tasks from the total 400, also selected using seed 1230.
                    848
                    849      C FULLRESULTSFORTASK-SPECIFIC ACCURACIES
                    850
                    851
                    852      C.1    MAINMODELSONFULL400TASKS
                    853
                    854                       Table 1: Solved Test Instances (%) Across Models on all 400 tasks.
                    855                                                          Solved Test Instances (%)
                    856                        Model                      Mean     Med.     25th Pctl.   75th Pctl.
                    857
                    858                        Baseline (ViT-Vanilla)     17.68    3.20     0.10         22.85
                    859                        ViTARC-VT                  66.03    87.85    27.55        99.30
                    860                        ViTARC(FullModel)          75.04    95.10    58.07        99.80
                    861
                    862
                    863
                                                                                16
