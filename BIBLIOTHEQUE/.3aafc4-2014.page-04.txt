                2.1    Apparent Complexity
                The ﬁrst notion, and arguably the one that matches our intuition most directly, we call apparent
                complexity.2 By the apparent complexity of an object x, we mean H (f (x)), where H is any of the
                entropy measures discussed previously, and f is some “denoising” or “smoothing” function—that
                is, a function that attempts to remove the “incidental” or “random” information in x, leaving only
                the “interesting, non-random” information. For example, if x is a bitmap image, then f (x) might
                simply be a blurred version of x.
                    Apparent complexity has two immense advantages.          First, it is simple: it directly captures
                the intuition that we want something like entropy, but that leaves out “incidental” information.
                For example, while the Kolmogorov complexity of a random sequence would be very large, the
                apparent complexity of the same sequence would typically be quite small, since the smoothing
                procedure would average out the random ﬂuctuations. Second, we can plausibly hope to compute
                (or at least, approximate) apparent complexity: we need “merely” solve the problems of computing
                H and f. It’s because of these advantages that the complexity measure we ultimately adopt for
                our experiments will be an approximate variant of apparent complexity.
                    On the other hand, apparent complexity also has a large disadvantage: namely, the apparent
                arbitrariness in the choice of the denoising function f. Who decides which information about x is
                “interesting,” and which is “incidental”?    Won’t f depend, not only on the type of object under
                study (bitmap images, audio recordings, etc.), but even more worryingly, on the prejudices of the
                investigator?   For example, suppose we choose f to blur out details of an image that are barely
                noticeable to the human eye. Then will studying the time-evolution of H (f (x)) tell us anything
                about x itself, or only about various quirks of the human visual system?
                    Fortunately, the apparent arbitrariness of the smoothing procedure is less of a problem than
                might initially be imagined.    It is very much like the need for a coarse-graining on phase space
                when one deﬁnes the Boltzmann entropy. In either case, these apparently-arbitrary choices are in
                fact well-motivated on physical grounds. While one could choose bizarre non-local ways to coarse-
                grain or smooth a distribution, natural choices are typically suggested by our physical ability to
                actually observe systems, as well as knowledge of their dynamical properties (see for example [3]).
                When deriving the equations of ﬂuid dynamics from kinetic theory, in principle one could choose
                to average over cells of momentum space rather than in position space; but there is no physical
                reason to do so, since interactions are local in position rather than momentum.        Likewise, when
                we observe conﬁgurations (whether with our eyes, or with telescopes or microscopes), large-scale
                features are more easily discerned than small-scale ones. (In ﬁeld theory this feature is formalized
                bytherenormalization group.) It therefore makes sense to smooth conﬁgurations over local regions
                in space.
                    Nevertheless, we would ideally like our complexity measure to tell us what the distinction be-
                tween “random” and “non-random” information consists of, rather than having to decide ourselves
                on a case-by-case basis. This motivates an examination of some alternative complexity measures.
                2.2    Sophistication
                Thesecondnotion—onethatoriginates in work of Kolmogorov himself—is sophistication. Roughly
                speaking, sophistication seeks to generalize Kolmogorov complexity to capture only the non-random
                   2Here we are using “apparent” in the sense of “directly perceivable,” without meaning to imply any connotation
                of “illusory.”
                                                                   4
