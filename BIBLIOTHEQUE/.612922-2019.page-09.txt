                                              Phenomenon                          Passage Highlights                                                               Question                                                               Answer                  Our
                                                                                                                                                                                                                                                                model
                                              Subtraction                         . . .    Twenty-ﬁve of his 150 men were                                          How many of Bartolom de Ams-                                               125                  145
                                             + Coreference                        sick, and his advance stalled ...                                                queta’s 150 men were not sick?
                                              Count + Filter                      . . .  Macedonians were the largest ethnic                                       Howmanyethnicities had less than                                              3                   2
                                                                                  group in Skopje, with 338,358 inhabi-                                           10000people?
                                                                                  tants ... Then came ... Serbs (14,298
                                                                                  inhabitants), Turks (8,595), Bosniaks
                                                                                  (7,585) and Vlachs (2,557) ...
                                              Domain                              . . .   Smith was sidelined by a torn pec-                                       HowmanyquartersdidSmithplay?                                                  0                   2
                                              knowledge                           toral muscle suffered during practice ...
                                              Addition                            . . .  culminating in the Battle of Vienna                                       What year did the Great Turkish                                           1698                1668
                                                                                  of 1683, which marked the start of the                                          Warend?
                                                                                  15-year-long Great Turkish War ...
                                      Table 5: Representative examples from our model’s error analysis. We list the identiﬁed semantic phenomenon,
                                      the relevant passage highlights, a gold question-answer pair, and the erroneous prediction by our model.
                                      the search was able to yield logical forms for 34%                                                                              Type                          (%)             Exact Match                                 F1
                                      of the training data, whereas with OpenIE, it was                                                                                                                            QN+ BERT QN+ BERT
                                      only 25%. On closer examination of a sample of                                                                                  Date                          1.57            28.7             38.7             35.5             42.8
                                      60questions and the information extracted by the                                                                                Numbers                      61.94            44.0             14.5             44.2             14.8
                                      SRLscheme(thebestperforming of the three), we                                                                                   Single Span                  31.71            58.2             64.6             64.6             70.1
                                      found that only 25% of the resulting tables con-                                                                                >1Spans                       4.77               0               0             17.13             25.0
                                      tained information needed to the answer the ques-                                                                          Table 6: Dev set performance breakdown by different
                                      tions. These observations show that high quality                                                                            answer types; our model (NAQANet, marked as QN+)
                                      information extraction is a strong prerequisite for                                                                        vs. BERT, the best-performing baseline.
                                      building semantic parsers for DROP. Additionally,
                                      the fact that this is a weakly supervised semantic
                                      parsing problem also makes training hard. The                                                                               8        Conclusion
                                      biggest challenge in this setup is the spuriousness
                                      of logical forms used for training, where the logical                                                                      We have presented DROP, a dataset of com-
                                      form evaluates to the correct denotation but does                                                                           plex reading comprehension questions that require
                                      not actually reﬂect the semantics of the question.                                                                          Discrete Reasoning Over Paragraphs. This dataset
                                      This makes it hard for the model trained on these                                                                           is substantially more challenging than existing
                                      spurious logical forms to generalize to unseen data.                                                                        datasets, with the best baseline achieving only
                                      From the set of logical forms for a sample of 60                                                                            32.7% F1, while humans achieve 96%. We hope
                                      questions analyzed, we found that only 8 questions                                                                          this dataset will spur research into more compre-
                                      (13%) contained non-spurious logical forms.                                                                                 hensive analysis of paragraphs, and into methods
                                                                                                                                                                  that combine distributed representations with sym-
                                                                                                                                                                  bolic reasoning. We have additionally presented
                                                                                                                                                                  initial work in this direction, with a model that
                                      Error Analysis                            Finally, in order to better under-                                                augmentsQANetwithlimitednumericalreasoning
                                      stand the outstanding challenges in DROP, we con-                                                                           capability, achieving 47% F1 on DROP.
                                      ducted an error analysis on a random sample of
                                      100 erroneous NAQANet predictions. The most                                                                                 Acknowledgments
                                      commonerrorswereonquestionswhichrequired
                                      complex type of reasoning, such as arithmetic                                                                              Wewould like to thank Noah Smith, Yoav Gold-
                                      operations (evident in 51% of the errors), count-                                                                           berg, andJonathanBerantforinsightfuldiscussions
                                      ing (30%), domain knowledge and common sense                                                                                that informed the direction of this work. The com-
                                      (23%), co-reference (6%), or a combination of dif-                                                                          putations on beaker.orgweresupportedinpart
                                      ferent types of reasoning (40%). See Table 5 for                                                                            by credits from Google Cloud.
                                      examples of some of the common phenomena.
                                                                                                                                                       2376
