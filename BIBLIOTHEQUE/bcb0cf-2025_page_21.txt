                     Published as a conference paper at ICLR 2025
                     efficiency. Unlike previous work such as Adaptive Computation Time (ACT) (Graves, 2016), which focuses
                     onadjusting the number of recurrent steps for each sample in a sequence model, MIND model offers finer
                     granularity in layer-wise adaptivity and considers the nuanced contributions of different layers to the final
                     model output for each individual sample.
                     In contrast, the MIND model not only allows for dynamic layer selection in both sequential and feed-forward
                     architectures like LSTMs (Hochreiter & Schmidhuber, 1997) and CNNs (LeCun et al., 1998), and also
                     provides a more nuanced approach by considering the activation profiles of each layer for every sample.
                     This architecture allows the MIND model to not only provide dynamic layer selection in both sequence and
                     feed-forward architectures, but also offers a more nuanced approach by considering the activation profiles of
                     each layer for every sample. This results in a more effective and computationally efficient model that adapts
                     to the complexities of individual samples across a wide range of tasks.
                                        Table 7: Corrected performance comparison on SQuAD 1.1 dataset
                                  Model                    Parameters     Exact Match (EM)      F1Score
                                  LSTM                        0.4M            64.744%           73.743%
                                  BERT-base(12-Layer)        110M              80.8%            88.52%
                                  MINDmodel              3M/0.3M/3.3M       90.5%±0.3%       95.4%±0.2%
                     E EXPERIMENTS
                     E.1   ANALYSIS OF ACTIVATION PROFILES ACROSS LAYERS
                     Tounderstand the MIND model’s processing of inputs with varying complexities, we recorded the activation
                     outputs from each layer during the processing of these inputs. As shown in Figure 5, distinct patterns were
                     observed in the activation intensities across different layers, depending on the input complexity.
                     For easy inputs, activation intensities were higher in the initial layers and decreased in the deeper layers. This
                     indicates that the model efficiently recognized and processed these inputs with minimal computational depth,
                     as the initial layers captured the essential features, requiring less complex processing in subsequent layers.
                     In contrast, hard inputs exhibited increasing activation intensities in the deeper layers, suggesting that more
                     complex feature extraction and processing were necessary. The Fixed-Point Iteration (FPI) layers played
                     a crucial role in this context, iteratively refining the representations to handle these inputs effectively. The
                     deeper layers captured intricate patterns and dependencies, demonstrating the model’s capability to adapt its
                     computational depth dynamically based on input complexity.
                     Tofurther quantify this behavior, we performed a statistical analysis of the activation magnitudes across the
                     layers for different complexity levels of inputs. We measured the mean and variance of activation values,
                     highlighting the dynamic adjustment of the MIND model’s depth according to input complexity, as visualized
                     in Figure 4. The heatmap visualization shows the activation profiles across three layers of the MIND model for
                     easy, medium, and hard input categories. Each subplot represents a different input complexity, demonstrating
                     how activation intensities vary from the first to the third layer. This visualization highlights the model’s
                     capacity to increase the depth of processing for more complex inputs while conserving resources for simpler
                     ones.
                     Byexamining the activation profiles, we gain insights into the adaptive mechanisms of the MIND model,
                     illustrating how it judiciously allocates computational resources. The ability to dynamically modulate layer
                     utilization based on input complexity underscores the efficiency and effectiveness of the MIND model in
                     handling a wide spectrum of tasks.
                     E.2   INFLUENCE OF PRE-TRAINING ON MIND MODEL’S EFFICACY
                     Theconvergencebehaviorofourmodel’strainingandtestinglossisacriticalaspectofitsevaluation. Figure 6
                     provides a detailed insight into this aspect. The similarity in convergence patterns between CIFAR-10 and
                                                                 21
