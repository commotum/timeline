               PCT: Point cloud transformer                                                                                       197
                [3] Li, Y.; Bu, R.; Sun, M.; Wu, W.; Di, X.; Chen, B.        [14] Yang, Z.; Dai, Z.; Yang, Y.; Carbonell, J. G.;
                    PointCNN: Convolution on x-transformed points. In:            Salakhutdinov, R.; Le, Q. V. XLNet: Generalized
                    Proceedings of the 32nd International Conference on           autoregressive pretraining for language understanding.
                    Neural Information Processing Systems, 828–838, 2018.         In: Proceedings of the 33rd Conference on Neural
                [4] Atzmon,    M.;   Maron,    H.;  Lipman,    Y. Point           Information Processing Systems, 5754–5764, 2019.
                    convolutional neural networks by extension operators.    [15] Dai, Z. H.; Yang, Z. L.; Yang, Y. M.; Carbonell, J.;
                    ACMTransactions on Graphics Vol. 37, No. 4, Article           Le, Q.; Salakhutdinov, R. Transformer-XL: Attentive
                    No. 71, 2018.                                                 language models beyond a ﬁxed-length context. In:
                [5] Wu,    W. X.;     Qi,  Z.;   Fuxin,   L.  PointConv:          Proceedings of the 57th Annual Meeting of the
                    Deep convolutional networks on 3D point clouds.              Association for Computational Linguistics, 2978–2988,
                    In:  Proceedings of the IEEE/CVF Conference on                2019.
                    Computer Vision and Pattern Recognition, 9613–9622,      [16] Lee, J.; Yoon, W.; Kim, S.; Kim, D.; Kim, S.; So,
                    2019.                                                         C. H.; Kang, J. BioBERT: A pre-trained biomedical
                [6] Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.;          language representation model for biomedical text
                    Jones, L.; Gomez, A. N.; Kaiser, L.; Polosukhin, I.           mining. Bioinformatics Vol. 36, No. 4, 1234–1240, 2020.
                    Attention is all you need. In: Proceedings of the        [17] Wang, F.; Jiang, M. Q.; Qian, C.; Yang, S.; Li, C.;
                    31st International Conference on Neural Information           Zhang, H. G.; Wang, X.; Tang, X. Residual attention
                    Processing, 6000–6010, 2017.                                  network for image classiﬁcation. In: Proceedings of
                [7] Dosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn,      the IEEE Conference on Computer Vision and Pattern
                    D.; Houlsby, N. An image is worth 16x16 words:                Recognition, 6450–6458, 2017.
                    Transformers for image recognition at scale. arXiv       [18] Hu, J.; Shen, L.; Sun, G. Squeeze-and-excitation
                    preprint arXiv:2010.11929, 2020.                              networks. In:     Proceedings of the IEEE/CVF
                [8] Wu, B.; Xu, C.; Dai, X.; Wan, A.; Zhang, P.; Tomizuka,        Conference   on Computer Vision and Pattern
                    M.; Keutzer, K.; Vajda, P. Visual transformers: Token-        Recognition, 7132–7141, 2018.
                    basedimagerepresentationandprocessingforcomputer         [19] Zhang, H.; Goodfellow, I. J.; Metaxas, D. N.; Odena,
                    vision. arXiv preprint arXiv:2006.03677, 2020.               A. Self-attention generative adversarial networks. In:
                [9] Bruna, J.; Zaremba, W.; Szlam, A.; LeCun, Y. Spectral         ProceedingsoftheInternationalConferenceonMachine
                    networks and locally connected networks on graphs.            Learning, 7354–7363, 2019.
                    In: Proceedings of the International Conference on       [20] Carion, N.; Massa, F.; Synnaeve, G.; Usunier, N.;
                    Learning Representations, 2014.                               Kirillov, A.; Zagoruyko, S. End-to-end object detection
               [10] Hu, S.-M.; Liang, D.; Yang, G.-Y.; Yang, G.-W.; Zhou,        with transformers. In: Computer Vision – ECCV
                    W.-Y. Jittor: A novel deep learning framework with           2020. Lecture Notes in Computer Science, Vol. 12346.
                    meta-operators and uniﬁed graph execution. Science           Vedaldi, A.; Bischof, H.; Brox, T.; Frahm, J. M. Eds.
                    China Information Sciences Vol. 63, No. 12, Article No.       Springer Cham, 213–229, 2020.
                    222103, 2020.
               [11] Bahdanau, D.; Cho, K. H.; Bengio, Y. Neural machine      [21] Qi, C. R.; Yi, L.; Su, H.; Guibas, L. J. PointNet++:
                    translation by jointly learning to align and translate.       Deep hierarchical feature learning on point sets in a
                    In: Proceedings of the 3rd International Conference on        metric space. In: Proceedings of the 31st Conference
                    Learning Representations, 2015.                               on Neural Information Processing Systems, 5099–5108,
               [12] Lin, Z.; Feng, M.; dos Santos, C. N.; Yu, M.;                 2017.
                    Xiang, B.; Zhou, B.; Bengio, Y. A structured self-       [22] Hermosilla, P.; Ritschel, T.; V´azquez, P. P.; Vinacua,
                                                                                  `
                    attentive sentence embedding. In: Proceedings of the          A.;  Ropinski,  T. Monte Carlo convolution for
                    International Conference on Learning Representations,         learning on non-uniformly sampled point clouds. ACM
                    2017.                                                        Transactions on Graphics Vol. 37, No. 6, Article No.
               [13] Devlin, J.; Chang, M.; Lee, K.; Toutanova, K.                 235, 2018.
                    BERT: Pre-training of deep bidirectional transformers    [23] Tatarchenko, M.; Park, J.; Koltun, V.; Zhou, Q.
                    for language understanding. In: Proceedings of the           Y. Tangent convolutions for dense prediction in 3D.
                    Conference of the North American Chapter of the               In: Proceedings of the IEEE/CVF Conference on
                    Association for Computational Linguistics: Human              Computer Vision and Pattern Recognition, 3887–3896,
                    Language Technologies, Vol. 1, 4171–4186, 2019.               2018.
