                   6  Conclusion
                   In this work, we explored the inner working mechanism of LLMs within and beyond the context
                   windowviadecomposedpositional vectors. We found that the initial tokens initially present different
                   positional information and serve as anchors for shaping the positional vectors of subsequent tokens.
                   Besides, after exceeding the context window, length extrapolation methods maintain the stability of
                   positional vectors, while context window extension methods achieve the interpolation of positional
                   vectors. Based on our observations, we proposed two methods: positional vector replacement and
                   attention window extension, which achieve training-free context window extension for specific LLMs.
                   Webelieve that positional vectors will serve as an effective tool for analyzing the context window of
                   LLMsandpromotethedesignofbetteralgorithms for extending the context windows of LLMs.
                   7  Limitation
                   Our work provides an extensive discussion and analysis of the context window through the lens
                   of positional vectors. However, our study is mainly constrained by the use of small-scale LLMs
                   that we trained ourselves, due to the unavailability of existing LLMs with the specific positional
                   encodings and attention patterns required for our experiments. Though some mainstream LLMs are
                   evaluated, these models are all based on RoPE. Furthermore, we have demonstrated the effectiveness
                   of our proposed methods solely on our own models, again limited by the absence of suitable external
                   models. In future work, we aim to seek a broader range of models to validate our findings more
                   comprehensively.
                   Acknowledgement
                   This work was partially supported by National Natural Science Foundation of China under Grant No.
                   62222215, Beijing Municipal Science and Technology Project under Grant No. Z231100010323009,
                   and Beijing Natural Science Foundation under Grant No. L233008. Xin Zhao is the corresponding
                   author.
                   References
                    [1] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari-
                      wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,
                      Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M.
                      Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz
                      Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec
                      Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In Ad-
                      vancesinNeuralInformationProcessingSystems33: AnnualConferenceonNeuralInformation
                      Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020.
                    [2] OpenAI. GPT-4 technical report. CoRR, abs/2303.08774, 2023.
                    [3] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min,
                      Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen,
                      Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and
                      Ji-Rong Wen. A survey of large language models. CoRR, abs/2303.18223, 2023.
                    [4] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
                      ≈Åukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information
                      processing systems, 30, 2017.
                    [5] Zihang Dai, Zhilin Yang, Yiming Yang, Jaime G. Carbonell, Quoc Viet Le, and Ruslan Salakhut-
                      dinov. Transformer-xl: Attentive language models beyond a fixed-length context. In ACL,
                      2019.
                    [6] Ofir Press, Noah A. Smith, and Mike Lewis. Train short, test long: Attention with linear
                      biases enables input length extrapolation. In The Tenth International Conference on Learning
                      Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022.
                                                   10
