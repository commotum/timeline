                                           End-to-EndDifferentiable Proving
                                        TimRockt√§schel                                Sebastian Riedel
                                       University of Oxford             University College London & Bloomsbury AI
                                tim.rocktaschel@cs.ox.ac.uk                      s.riedel@cs.ucl.ac.uk
                                                                     Abstract
                                   Weintroduce neural networks for end-to-end differentiable proving of queries to
                                   knowledge bases by operating on dense vector representations of symbols. These
                                   neuralnetworksareconstructedrecursivelybytakinginspirationfromthebackward
                                   chaining algorithm as used in Prolog. SpeciÔ¨Åcally, we replace symbolic uniÔ¨Åcation
                                   with a differentiable computation on vector representations of symbols using a
                                   radial basis function kernel, thereby combining symbolic reasoning with learning
                                   subsymbolic vector representations. By using gradient descent, the resulting neural
                                   network can be trained to infer facts from a given incomplete knowledge base.
                                   It learns to (i) place representations of similar symbols in close proximity in a
                                   vector space, (ii) make use of such similarities to prove queries, (iii) induce logical
                                   rules, and (iv) use provided and induced logical rules for multi-hop reasoning. We
                                   demonstrate that this architecture outperforms ComplEx, a state-of-the-art neural
                                   link prediction model, on three out of four benchmark knowledge bases while at
                                   the same time inducing interpretable function-free Ô¨Årst-order logic rules.
                          1    Introduction
                          Current state-of-the-art methods for automated Knowledge Base (KB) completion use neural link pre-
                          dictionmodelstolearndistributedvectorrepresentationsofsymbols(i.e. subsymbolicrepresentations)
                          for scoring fact triples [1‚Äì7]. Such subsymbolic representations enable these models to generalize
                          to unseen facts by encoding similarities: If the vector of the predicate symbol grandfatherOf is
                          similar to the vector of the symbol grandpaOf, both predicates likely express a similar relation.
                          Likewise, if the vector of the constant symbol LISA is similar to MAGGIE, similar relations likely
                          hold for both constants (e.g. they live in the same city, have the same parents etc.).
                          This simple form of reasoning based on similarities is remarkably effective for automatically complet-
        arXiv:1705.11040v2  [cs.NE]  4 Dec 2017ing large KBs. However, in practice it is often important to capture more complex reasoning patterns
                          that involve several inference steps. For example, if ABE is the father of HOMER and HOMER is a
                          parent of BART, we would like to infer that ABE is a grandfather of BART. Such transitive reasoning
                          is inherently hard for neural link prediction models as they only learn to score facts locally. In
                          contrast, symbolic theorem provers like Prolog [8] enable exactly this type of multi-hop reasoning.
                          Furthermore, Inductive Logic Programming (ILP) [9] builds upon such provers to learn interpretable
                          rules from data and to exploit them for reasoning in KBs. However, symbolic provers lack the ability
                          to learn subsymbolic representations and similarities between them from large KBs, which limits
                          their ability to generalize to queries with similar but not identical symbols.
                          While the connection between logic and machine learning has been addressed by statistical relational
                          learning approaches, these models traditionally do not support reasoning with subsymbolic repre-
                          sentations (e.g. [10]), and when using subsymbolic representations they are not trained end-to-end
                          from training data (e.g. [11‚Äì13]). Neural multi-hop reasoning models [14‚Äì18] address the aforemen-
                          tioned limitations to some extent by encoding reasoning chains in a vector space or by iteratively
                          reÔ¨Åning subsymbolic representations of a question before comparison with answers. In many ways,
                          these models operate like basic theorem provers, but they lack two of their most crucial ingredients:
                  interpretability and straightforward ways of incorporating domain-speciÔ¨Åc knowledge in form of
                  rules.
                  Ourapproachtothis problem is inspired by recent neural network architectures like Neural Turing
                  Machines [19], Memory Networks [20], Neural Stacks/Queues [21, 22], Neural Programmer [23],
                  Neural Programmer-Interpreters [24], Hierarchical Attentive Memory [25] and the Differentiable
                  Forth Interpreter [26]. These architectures replace discrete algorithms and data structures by end-to-
                  end differentiable counterparts that operate on real-valued vectors. At the heart of our approach is the
                  idea to translate this concept to basic symbolic theorem provers, and hence combine their advantages
                  (multi-hop reasoning, interpretability, easy integration of domain knowledge) with the ability to
                  reason with vector representations of predicates and constants. SpeciÔ¨Åcally, we keep variable binding
                  symbolic but compare symbols using their subsymbolic vector representations.
                  Concretely, we introduce Neural Theorem Provers (NTPs): End-to-end differentiable provers for
                  basic theorems formulated as queries to a KB. We use Prolog‚Äôs backward chaining algorithm as
                  a recipe for recursively constructing neural networks that are capable of proving queries to a KB
                  using subsymbolic representations. The success score of such proofs is differentiable with respect to
                  vector representations of symbols, which enables us to learn such representations for predicates and
                  constants in ground atoms, as well as parameters of function-free Ô¨Årst-order logic rules of predeÔ¨Åned
                  structure. By doing so, NTPs learn to place representations of similar symbols in close proximity in a
                  vector space and to induce rules given prior assumptions about the structure of logical relationships
                  in a KB such as transitivity. Furthermore, NTPs can seamlessly reason with provided domain-speciÔ¨Åc
                  rules. As NTPs operate on distributed representations of symbols, a single hand-crafted rule can
                  be leveraged for many proofs of queries with symbols that have a similar representation. Finally,
                  NTPsdemonstrate a high degree of interpretability as they induce latent rules that we can decode to
                  human-readable symbolic rules.
                  Ourcontributions are threefold: (i) We present the construction of NTPs inspired by Prolog‚Äôs back-
                  ward chaining algorithm and a differentiable uniÔ¨Åcation operation using subsymbolic representations,
                  (ii) we propose optimizations to this architecture by joint training with a neural link prediction model,
                  batch proving, and approximate gradient calculation, and (iii) we experimentally show that NTPs can
                  learn representations of symbols and function-free Ô¨Årst-order rules of predeÔ¨Åned structure, enabling
                  them to learn to perform multi-hop reasoning on benchmark KBs and to outperform ComplEx [7], a
                  state-of-the-art neural link prediction model, on three out of four KBs.
                  2  Background
                  In this section, we brieÔ¨Çy introduce the syntax of KBs that we use in the remainder of the paper.
                  Werefer the reader to [27, 28] for a more in-depth introduction. An atom consists of a predicate
                  symbol and a list of terms. We will use lowercase names to refer to predicate and constant symbols
                  (e.g. fatherOf and BART), and uppercase names for variables (e.g. X,Y,Z). As we only consider
                  function-free Ô¨Årst-order logic rules, a term can only be a constant or a variable. For instance,
                  [grandfatherOf,Q,BART] is an atom with the predicate grandfatherOf, and two terms, the
                  variable Q and the constant BART. We consider rules of the form H :‚Äì B, where the body B is a
                  possibly empty conjunction of atoms represented as a list, and the head H is an atom. We call a rule
                  with no free variables a ground rule. All variables are universally quantiÔ¨Åed. We call a ground rule
                  with an empty body a fact. A substitution set œà = {X /t ,...,X /t } is an assignment of variable
                                                   1 1     N N
                  symbols Xi to terms ti, and applying substitutions to an atom replaces all occurrences of variables
                  Xi by their respective term ti.
                  Given a query (also called goal) such as [grandfatherOf,Q,BART], we can use Prolog‚Äôs backward
                  chaining algorithm to Ô¨Ånd substitutions for Q [8] (see appendix A for pseudocode). On a high level,
                  backward chaining is based on two functions called OR and AND. OR iterates through all rules
                  (including rules with an empty body, i.e., facts) in a KB and uniÔ¨Åes the goal with the respective
                  rule head, thereby updating a substitution set. It is called OR since any successful proof sufÔ¨Åces
                  (disjunction). If uniÔ¨Åcation succeeds, OR calls AND to prove all atoms (subgoals) in the body of
                  the rule. To prove subgoals of a rule body, AND Ô¨Årst applies substitutions to the Ô¨Årst atom that is
                  then proven by again calling OR, before proving the remaining subgoals by recursively calling AND.
                  This function is called AND as all atoms in the body need to be proven together (conjunction). As
                  an example, a rule such as [grandfatherOf,X,Y] :‚Äì [[fatherOf,X,Z],[parentOf,Z,Y]] is used
                                                 2
                                in OR for translating a goal like [grandfatherOf,Q,BART] into subgoals [fatherOf,Q,Z] and
                                                                                                    1
                                [parentOf,Z,BART]that are subsequently proven by AND.
                                3    Differentiable Prover
                                In the following, we describe the recursive construction of NTPs ‚Äì neural networks for end-to-end
                                differentiable proving that allow us to calculate the gradient of proof successes with respect to vector
                                representations of symbols. We deÔ¨Åne the construction of NTPs in terms of modules similar to
                                dynamicneuralmodulenetworks[29]. Eachmoduletakesasinputsdiscreteobjects(atomsandrules)
                                and a proof state, and returns a list of new proof states (see Figure 1 for a graphical representation).
                                Aproofstate S = (œà,œÅ) is a tuple consisting of
                                the substitution set œà constructed in the proof
                                so far and a neural network œÅ that outputs a
                                real-valued success score of a (partial) proof.              X/Q                              X/Q
                                                                                            Y/BART                          Y/BART
                               While discrete objects and the substitution set                                              Z/HOMER
                                are only used during construction of the neu-
                                                                                              S          S                    S0         S0
                                ral network, once the network is constructed a                 œà          œÅ                     œà         œÅ
                                continuous proof success score can be calcu- Figure 1: A module is mapping an upstream proof
                                lated for many different goals at training and           state (left) to a list of new proof states (right),
                                test time. To summarize, modules are instanti-           thereby extending the substitution set S            and
                                ated by discrete objects and the substitution set.                                                        œà
                               They construct a neural network representing              adding nodes to the computation graph of the neu-
                                the (partial) proof success score and recursively        ral network SœÅ representing the proof success.
                                instantiate submodules to continue the proof.
                               ThesharedsignatureofmodulesisD√óS ‚Üí SN whereDisadomainthatcontrolstheconstructionof
                                the network, S is the domain of proof states, and N is the number of output proof states. Furthermore,
                                let Sœà denote the substitution set of the proof state S and let SœÅ denote the neural network for
                                calculating the proof success.
                               Weusepseudocodeinstyle of a functional programming language to deÔ¨Åne the behavior of modules
                                and auxiliary functions. Particularly, we are making use of pattern matching to check for properties
                                of arguments passed to a module. We denote sets by Euler script letters (e.g. E), lists by small capital
                                letters (e.g. E), lists of lists by blackboard bold letters (e.g. E) and we use : to refer to prepending an
                                element to a list (e.g. e : E or E : E). While an atom is a list of a predicate symbol and terms, a rule
                                                                                                                                          2
                                can be seen as a list of atoms and thus a list of lists where the head of the list is the rule head.
                                3.1   UniÔ¨Åcation Module
                                UniÔ¨Åcation of two atoms, e.g., a goal that we want to prove and a rule head, is a central operation
                                in backward chaining. Two non-variable symbols (predicates or constants) are checked for equality
                                and the proof can be aborted if this check fails. However, we want to be able to apply rules even
                                if symbols in the goal and head are not equal but similar in meaning (e.g. grandfatherOf and
                                grandpaOf)andthusreplace symbolic comparison with a computation that measures the similarity
                                of both symbols in a vector space.
                               Themoduleunifyupdatesasubstitution set and creates a neural network for comparing the vector
                                representations of non-variable symbols in two sequences of terms. The signature of this module
                                is L √óL √ó S ‚Üí S where L is the domain of lists of terms. unify takes two atoms represented
                                as lists of terms and an upstream proof state, and maps these to a new proof state (substitution set
                                and proof success). To this end, unify iterates through the list of terms of two atoms and compares
                                their symbols. If one of the symbols is a variable, a substitution is added to the substitution set.
                                Otherwise, the vector representations of the two non-variable symbols are compared using a Radial
                                                                                                                         1
                                Basis Function (RBF) kernel [30] where ¬µ is a hyperparameter that we set to ‚àö2 in our experiments.
                               Thefollowing pseudocode implements unify. Note that "_" matches every argument and that the
                                   1For    clarity,   we will      sometimes     omit    lists  when     writing    rules   and    atoms,    e.g.,
                                grandfatherOf(X,Y):‚ÄìfatherOf(X,Z),parentOf(Z,Y).
                                   2For example, [[grandfatherOf,X,Y],[fatherOf,X,Z],[parentOf,Z,Y]].
                                                                                        3
                                           order matters, i.e., if arguments match a line, subsequent lines are not evaluated.
                                           1. unify ([ ],[ ],S) = S
                                                           Œ∏
                                           2. unify ([ ],_,_) = FAIL
                                                           Œ∏
                                           3. unify (_,[ ],_) = FAIL
                                                           Œ∏
                                           4. unify (h : H,g : G,S) = unify (H,G,S0) = (S0 ,S0)                                                 where
                                                           Œ∏                                          Œ∏                           œà      œÅ
                                                      Ô£±                                                  Ô£º                         (                                                           )!
                                                      Ô£≤ S ‚à™{h/g} ifh‚ààV                                   Ô£Ω                                             ‚àíkŒ∏ ‚àíŒ∏ k
                                                             œà                                                                                exp            h:    g: 2        if h,g 6‚àà V
                                            S0 =           S ‚à™{g/h} ifg ‚ààV,h6‚ààV                              ,    S0 = min S ,                                2¬µ2
                                               œà      Ô£≥ œà                                                Ô£æ          œÅ                 œÅ       1                                otherwise
                                                           S                     otherwise
                                                             œà
                                           Here, S0 refers to the new proof state, V refers to the set of variable symbols, h/g is a substitution
                                           fromthevariablesymbolhtothesymbolg,andŒ∏g: denotestheembeddinglookupofthenon-variable
                                           symbolwithindexg. unifyisparameterizedbyanembeddingmatrixŒ∏ ‚àà R|Z|√ók whereZ istheset
                                           of non-variables symbols and k is the dimension of vector representations of symbols. Furthermore,
                                           FAILrepresents a uniÔ¨Åcation failure due to mismatching arity of two atoms. Once a failure is reached,
                                           weabort the creation of the neural network for this branch of proving. In addition, we constrain
                                           proofs to be cycle-free by checking whether a variable is already bound. Note that this is a simple
                                           heuristic that prohibits applying the same non-ground rule twice. There are more sophisticated ways
                                           for Ô¨Ånding and avoiding cycles in a proof graph such that the same rule can still be applied multiple
                                           times (e.g. [31]), but we leave this for future work.
                                           Example Assumethatweareunifyingtwoatoms[grandpaOf,ABE,BART]and[s,Q,i]givenan
                                           upstream proof state S = (‚àÖ,œÅ) where the latter input atom has placeholders for a predicate s
                                           and a constant i, and the neural network œÅ would output 0.7 when evaluated. Furthermore, assume
                                           grandpaOf, ABE and BART represent the indices of the respective symbols in a global symbol
                                           vocabulary. Then, the new proof state constructed by unify is:
                                                          unify ([grandpaOf,ABE,BART],[s,Q,i],(‚àÖ,œÅ)) = (S0 ,S0) =
                                                                     Œ∏                                                                               œà     œÅ
                                                                    {Q/ABE},min œÅ,exp(‚àíkŒ∏                                        ‚àíŒ∏ k ),exp(‚àíkŒ∏                         ‚àíŒ∏ k )
                                                                                                                  grandpaOf:           s: 2                    BART:          i:  2
                                           Thus, the output score of the neural network S0 will be high if the subsymbolic representation of the
                                                                                                                    œÅ
                                           input s is close to grandpaOf and the input i is close to BART. However, the score cannot be higher
                                           than 0.7 due to the upstream proof success score in the forward pass of the neural network œÅ. Note
                                           that in addition to extending the neural networks œÅ to S0, this module also outputs a substitution set
                                                                                                                                  œÅ
                                           {Q/ABE}atgraphcreation time that will be used to instantiate submodules.
                                           3.2      ORModule
                                           Based on unify, we now deÔ¨Åne the or module which attempts to apply rules in a KB. The signature
                                           of or is L √ó N√óS ‚Üí SN whereListhedomainofgoalatomsandNisthedomainofintegersused
                                           for specifying the maximum proof depth of the neural network. Furthermore, N is the number of
                                                                                                                                                                    3
                                           possible output proof states for a goal of a given structure and a provided KB. We implement or as
                                                    K                         0      0           K
                                           1. or (G,d,S) = [S | S ‚àà and (B,d,unify (H,G,S))for H :‚Äì B ‚àà K]
                                                    Œ∏                                            Œ∏                      Œ∏
                                           where H :‚Äì B denotes a rule in a given KB K with a head atom H and a list of body atoms B. In
                                           contrast to the symbolic OR method, the or module is able to use the grandfatherOf rule above
                                           for a query involving grandpaOf provided that the subsymbolic representations of both predicates
                                           are similar as measured by the RBF kernel in the unify module.
                                           Example For a goal [s,Q,i], or would instantiate an and submodule based on the rule
                                           [grandfatherOf,X,Y] :‚Äì[[fatherOf,X,Z],[parentOf,Z,Y]]asfollows
                                                  K                               0    0          K                                                                                    ÀÜ
                                              or ([s,Q,i],d,S) = [S |S ‚àà and ([[fatherOf,X,Z],[parentOf,Z,Y]],d,({X/Q,Y/i},S )),...]
                                                  Œ∏                                               Œ∏                                                              |           {z          œÅ}
                                                                                                                                                                      result of unify
                                                3The creation of the neural network is dependent on the KB but also the structure of the goal. For instance,
                                           the goal s(Q,i) would result in a different neural network, and hence a different number of output proof states,
                                           than s(i,j).
                                                                                                                         4
                             3.3   ANDModule
                             For implementing and we Ô¨Årst deÔ¨Åne an auxiliary function called substitute which applies substitu-
                             tions to variables in an atom if possible. This is realized via
                             1. substitute([ ],_) = [ ]
                             2. substitute(g : G,œà) =  x        if g/x ‚àà œà  : substitute(G,œà)
                                                            g    otherwise
                             For example, substitute([fatherOf,X,Z],{X/Q,Y/i}) results in [fatherOf,Q,Z].
                             The signature of and is L √ó N √ó S ‚Üí SN where L is the domain of lists of atoms and N is the
                             numberofpossible output proof states for a list of atoms with a known structure and a provided KB.
                             This module is implemented as
                                     K
                             1. and (_,_,FAIL) = FAIL
                                     Œ∏
                                     K
                             2. and (_,0,_) = FAIL
                                     Œ∏
                                     K
                             3. and ([ ],_,S) = S
                                     Œ∏
                                     K                    00    00      K          0       0     K
                             4. and (G : G,d,S) = [S | S ‚àà and (G,d,S ) for S ‚àà or (substitute(G,Sœà),d‚àí1,S)]
                                     Œ∏                                  Œ∏                        Œ∏
                             where the Ô¨Årst two lines deÔ¨Åne the failure of a proof, either because of an upstream uniÔ¨Åcation
                             failure that has been passed from the or module (line 1), or because the maximum proof depth has
                             been reached (line 2). Line 3 speciÔ¨Åes a proof success, i.e., the list of subgoals is empty before the
                             maximumproofdepthhasbeenreached. Lastly, line 4 deÔ¨Ånes the recursion: The Ô¨Årst subgoal G is
                             proven by instantiating an or module after substitutions are applied, and every resulting proof state
                             S0 is used for proving the remaining subgoals G by again instantiating and modules.
                             Example ContinuingtheexamplefromSection3.2, the and module would instantiate submodules
                             as follows:
                                 K                                                         ÀÜ
                             and ([[fatherOf,X,Z],[parentOf,Z,Y]],d,({X/Q,Y/i},S )) =
                                 Œ∏                                          |       {z      œÅ}
                                                                             result of unify in or
                                    00  00      K                         0       0     K                                         ÀÜ
                                  [S |S ‚ààand ([[parentOf,Z,Y]],d,S )forS ‚àà or ([fatherOf,Q,Z],d‚àí1,({X/Q,Y/i},S ))]
                                                Œ∏                                       Œ∏ |       {z      }        |       {z      œÅ}
                                                                                             result of substitute   result of unify in or
                             3.4   Proof Aggregation
                             Finally, we deÔ¨Åne the overall success score of proving a goal G using a KB K with parameters Œ∏ as
                                                                   K
                                                               ntp (G,d) =          argmax        SœÅ
                                                                   Œ∏
                                                                               S ‚àà orK(G,d,(‚àÖ,1))
                                                                                      Œ∏
                                                                                    S6=FAIL
                             wheredisapredeÔ¨Ånedmaximumproofdepthandtheinitialproofstateissettoanemptysubstitution
                             set and a proof success score of 1.
                             Example Figure2illustrates an examplary NTP computation graph constructed for a toy KB. Note
                             that such an NTP is constructed once before training, and can then be used for proving goals of the
                             structure [s,i,j] at training and test time where s is the index of an input predicate, and i and j are
                             indices of input constants. Final proof states which are used in proof aggregation are underlined.
                             3.5   Neural Inductive Logic Programming
                             WecanuseNTPsforILPbygradientdescent instead of a combinatorial search over the space of
                             rules as, for example, done by the First Order Inductive Learner (FOIL) [32]. SpeciÔ¨Åcally, we are
                             using the concept of learning from entailment [9] to induce rules that let us prove known ground
                             atoms, but that do not give high proof success scores to sampled unknown ground atoms.
                             Let Œ∏r:,Œ∏s:,Œ∏t: ‚àà Rk be representations of some unknown predicates with indices r,s and t respec-
                             tively. The prior knowledge of a transitivity between three unknown predicates can be speciÔ¨Åed via
                                                                                 5
                                                                                                                                                                                                             orK([s,i,j],2,(‚àÖ,1))
                                                                                                                                                                                                1.                Œ∏                                               3.
                                                                                                                                                                                                                                   2.
                                                                                                                       unify ([fatherOf,ABE,HOMER],[s,i,j],(‚àÖ,1))                                                             . . .                unify ([grandfatherOf,X,Y],[s,i,j],(‚àÖ,1))
                                                                                                                                   Œ∏                                                                                                                          Œ∏
                                                                                                                                                        S =(‚àÖ,œÅ )                                                    S =(‚àÖ,œÅ )                                          S =({X/i,Y/j},œÅ )
                                                                                                                                                           1                1                                           2                2                                3                                 3        Example Knowledge Base:
                                                                                                                                                                                                                                                                                                                     1. fatherOf(ABE,HOMER).
                                                                                                                                                                                           K                                                                                                                         2. parentOf(HOMER,BART).
                                                                                                                                                                                    and ([[fatherOf,X,Z],[parentOf,Z,Y]],2,S3)
                                                                                                                                                                                           Œ∏                                                                                                                         3. grandfatherOf(X,Y) :‚Äì
                                                                                                                                                                                                                                   substitute                                                                                 fatherOf(X,Z),
                                                                                                                                                                                                             K                                                                                                                parentOf(Z,Y).
                                                                                                                                                                                                        or ([fatherOf,i,Z],1,S )
                                                                                                                                                                                                1.           Œ∏                                        3           2.
                                                                                                                                                                                                                                   3.
                                                                                                                  unify ([fatherOf,ABE,HOMER],[fatherOf,i,Z],S )                                                              . . .        unify ([parentOf,HOMER,BART],[fatherOf,i,Z],S )
                                                                                                                             Œ∏                                                                                    3                                   Œ∏                                                                                      3
                                                                                                                                    S =({X/i,Y/j,Z/HOMER},œÅ )                                                         S =FAIL                                   S =({X/i,Y/j,Z/BART},œÅ )
                                                                                                                                       31                                                      31                        33                                        32                                                  32
                                                                                                                                               K                                                                                                                         K
                                                                                                                                        and ([parentOf,Z,Y],2,S31)                                                                                                and ([parentOf,Z,Y],2,S32)
                                                                                                                                               Œ∏                                                                                                                         Œ∏
                                                                                                                                                                      substitute                                                                                                                substitute
                                                                                                                                     orK([parentOf,HOMER,j],1,S )                                                                                                orK([parentOf,BART,j],1,S )
                                                                                                                                         Œ∏                                                    31                                                                     Œ∏                                                32
                                                                                                                                               . . . 1.               2.        3. . . .                                                                                 . . .    3.            2.        1. . . .
                                                                                                                                                                 . . .                                                                                                                      . . .
                                                                                              S        =({X/i,Y/j,Z/HOMER},œÅ                                   )                             S        =FAIL                                   S        =FAIL                                       S        =({X/i,Y/j,Z/BART},œÅ                                 )
                                                                                                311                                                       311                                   313                                              323                                                  321                                                  321
                                                                                                                                  S        =({X/i,Y/j,Z/HOMER},œÅ                                    )                                                         S         =({X/i,Y/j,Z/BART},œÅ                                )
                                                                                                                                     312                                                       312                                                               322                                                   322
                                                                                Figure 2: Exemplary construction of an NTP computation graph for a toy knowledge base. Indices
                                                                                on arrows correspond to application of the respective KB rule. Proof states (blue) are subscripted
                                                                               with the sequence of indices of the rules that were applied. Underlined proof states are aggregated to
                                                                                obtain the Ô¨Ånal proof success. Boxes visualize instantiations of modules (omitted for unify). The
                                                                                proofs S ,S                                       and S                      fail due to cycle-detection (the same rule cannot be applied twice).
                                                                                                         33            313                        323
                                                                                r(X,Y):‚Äìs(X,Z),t(Z,Y). Wecallthis a parameterized rule as the corresponding predicates are
                                                                                unknownandtheirrepresentationsarelearnedfromdata. Sucharulecanbeusedforproofsattraining
                                                                                and test time in the same way as any other given rule. During training, the predicate representations
                                                                                of parameterized rules are optimized jointly with all other subsymbolic representations. Thus, the
                                                                                model can adapt parameterized rules such that proofs for known facts succeed while proofs for
                                                                                sampled unknown ground atoms fail, thereby inducing rules of predeÔ¨Åned structures like the one
                                                                                above. Inspired by [33], we use rule templates for conveniently deÔ¨Åning the structure of multiple
                                                                                parameterized rules by specifying the number of parameterized rules that should be instantiated for
                                                                                a given rule structure (see appendix E for examples). For inspection after training, we decode a
                                                                                parameterized rule by searching for the closest representations of known predicates. In addition,
                                                                               weprovide users with a rule conÔ¨Ådence by taking the minimum similarity between unknown and
                                                                                decoded predicate representations using the RBF kernel in unify. This conÔ¨Ådence score is an upper
                                                                                bound on the proof success score that can be achieved when the induced rule is used in proofs.
                                                                                4            Optimization
                                                                                In this section, we present the basic training loss that we use for NTPs, a training loss where a neural
                                                                                link prediction models is used as auxiliary task, as well as various computational optimizations.
                                                                                4.1             Training Objective
                                                                                Let K be the set of known facts in a given KB. Usually, we do not observe negative facts and thus
                                                                                resort to sampling corrupted ground atoms as done in previous work [34]. SpeciÔ¨Åcally, for every
                                                                                                                                                                                                                                  ÀÜ                            ÀÜ                Àú Àú                                                              ÀÜ ÀÜ Àú                         Àú
                                                                                [s,i,j] ‚àà K we obtain corrupted ground atoms [s,i,j],[s,i,j],[s,i,j] 6‚àà K by sampling i,j,i and j
                                                                                from the set of constants. These corrupted ground atoms are resampled in every iteration of training,
                                                                                and we denote the set of known and corrupted ground atoms together with their target score (1.0 for
                                                                                known ground atoms and 0.0 for corrupted ones) as T . We use the negative log-likelihood of the
                                                                                proof success score as loss function for an NTP with parameters Œ∏ and a given KB K
                                                                                                                                            X                                                          K                                                                                                               K
                                                                                                L                K =                                                ‚àíylog(ntp ([s,i,j],d) )‚àí(1‚àíy)log(1‚àíntp ([s,i,j],d) )
                                                                                                     ntp                                                                                               Œ∏                                    œÅ                                                                          Œ∏                                    œÅ
                                                                                                                 Œ∏
                                                                                                                               ([s,i,j],y) ‚àà T
                                                                               where [s,i,j] is a training ground atom and y its target proof success score. Note that since in our
                                                                                application all training facts are ground atoms, we only make use of the proof success score œÅ and not
                                                                                                                                                                                                                               6
                             the substitution list of the resulting proof state. We can prove known facts trivially by a uniÔ¨Åcation
                             with themselves, resulting in no parameter updates during training and hence no generalization.
                             Therefore, during training we are masking the calculation of the uniÔ¨Åcation success of a known
                             ground atom that we want to prove. SpeciÔ¨Åcally, we set the uniÔ¨Åcation score to 0 to temporarily hide
                             that training fact and assume it can be proven from other facts and rules in the KB.
                             4.2   Neural Link Prediction as Auxiliary Loss
                             At the beginning of training all subsymbolic representations are initialized randomly. When unifying
                             a goal with all facts in a KB we consequently get very noisy success scores in early stages of training.
                             Moreover, as only the maximum success score will result in gradient updates for the respective
                             subsymbolic representations along the maximum proof path, it can take a long time until NTPs learn
                             to place similar symbols close to each other in the vector space and to make effective use of rules.
                             To speed up learning subsymbolic representations, we train NTPs jointly with ComplEx [7] (Ap-
                             pendix B). ComplEx and the NTP share the same subsymbolic representations, which is feasible
                             as the RBF kernel in unify is also deÔ¨Åned for complex vectors. While the NTP is responsible for
                             multi-hop reasoning, the neural link prediction model learns to score ground atoms locally. At test
                             time, only the NTP is used for predictions. Thus, the training loss for ComplEx can be seen as an
                             auxiliary loss for the subsymbolic representations learned by the NTP. We term the resulting model
                             NTPŒª. Based on the loss in Section 4.1, the joint training loss is deÔ¨Åned as
                             L       K = L      K +      X ‚àíylog(complex (s,i,j))‚àí(1‚àíy)log(1‚àícomplex (s,i,j))
                               ntpŒª        ntp                                      Œ∏                                        Œ∏
                                     Œ∏          Œ∏
                                                    ([s,i,j],y) ‚àà T
                             where [s,i,j] is a training atom and y its ground truth target.
                             4.3   Computational Optimizations
                             NTPsasdescribedabovesuffer from severe computational limitations since the neural network is
                             representing all possible proofs up to some predeÔ¨Åned depth. In contrast to symbolic backward
                             chainingwhereaproofcanbeabortedassoonasuniÔ¨Åcationfails,indifferentiableprovingweonlyget
                             a uniÔ¨Åcation failure for atoms whose arity does not match or when we detect cyclic rule application.
                             Wepropose two optimizations to speed up NTPs in the Appendix. First, we make use of modern
                             GPUsbybatchprocessing many proofs in parallel (Appendix C). Second, we exploit the sparseness
                             of gradients caused by the min and max operations used in the uniÔ¨Åcation and proof aggregation
                             respectively to derive a heuristic for a truncated forward and backward pass that drastically reduces
                             the number of proofs that have to be considered for calculating gradients (Appendix D).
                             5    Experiments
                             Consistent with previous work, we carry out experiments on four benchmark KBs and compare
                             ComplExwiththeNTPandNTPŒªintermsofareaunderthePrecision-Recall-curve(AUC-PR)on
                             the Countries KB, and Mean Reciprocal Rank (MRR) and HITS@m [34] on the other KBs described
                             below. Training details, including hyperparameters and rule templates, can be found in Appendix E.
                             Countries     TheCountries KB is a dataset introduced by [35] for testing reasoning capabilities of
                             neural link prediction models. It consists of 244 countries, 5 regions (e.g. EUROPE), 23 subregions
                             (e.g. WESTERN EUROPE, NORTHERN AMERICA),and1158factsabouttheneighborhoodofcountries,
                             and the location of countries and subregions. We follow [36] and split countries randomly into a train-
                             ing set of 204 countries (train), a development set of 20 countries (dev), and a test set of 20 countries
                             (test), such that every dev and test country has at least one neighbor in the training set. Subsequently,
                             three different task datasets are created. For all tasks, the goal is to predict locatedIn(c,r) for every
                             test country c and all Ô¨Åve regions r, but the access to training atoms in the KB varies.
                             S1:     All ground atoms locatedIn(c,r) where c is a test country and r is a re-
                             gion are removed from the KB. Since information about the subregion of test coun-
                             tries is still contained in the KB, this task can be solved by using the transitivity rule
                             locatedIn(X,Y):‚ÄìlocatedIn(X,Z),locatedIn(Z,Y).
                             S2: In addition to S1, all ground atoms locatedIn(c,s) are removed where c is a test country and s
                                                                                 7
                                     Table 1: AUC-PR results on Countries and MRR and HITS@m on Kinship, Nations, and UMLS.
                                         Corpus       Metric                    Model                             Examples of induced rules and their conÔ¨Ådence
                                                                 ComplEx        NTP          NTPŒª
                                                S1   AUC-PR     99.37¬±0.4   90.83¬±15.4    100.00¬± 0.0    0.90 locatedIn(X,Y) :‚Äì locatedIn(X,Z), locatedIn(Z,Y).
                                     Countries  S2   AUC-PR     87.95¬±2.8   87.40¬±11.7     93.04¬± 0.4    0.63 locatedIn(X,Y) :‚Äì neighborOf(X,Z), locatedIn(Z,Y).
                                                S3   AUC-PR     48.44¬±6.3   56.68¬±17.6     77.26¬±17.0    0.32 locatedIn(X,Y) :‚Äì
                                                                                                               neighborOf(X,Z), neighborOf(Z,W), locatedIn(W,Y).
                                                     MRR              0.81          0.60           0.80  0.98 term15(X,Y) :‚Äì term5(Y,X)
                                     Kinship         HITS@1           0.70          0.48          0.76   0.97 term18(X,Y) :‚Äì term18(Y,X)
                                                     HITS@3          0.89           0.70           0.82  0.86 term4(X,Y) :‚Äì term4(Y,X)
                                                     HITS@10         0.98           0.78           0.89  0.73 term12(X,Y) :‚Äì term10(X, Z), term12(Z, Y).
                                                     MRR             0.75          0.75            0.74  0.68 blockpositionindex(X,Y) :‚Äì blockpositionindex(Y,X).
                                     Nations         HITS@1          0.62          0.62            0.59  0.46 expeldiplomats(X,Y) :‚Äì negativebehavior(X,Y).
                                                     HITS@3           0.84          0.86          0.89   0.38 negativecomm(X,Y) :‚Äì commonbloc0(X,Y).
                                                     HITS@10         0.99          0.99           0.99   0.38 intergovorgs3(X,Y) :‚Äì intergovorgs(Y,X).
                                                     MRR              0.89          0.88          0.93   0.88 interacts_with(X,Y) :‚Äì
                                     UMLS            HITS@1           0.82          0.82          0.87         interacts_with(X,Z), interacts_with(Z,Y).
                                                     HITS@3           0.96          0.92          0.98   0.77 isa(X,Y) :‚Äì isa(X,Z), isa(Z,Y).
                                                     HITS@10         1.00           0.97          1.00   0.71 derivative_of(X,Y) :‚Äì
                                                                                                               derivative_of(X,Z), derivative_of(Z,Y).
                                    is a subregion. The location of test countries needs to be inferred from the location of its neighboring
                                    countries: locatedIn(X,Y) :‚Äì neighborOf(X,Z),locatedIn(Z,Y). This task is more difÔ¨Åcult
                                    than S1, as neighboring countries might not be in the same region, so the rule above will not always
                                    hold.
                                    S3:     In addition to S2, all ground atoms locatedIn(c,r) where r is a region and c
                                    is a training country that has a test or dev country as a neighbor are also removed.
                                    The location of test countries can for instance be inferred using the three-hop rule
                                    locatedIn(X,Y):‚ÄìneighborOf(X,Z),neighborOf(Z,W),locatedIn(W,Y).
                                    Kinship, Nations &UMLS WeusetheNations,Alyawarrakinship(Kinship)andUniÔ¨ÅedMedical
                                    Language System (UMLS) KBs from [10]. We left out the Animals dataset as it only contains unary
                                    predicates and can thus not be used for evaluating multi-hop reasoning. Nations contains 56 binary
                                    predicates, 111 unary predicates, 14 constants and 2565 true facts, Kinship contains 26 predicates,
                                   104 constants and 10686 true facts, and UMLS contains 49 predicates, 135 constants and 6529 true
                                    facts. Since our baseline ComplEx cannot deal with unary predicates, we remove unary atoms from
                                    Nations. We split every KB into 80% training facts, 10% development facts and 10% test facts. For
                                    evaluation, we take a test fact and corrupt its Ô¨Årst and second argument in all possible ways such that
                                    the corrupted fact is not in the original KB. Subsequently, we predict a ranking of every test fact and
                                    its corruptions to calculate MRR and HITS@m.
                                    6    Results and Discussion
                                    Results for the different model variants on the benchmark KBs are shown in Table 1. Another method
                                    for inducing rules in a differentiable way for automated KB completion has been introduced recently
                                    by[37] and our evaluation setup is equivalent to their Protocol II. However, our neural link prediction
                                    baseline, ComplEx, already achieves much higher HITS@10 results (1.00 vs. 0.70 on UMLS and
                                    0.98 vs. 0.73 on Kinship). We thus focus on the comparison of NTPs with ComplEx.
                                    First, we note that vanilla NTPs alone do not work particularly well compared to ComplEx. They only
                                    outperform ComplEx on Countries S3 and Nations, but not on Kinship or UMLS. This demonstrates
                                    the difÔ¨Åculty of learning subsymbolic representations in a differentiable prover from uniÔ¨Åcation
                                    alone, and the need for auxiliary losses. The NTPŒª with ComplEx as auxiliary loss outperforms the
                                    other models in the majority of tasks. The difference in AUC-PR between ComplEx and NTPŒª is
                                    signiÔ¨Åcant for all Countries tasks (p < 0.0001).
                                    AmajoradvantageofNTPsisthatwecaninspectinducedruleswhichprovideuswithaninterpretable
                                    representation of what the model has learned. The right column in Table 1 shows examples of induced
                                    rules by NTPŒª (note that predicates on Kinship are anonymized). For Countries, the NTP recovered
                                    those rules that are needed for solving the three different tasks. On UMLS, the NTP induced
                                    transitivity rules. Those relationships are particularly hard to encode by neural link prediction models
                                    like ComplEx, as they are optimized to locally predict the score of a fact.
                                                                                                   8
                   7  Related Work
                   Combining neural and symbolic approaches to relational learning and reasoning has a long tradition
                   andlet to various proposed architectures over the past decades (see [38] for a review). Early proposals
                   for neural-symbolic networks are limited to propositional rules (e.g., EBL-ANN [39], KBANN [40]
                   and C-IL2P [41]). Other neural-symbolic approaches focus on Ô¨Årst-order inference, but do not
                   learn subsymbolic vector representations from training facts in a KB (e.g., SHRUTI [42], Neural
                   Prolog [43], CLIP++ [44], Lifted Relational Neural Networks [45], and TensorLog [46]). Logic
                   Tensor Networks [47] are in spirit similar to NTPs, but need to fully ground Ô¨Årst-order logic rules.
                   However, they support function terms, whereas NTPs currently only support function-free terms.
                   Recentquestion-answeringarchitecturessuchas[15,17,18]translatequeryrepresentationsimplicitly
                   in a vector space without explicit rule representations and can thus not easily incorporate domain-
                   speciÔ¨Åc knowledge. In addition, NTPs are related to random walk [48, 49, 11, 12] and path encoding
                   models [14, 16]. However, instead of aggregating paths from random walks or encoding paths to
                   predict a target predicate, reasoning steps in NTPs are explicit and only uniÔ¨Åcation uses subsymbolic
                   representations. This allows us to induce interpretable rules, as well as to incorporate prior knowledge
                   either in the form of rules or in the form of rule templates which deÔ¨Åne the structure of logical
                   relationships that we expect to hold in a KB. Another line of work [50‚Äì54] regularizes distributed
                   representations via domain-speciÔ¨Åc rules, but these approaches do not learn such rules from data and
                   only support a restricted subset of Ô¨Årst-order logic. NTPs are constructed from Prolog‚Äôs backward
                   chaining and are thus related to UniÔ¨Åcation Neural Networks [55, 56]. However, NTPs operate on
                   vector representations of symbols instead of scalar values, which are more expressive.
                   As NTPs can learn rules from data, they are related to ILP systems such as FOIL [32], Sherlock
                   [57] and meta-interpretive learning of higher-order dyadic Datalog (Metagol) [58]. While these ILP
                   systems operate on symbols and search over the discrete space of logical rules, NTPs work with
                   subsymbolic representations and induce rules using gradient descent. Recently, [37] introduced
                   a differentiable rule learning system based on TensorLog and a neural network controller similar
                   to LSTMs [59]. Their method is more scalable than the NTPs introduced here. However, on
                   UMLSandKinshipourbaselinealreadyachieved stronger generalization by learning subsymbolic
                   representations. Still, scaling NTPs to larger KBs for competing with more scalable relational learning
                   methods is an open problem that we seek to address in future work.
                   8  Conclusion and Future Work
                   Weproposed an end-to-end differentiable prover for automated KB completion that operates on
                   subsymbolic representations. To this end, we used Prolog‚Äôs backward chaining algorithm as a recipe
                   for recursively constructing neural networks that can be used to prove queries to a KB. SpeciÔ¨Åcally,
                   weintroduced a differentiable uniÔ¨Åcation operation between vector representations of symbols. The
                   constructed neural network allowed us to compute the gradient of proof successes with respect to
                   vector representations of symbols, and thus enabled us to train subsymbolic representations end-to-
                   end from facts in a KB, and to induce function-free Ô¨Årst-order logic rules using gradient descent. On
                   benchmark KBs, our model outperformed ComplEx, a state-of-the-art neural link prediction model,
                   onthree out of four KBs while at the same time inducing interpretable rules.
                   To overcome the computational limitations of the end-to-end differentiable prover introduced in
                   this paper, we want to investigate the use of hierarchical attention [25] and reinforcement learning
                   methods such as Monte Carlo tree search [60, 61] that have been used for learning to play Go [62]
                   and chemical synthesis planning [63]. In addition, we plan to support function terms in the future.
                   Basedon[64],wearefurthermoreinterested in applying NTPs to automated proving of mathematical
                   theorems, either in logical or natural language form, similar to recent approaches by [65] and [66].
                   Acknowledgements
                   WethankPasquale Minervini, Tim Dettmers, Matko Bosnjak, Johannes Welbl, Naoya Inoue, Kai
                   Arulkumaran, and the anonymous reviewers for very helpful comments on drafts of this paper. This
                   work has been supported by a Google PhD Fellowship in Natural Language Processing, an Allen
                   Distinguished Investigator Award, and a Marie Curie Career Integration Award.
                                                    9
             References
             [1] Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. Factorizing YAGO: scalable machine learning
               for linked data. In Proceedings of the 21st World Wide Web Conference 2012, WWW 2012, Lyon, France,
               April 16-20, 2012, pages 271‚Äì280, 2012. doi: 10.1145/2187836.2187874.
             [2] Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M. Marlin. Relation extraction with
               matrix factorization and universal schemas. In Human Language Technologies: Conference of the North
               American Chapter of the Association of Computational Linguistics, Proceedings, June 9-14, 2013, Westin
               Peachtree Plaza Hotel, Atlanta, Georgia, USA, pages 74‚Äì84, 2013.
             [3] Richard Socher, Danqi Chen, Christopher D. Manning, and Andrew Y. Ng. Reasoning with neural tensor
               networks for knowledge base completion. In Advances in Neural Information Processing Systems 26:
               27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held
               December5-8, 2013, Lake Tahoe, Nevada, United States., pages 926‚Äì934, 2013.
             [4] Kai-Wei Chang, Wen-tau Yih, Bishan Yang, and Christopher Meek. Typed tensor decomposition of
               knowledge bases for relation extraction. In Proceedings of the 2014 Conference on Empirical Methods in
               Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a
               Special Interest Group of the ACL, pages 1568‚Äì1579, 2014.
             [5] Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and relations
               for learning and inference in knowledge bases. In International Conference on Learning Representations
               (ICLR), 2015.
             [6] Kristina Toutanova, Danqi Chen, Patrick Pantel, Hoifung Poon, Pallavi Choudhury, and Michael Gamon.
               Representing text for joint embedding of text and knowledge bases. In Proceedings of the 2015 Conference
               on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21,
               2015, pages 1499‚Äì1509, 2015.
             [7] Th√©o Trouillon, Johannes Welbl, Sebastian Riedel, √âric Gaussier, and Guillaume Bouchard. Complex
               embeddings for simple link prediction. In Proceedings of the 33nd International Conference on Machine
               Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, pages 2071‚Äì2080, 2016.
             [8] Herv√© Gallaire and Jack Minker, editors. Logic and Data Bases, Symposium on Logic and Data Bases,
               Centre d‚Äô√©tudes et de recherches de Toulouse, 1977, Advances in Data Base Theory, New York, 1978.
               PlemumPress. ISBN0-306-40060-X.
             [9] Stephen Muggleton. Inductive logic programming. New Generation Comput., 8(4):295‚Äì318, 1991. doi:
               10.1007/BF03037089.
             [10] Stanley Kok and Pedro M. Domingos. Statistical predicate invention. In Machine Learning, Proceedings
               of the Twenty-Fourth International Conference (ICML 2007), Corvallis, Oregon, USA, June 20-24, 2007,
               pages 433‚Äì440, 2007. doi: 10.1145/1273496.1273551.
             [11] Matt Gardner, Partha Pratim Talukdar, Bryan Kisiel, and Tom M. Mitchell. Improving learning and
               inference in a large knowledge-base using latent syntactic cues. In Proceedings of the 2013 Conference on
               Empirical Methods in Natural Language Processing, EMNLP 2013, 18-21 October 2013, Grand Hyatt
               Seattle, Seattle, Washington, USA, A meeting of SIGDAT, a Special Interest Group of the ACL, pages
               833‚Äì838, 2013.
             [12] Matt Gardner, Partha Pratim Talukdar, Jayant Krishnamurthy, and Tom M. Mitchell. Incorporating vector
               space similarity in random walk inference over knowledge bases. In Proceedings of the 2014 Conference
               on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar,
               AmeetingofSIGDAT,aSpecialInterest Group of the ACL, pages 397‚Äì406, 2014.
             [13] Islam Beltagy, Stephen Roller, Pengxiang Cheng, Katrin Erk, and Raymond J Mooney. Representing
               meaning with a combination of logical and distributional models. Computational Linguistics, 2017.
             [14] Arvind Neelakantan, Benjamin Roth, and Andrew McCallum. Compositional vector space models
               for knowledge base completion. In Proceedings of the 53rd Annual Meeting of the Association for
               Computational Linguistics and the 7th International Joint Conference on Natural Language Processing
               of the Asian Federation of Natural Language Processing, ACL 2015, July 26-31, 2015, Beijing, China,
               Volume 1: Long Papers, pages 156‚Äì166, 2015.
             [15] Baolin Peng, Zhengdong Lu, Hang Li, and Kam-Fai Wong. Towards neural network-based reasoning.
               CoRR,abs/1508.05508, 2015.
                                  10
                           [16] Rajarshi Das, Arvind Neelakantan, David Belanger, and Andrew McCallum. Chains of reasoning over
                                entities, relations, and text using recurrent neural networks. In Conference of the European Chapter of the
                                Association for Computational Linguistics (EACL), 2017.
                           [17] Dirk Weissenborn.  Separating answers from queries for neural reading comprehension.  CoRR,
                                abs/1607.03316, 2016.
                           [18] Yelong Shen, Po-Sen Huang, Jianfeng Gao, and Weizhu Chen. Reasonet: Learning to stop reading
                                in machine comprehension. In Proceedings of the Workshop on Cognitive Computation: Integrating
                                neural and symbolic approaches 2016 co-located with the 30th Annual Conference on Neural Information
                                Processing Systems (NIPS 2016), Barcelona, Spain, December 9, 2016., 2016.
                           [19] Alex Graves, Greg Wayne, and Ivo Danihelka. Neural turing machines. CoRR, abs/1410.5401, 2014.
                           [20] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. CoRR, abs/1410.3916, 2014.
                           [21] Edward Grefenstette, Karl Moritz Hermann, Mustafa Suleyman, and Phil Blunsom. Learning to transduce
                                with unbounded memory. In Advances in Neural Information Processing Systems 28: Annual Conference
                                on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages
                               1828‚Äì1836, 2015.
                           [22] ArmandJoulin and Tomas Mikolov. Inferring algorithmic patterns with stack-augmented recurrent nets.
                                In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information
                                Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages 190‚Äì198, 2015.
                           [23] Arvind Neelakantan, Quoc V. Le, and Ilya Sutskever. Neural programmer: Inducing latent programs with
                                gradient descent. In International Conference on Learning Representations (ICLR), 2016.
                           [24] Scott E. Reed and Nando de Freitas. Neural programmer-interpreters. In International Conference on
                                Learning Representations (ICLR), 2016.
                           [25] Marcin Andrychowicz, Misha Denil, Sergio Gomez Colmenarejo, Matthew W. Hoffman, David Pfau, Tom
                                Schaul, and Nando de Freitas. Learning to learn by gradient descent by gradient descent. In Advances in
                                Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems
                                2016, December 5-10, 2016, Barcelona, Spain, pages 3981‚Äì3989, 2016.
                           [26] Matko Bosnjak, Tim Rockt√§schel, Jason Naradowsky, and Sebastian Riedel. Programming with a differen-
                                tiable forth interpreter. In International Conference on Machine Learning (ICML), 2017.
                           [27] Stuart J. Russell and Peter Norvig. ArtiÔ¨Åcial Intelligence - A Modern Approach (3. internat. ed.). Pearson
                                Education, 2010. ISBN 978-0-13-207148-2.
                           [28] Lise Getoor. Introduction to statistical relational learning. MIT press, 2007.
                           [29] Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Learning to compose neural networks
                                for question answering. In NAACL HLT 2016, The 2016 Conference of the North American Chapter of the
                                Association for Computational Linguistics: Human Language Technologies, San Diego California, USA,
                                June 12-17, 2016, pages 1545‚Äì1554, 2016.
                           [30] David S Broomhead and David Lowe. Radial basis functions, multi-variable functional interpolation and
                                adaptive networks. Technical report, DTIC Document, 1988.
                           [31] AllenVanGelder. EfÔ¨Åcientloopdetectioninprologusingthetortoise-and-haretechnique. J.Log.Program.,
                                4(1):23‚Äì31, 1987. doi: 10.1016/0743-1066(87)90020-3.
                           [32] J. Ross Quinlan. Learning logical deÔ¨Ånitions from relations. Machine Learning, 5:239‚Äì266, 1990. doi:
                               10.1007/BF00117105.
                           [33] William Yang Wang and William W. Cohen. Joint information extraction and reasoning: A scalable
                                statistical relational learning approach. In Proceedings of the 53rd Annual Meeting of the Association for
                                Computational Linguistics and the 7th International Joint Conference on Natural Language Processing
                                of the Asian Federation of Natural Language Processing, ACL 2015, July 26-31, 2015, Beijing, China,
                                Volume 1: Long Papers, pages 355‚Äì364, 2015.
                           [34] Antoine Bordes, Nicolas Usunier, Alberto Garc√≠a-Dur√°n, Jason Weston, and Oksana Yakhnenko. Translat-
                                ing embeddings for modeling multi-relational data. In Advances in Neural Information Processing Systems
                                26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting
                                held December 5-8, 2013, Lake Tahoe, Nevada, United States., pages 2787‚Äì2795, 2013.
                                                                          11
             [35] Guillaume Bouchard, Sameer Singh, and Theo Trouillon. On approximate reasoning capabilities of
               low-rank vector spaces. In Proceedings of the 2015 AAAI Spring Symposium on Knowledge Representation
               and Reasoning (KRR): Integrating Symbolic and Neural Approaches, 2015.
             [36] Maximilian Nickel, Lorenzo Rosasco, and Tomaso A. Poggio. Holographic embeddings of knowledge
               graphs. In Proceedings of the Thirtieth AAAI Conference on ArtiÔ¨Åcial Intelligence, February 12-17, 2016,
               Phoenix, Arizona, USA., pages 1955‚Äì1961, 2016.
             [37] Fan Yang, Zhilin Yang, and William W. Cohen. Differentiable learning of logical rules for knowledge base
               completion. CoRR, abs/1702.08367, 2017.
             [38] Artur S. d‚ÄôAvila Garcez, Krysia Broda, and Dov M. Gabbay. Neural-symbolic learning systems: founda-
               tions and applications. Springer Science & Business Media, 2012.
             [39] Jude W Shavlik and Geoffrey G Towell. An approach to combining explanation-based and neural learning
               algorithms. Connection Science, 1(3):231‚Äì253, 1989.
             [40] Geoffrey G. Towell and Jude W. Shavlik. Knowledge-based artiÔ¨Åcial neural networks. Artif. Intell., 70
               (1-2):119‚Äì165, 1994. doi: 10.1016/0004-3702(94)90105-8.
             [41] Artur S. d‚ÄôAvila Garcez and Gerson Zaverucha. The connectionist inductive learning and logic program-
               mingsystem. Appl. Intell., 11(1):59‚Äì77, 1999. doi: 10.1023/A:1008328630915.
             [42] Lokendra Shastri. Neurally motivated constraints on the working memory capacity of a production system
               for parallel processing: Implications of a connectionist model based on temporal synchrony. In Proceedings
               of the Fourteenth Annual Conference of the Cognitive Science Society: July 29 to August 1, 1992, Cognitive
               Science Program, Indiana University, Bloomington, volume 14, page 159. Psychology Press, 1992.
             [43] Liya Ding. Neural prolog-the concepts, construction and mechanism. In Systems, Man and Cybernetics,
               1995. Intelligent Systems for the 21st Century., IEEE International Conference on, volume 4, pages
               3603‚Äì3608. IEEE, 1995.
             [44] Manoel V. M. Fran√ßa, Gerson Zaverucha, and Artur S. d‚ÄôAvila Garcez. Fast relational learning using
               bottom clause propositionalization with artiÔ¨Åcial neural networks. Machine Learning, 94(1):81‚Äì104, 2014.
               doi: 10.1007/s10994-013-5392-1.
             [45] Gustav Sourek, Vojtech Aschenbrenner, Filip Zelezn√Ω, and Ondrej Kuzelka. Lifted relational neural
               networks. In Proceedings of the NIPS Workshop on Cognitive Computation: Integrating Neural and
               Symbolic Approaches co-located with the 29th Annual Conference on Neural Information Processing
               Systems (NIPS 2015), Montreal, Canada, December 11-12, 2015., 2015.
             [46] William W. Cohen. Tensorlog: A differentiable deductive database. CoRR, abs/1605.06523, 2016.
             [47] Luciano SeraÔ¨Åni and Artur S. d‚ÄôAvila Garcez. Logic tensor networks: Deep learning and logical reasoning
               from data and knowledge. In Proceedings of the 11th International Workshop on Neural-Symbolic
               Learning and Reasoning (NeSy‚Äô16) co-located with the Joint Multi-Conference on Human-Level ArtiÔ¨Åcial
               Intelligence (HLAI 2016), New York City, NY, USA, July 16-17, 2016., 2016.
             [48] Ni Lao, Tom M. Mitchell, and William W. Cohen. Random walk inference and learning in A large scale
               knowledge base. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language
               Processing, EMNLP 2011, 27-31 July 2011, John McIntyre Conference Centre, Edinburgh, UK, A meeting
               of SIGDAT, a Special Interest Group of the ACL, pages 529‚Äì539, 2011.
             [49] Ni Lao, Amarnag Subramanya, Fernando C. N. Pereira, and William W. Cohen. Reading the web with
               learned syntactic-semantic inference rules. In Proceedings of the 2012 Joint Conference on Empirical
               MethodsinNaturalLanguageProcessingandComputationalNaturalLanguageLearning,EMNLP-CoNLL
               2012, July 12-14, 2012, Jeju Island, Korea, pages 1017‚Äì1026, 2012.
             [50] Tim Rockt√§schel, Matko Bosnjak, Sameer Singh, and Sebastian Riedel. Low-Dimensional Embeddings of
               Logic. In ACL Workshop on Semantic Parsing (SP‚Äô14), 2014.
             [51] Tim Rockt√§schel, Sameer Singh, and Sebastian Riedel. Injecting logical background knowledge into
               embeddings for relation extraction. In NAACL HLT 2015, The 2015 Conference of the North American
               Chapter of the Association for Computational Linguistics: Human Language Technologies, Denver,
               Colorado, USA, May 31 - June 5, 2015, pages 1119‚Äì1129, 2015.
             [52] Ivan Vendrov, Ryan Kiros, Sanja Fidler, and Raquel Urtasun. Order-embeddings of images and language.
               In International Conference on Learning Representations (ICLR), 2016.
                                  12
             [53] Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard H. Hovy, and Eric P. Xing. Harnessing deep neural
               networks with logic rules. In Proceedings of the 54th Annual Meeting of the Association for Computational
               Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers, 2016.
             [54] Thomas Demeester, Tim Rockt√§schel, and Sebastian Riedel. Lifted rule injection for relation embeddings.
               In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP
               2016, Austin, Texas, USA, November 1-4, 2016, pages 1389‚Äì1399, 2016.
             [55] Ekaterina Komendantskaya. UniÔ¨Åcation neural networks: uniÔ¨Åcation by error-correction learning. Logic
               Journal of the IGPL, 19(6):821‚Äì847, 2011. doi: 10.1093/jigpal/jzq012.
             [56] Steffen H√∂lldobler. A structured connectionist uniÔ¨Åcation algorithm. In Proceedings of the 8th National
               Conference on ArtiÔ¨Åcial Intelligence. Boston, Massachusetts, July 29 - August 3, 1990, 2 Volumes., pages
               587‚Äì593, 1990.
             [57] Stefan Schoenmackers, Jesse Davis, Oren Etzioni, and Daniel S. Weld. Learning Ô¨Årst-order horn clauses
               from web text. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language
               Processing, EMNLP 2010, 9-11 October 2010, MIT Stata Center, Massachusetts, USA, A meeting of
               SIGDAT,aSpecial Interest Group of the ACL, pages 1088‚Äì1098, 2010.
             [58] Stephen H Muggleton, Dianhuan Lin, and Alireza Tamaddoni-Nezhad. Meta-interpretive learning of
               higher-order dyadic datalog: Predicate invention revisited. Machine Learning, 100(1):49‚Äì73, 2015.
             [59] SeppHochreiterandJ√ºrgenSchmidhuber. Longshort-termmemory. NeuralComputation,9(8):1735‚Äì1780,
               1997. doi: 10.1162/neco.1997.9.8.1735.
             [60] R√©mi Coulom. EfÔ¨Åcient selectivity and backup operators in monte-carlo tree search. In Computers and
               Games, 5th International Conference, CG 2006, Turin, Italy, May 29-31, 2006. Revised Papers, pages
               72‚Äì83, 2006. doi: 10.1007/978-3-540-75538-8_7.
             [61] Levente Kocsis and Csaba Szepesv√°ri. Bandit based monte-carlo planning. In Machine Learning:
               ECML2006,17thEuropeanConferenceonMachineLearning,Berlin,Germany,September18-22,2006,
               Proceedings, pages 282‚Äì293, 2006. doi: 10.1007/11871842_29.
             [62] David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian
               Schrittwieser, Ioannis Antonoglou, Vedavyas Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik
               Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy P. Lillicrap, Madeleine Leach, Koray
               Kavukcuoglu, Thore Graepel, and Demis Hassabis. Mastering the game of go with deep neural networks
               and tree search. Nature, 529(7587):484‚Äì489, 2016. doi: 10.1038/nature16961.
             [63] MarwinH.S.Segler,MikePreu√ü,andMarkP.Waller. Towards"alphachem": Chemicalsynthesisplanning
               with tree search and deep neural network policies. CoRR, abs/1702.00020, 2017.
             [64] Mark E. Stickel. A prolog technology theorem prover. New Generation Comput., 2(4):371‚Äì383, 1984. doi:
               10.1007/BF03037328.
             [65] Cezary Kaliszyk, Fran√ßois Chollet, and Christian Szegedy. Holstep: A machine learning dataset for
               higher-order logic theorem proving. In International Conference on Learning Representations (ICLR),
               2017.
             [66] Sarah M. Loos, Geoffrey Irving, Christian Szegedy, and Cezary Kaliszyk. In International Conferences on
               Logic for Programming, ArtiÔ¨Åcial Intelligence and Reasoning (LPAR), 2017.
             [67] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International
               Conference on Learning Representations (ICLR), 2015.
             [68] Xavier Glorot and Yoshua Bengio. Understanding the difÔ¨Åculty of training deep feedforward neural
               networks. In Proceedings of the Thirteenth International Conference on ArtiÔ¨Åcial Intelligence and
               Statistics, AISTATS 2010, Chia Laguna Resort, Sardinia, Italy, May 13-15, 2010, pages 249‚Äì256, 2010.
             [69] Mart√≠n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Gregory S.
               Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian J. Goodfellow, Andrew Harp,
               Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal J√≥zefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh
               Levenberg, Dan Man√©, Rajat Monga, Sherry Moore, Derek Gordon Murray, Chris Olah, Mike Schuster,
               Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul A. Tucker, Vincent Vanhoucke, Vijay
               Vasudevan, Fernanda B. Vi√©gas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu,
               and Xiaoqiang Zheng. TensorÔ¨Çow: Large-scale machine learning on heterogeneous distributed systems.
               CoRR,abs/1603.04467, 2016.
                                  13
                         Appendix
                         A BackwardChainingPseudocode
                         SimpliÔ¨Åed pseudocode for symbolic backward chaining (cycle detection omitted for brevity, see
                         [27, 31, 8] for details).
                          1. or(G,S) = [S0 | S0 ‚àà and(B,unify(H,G,S)) for H :‚Äì B ‚àà K]
                          2. and(_,FAIL) = FAIL
                          3. and([ ],S) = S
                          4. and(G : G,S) = [S00 | S00 ‚àà and(G,S0) for S0 ‚àà or(substitute(G,S),S)]
                          5. unify(_,_,FAIL) = FAIL
                          6. unify([ ],[ ],S) = S
                          7. unify([ ],_,_) = FAIL
                          8. unify(_,[ ],_) = FAIL
                                                                 Ô£±                              Ô£º
                                                         Ô£´          S‚à™{h/g} ifh‚ààV                 Ô£∂
                                                                 Ô£¥                              Ô£¥
                                                                 Ô£≤ S‚à™{g/h} ifg ‚ààV,h6‚ààV Ô£Ω
                          9. unify(h : H,g : G,S) = unifyÔ£¨H,G,                                    Ô£∑
                                                         Ô£≠          S           if g = h          Ô£∏
                                                                 Ô£¥                              Ô£¥
                         10. substitute([ ],_) = [ ]             Ô£≥ FAIL         otherwise       Ô£æ
                         11. substitute(g : G,S) =  x   if g/x ‚àà S  : substitute(G,S)
                                                     g   otherwise
                         B ComplEx
                         ComplEx[7]isastate-of-the-art neural link prediction model that represents symbols as complex
                         vectors. Let real(Œ∏i:) denote the real part and imag(Œ∏i:) the imaginary part of a complex vector
                                k
                         Œ∏i: ‚àà C representing the symbol with the ith index. The scoring function deÔ¨Åned by ComplEx is
                                                        >                                >
                         complex (s,i,j) = œÉ real(Œ∏ ) (real(Œ∏ )real(Œ∏ ))+real(Œ∏ ) (imag(Œ∏ )imag(Œ∏ ))+
                                  Œ∏                  s:         i:         j:         s:          i:          j:
                                        >                                  >                       
                              imag(Œ∏ ) (real(Œ∏ )imag(Œ∏ ))‚àíimag(Œ∏ ) (imag(Œ∏ )real(Œ∏ ))
                                     s:         i:          j:           s:          i:        j:
                         wheredenotestheelement-wisemultiplicationandœÉ thesigmoidfunction. ThebeneÔ¨ÅtofComplEx
                         over other neural link prediction models such as RESCAL [1] or DistMult [5] is that by using complex
                         vectors as subsymbolic representations it can capture symmetric as well as asymmetric relations.
                         C BatchProving
                         Let A ‚àà RN√ók be a matrix of N subsymbolic representations that are to be uniÔ¨Åed with M other
                         representations B ‚àà RM√ók. We can adapt the uniÔ¨Åcation module to calculate the uniÔ¨Åcation success
                         in a batched way using
                                    Ô£´ v                           Ô£´                    Ô£∂          Ô£∂
                                        uÔ£´Ô£Æ P            Ô£π    Ô£∂        Ô£Æ P          Ô£π>
                                        u       k   A2                      k  B2
                                    Ô£¨ u         i=1  1i           Ô£¨         i=1  1i    Ô£∑          Ô£∑
                                    Ô£¨ uÔ£¨Ô£Ø         .      Ô£∫ >Ô£∑ Ô£¨ Ô£Ø             .     Ô£∫ Ô£∑         >Ô£∑      N√óM
                                 exp  ‚àíu          .        1    + 1           .           ‚àí2AB      ‚ààR
                                    Ô£¨ tÔ£≠Ô£∞         .      Ô£ª MÔ£∏ Ô£≠ NÔ£∞            .     Ô£ª Ô£∏           Ô£∑
                                    Ô£≠         P                           P                       Ô£∏
                                                k   A2                      k  B2
                                                i=1  Ni                     i=1  Mi
                         where 1N and 1M are vectors of N and M ones respectively, and the square root is taken element-
                         wise. In practice, we partition the KB into rules that have the same structure and batch-unify goals
                         with all rule heads per partition at the same time on a Graphics Processing Unit (GPU). Furthermore,
                         substitution sets bind variables to vectors of symbol indices instead of single symbol indices, and min
                         and max operations are taken per goal.
                                                                     14
                    D KmaxGradientApproximation
                    NTPsallowustocalculate the gradient of proof success scores with respect to subsymbolic repre-
                    sentations and rule parameters. While backpropagating through this large computation graph will
                    give us the exact gradient, it is computationally infeasible for any reasonably-sized KB. Consider
                    the parameterized rule Œ∏1:(X,Y) :‚Äì Œ∏2:(X,Z),Œ∏3:(Z,Y) and let us assume the given KB contains
                    1 000 facts with binary predicates. While X and Y will be bound to the respective representations
                    in the goal, Z we will be substituted with every possible second argument of the 1 000 facts in the
                    KBwhenprovingtheÔ¨Årstatominthebody. Moreover, for each of these 1 000 substitutions, we will
                    again need to compare with all facts in the KB when proving the second atom in the body of the rule,
                    resulting in 1 000 000 proof success scores. However, note that since we use the max operator for
                    aggregating the success of different proofs, only subsymbolic representations in one out of 1 000 000
                    proofs will receive gradients.
                    Toovercomethis computational limitation, we propose the following heuristic. We assume that when
                    unifying the Ô¨Årst atom with facts in the KB, it is unlikely for any uniÔ¨Åcation successes below the top
                    Ksuccesses to attain the maximum proof success when unifying the remaining atoms in the body of
                    a rule with facts in the KB. That is, after the uniÔ¨Åcation of the Ô¨Årst atom, we only keep the top K
                    substitutions and their success scores, and continue proving only with these. This means that all other
                    partial proofs will not contribute to the forward pass at this stage, and consequently not receive any
                    gradients on the backward pass of backpropagation. We term this the K max heuristic. Note that we
                    cannot guarantee anymore that the gradient of the proof success is the exact gradient, but for a large
                    enough K wegetaclose approximation to the true gradient.
                    E TrainingDetails
                    WeuseADAM[67]withaninitiallearningrateof0.001andamini-batch size of 50 (10 known and
                    40corrupted atoms) for optimization. We apply an ` regularization of 0.01 to all model parameters,
                                                          2
                    and clip gradient values at [‚àí1.0,1.0]. All subsymbolic representations and rule parameters are
                    initialized using Xavier initialization [68]. We train all models for 100 epochs and repeat every
                    experiment on the Countries corpus ten times. Statistical signiÔ¨Åcance is tested using the independent
                    t-test. All models are implemented in TensorFlow [69]. We use a maximum proof depth of d = 2
                    and add the following rule templates where the number in front of the rule template indicates how
                    often a parameterized rule of the given structure will be instantiated. Note that a rule template such
                    as #1(X,Y):‚Äì#2(X,Z),#2(Z,Y)speciÔ¨Åesthatthetwopredicaterepresentations in the body are
                    shared.
                    Countries S1
                    3 #1(X,Y):‚Äì#1(Y,X).
                    3 #1(X,Y):‚Äì#2(X,Z),#2(Z,Y).
                    Countries S2
                    3 #1(X,Y):‚Äì#1(Y,X).
                    3 #1(X,Y):‚Äì#2(X,Z),#2(Z,Y).
                    3 #1(X,Y):‚Äì#2(X,Z),#3(Z,Y).
                    Countries S3
                    3 #1(X,Y):‚Äì#1(Y,X).
                    3 #1(X,Y):‚Äì#2(X,Z),#2(Z,Y).
                    3 #1(X,Y):‚Äì#2(X,Z),#3(Z,Y).
                    3 #1(X,Y):‚Äì#2(X,Z),#3(Z,W),#4(W,Y).
                    Kinship, Nations & UMLS
                    20#1(X,Y):‚Äì#2(X,Y).
                    20#1(X,Y):‚Äì#2(Y,X).
                    20#1(X,Y):‚Äì#2(X,Z),#3(Z,Y).
                                                        15
