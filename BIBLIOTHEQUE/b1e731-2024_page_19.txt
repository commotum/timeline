           Melanie Mitchell, Alessandro B Palmarini, and Arseny Moskvichev. Comparing humans, gpt-4, and
            gpt-4v on abstraction and reasoning tasks. arXiv preprint arXiv:2311.09247, 2023.
           Arseny Moskvichev, Victor Vikram Odouard, and Melanie Mitchell. The conceptarc benchmark:
            Evaluating understanding and generalization in the arc domain. arXiv preprint arXiv:2305.07141,
            2023.
           Vijayaraghavan Murali, Letao Qi, Swarat Chaudhuri, and Chris Jermaine. Neural sketch learning for
            conditional program generation. arXiv preprint arXiv:1703.05698, 2017.
           Maxwell Nye, Luke Hewitt, Joshua Tenenbaum, and Armando Solar-Lezama. Learning to infer
            program sketches. In International Conference on Machine Learning, pages 4861–4870. PMLR,
            2019.
           Peter-Michael Osera and Steve Zdancewic. Type-and-example-directed program synthesis. ACM
            SIGPLANNotices,50(6):619–630, 2015.
           Richard E Pattis. Karel the robot: a gentle introduction to the art of programming. John Wiley &
            Sons, 1994.
           Scott Reed and Nando De Freitas. Neural programmer-interpreters. arXiv preprint arXiv:1511.06279,
            2015.
           Kensen Shi, Joey Hong, Yinlin Deng, Pengcheng Yin, Manzil Zaheer, and Charles Sutton. Exedec:
            Execution decomposition for compositional generalization in neural program synthesis. arXiv
            preprint arXiv:2307.13883, 2023.
           RayJSolomonoff. Aformaltheoryofinductive inference. part i. Information and control, 7(1):1–22,
            1964.
           Phillip D Summers. A methodology for lisp program construction from examples. Journal of the
            ACM(JACM),24(1):161–175,1977.
           Shao-Hua Sun, Hyeonwoo Noh, Sriram Somasundaram, and Joseph Lim. Neural program synthesis
            from diverse demonstration videos. In International Conference on Machine Learning, pages
            4790–4799. PMLR, 2018.
           DweepTrivedi, Jesse Zhang, Shao-Hua Sun, and Joseph J Lim. Learning to synthesize programs as
            interpretable and generalizable policies. Advances in neural information processing systems, 34:
            25146–25163, 2021.
           AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanN.Gomez,Lukasz
            Kaiser, and Illia Polosukhin. Attention is all you need. Advances in Neural Information Processing
            Systems, 2017.
           Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi DQ Bui, Junnan Li, and Steven CH Hoi.
            Codet5+: Open code large language models for code understanding and generation. arXiv preprint
            arXiv:2305.07922, 2023.
           Ruibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Chen Xing, Huishuai Zhang,
            YanyanLan,LiweiWang,andTie-YanLiu. Onlayernormalization in the transformer architecture,
            2020. URLhttps://arxiv.org/abs/2002.04745.
           Yuichi Yoshida and Takeru Miyato. Spectral norm regularization for improving the generalizability
            of deep learning. arXiv preprint arXiv:1705.10941, 2017.
           Peiyu Yu, Dinghuai Zhang, Hengzhi He, Xiaojian Ma, Ruiyao Miao, Yifan Lu, Yasi Zhang, Deqian
            Kong, Ruiqi Gao, Jianwen Xie, et al. Latent energy-based odyssey: Black-box optimization via
            expanded exploration in the energy-based latent space. arXiv preprint arXiv:2405.16730, 2024.
           Wojciech Zaremba, Tomas Mikolov, Armand Joulin, and Rob Fergus. Learning simple algorithms
            from examples. In International conference on machine learning, pages 421–429. PMLR, 2016.
           ShunZhang,ZhenfangChen,YikangShen,MingyuDing,JoshuaBTenenbaum,andChuangGan.
            Planning with large language models for code generation. arXiv preprint arXiv:2303.05510, 2023.
                               19
