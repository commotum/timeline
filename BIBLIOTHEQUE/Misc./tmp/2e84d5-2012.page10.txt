                                                                                                                                                                                       Neuron
                                                                                                                                                 Perspective
                                                                                                                                             Figure 4. Hierarchical Inference and
                                                                                                                                             Predictive Coding
                                                                                                                                             This ﬁgure describes the predictive coding
                                                                                                                                             scheme associated with a simple hierarchical
                                                                                                                                             model shown on the left. In this model each node
                                                                                                                                             has a single parent. The ensuing inversion or
                                                                                                                                             generalizedpredictivecodingschemeisshownon
                                                                                                                                             the right. The key quantities in this scheme are
                                                                                                                                             (conditional) expectationsofthehiddenstatesand
                                                                                                                                             causesandtheirassociatedpredictionerrors.The
                                                                                                                                             basicarchitecture—impliedbytheinversionofthe
                                                                                                                                             graphical   (hierarchical)   model—suggests that
                                                                                                                                             prediction errors (caused by unpredicted ﬂuctua-
                                                                                                                                             tions in hidden variables) are passed up the hier-
                                                                                                                                             archy to update conditional expectations. These
                                                                                                                                             conditional expectations now provide predictions
                                                                                                                                             that are passed down the hierarchy to form
                                                                                                                                             prediction errors. We presume that the forward
                      andbackwardmessagepassingbetweenhierarchicallevelsismediated byextrinsic (feedforward and feedback) connections. Neuronal populations encoding
                      conditional expectations and prediction errors now have to be deployed in a canonical microcircuit to understand the computational logic of intrinsic
                      connections—within each level of the hierarchy—as shown in the next ﬁgure.
                      setting, Equation (1) minimizes variational free energy and corre-                       remainderofthisPerspective, wefocusonintrinsicconnections
                      spondstogeneralizedpredictivecoding.Underlinearmodels,it                                 and cortical microcircuits.
                      reducestolinearpredictivecoding,alsoknownasKalman-Bucy
                      ﬁltering (see Friston, 2010 for details).                                                TheCortical Microcircuit and Predictive Coding
                         In neuronal network terms, Equation (1) says that prediction                          WenowtrytoassociatethevariablesinEquation(1)withspeciﬁc
                      error units receive messages from the same level and the level                           populations in the canonical microcircuit. Figure 5 illustrates
                      above. This is because the hierarchical form of the model only                           a remarkable correspondence between the form of Equation
                      requires conditional expectations from neighboring levels to                             (1) and the connectivity of the canonical microcircuit. Further-
                      form prediction errors, as can be seen schematically in Figure 4.                        more, the resulting scheme corresponds almost exactly to the
                      Conversely, expectations are driven by prediction error from the                         computational architecture proposed by Mumford (1992). This
                      same level and the level below—updating expectations about                               correspondence rests upon the following intuitive steps.
                      hidden states and causes respectively. These constitute the
                      bottom-up and lateral messages that drive conditional expecta-                               d First, we divide the excitatory cells in the superﬁcial
                      tions to provide better predictions—or representations—that                                     and deep layers into principal (pyramidal) cells and excit-
                      suppresspredictionerror.Thisupdatingcorrespondstoanaccu-                                        atory interneurons. This accommodates the fact that (in
                      mulation of prediction errors, in that the rate of change of condi-                             macaque V1) a signiﬁcant percentage of superﬁcial L2/3
                      tionalexpectationsisproportionaltopredictionerror.Electrophys-                                  cells (about half) and deep L5 excitatory cells (about
                      iologically, this means that one would expect to see a transient                                80%)donotprojectoutsidethecortical column (Callaway
                      prediction error response to bottom-up afferents (in neuronal                                   and Wiser, 1996; Briggs and Callaway, 2005).
                      populations encoding prediction error) that is suppressed to                                 d Second, we know that the superﬁcial and deep pyramidal
                      baseline ﬁring rates by sustained responses (in neuronal popu-                                  cells provide feedforward and feedback connections,
                      lations encoding predictions). This is the essence of recurrent                                 respectively. This means that superﬁcial pyramidal cells
                      messagepassingbetweenhierarchicallevelstosuppresspredic-                                        must encode and broadcast prediction errors on hidden
                      tion error (see Friston, 2008 for a more detailed discussion).                                  causes xði+1Þ, while deep pyramidal cells must encode
                                                                                                                                   v
                                                                                                                                                           ðiÞ  ðiÞ
                         The nature of this message passing is remarkably consistent                                  conditional expectations ðm~ ;m~ Þ so that they can elabo-
                                                                                                                                                           v    x
                      with the anatomical and physiological features of cortical hierar-                              rate feedback predictions.
                      chies. An important prediction is that the nonlinear functions of                            d Third, we know that the (spiny stellate) excitatory cells in
                      the generative model—modeling context-sensitive dependen-                                       thegranularlayerreceivefeedforwardconnectionsencod-
                      cies among hidden variables—appear only in the top-down                                         ing prediction errors xðiÞ on the hidden causes of the level
                                                                                                                                                    v
                      andlateral predictions. This means, neurobiologically, we would                                 below.
                      predictfeedbackconnectionstopossessnonlinearorneuromo-                                       d Thisleavestheinhibitoryinterneuronsinthegranularlayer,
                      dulatory characteristics, in contrast to feedforward connections                                which, for symmetry, we associate with prediction errors
                      that mediate a linear mixture of prediction errors. This functional                             on the hidden states.
                      asymmetry is exactly consistent with the empirical evidence                                  d The remaining populations are the excitatory and inhibi-
                      reviewed above. Another key feature of Equation (1) is that the                                 tory interneurons in the supragranular layer, to which we
                      top-down predictions produce prediction errors through sub-                                     assign expectations about hidden causes and states,
                      traction. In other words, feedback connections should exert                                     respectively. These are mapped through descending
                      inhibitory effects, of the sort seen empirically. Table 2 summa-                                (intrinsic) feedforward connections to cells in the deep
                      rizes the features of extrinsic connectivity (reviewed in the pre-                              layers that generate predictions. We do not suppose that
                      vious section) that are explained by predictive coding. In the                                  this is a simple one-to-one mapping—rather it mediates
                      704 Neuron76,November21,2012ª2012ElsevierInc.
