               www.nature.com/scientificdata/                                                                                                     www.nature.com/scientificdata
                                                         Fig. 2  ARC Experiment Interface. Participants were given instructions about the dif㘶erent controls and 
                                                         layout of the interface, followed by a tutorial task. Shown here is a tutorial task chosen from the training 
                                                         set (e9afcf9a.json). T㔴e experimental platform we used is made available at exps.gureckislab.org/e/
                                                         assumption-fast-natural.
                                                         Procedure.  T㔴e experiment consisted of 5 ARC tasks which were randomly selected from either the set of 400 
                                                         training tasks or from the 400 evaluation tasks. To reduce the potential for attrition or dropouts, we reduced the 
                                                         amount of ARC tasks participants were required to solve from 10 to 5 tasks af㘶er collecting 241 out of 783 partic-
                                                         ipants from the f㘶rst phase of data collection on the training set. On average, participants completed the experi-
                                                         ment in 23 minutes and 1 second (SD = 13m 24s) for the training set, and 28 minutes and 51 seconds (SD=16m 
                                                         19s) for the evaluation set. T㔴ere was no time limit for completing a task. Participants who exceeded the total 
                                                         time limit of 90 minutes were dealt with manually by email, but were included in our dataset nonetheless. For 
                                                                                                                                                                                                        -
                                                         each task, participants were given three attempts. Af㘶er each attempt, feedback was given on whether the sub
                                                         mitted solution was correct or not. Participants were not allowed to resubmit a previously incorrect output grid, 
                                                         ensuring that each of their attempts would be unique. We implemented this feature af㘶er collecting data from the 
                                                         f㘶rst 340 participants in the training set experiment. Prior to that, we observed that approximately 8% of incor-
                                                         rect second and third submission attempts were the same as earlier submission attempts on the same task. If the 
                                                         participant failed to generate the solution af㘶er three attempts, they automatically proceeded onto the next task. 
                                                         We also collected natural-language descriptions of the inferred solutions by asking participants to write down 
                                                         their solution in words (English). T㔴is was f㘶rst done af㘶er submitting an initial attempt before any feedback 
                                                         was given. If the initial submission was incorrect, participants were asked to submit a second natural-language 
                                                         description, either af㘶er a subsequent correct submission or on their last (but still incorrect) submission.
                                                         Data Records
                                                                                                                                                                               14
                                                         T㔴e dataset is publicly available on an Open Science Framework (OSF) data repository  under a Creative 
                                                         Commons License (CC0 1.0 Universal), with this section being the primary source of information on the avail-
                                                         ability and content of the data being described. T㔴e dataset is organized in two main directories: data/ and 
                                                         survey/.
                                                         Data directory.  T㔴is directory contains three primary CSV f㘶les: 
                                                         •	   data.csv: T㔴e main dataset f㘶le, where each row represents a single action taken by a unique participant on 
                                                              a specif㘶c task and attempt. Actions refer to the use of tools and other relevant clicks within the user interface: 
                                                              edit a cell, copy-paste, select, f㘶ood f㘶ll, undo, submit, etc. Key columns include:
                                                             – hashed_id: Anonymized participant identif㘶er.
                                                             – task_name: Name of the task.
                                                             – attempt_number: Number of the current attempt.
                                                             – action_id: Number of the action taken for the current attempt.
                                                             – action: Action taken by the participant within the user-interface.
               Scientific Data | (2025) 12:1380 | https://doi.org/10.1038/s41597-025-05687-1                                                                                                           4
