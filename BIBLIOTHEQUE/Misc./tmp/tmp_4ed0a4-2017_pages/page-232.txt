                                                            7.2.  PAIRS  AND  CONDITIONAL  ENTROPY                                                               219
                     t a k e n   o v e r  a ll  tu p le s   q^  o f n o n -n e g a tiv e   re a ls   t h a t   s u m   u p   to   1.  L e t  u s  r e s tr ic t  o u r 
                     a t t e n t i o n   to   “r a n k   1”  tu p le s   t h a t   h a v e   th e   fo rm
                                                                                  Qij — ([i* ' q*j
                     for  som e  tu p le s  o f  n o n -n e g a tiv e   re a ls  qi*  a n d   g*j  (b o th   tu p le s   h a v e   s u m   1).  T h e n  
                     ( — log qij)  can  be  decom posed  into  (— logg**)  +   (— logg*j),  and  th e  en tire  sum   is 
                     decom posed  into  tw o  parts,  w hich  after  p artial  sum m ation  over  one  coordinate 
                     becom es equal to
                                                                               EPi*(~log 4i*)
                                                                                 i
                     a n d
                                                                                j
                     respectively.  T h e  m inim al  values  of th e   tw o  p a rts  are  H(£)  a n d   H{rf).
                            Therefore,  th e  left-hand  side  of our  inequality  is  th e  m inim um   over  all  tu p les 
                     a n d   th e   rig h t-h a n d   sid e   is  th e   m in im u m   o v er  ra n k   1  tu p le s,  a n d   th e   in e q u a lity   is 
                     proven.                                                                                                                                      □
                            7.2.2.  Conditional entropy.  Recall the definition of conditional probability. 
                     Let  A and  В be  tw o  events.  T he  conditional probability of  В w ith  condition  A 
                     ( d e n o te d   a s  P r[£ ? |A ])  is  d e fin e d   a s  th e   ra tio   P r[A   a n d   B\/'Px[A\.                T h is  d efin itio n  
                     assum es th a t Pr[A ]  >   0 .  T h e  m o tiv a tio n  is clear:  W e a re  in te re ste d  in  th e  fra c tio n  of 
                     o u tc o m e s w h en  В h a p p e n e d  b u t re s tric t o u r a tte n tio n  to  th e  case w h en  A h a p p e n e d .
                            Let  A be an event  (th at  has non-zero probability),  and  let £ be a random  vari­
                     able w ith finite range                   ,...,£&•  T h en  we m ay consider th e  conditional distribution 
                     of  £  w h en   A h ap p en s.             We  get  a  new   random   variable:  now                                 h a s   p r o b a b ility  
                     Pr[(£ =                   i n s te a d   o f  P r[£   =   £*].  T h e   e n tro p y   o f th is   d is tr ib u tio n   is  c a lle d   con­
                     ditional entropy of £ with condition A and is denoted by Н(^\А). (T he distribution 
                     itself could  be  d en o ted   by  (£|A ).)
                              218 Show that H(£\A) can be greater than H(£)  and can be less than H(£). 
                            (Hint The distribution  (£|A )  has  not  m uch  in  com m on  w ith  th e  d istrib u tio n
                     of £,  especially  if A has  sm all  probability.
                            I n fo rm a lly   sp e a k in g ,  H(f\A)  is  th e   m in im a l  a v erag e  c o d e  le n g th   if th e   av erag e 
                     is  ta k e n   o n ly   o v e r  th e   c a s e s  w h e n   A h a p p e n s .
                            Now let us consider two random  variables £ and 77  (as w as done in the previous 
                     section).  L et  as  assum e  th a t  each  value  of b o th   £  an d   77  h as  non-zero  p ro b ab ility  
                     ( z e r o - p r o b a b ility   o u tc o m e s   c o u ld   b e   ig n o re d ).    For  each  value  rjj  (for  77)  consider 
                     t h e   e v e n t  77  =   777.  ( I t s   p r o b a b ility   w a s  d e n o te d   b y   p*j.)  C o n s id e r  th e   c o n d itio n a l 
                     e n tro p y   o f  v a ria b le   £  h a v in g   th is   e v e n t  a s  th e   c o n d itio n .  In   o th e r   w o rd s,  c o n s id e r 
                     t h e   e n tr o p y   o f  th e   d is tr ib u tio n   i          Pij/p*j■         T h e n   w e  av erag e  th e se   e n tro p ies, 
                     using  probabilities  of th e  events  77 =   rjj  as  w eights.  T h e  resu ltin g   average  is  called 
                     conditional entropy of £ with condition 77.  It is denoted by H(£\ij). So by definition
                                                              Щ£\г}) = E  Prfo = ГЬ]Н(Л\П = Vj) 
                                                                                 3
                     or,  u sin g   th e   n o ta tio n   a b o v e ,
                                                                                                             log^
                                                                               j           г            '          p*j
