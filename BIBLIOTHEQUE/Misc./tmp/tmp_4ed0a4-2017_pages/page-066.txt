                          2.3.  COMPLEXITY  AS THE AMOUNT OF INFORMATION            51
                   Figure  7.  Two  independent  incompressible  strings  of length  n 
                   and their XOR
               Note that even if a5 is negative, the sums 05+ 02, 05 + 04 and a5 + üq, being 
           mutual information expressions for pairs, are 11011-negative.  (In our examples these 
           sums are equal to 0.)
               This example corresponds to the simple case of secret sharing of secret 2 be­
           tween two people:  if one of them knows x and the other one knows y, then neither of 
           them has any information about 2 in isolation (since I(x:z) ~ 0 and I{y:z) « 0)), 
           but together they can reconstruct 2 as a bitwise sum of x and y.
               One can check that we have already given a full list  of inequalities that  are 
           true for complexities of three strings and their combinations (all a,;, except for 05, 
           are non-negative,  as well as the three sums mentioned above).  We return to this 
           question in Chapter 10.
               Our diagram is a good mnemonic tool.  For example,  consider again the in­
           equality
                               C{x, y, z) ^ C(x, y) + C(x, 2) + C(y, 2).
           In our new variables it can be rewritten as 02 + 04 + 05 + ae  ^ 0 (you can easily 
           check it by counting the multiplicity of each a* in both sides of the inequality).  It 
           remains to note that 02 + 05  ^  0,  04  ^  0,  and  ae  ^  0.  (Alas,  the symmetry is 
           broken again!)
                63 Prove that I(xy.z) = I(x:z) + I(y:z\x) + 0(\ogn) for strings æ,y, 2 of 
           complexity at most n.
               (Hint:  Use the diagram.)
               This problem shows that information in xy about 2 can somehow be split into 
           two  parts:  information  in  x  about  2  and  information  in  y  about  2  (when  x  is 
           known).  This is somehow similar to the equality C(x, y) = C(x) + C(y \ x), but now 
           complexity is replaced by the quantity of information about 2.  As a corollary we 
           immediately get that if xy is independent with 2, then x is independent with 2 and, 
           at the same time, y is independent with 2 when x is known.  (Here independence 
           means that mutual information is negligible.)  A symmetric argument shows that y 
           is independent with 2 and x is independent with 2 when y is known.
                64  Show that properties  “x  is independent with y”  and  ux  is independent 
           with y when 2 is known”  are quite different:  each of them can be true when the 
           other is false.
                65  We say that strings x, y, 2, t form a Markov chain (a well-known notion in 
           probability theory now transferred to algorithmic information theory) if I(x : 21 y) 
           and I((x,y) :t\z) are negligible.  (Of course, we need to specify what is “negligible” 
           to get a formal definition.)  Show that the reversed sequence of strings also forms a 
           Markov chain, i.e., that I(t:y\z) and I((t,z) :x\y) are negligible.
