        472        2.  FOUR  ALGORITHMIC  FACES  OF  RANDOMNESS
        in  the  first  language  into  an  equivalent  text  in  the  second  language.  We  then 
        can conclude that  description  language  corresponding to  the second  language  is 
        not worse than that corresponding to the first language.  For example, a Turkish- 
        language description of an object may consist of two parts:  a Japanese-language 
        description and a Japanese-Turkish translation algorithm.  In this way we get a 
        Turkish description that is longer than a Japanese description at most by a constant 
        (the length of the Japanese-Turkish translation algorithm).  This constant does not 
        depend on the choice of the object described.  Taking the shortest possible Japanese 
        description, we conclude that the Turkish language is not worse than the Japanese 
        language if we consider both as description languages.
          Let us call a language family any family of description languages.  Having some 
        language family C,  we may ask whether there exists an optimal language in this 
        family.  A language A from L is  optimal  (for C)  if it is not worse than any other 
        description language in the family, i.e., if
                            (VR e C) (A < B).
          An optimal description language,  if it exists for some family,  should be used 
        to  measure complexity.  The complexity of an object with respect  to some fixed 
        optimal  description  language  can  be  called  algorithmic  entropy  of this  object.10 
        Entropy  is  the  final  version  of the  measure  of complexity  (when some family of 
        description languages is fixed).
          For some language families one can prove the existence of an optimal description 
        language.  For those families the notion of entropy is well defined.  The statements 
        of this type are usually called Solomonoff-Kolmogorov theorems,  since they were 
        first to discover such statements.
          A given family may contain (and usually contains)  many optimal description 
        languages.  Each of them gives some entropy function.  However,  due to the op­
        timality definition, every two entropies (corresponding to two optimal description 
        languages for some family) differ by at most an additive constant.  In other words, 
        if A and В are two optimal description languages in the family C, then there exists 
        a constant c such that
                         I Comply) -  Compß(y) I < c
        for all y.
          Remark.  Of course, one can rightfully complain that the notion of entropy 
        that pretends to be a complexity measure for individual objects is still defined only 
        up to some bounded additive term, and one would like to select some true entropy 
        function among different ones.  However, attempts of this type have not succeeded 
        up to now.
          We use the letter К to denote algorithmic entropy  (as a tribute to  Kolmo­
        gorov)11  and  sometimes  add  another  letter  to  specify  the  family  of description 
        languages used.  If K'  and K"  are two entropy functions for the same family of 
        description languages, then
                             I К' -  К" I  < c
        (as we have noted).
          10In the main part of the book we keep the name complexity for this notion, and we use the 
        word entropy for Shannon entropy only.
          11 In the main part of the book the letter К  is used for prefix version of complexity (entropy).
