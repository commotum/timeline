                       5.9.  RANDOMNESS  WITH  RESPECT TO  DIFFERENT  MEASURES         183
                Proof.  Consider the preimage Fu — f~ 1(T,u) of Eu.  This is an effectively open 
            subset of E.  By definition, the //-measure of the set Fu  (recall that the measure // 
            is concentrated on infinite sequences) equals i/(Eu).  If the deficiency dv{u) is small, 
            i/(Eu) cannot be significantly less than the continuous a priori probability of Eu.
                Now consider the continuous a priori probability of the set Fu, i.e., the proba­
            bility of the event  “the output of an universal probabilistic machine M belongs to 
            Fu".  This event can be rephrased as follows:  the output of the machine foM  (that 
            applies /  to the output of M ) starts with u.  Comparing the machine /  о M and 
            the universal one, we conclude that the (continuous) a priori probability of the set 
            Fu can be only a constant times bigger than the (continuous) a priori probability 
            of Eu.  The latter is 2dv^  times bigger than vÇEu) that is equal to the //-measure 
            of the set Fu.  Therefore we get an inequality between two measures of Fu  (the a 
            priori probability a and //):
                                          a(Fu) < 0 (2d"(u)).
                                          KFu)
            Since the set  Fu  can be represented as the union of a (possibly non-enumerable) 
            family of disjoint intervals, we conclude that the similar inequality is true for some 
            interval T,w in this family:
                                               < ^Ли) -0{l).
            Since T,w  C  Fu, we conclude that f(w)  >  u, and the preceding inequality implies 
            that dß(w) < dv{u) + 0(1).  Lemma 2 is proven.
               Now we continue the proof of statement  (b).  Let tn  —  (r)n  be the prefix of 
            a i/-random sequence т that has length n.  The randomness criterion guarantees 
            that  ^-deficiencies  of ti  are  bounded.  Then  the  lemma says  that  there  exists  a 
            sequence of strings wq,w\, ... that have bounded //-deficiencies such that f(wi) is 
            an extension  of t{.  If we  knew  that  all Wi  are  compatible,  this  would  give  us  a 
            desired result  (a random preimage of t).  However,  there is no reason to expect 
            this.
               Nevertheless, a standard compactness argument shows that the sequence Wi has 
            a subsequence that either consists of identical strings or converges to some infinite 
            sequence oj.  The latter means that  any  (finite)  prefix of a;  is  a prefix of all  but 
            finitely many strings in the sequence.
               In the first case the sequence т is the image of the finite string w that appears 
            infinitely often in the sequence Wi.  This can happen for a i/-random sequence r if 
            this sequence (the corresponding singleton) has a positive measure; т is computable 
            in this case.  Then we let oj be any //-random continuation of the string w (we know 
            that it exists, since the //-deficiency of w is finite and ß(ftw) > 0).
               In the second case an infinite subsequence of the sequence W{  converges to oj. 
            To  prepare  ourselves  for  this  case,  let  us  make  a digression  and  prove  that  the 
            randomness deficiency is almost monotone.
               Recall the randomness criterion (Theorems 91 and 93).  It guarantees that for 
            ML-random sequences the deficiency of their prefixes is bounded while for non- 
            random sequences the deficiencies tend to infinity.  This implies that the interme­
            diate situation  is not  possible:  There is no sequence such that  deficiencies of its 
            prefixes are not bounded but do not tend to infinity.  This looks rather strange, and 
            one may ask why this happens.  The following theorem provides some explanation.
