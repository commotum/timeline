                                     INTRODUCTION.  WHAT IS THIS BOOK  ABOUT?
              6
                   This theorem implies that the amount of information “does not depend on the 
              specific  encoding”.  For  instance,  if we  reverse  all  bits  of some  string  (replace  0 
              by 1  and vice versa), or add a zero bit after each bit of that string,  the resulting 
              string has the same Kolmogorov complexity as the original one (up to an additive 
              constant).  Indeed, the transformation itself and its inverse can be performed by an 
              algorithm.
                   Here is one more example of a natural property of Kolmogorov complexity.  Let 
              X and y be strings.  How much information does their concatenation xy have?  We 
              expect that the quantity of information in xy does not exceed the sum of those in x 
              and y.  This is indeed true; however, a small additive term is needed.
                   Theorem 4.  There is a constant c such that for all x  and y 
                                        C{xy) < C(x) + 2 log C(x) + C{y) + c.
                   Proof.  Let us try first  to  prove  the statement  in  a stronger  form,  without 
              the term 2 log C(x).  Let  D be the optimal description mode that is used in the 
              definition  of Kolmogorov complexity.  Define  the following description mode  D'. 
              If D{jp)  = x and D(q) — y, we consider pq as a description of xy,  that is,  we let 
              D'(pq)  = xy.  Then the complexity of xy with respect to D' does not exceed the 
              length of pq,  that  is,  l{p) + l{q).  If p  and  q  are minimal descriptions,  we obtain 
              Co'(з^у) ^ CD{x) + Co{y)-  By optimality the same inequality holds for D in place 
              of D', up to an additive constant.
                   What is wrong with this argument?  The problem is that D' is not well defined. 
              We let D'ijpq) = D(p)D(q).  However, D' has no means to separate p from q.  It may 
              happen that there are two ways to split the input into p and q yielding different 
              results:
                                   V\4i=V242  but  D{pi)D{qi) ф D(p2)D(q2).
                   There are two ways to fix this bug.  The first  one,  which we use  now,  goes 
              as follows.  Let us prepend the string pq by the length l(p) of string p  (in binary 
              notation).  This allows us to separate p and q.  However,  we need to find where 
              l(p) ends, so let us double all the bits in the binary representation of l(p) and then 
              put 01 as separator.  More specifically, let bin(fc) denote the binary representation 
              of integer  k,  and  let  x  be  the  result  of doubling  each  bit  in  x.    (For  example, 
              bin(5) = 101, and bin(5) = 110011.)  Let
                                            D'{ bin(/(p)) Olpq) = D{p)D(q).
              Thus D' is well defined:  the algorithm D' scans bin(/(p)) while all the digits are 
              doubled.  Once it sees 01,  it determines l(p), and then scans l(p) digits to find p. 
              The rest of the input is q, and the algorithm is able to compute D(p)D(q).
                   Now we see that Со'(ху) is at most 2/(bin(/(p))) + 2 + l(j>) + l{q).  The length 
              of the binary representation of l(p)  is at most log2/(p) + 1.  Therefore,  xy has a 
              description of length at most 2 log2 l(p) + 4 + l{jp) + l(q) with respect to D', which 
              implies the statement of the theorem.                                                         □
                   The second way to  fix  the bug mentioned  above goes  as  follows.  We could 
              modify the definition of Kolmogorov complexity by requiring descriptions  to  be 
              self-delimiting; we discuss this approach in detail in Chapter 4.
