        370      12.  MULTISOURCE ALGORITHMIC INFORMATION THEORY
          Theorem 229.  Let A and В be arbitrary strings of complexity at most n.  Then 
        there exists a string X  of length at most C(A\B) + O(logn)  such that C(X\ A) = 
        O(logn)  and C(A\B,X) = O(logn).
          The hidden constant in O(logn) does not depend on n, A, B.
          This statement can be reformulated:  For every A and В there exists a program 
        that transforms В to A, has logarithmic complexity given A, and has unconditional 
        complexity C(A | B) (up to logarithmic precision).  In other words, the additional re­
        striction saying that the program should be simple relative to A, increases the min­
        imal possible (unconditional) complexity of the program only by 0(logC(A, B)).
          P r o o f.  Assume that the string A has complexity a.  Replace A by its (shortest) 
        description of length a.  This replacement changes the values of C(A \ В), C(X | A), 
        and C(A\B,X) only by O(logn).  So we may assume without loss of generality 
        that A has length a.  (Complexity of A remains close to a, but this does not matter 
        for us.)
          Assume that the conditional complexity C(A\B) equals m.  The idea of the 
        proof can be explained as follows.  Consider some hash function x '■ ®a ~that 
        computes an m-bit hash value (fingerprint) for every а-bit string.
          For a given string В we have about 2m strings Z of length a such that C(Z \ В) ^
        m.  Let Sß  C Ba be the set of these strings.  According to our assumption, A is one 
        of the elements of Sß.
          Imagine that we are extremely lucky, and all the strings in Sß  have different 
        hash values.  Then every string P £ Sß can be uniquely reconstructed if we know 
        x(P)  and В  (the function x 1S assumed to be fixed).  So we can use x{A)  as X 
        in the statement of the theorem.  It has correct length, is simple relative to A (we 
        assume that x 1S simple),  and,  together with B,  allows us to reconstruct  A—we 
        have to enumerate Sß until we find a string with the correct hash value.
          Of course this is too good to be true.  For every hash function x,  if a > m, 
        there are at least 2a~m strings that have the same hash value (and for simple x we 
        can find many simple strings with the same hash values, and they will be in Sß for 
        every В), so we cannot hope to be so lucky.
          We need to modify our plan and consider for every Z £ Ma several (poly(n)) 
        hash values instead of one.  Instead of a hash function, we consider now a bipartite 
        graph £cBax Bm where each left vertex Z has at most poly(n) right neighbors. 
        These neighbors are called fingerprints of Z.
          Proving the theorem, we look for X among the fingerprints of A.  This guar­
        antees that  C(X\A) —  O(logn),  assuming that graph E is simple  (has O(logn) 
        complexity).  Indeed,  to specify X when A is known,  it  is enough to specify the 
        ordinal number of X among the fingerprints of A.
          If, for a given A £ Sß, one of its fingerprints X determines A inside Sß uniquely 
        (no other strings in Sß have X among their fingerprints), then we can reconstruct 
        A by enumerating Sß and waiting for a string that has X among its fingerprints. 
        In  this  case  C(A\B,X)  =  O(logn);  we  assume  here that  E  is simple,  i.e.,  has 
        complexity O(logn).
          Moreover,  the same complexity bound holds if there are polynomially many 
        (in  n)  strings  in  Sß  that  have  X  among their  fingerprints.  We  need to specify 
        additionally  the  ordinal  number  of A  among  these  strings  (in  the  order  of the 
        enumeration of Sß), and this requires additionally 0 (logn)-bits.
