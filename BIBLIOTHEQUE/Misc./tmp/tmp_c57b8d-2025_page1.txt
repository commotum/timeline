                           MathClean:ABenchmarkforSyntheticMathematicalData
                                                                                                Cleaning
                                                           †                                                           †                                                       †
                                         HaoLiang                                                 Meiyi Qiang                                                 Yuying Li
                                      Peking University                                Beijing Institute of Technology                           Beijing Institute of Technology
                                         Beijing, China                                            Beijing, China                                            Beijing, China
                                hao.liang@stu.pku.edu.cn                                    1120213065@bit.edu.cn                                        liyuying@bit.edu.cn
                                          Zefeng He                                             YongzhenGuo                                              ZhengzhouZhu
                                     Nanjing University                                              AntGroup                                             Peking University
                                        Nanjing, China                                             Beijing, China                                            Beijing, China
                              221250021@smail.nju.edu.cn                               yongzhen.gyz@antgroup.com                                          zhuzz@pku.edu.cn
                                                                                            ∗                                                   ∗
                                                                  WentaoZhang                                                      Bin Cui
                                                                   Peking University                                         Peking University
                                                                      Beijing, China                                            Beijing, China
                                                            wentao.zhang@pku.edu.cn                                         bin.cui@pku.edu.cn
                    Abstract                                                                                     ACMReferenceFormat:
                   With the rapid development of large language models (LLMs),                                   HaoLiang†,MeiyiQiang†,YuyingLi†,ZefengHe,YongzhenGuo,Zhengzhou
                                                                                                                                        ∗              ∗
                    the quality of training data has become crucial. Among the vari-                             Zhu,WentaoZhang ,andBinCui .2025.MathClean:ABenchmarkforSyn-
                    ous types of training data, mathematical data plays a key role in                            thetic Mathematical Data Cleaning. In . ACM, New York, NY, USA, 13 pages.
                    enabling LLMs to acquire strong reasoning abilities. While high-                             https://doi.org/10.1145/nnnnnnn.nnnnnnn
                    quality open-source data is important, it is often insufÏcient for                           1 Introduction
                    pre-training, necessitating the addition of synthetic math prob-                             LLMshavedemonstratedexceptional performance across a wide
                    lems. However, synthetic math questions and answers can intro-                               range of tasks in various domains [20, 29]. It has been established
                    duce inaccuracies, which may degrade both the training data and                              that data plays a crucial role in the success of LLMs [1, 3, 34].
                   web data. Therefore, an effective method for cleaning synthetic                               Recently, several studies have focused on data cleaning to improve
                    math data is essential. In this paper, we propose the MathClean                              LLMtraining [5, 8, 15, 33] and achieved success in training LLMs.
                    benchmark to evaluate the effectiveness of math data cleaning                                    AmongthevarioustypesofdataforLLMs,mathematicaldatais
                    models. The MathClean benchmark consists of 2,000 correct ques-                              one of the most crucial, as it enhances a model’s reasoning capa-
                    tions and 2,000 erroneous questions with additional 2,000 correct                            bilities [14, 34]. However, collecting large amount of mathematical
                    and erroneous answers sourced from augmented data based on                                   data presents several challenges: (1) High-quality MathQA data is
                    GSM8KandMATH.Moreover, we also annotate error types for                                      scarce and often requires data generation [28, 42]. (2) Ensuring the
                    each question or answer, since it can assess whether models can                              correctness of synthetic mathematical data is challenging [28]. (3)
                    correctly identify the error categories for future improvements. Fi-                         Evaluating the correctness of mathematical data remains a com-
                    nally, we present comprehensive evaluations using state-of-the-art                           plex task [25, 41, 43]. To address these challenges, several studies
                   (SOTA)models. Our results demonstrate that even strong models                                 have proposed output reward models (ORMs) [39] and process
                    like GPT-o1 and DeepSeek-R1 perform poorly on this benchmark,                                reward models (PRMs) [19, 25, 30] to assess the correctness of syn-
                    highlightingtheutilityofMathClean.Ourcodeanddataisavailable                                  thetic answers. To evaluate the effectiveness of these ORMs and
            arXiv:2502.19058v1  [cs.CL]  26 Feb 2025at https://github.com/YuYingLi0/MathClean.                   PRMs, researchers in our community have developed ORM and
                                                                                                                 PRMbenchmarks [25, 41, 43]. These benchmarks primarily aim
                    Keywords                                                                                     to enhance PRM performance, thereby improving mathematical
                    Mathematical Data, Synthetic Data Cleaning Benchmark                                         reasoning capabilities. Rather than focusing on inference, our work
                                                                                                                 prioritizes mathematical training data cleaning. We establish the
                                                                                                                 following two tasks as our key objectives for improvement:
                    Permission to make digital or hard copies of all or part of this work for personal or            Correctness of Questions and Answers. Recent advance-
                    classroom use is granted without fee provided that copies are not made or distributed        ments in synthetic mathematical training data have been signifi-
                    for profit or commercial advantage and that copies bear this notice and the full citation    cant [28, 42]. OpenMathInstruct1 and 2 [28] have generated over
                    onthefirst page. Copyrights for components of this work owned by others than the             14 million QA pairs based on GSM8K and MATH. However, it is
                    author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
                    republish,topostonserversortoredistributetolists,requirespriorspecificpermission             reported that approximately 50% of the generated QA pairs are in-
                    and/or a fee. Request permissions from permissions@acm.org.                                  correct. Moreover, OpenMathInstruct1 and 2 [28], Given the large
                    Conference’17, July 2017, Washington, DC, USA
                   ©2025Copyrightheldbytheowner/author(s). Publication rights licensed to ACM.                   0
                   ACMISBN978-x-xxxx-xxxx-x/YY/MM                                                                0†: Equal Contribution.
                    https://doi.org/10.1145/nnnnnnn.nnnnnnn                                                       ∗: Corresponding Authors
