                                                                                                                   e          Grid Feature Encoder                           Sensor-Time Attention
                                                                                                                   r
                                                                                                                   u
                                                                                                   ‚Ä¶               t                Camera Feature Fetching                         Sparse Window Partition
                                                                                                                   a
                                                                                                                   e                                                                                                                      d        x
                                                                                                                                    Pillar Feature Extraction                        4DPositionalEncoding                                          o
                                                                                                                   DAR F                                                                                                                  ea       B
                                                                                                                   i                  Point-wise Attention                              Pyramid Context                                            n 
                                                                                                                   L
                                                                                  Ì†µÌ∞ø
                                          Ì†µÌ∞ø
                                                                                    Ì†µÌ±°
                                            Ì†µÌ±°      LiDAR Sequence
                                                                                     2
                                            1                                                                                                                                                                                     PN      n H      io
                                                                                                                   e                                                            n                                                 R       io       ect
                                                                                                                   r                                                            o                                                         ect
                                                                                                                   u                                                            i
                                                                                                                   t                                                            ct  f                    n     )
                                                                                                                                                                                                               Ì†µÌ≤á
                                                                                                                   ea             s   Ì†µÌ±á                                            √ó                    o     √ó
                                                                                                                                  d                                                 )                    ti                               Det
                                                                                                                                  i                                             era Ì†µÌøê
                                                                                                   ‚Ä¶                F                                                           t   √ó                    n     Ì†µÌøê                                  D Det
                                                                                                                                                                                                               √ó
                                                                                                                                   Gr                                            In T                                                              3
                                                                                                                                                                                    √ó                    tte   ( T
                                                                                                                   era                                   Ì†µÌ∞ª                                                    √ó
                                                                                                                                  V                                             se  Â†µÌ≤ò                   A     )
                                                                                                                                                                                i
                                                                                                                                                                                                               Â†µÌ≤ò
                                                                                                                                                                                    Â†µÌ±æ
                                                                                                                                  E         Â†µÌ±§                                                           -
                                                                                                                                           Ì†µÌ∞ª
                                                                                                                   m                       Ì†µÌ∞ª
                                                                                                                                            Â†µÌ±§
                                                                                                                                                                                    √ó                    f     Â†µÌ±æ
                                                                                                                                                            Ì†µÌ±ì                  w
                                                                                                                   a              B                          Â†µÌ∞∂                                   ‚Ä¶            √ó
                                                                                                                                                         W                      -   Â†µÌ≤ò                   el
                                                                                                                                                                                                               Â†µÌ≤ò
                                                                                                                                                                                    Ì†µÌ±Ø
                                                                                                                   C                    Â†µÌ±§                                      d   (
                                                                                                                                       Â†µÌ±ä
                                                                                                                                                                                i                        S     Ì†µÌ±Ø
                                                                                                                                                  Ì†µÌ∞ª                                         ‚Ä¶                 (
                                                                                                                                                     Ì†µÌ±ì                         Gr
                                                                                                                                                 W    Ì†µÌ∞ø
                                          Â†µÌ∞º
                                           Ì†µÌ±°
                                                    Camera Sequence               Â†µÌ∞º
                                            1
                                                                                   Ì†µÌ±°
                                                                                    2
                       Figure2. ArchitectureofLiDARImageFusionTransformer(LIFT).LIFTtakesbothsequentialLiDARpointcloudsandsequentialcamera
                       images as input, which are processed into BEV grids by Grid Feature Encoder and fused with Sensor-Time 4D Attention.
                       Cross-Sensor Fusion. Cross-sensor fusion between cam-                                                                 images as input and aims at exploiting their mutual inter-
                       eras and LiDAR has shown great advantages for 3D object                                                               actions. Figure 2 illustrates the overall architecture of our
                       detection. Some approaches perform fusion based on 2D                                                                 proposed method, which consists of two main components:
                       detectionresults [22]orobjectregionproposals[3,11]. An-                                                               (1) Grid Feature Encoder (Section 3.1) to process the input
                       other line of attempts [14,15,44] fuse cross-modal features                                                           sequential cross-sensor data into grid features. (2) Sensor-
                       at the BEV space [15,44]. From a different perspective,                                                               Time4DAttention(Section3.2)tolearnthe4Dsensor-time
                       other methods [9,27,31,47] perform fusion at point level.                                                             interaction relations given the grid-wise BEV representa-
                       For example, PointPainting [31] and PointAugmenting [32]                                                              tions. Furthermore, we equip our LIFT with sensor-time
                       respectively fetch segmentation scores and image features                                                             data augmentation (Section 3.3).
                       for each LiDAR points by project points into camera im-                                                               3.1. Grid Feature Encoder
                       ages. Despite the demonstrated success, those projection-
                       based approaches are easily affected by projection errors,                                                                 Compared to a typical point cloud detectors, which
                       resulting in ambiguous fusion with misaligned information.                                                            learns to classify and localize objects based on single-frame
                       In this work, we build a Transformer-based architecture to                                                            LiDARpointcloud,LIFTtakesbothsequentialpointclouds
                       rethink the cross-modal information interaction problem in                                                            and camera images as input. Specifically, the point clouds
                       the time stream.                                                                                                      can be presented as a sequence of frames L = {L }T ,
                                                                                                                                                                                                                                            ti   i=1
                       Transformer. Transformers were first proposed for the                                                                 where L = {l ,...,l                             } consists of N                  LiDAR points
                                                                                                                                                             t            1            NL                                 L
                       sequence-to-sequence machine translation task [30]. The                                                               l     ‚àà Rd scattered over the 3D coordinate space.                                                   Be-
                                                                                                                                              i
                       core mechanism of Transformers, self-attention, makes                                                                 sides, camera images are presented in time stream I =
                                                                                                                                                      T                     U√óV√ó3√óNC
                       it particularly suitable for modeling sequential relation-                                                            {I }           , I     ‚àà R                            , where U and V denotes the
                                                                                                                                                 t              t
                                                                                                                                                  i   i=1
                       ship [5, 10, 13, 19]. The self-attention operation also pro-                                                          original image size, and N                            is the number of images per
                                                                                                                                                                                               C
                       vides a natural potential for cross-modal information fu-                                                             scan. For sequential data processing, we use the prior of
                       sion. Examples include fusing audio and visual signals for                                                            vehicle pose to remove the effects of ego-motion between
                       audio enhancement [29], speech recognition [7] and video                                                              different point clouds, then we process each frame follow-
                       retrieval [4]. In the context of autonomous driving, several                                                          ing the feature generation pipeline as shown in Figure 3.
                       works apply the attention mechanism to fuse global cross-                                                             Camera Feature Fetching.                                  For perspective alignment
                       modal signals for motion forecasting and planning [21,33].                                                            between modalities, we first align the representations for
                       In this work, we apply the self-attention in sparse 4D win-                                                           cross-sensor data input.                        Specifically, for the camera in-
                       dows, considering both the spatiotemporal and cross-sensor                                                            put, we use the off-the-shelf 2D object detector [45] to ex-
                       interaction at the same time.                                                                                         tract image features. Then we project point clouds onto
                       3. LiDARImageFusionTransformer                                                                                        the image plane by a prior homogeneous transformation
                                                                                                                                             G‚ààR4√ó4forfetchingthecorresponding point-wise image
                             In this work, we present LiDAR Image Fusion Trans-                                                              features. There are two benefits. First, the point-level rep-
                       former (LIFT), an end-to-end single-stage 3D object detec-                                                            resentation aligns images and points in the same 3D coor-
                       tion approach, which takes both sequential point clouds and                                                           dinate, enabling fine-grained interaction across sensor fea-
                                                                                                                                      17174
