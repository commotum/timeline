                                                                                                               Average
                                                      Participants   Participants     Genders     Mean       WordCount
                                   Model               Recruited      Excluded      (m:f:other)    Age     (human:model)
                                   Control                 76             7           32:37:0       39         216:216
                                   GPT-3Small              80             7           41:31:1       40         216:188
                                   GPT-3Medium             80             7           46:28:2       39         216:202
                                   GPT-3Large              81             24          46:28:2       37         216:200
                                   GPT-3XL                 79             14          32:32:1       38         216:199
                                   GPT-32.7B               80             11          36:33:0       40         216:202
                                   GPT-36.7B               76             5           46:28:2       37         216:195
                                   GPT-313.0B              81             13          46:28:2       37         216:209
                                   GPT-3175B               80             9           42:29:0       37         216:216
                   TableE.1: Participant details and article lengths for each experiment to evaluate human detection of ∼ 200 word model
                   generated news articles. Participants were excluded due to internet check fails.
                   Figure E.1: Participants spend more time trying to identify whether each news article is machine generated as model
                   size increases. Duration on the control model is indicated with the dashed line. Line of best ﬁt is a linear model on a log
                   scale with 95% conﬁdence intervals.
                   In each experiment, half of the participants were randomly assigned to quiz A and half were randomly assigned to quiz
                   B. Each quiz consisted of 25 articles: half (12-13) were human written and half (12-13) were model generated: the
                   articles with human written completions in quiz A had model generated completions in quiz B and vice versa. The
                   order of quiz question was shufﬂed for each participant. Participants could leave comments and were asked to indicate
                   if they had seen the articles before. Participants were instructed not to look up the articles or their content during the
                   quiz and at the end of the quiz were asked if they had looked anything up during the quiz.
                   Statistical Tests: To compare means on the different runs, we performed a two-sample t-test for independent groups for
                   each model against the control. This was implemented in Python using the scipy.stats.ttest_ind function. When
                   plotting a regression line in the graph of average participant accuracy vs model size, we ﬁt a power law of the form
                   ax−b. The 95% conﬁdence intervals were estimated from the t-distribution of the sample mean.
                   Duration statistics: In the main text, we discussed the ﬁnding that the ability of human participants to distinguish
                   model and human generated news articles decreases as our models become larger. We have also found that the
                   average time spent for a given set of questions increases as the model size increases, as shown in Figure E.1. Lower
                                                                              47
