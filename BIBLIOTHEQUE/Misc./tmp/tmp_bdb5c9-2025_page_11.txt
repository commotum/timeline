           Preprint.
           ZexueHe,LeonidKarlinsky, Donghyun Kim, Julian McAuley, Dmitry Krotov, and Rogerio Feris.
            Camelot: Towards large language models with training-free consolidated associative memory,
            2024b. URLhttps://arxiv.org/abs/2402.13449.
           MengkangHu,TianxingChen,QiguangChen,YaoMu,WenqiShao,andPingLuo. Hiagent: Hier-
            archical working memory management for solving long-horizon agent tasks with large language
            model. arXiv preprint arXiv:2408.09559, 2024.
           Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song,
            and Denny Zhou. Large language models cannot self-correct reasoning yet, 2024. URL https:
            //arxiv.org/abs/2310.01798.
           Ryo Kamoi, Yusen Zhang, Nan Zhang, Jiawei Han, and Rui Zhang. When can llms actually
            correct their own mistakes? a critical survey of self-correction of llms, 2024. URL https:
            //arxiv.org/abs/2406.01297.
           Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,
            Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe
            Kiela. Retrieval-augmented generation for knowledge-intensive nlp tasks, 2021. URL https:
            //arxiv.org/abs/2005.11401.
           Wen-DingLi,KeyaHu,CarterLarsen,YuqingWu,SimonAlford,CalebWoo,SpencerM.Dunn,
            HaoTang, Michelangelo Naim, Dat Nguyen, Wei-Long Zheng, Zenna Tavares, Yewen Pu, and
            Kevin Ellis. Combining induction and transduction for abstract reasoning, 2024. URL https:
            //arxiv.org/abs/2411.02272.
           Lei Liu, Xiaoyan Yang, Yue Shen, Binbin Hu, Zhiqiang Zhang, Jinjie Gu, and Guannan Zhang.
            Think-in-memory: Recalling and post-thinking enable llms with long-term memory, 2023. URL
            https://arxiv.org/abs/2311.08719.
           Yitao Liu, Chenglei Si, Karthik Narasimhan, and Shunyu Yao. Contextual experience replay for
            self-improvement of language agents. arXiv preprint arXiv:2506.06698, 2025.
           AmanMadaan,NiketTandon,PrakharGupta,SkylerHallinan,LuyuGao,SarahWiegreffe,UriAlon,
            NouhaDziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder,
            Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark. Self-refine: Iterative
            refinement with self-feedback, 2023. URL https://arxiv.org/abs/2303.17651.
           Ali Modarressi, Abdullatif Köksal, Ayyoob Imani, Mohsen Fayyaz, and Hinrich Schütze. Memllm:
            Finetuning llms to use an explicit read-write memory. arXiv preprint arXiv:2404.11672, 2024.
           Charles Packer, Sarah Wooders, Kevin Lin, Vivian Fang, Shishir G. Patil, Ion Stoica, and Joseph E.
            Gonzalez. Memgpt: Towards llms as operating systems, 2024. URL https://arxiv.org/
            abs/2310.08560.
           Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and
            Michael S. Bernstein. Generative agents: Interactive simulacra of human behavior, 2023. URL
            https://arxiv.org/abs/2304.03442.
           Julien Pourcel, Cédric Colas, and Pierre-Yves Oudeyer. Self-improving language models for evolu-
            tionary program synthesis: A case study on arc-agi, 2025. URL https://arxiv.org/abs/
            2507.14172.
           Linlu Qiu, Liwei Jiang, Ximing Lu, Melanie Sclar, Valentina Pyatkin, Chandra Bhagavatula, Bailin
            Wang,YoonKim,YejinChoi,NouhaDziri,andXiangRen. Phenomenalyetpuzzling: Testing
            inductive reasoning capabilities of language models with hypothesis refinement, 2024. URL
            https://arxiv.org/abs/2310.08559.
           Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik Narasimhan, and
            Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning, 2023. URL
            https://arxiv.org/abs/2303.11366.
                               11
