214 = Unified Theories of Cognition

task, one symbolic execution and two test-case executions. Soar
follows the same path repeatedly—retrieve, generate, test—be-
cause it has learned search control for doing this, not because it has
a data structure that it follows. This was true even of the plan it
developed originally, which is remembered as what steps to prefer
under what conditions, not as a declarative plan.

Soar (de 331 to de 335) repeats the behavior of (de 301 to de 305),
retrieving the input and generating an element. By now it has
looked at all members of the input set (both of them), hence can
return the result (de 336 to de 337). This completes the computa-
tion, but Soar was doing this computation to obtain an algorithm,
The criterion for the latter is that all the potential places in the
existing algorithm where branches could occur have been inves-
tigated. It knows to do this (dc 343), proceeds to do so {de 349 and
de 351), and concludes that there is nothing more to be covered (de
354). Thus, it concludes that the algorithm has been designed (de
358). In fact, this is not a proof of the correctness of the algorithm,
for in general one cannot verify an algorithm by examining a finite
set of specific cases. :

As we have said, Soar leams on whatever it does. So we should
expect some learning as it attempts to design algorithms. Figure
4-21 gives a summary picture of two pairs of algorithms: a pair of
simple ones, find the subset of positive elements of a set (the latter
being the one used for illustration) and find the intersection of two
sets, and a pair that is slightly more complex, merge sort and inser-
tion sort. In each case, one member of the pair was done and then
the other. For each pair, the upper line is the behavior (total deci-
sion cycles) without learning, and the two lower lines show the
behavior with learning.

Consider first the tower learning line (all goals). Both pairs tell
the same story. There is within-trial learning from the beginning of
each task to the end of it. There is also between-trial learning from
the first member of the pair to the second. This can be seen most
easily in the right-hand graph showing the sort routines. If there
was no transfer from doing the insertion sort to the merge sort,
there would be only the within-trial transfer for the merge sort. This
should produce a curve that was just barely steeper than the learn-
ing curve for insertion sort, corresponding to the fact that the no-
learning curve is barely steeper. Instead, the learning curve for
merge-sort is actually flatter, showing the effect of the between-trial
