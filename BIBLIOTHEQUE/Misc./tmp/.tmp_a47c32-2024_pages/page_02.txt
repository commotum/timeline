                                                                                                                                                                                       Fixed Point Diffusion Model (FPDM)
                     recently, a vision transformer architecture [13, 50]. However,                                                       Diffusion Transformer (DiT)
                     as diffusion models are increasingly deployed in production,                                                        .
                                                                                                                                                         …
                     especially on mobile and edge devices, their large size and                                                                                                                      f
                                                                                                                                                                               Noise
                                                                                                                                                                                                       ﬁxed- 
                                                                                                                                 Noise
                                                                                                                                                                                           f                      f
                                                                                                                                                                                                       point
                                                                                                                                                                                            pre                    post
                                                                                                                                            f      f            f
                                                                                                                                                                                 x
                                                                                                                                             1      2            L
                                                                                                                                                                                                      ..
                                                                                                                                   x
                                                                                                                                                                                  T
                     computational costs pose significant challenges.                                                               T
                                                                                                                                                         …
                                                                                                                                                                                                       × N
                          This paper introduces the Fixed Point Diffusion Model                                                                                 t = T .                                           t = T .
                     (FPDM), which integrates an implicit fixed point solving
                     layer into the denoising network of a diffusion model. In                                                                           …
                                                                                                                                                                                                                          ...
                                                                                                                                                                                                      f
                                                                                                                                                                                                       ﬁxed- 
                                                                                                                                                                                           f                      f
                                                                                                                                                                        ...
                                                                                                                                                                                                       point
                                                                                                                                                                                            pre                    post
                                                                                                                                            f      f            f
                                                                                                                                             1      2            L
                     contrast to traditional networks with a fixed number of layers,                                                                                                                  ..
                                                                                                                                                         …
                                                                                                                                                                                                                             Sample x
                                                                                                                                                                          Sample x
                                                                                                                                                                                                                                   0
                     FPDMisabletoutilize a variable amount of computation                                                                                                        0
                                                                                                                                                                                                       × N
                                                                                                                                                              t = T-1 .
                     at each timestep, with the amount of computation directly                                                                                                                                   t = T-1.
                     influencing the accuracy of the resulting solutions. This fixed                                           Figure 2. The architecture of FPDM compared with DiT. FPDM keeps
                     point network is then applied sequentially, as in standard                                                the first and last transformer block as pre and post processing layers and
                     diffusion models, to progressively denoise a data sample                                                  replaces the explicit layers in-between with an implicit fixed point layer.
                     from pure Gaussian noise.                                                                                 Sampling from the full reverse diffusion process involves solving many
                                                                                                                               of these fixed point layers in sequence, which enables the development of
                          FPDMoffersefficiency gains at two levels of granularity:                                             newtechniques such as timestep smoothing (Sec. 3.3) and solution reuse
                     that of individual timesteps and that of the entire diffusion                                             (Sec. 3.3).
                     process. First, at the timestep level, it provides:                                                       2. Related Work
                     1. A substantial reduction in parameter count compared to
                          previous networks (87% compared to DiT [37]).                                                        Diffusion Models (DMs).                          Diffusion models [2, 22], or
                     2. Reduced memory usage during both training and sam-                                                     score-based generative models [47, 48], are the source of
                          pling (60% compared to DiT [37]).                                                                    tremendous recent progress in image generation. They learn
                     Second, at the diffusion process level, it provides:                                                      to reverse a Markovian noising process using a denoiser
                     1. The ability to smoothly distribute or reallocate computa-                                              parametrized by a neural network, traditionally a U-Net [41].
                          tion among timesteps. This contrasts with all previous                                               Thedenoisingparadigmcanbeseenasthediscretizationofa
                          diffusion models, which must perform a full forward pass                                             stochastic differential equation in a continuous domain [49].
                          at every sampling timestep.                                                                          Later work equipped DMs with different sampling meth-
                     2. Thecapacity to reuse solutions from one fixed-point layer                                              ods [33, 46, 52] and applied conditional control from multi-
                          asaninitializationforthelayerinthesubsequenttimestep,                                                ple modalities [12, 35, 48]. Recently, DMs with transformer-
                          further improving efficiency.                                                                        based architectures (DiTs) were shown to be highly effec-
                                                                                                                               tive [37]; FPDM builds upon the DiT architecture.
                     Ourfixed-point network thereby delivers immediate benefits,                                                    The heavy memory and computation requirements of
                     in the form of reduced size and memory (Sec. 3.2), and                                                    DMsscale up quadratically with the image resolution and
                     further benefits when integrated into the diffusion process, in                                           linearly with the number of sampling timesteps. To reduce
                     the form of increased flexibility during sampling (Sec. 3.3).                                             training cost, LDM [40] proposes to downsample images
                          To realize these benefits, it is imperative to train our                                             with a pre-trained Variational Autoencoder [28] and perform
                     models using an efficient and effective differentiable fixed-                                             denoising in latent space. However, the inference cost of
                     point solver. Although several implicit training methods                                                  DMsisstill considered their primary drawback.
                     exist in the literature [5, 14, 17], we find these existing ap-
                     proaches to be unstable or underperformant in our setting.                                                Implicit Networks and Deep Equilibrium Models.
                     Hence, we develop a new training procedure named Stochas-                                                 Whereas traditional neural networks calculate outputs by
                     tic Jacobian-Free Backpropagation (S-JFB) (Sec. 3.4), in-                                                 performing a pass through a stack of layers, implicit neural
                     spired by Jacobian-Free Backpropagation (JFB) [14]. This                                                  networksdefinetheiroutputsbythesolutionsofdynamicsys-
                     procedure is stable, highly memory-efficient, and surpasses                                               tems. Specifically, Deep Equilibrium Models (DEQs) [5, 16]
                     standard JFB in performance.                                                                              define their output by the fixed point of an equilibrium layer
                          Wedemonstratetheefficacyofourmethodthroughexten-                                                     f . The equilibrium state of DEQs, z∗, is equivalent to the
                                                                                                                                 θ
                     sive experiments (Sec. 4) on four popular image generation                                                output of an infinite-depth, weight-sharing explicit neural
                     datasets: LSUN-Church [53], CelebA-HQ [24], FFHQ [4],                                                     network: lim                    f (zk) = f (z∗) = z∗. In its forward
                                                                                                                                                      k→∞ θ                    ∗ θ
                     and ImageNet [11]. FPDM excels over standard diffu-                                                       pass, the equilibrium state z                      can be computed by apply-
                     sion models when computational resources during sampling                                                  ing solvers like Broyden’s method [9] or Anderson’s ac-
                     are limited. Finally, detailed analysis and ablation studies                                              celeration [3]. In the backward pass, one can implicitly
                     (Sec. 5) demonstrate the efficacy of our proposed network,                                                differentiate through the equilibrium state z∗, or use one of
                     sampling techniques, and training methods.                                                                the recently-proposed accelerated training methods [14, 17].
                                                                                                                          2
