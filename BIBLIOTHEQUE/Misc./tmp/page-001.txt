                        Exploring Context Window of Large Language Models
                                       via Decomposed Positional Vectors
                                            1∗       3∗         4                 1†              4
                                 Zican Dong , Junyi Li , Xin Men , Wayne Xin Zhao , Bingning Wang
                                                       1              4             1,2
                                             ZhenTian ,WeipengChen ,Ji-RongWen
                                   1 Gaoling School of Artificial Intelligence, Renmin University of China
                                           2 School of Information, Renmin University of China
                                    3 Department of Computer Science, National University of Singapore
                                                           4 Baichuan Inc.
                                          dongzican@ruc.edu.cn, junyi_cs@nus.edu.sg
                                         batmanfly@gmail.com, daniel@baichuan-inc.com
                                                             Abstract
                               Transformer-based large language models (LLMs) typically have a limited context
                               window, resulting in significant performance degradation when processing text
                               beyond the length of the context window. Extensive studies have been proposed to
                               extend the context window and achieve length extrapolation of LLMs, but there is
                               still a lack of in-depth interpretation of these approaches. In this study, we explore
                               the positional information within and beyond the context window for deciphering
                               the underlying mechanism of LLMs. By using a mean-based decomposition
                               method, we disentangle positional vectors from hidden states of LLMs and analyze
                               their formation and effect on attention. Furthermore, when texts exceed the context
                               window, we analyze the change of positional vectors in two settings, i.e., direct
                               extrapolation and context window extension. Based on our findings, we design two
                               training-free context window extension methods, positional vector replacement
                               and attention window extension. Experimental results show that our methods can
                               effectively extend the context window length.
                        1  Introduction
                        Recently, Transformer-based large language models (LLMs) have demonstrated excellent capabilities
                        on downstream tasks [1–3], in which positional encodings (e.g., absolute or relative) are widely used
                        in Transformers to better capture positional information within input sequences [4, 5]. However,
                        LLMstypically suffer from a limited input length (called context window), which is constrained by
                        the maximum length of training data. Beyond the context window, the positional encodings at larger
                        position indices are out-of-distribution (OOD), not encountered during the training phase. Therefore,
                        when the input sequence exceeds the context window length, there would often be a significant
                        degradation in model performances, as evidenced by a surge in perplexity (PPL) score [6].
                        Prior work has primarily focused on extending the context window of existing LLMs by manipulating
                        positional encodings. Owing to its excellent performance and long-term decay nature, RoPE [7] has
                        been widely used to learn positional encodings for existing LLMs [8, 9]. To circumvent the OOD
                        positional encodings in RoPE, various methods have been proposed to modify the base [10–12] or
                        positional indices [13–16]. In addition, special relative positional encodings that apply larger negative
                        biases to attention based on the relative distance have achieved promising length extrapolation, which
                          ∗Equal Contribution.
                          †Corresponding author.
                        38th Conference on Neural Information Processing Systems (NeurIPS 2024).
