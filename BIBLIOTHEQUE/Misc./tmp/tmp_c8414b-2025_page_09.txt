                                       Product of Experts with LLMs: Boosting Performance on ARC Is a Matter of Perspective
                                                                                             6. Discussion
                              AccuracyforDifferent Selection Methods                         Ourmethodbuilds on familiar techniques – data augmenta-
                             for the 3M Sudoku Dataset (1000 samples)                        tion, Bayesian modeling, and product of experts scoring –
                           1                                                                 but tailors them specifically for ARC-like puzzles.
                      ed)                                                                    At our methods’ core, we use a single fine-tuned LLM
                      Solv0.8                                                                in two roles: as a generator, it proposes solutions for each
                                                                                             puzzleaugmentation; asascorer,itre-scoreseachgenerated
                                    Generation Accuracy                                      candidate across all augmentations by taking the product
                         0.6                           Q ˆ
                                    Product-of-Experts   j Pj (ours)                         (geometric mean) of likelihoods. The benefit is twofold.
                      oportion                        1 P ˆ                                  First, a candidate solution must be jointly plausible under
                      (Pr           MeanProbability, N     j Pj
                         0.4        MaxGenerationProbability                                 every valid transformation to rank preferably, making it
                                    Selection Accuracy                                       harder for the model to latch onto spurious correlations
                         0.2        Overall Accuracy                                         found in just one representation. Second, this log-linear
                      Accuracy                                                               pooling approach naturally acts as an ensemble method, as
                           0                                                                 weshowinSection4.1.
                               0          1          2          3          4                 Despite ARC’s reputation for complexity, our two-phase
                                    Confidence Threshold (-log(prob))                        “generate-then-re-score” routine achieves SOTA results
                                                                                             among open models. While only a single closed-source
                 Figure 6. Results of the Sudoku experiments (plot equivalent to             solution (arcprize.org, 2025) posts a higher absolute score
                 Figure 4, but showing top-1 accuracy instead of top-2). We can              at $17 per task, our fully open-source process stands out
                 see that our product of experts approach increases the accuracy             for its transparency, reproducibility and, above all, its cost-
                 substantially to 53% solved Sudoku puzzles over simply selecting            effectiveness of only 0.02$ per task.
                 the generated solution with the highest sampling probability. Note
                 that generation accuracy completely coincides with product of               By applying these ideas to ARC, we underline a broader
                 experts probability, showing that if a correct solution is sampled,         principle: when dealing with structured or abstract rea-
                 our approach consistently selects it.                                       soning tasks, the key factor is to exploit valid semantic-
                 73.3%2-guessaccuracy on ConceptARC (using the exact                         preserving transformations, forcing a model to remain con-
                 samehyperparametersasDFST=9%),showingthatwegen-                             sistent across multiple views of the same problem. This
                 eralize well to other ARC-like datasets of similar difficulty.              allows us to use a single model as an ensemble of experts.
                                                                                             Webelieve this perspective can generalize to more complex
                 5.6. Sudoku                                                                 symbolic reasoning challenges, wherever such transforma-
                                                                                             tions can be defined. Our results demonstrate that large lan-
                 We further test our approach on the Sudoku 3M dataset                       guage models, properly steered in inference and supported
                 (Radcliffe, 2020) to evaluate generalizability of the method                by prior aware scoring, can go beyond default sampling
                 to different domains. Since the underlying ”rules” of Su-                   approaches to capture deeper structures in abstract domains.
                 doku remain consistent between tasks, we do not use any
                 test-time training in this case. Instead, we start out with                 6.1. Future Work
                 our Llama 3B model pre-trained on ARC, which we then                        Building upon our insights, several promising directions
                 finetune again on 128000 Sudoku tasks. As the Sudoku                        emerge for future investigation. First, it would be valuable
                 tasks never have any ambiguity, we report top-1 accuracy                    to further explore the generalizability of using a single large
                 rather than top-2. To handle the increased complexity for                   language model as a Product-of-Experts through augmenta-
                 the LLMcomparedtoARC,weuseDFSwithathresholdof                               tions beyond ARC-specific transformations. In particular,
                 T=1%,whichprovidesagoodtrade-offbetweenaccuracy                             text-based augmentations such as linguistic reformulations
                 and runtime (see Figure 6). This setup reaches 53% accu-                    or stylistic variations present possible paths to extend our
                 racy on 1000 randomly chosen unseen Sudoku puzzles, far                     method to a broader array of natural language reasoning
                 better than state-of-the-art LLMs, which have a solve-rate                  tasks. Second, the effectiveness of our depth-first search
                 less than 3% on comparable benchmarks (Seely et al., 2025).                 (DFS) candidate-generation strategy warrants evaluation
                 Notably, if the correct solution of a puzzle is sampled, we                 beyond ARC-like puzzles; exploring tasks such as logical
                 select it in 100% of cases. This is caused by the fact that Su-             reasoning, program synthesis, or mathematical problem-
                 dokucorrectness is simple to evaluate. Using our standard                   solving could yield insights into its broader applicability
                 augmentations described in Section 5.3 on the predictions,                  and effectiveness in structured problem-solving domains.
                 the model can identify errors more frequently, thereby sig-
                 nificantly reducing the likelihood of false positives.
                                                                                         9
