                       Model                         Position   Segment       MNLI        QQP QNLI SST2 CoLA STS-B Avg
                                                                               393k       364k     105k      67k      8.5k      7k
                       Devlin et al. (2018)           input       input     85.8 / 85.9   91.1     89.9     93.2      58.7     89.0     84.8
                       Shawetal. (2018)             per-head      input     86.3 / 86.0   91.2     90.5     93.2      59.8     89.3     85.2
                       Raffel et al. (2020)         per-head      input     86.4 / 86.2   91.2     90.1     93.0      59.6     90.1     85.2
                       Keetal. (2020)               per-head      input     86.1 / 86.2   91.2     90.3     93.1      59.6     89.6     85.2
                       DIET-REL                     per-head      input     86.0 / 86.1   91.0     89.8     92.8      59.6     89.0     84.9
                       DIET-REL                     per-head    per-head    86.3 / 86.3   91.0     90.5     92.9      60.3     89.3     85.2
                       DIET-ABS (dp=128, share)     per-head    per-head    86.4 / 86.4   90.8     89.5     93.0      59.8     90.2     85.2
                       Wangetal.(2020) (dp=32)        input       input     82.3 / 82.6   90.2     86.3     91.4      53.9     87.6     82.0
                       DIET-ABSLIN (d =32)          per-head      input     83.0 / 83.1   90.6     86.7     92.0      55.7     87.6     82.7
                                        p
                    Table 2: GLUE: Results on the GLUE dev set of the ﬁnetuned models based on a pre-trained model with 12-
                    layer BERT         architecture. We report the median of the maximum accuracy over all checkpoints among ﬁve
                                 BASE
                    runs. We notice that the shared DIET-ABS with rank 128 performs competitively with existing relative positional
                    embedding SoTA models without the inductive bias of the relative positions. The proposed method also improves
                    performance in the low-rank long range transformer setting of (Wang et al., 2020), where relative positional
                    embedding approaches are inefﬁcient to use.
                                                                              Classiﬁcation             Question Answering
                       Model                          Position    Segment        XNLI           XQuAD         MLQA         TyDiQA       Avg
                                                                                  393k                   88k                 3.7k
                       Devlin et al. (2018)             input       input         67.0         66.0 / 49.9  56.2 / 41.0   59.0 / 47.9   55.3
                       Shawetal. (2018)               per-head      input         67.9         69.5 / 53.9  58.2 / 43.1   64.8 / 49.9   58.2
                       Raffel et al. (2020)           per-head      input         68.5         69.9 / 53.5  59.5 / 44.3   63.8 / 50.6   58.6
                       Keetal. (2020)                 per-head      input         67.8         68.6 / 52.0  58.6 / 43.2   63.9 / 48.7   57.5
                       DIET-REL                       per-head      input         68.0         68.1 / 52.8  57.7 / 42.7   63.3 / 50.9   57.6
                       DIET-REL                       per-head    per-head        68.4         69.4 / 54.4  58.6 / 43.5   62.4 / 49.3   58.0
                       DIET-ABS (dp=128, share)       per-head    per-head        68.5         70.0 / 53.6  59.8 / 44.5   64.6 / 51.5   58.9
                       Wangetal.(2020) (dp=256)         input       input         63.6         59.1 / 43.7  48.9 / 34.0   50.5 / 37.9   48.2
                       DIET-ABSLIN(d =256)            per-head      input         64.4         61.6 / 46.0  52.2 / 37.0   53.6 / 40.9   50.8
                                        p
                    Table 3: XTREME: Fine-tune cross-lingual model on English training set (Cross-lingual Transfer). Performance
                    is measured by accuracy for classiﬁcation, and f1 score / exact match for question answering. In agreement with
                    results in Table 2 we see in this table that using per-head position encodings is strictly better than absolute position
                    encodings at the input. With layer-wise sharing, DIET-ABS with rank 128 outperforms all SoTA models.
                     Model                  EN-DE DE-EN EN-CS CS-EN                 ble 2. We ﬁrst notice that all the approaches that
                     Vaswani et al. (2017)   39.00    38.42    18.55   22.93        encodepositionfeatures explicitly at per-head level
                     Shawetal. (2018)        40.10    38.90    18.74   23.89        perform better than the baseline additive position
                      DIET-REL               39.47    38.49    18.68   23.93        encodings at the input (Devlin et al., 2018). All
                    Table 4: Machine Translation: We report results com-            modelsincorporatingrelativepositions(Shawetal.,
                    paring different position encoding methods for Trans-           2018; Raffel et al., 2020; Ke et al., 2020), despite
                    formers on machine translation tasks en-de, de-en, en-          their modeling differences, have very similar av-
                    cs and cs-en from the Newstest 2018 dataset. We no-             erage score. We show further gains (84.9 to 85.2
                    tice that all per-head position encoding schemes (all ex-       for DIET-REL) by moving segment features to per-
                    cept the ﬁrst row) do better than the absolute position         head.
                    embeddings added at the input. Further the proposed
                    simple DIET-REL approach is competitive with other                 Interestingly we notice that the proposed abso-
                    position encoding approaches.                                   lute position encoding method DIET-ABS, with
                                                                                    layer-wise sharing, is on par with all previous
                                                                                    SoTA relative positional encodings. This shows
                    Results     Weexamine how different ways of en-                 that even absolute position encodings can perform
                    coding position and segment affect the transfer                 better when included per-head instead at the input.
                    learning ability of the pre-trained English BERT                Wepresent a detailed ablation study varying the
                    models by ﬁne-tuning on the GLUE benchmark                      rank and sharing methods of absolute positional
                    (Wanget al., 2019), and present the results in Ta-              attention (DIET-ABS) in Table 8 and Tables 9 in
                                                                               2979
