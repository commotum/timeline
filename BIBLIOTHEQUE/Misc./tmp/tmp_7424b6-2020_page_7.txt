        Figure 2.1: Zero-shot, one-shot and few-shot, contrasted with traditional ﬁne-tuning. The panels above show
        four methods for performing a task with a language model – ﬁne-tuning is the traditional method, whereas zero-, one-,
        and few-shot, which we study in this work, require the model to perform the task with only forward passes at test
        time. We typically present the model with a few dozen examples in the few shot setting. Exact phrasings for all task
        descriptions, examples and prompts can be found in Appendix G.
           • Zero-Shot(0S)isthesameasone-shotexceptthatnodemonstrationsareallowed, andthemodelisonlygiven
           a natural language instruction describing the task. This method provides maximum convenience, potential for
           robustness, and avoidance of spurious correlations (unless they occur very broadly across the large corpus of
           pre-training data), but is also the most challenging setting. In some cases it may even be difﬁcult for humans
           to understand the format of the task without prior examples, so this setting is in some cases “unfairly hard”.
           For example, if someone is asked to “make a table of world records for the 200m dash”, this request can be
           ambiguous, as it may not be clear exactly what format the table should have or what should be included (and
           even with careful clariﬁcation, understanding precisely what is desired can be difﬁcult). Nevertheless, for at
           least some settings zero-shot is closest to how humans perform tasks – for example, in the translation example
           in Figure 2.1, a human would likely know what to do from just the text instruction.
        Figure 2.1 shows the four methods using the example of translating English to French. In this paper we focus on
        zero-shot, one-shot and few-shot, with the aim of comparing them not as competing alternatives, but as different
        problem settings which offer a varying trade-off between performance on speciﬁc benchmarks and sample efﬁciency.
        Weespecially highlight the few-shot results as many of them are only slightly behind state-of-the-art ﬁne-tuned models.
        Ultimately, however, one-shot, or even sometimes zero-shot, seem like the fairest comparisons to human performance,
        and are important targets for future work.
        Sections 2.1-2.3 below give details on our models, training data, and training process respectively. Section 2.4 discusses
        the details of how we do few-shot, one-shot, and zero-shot evaluations.
                               7
