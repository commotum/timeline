                                                                                    Wake
                                             Objective: For each task x in X, ﬁnd best program ρ solving x under current library L
                                                                                                     x
                               Library L
                               f1(x) =(+ x 1)                                 Neurally guided search
                               f2(z) =(fold cons                           Propose programs ρ in                   Best program ρ for task x
                                                                                                                                   x
                                   (cons z nil))      Recognition          decreasing order under Q(·|x)           (map f (fold f nil x))
                                                                                                                          1          2
                               · · · · · · · · ·      Model Q(·|x)         until timeout
                               Task x                                                                         Choose ρx that maximizes:
                               [7 2 3]→[4 3 8]                                                                P[ρ|x,L] ∝ P[x|ρ]P[ρ|L]
                                 [3 8]→[9 4]
                               [4 3 2]→[3 4 5]
                                 Sleep: Abstraction                                  Library                           Sleep: Dreaming
                       Objective: Grow library L to compress                                                Objective: Train recognition model Q(ρ|x)
                       programs found during waking                                                         to predict best programs ρ for typical
                                                                            prog      prog     prog                                     x
                                                                                                            tasks x and current library L
                       program for task 1      program for task 2                                                    Fantasies       Replays
                        (cons (+ 1 1))           (+ (car z) 1)              task      task     task           1. draw                         1. recall
                                                                                                            programs        sample        sampletasks x
                            cons                              1                       is                       ρ from                         solved in
                                                    +
                                +    1   1            car   z                                                library L                        waking
                                                                                                                  2. set task x    2. set program
                                                                                                                  to output of     ρ to retrieved
                                                                                                                  executing ρ      solution ρx
                                        Refactoring
                              Propose new library routines from
                            subtrees of refactorings of programs
                                                                                                                   Train network on x,ρ pairs
                                                    New library L
                                                    w/ routine                                                  Task                        Program
                       Expand L w/                         (+ x 1)                                                x                             ρ
                       the routine that            +      1
                       maximizes:                                       Repeat                    Train            Gradient step in parameters of Q
                       P[L]Q            max       P[x|ρ]P[ρ|L]          until no                   until                to maximize logQ(ρ|x)
                              x∈Xρ:refactorings of ρx                   increase             converged
                                                                        in score
                   Figure 2: DreamCoder’s basic algorithmic cycle, which serves to perform approximate Bayesian
                   inference for the graphical model diagrammed in the middle. The system observes programming
                   tasks (e.g., input/outputs for list processing or images for graphics programs), which it explains with
                   latent programs, while jointly inferring a latent library capturing cross-program regularities. A neural
                   network, called the recognition model (red arrows) is trained to quickly infer programs with high
                   posterior probability. The Wake phase (top) infers programs while holding the library and recognition
                   model ﬁxed. A single task, ‘increment and reverse list’, is shown here. The Abstraction phase of
                   sleep (left) updates the library while holding the programs ﬁxed by refactoring programs found during
                   waking and abstracting out common components (highlighted in orange). Program components that
                   best increase a Bayesian objective (intuitively, that best compress programs found during waking) are
                   incorporated into the library, until no further increase in probability is possible. A second sleep phase,
                   Dreaming (right) trains the recognition model to predict an approximate posterior over programs
                   conditioned on a task. The recognition network is trained on ‘Fantasies’ (programs sampled from
                   library) and ‘Replays’ (programs found during waking).
                                                                                       6
