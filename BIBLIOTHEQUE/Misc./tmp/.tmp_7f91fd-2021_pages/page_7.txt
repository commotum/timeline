                                                         Large-scale few-shot program induction and synthesis 
                Figure 4. (Left) We purposely bias the test to generalize to longer computations than those seen for training examples.This plot shows 
                the ratio of number of maximum number of lines executed for a test input vs maximum number of lines executed for a training input. 
                Programs without loops, where the ratio is 1, are ommitted.(Center) Depth of indentation execution (nested loops and if statements), 
                which often signifcantly affects the diffculty of program synthesis. (Right) number of times each integer in [-200,200] appears as an 
                input or output on a test-case. We can see that they follow a very intuitive distribution, with smaller integers being more popular, positive 
                numbers being more common than their negative counterparts and a peak at 100 and -100. 
                      strings. The interface then returns whether the function           us to judge the correctness of equivalent implementations of 
                      compiled and, if it did, a list of results for each input. In      the same function or implicit programs, like those described 
                      case of a runtime error or a timeout, it returns "Runtime          by neural networks.  More concretely, for each task, we 
                      error" or "Timeout" respectively.  This is useful for              give the method all 10 training examples and evaluate its 
                      approaches that use the environment as a black-box                 performance on the 10 test examples, only counting exact 
                      without interacting with individual instructions.                  answers. We can then measure the example accuracy (the 
                   2.  In contrast to traditional C++, we can run a program              fraction of correctly-solved test-cases across all meta-test 
                      line by line and return the appropriate variables with             tasks), and task accuracy (the fraction of tasks with all of 
                      new values. This mode is restricted to our subset of               their 10 test examples correctly predicted).  Note that, al-
                      C++ (that all programs in PROGRESbelong to), but                   though both measures are related, a method may have higher 
                      it is useful for methods that use partial executions to            task accuracy than another, while having lower example ac-
                      guide synthesis (Ellis et al., 2019).                              curacy. As described in previous work (Devlin et al., 2017), 
                                                                                         having a high example accuracy is more desirable when 
                                                                                         we are using the method on a per-example basis (like an 
                4. Benchmark                                                             auto-suggest tool) whereas task accuracy is more important 
                4.1. Evaluation protocol                                                 in cases where we would like the induced program to make 
                                                                                         an indeterminate number of predictions without having to 
                Our goal is to generalize to relevant subprograms from un-               check all of them. 
                seen programming contests. Therefore, we choose to divide 
                between meta-train, meta-validation and meta-test at the                 4.2. Baselines 
                level of contests: training takes contests <1000, validation             We evaluate multiple baselines, all based on the same core 
                between 1000 and 1249 and testing more than 1250. Some                   architecture (a large-scale language model), in order to bet-
                subprograms (especially short ones like "return v0+1") are               ter understand their differences. 
                repeated multiple times. If in a single problem (thus shar-
                ing the context text and often the same input-output pairs)              Fine-tuning a pre-trained language model to generate 
                there are multiple copies of the same subprogram, we merge               code  from  examples  Inspired  by  the  RobustFill  pro-
                them into a single task, pooling their input-output examples.            gram synthesis model (Devlin et al., 2017) and recent 
                Note that the same subprogram can be in different problems.              advances in language model pre-training, we build a neural 
                However, they will not be the same task, because both the                program synthesis baseline.  Our aim was to determine 
                input-output pairs and the context text will differ. Intuitively,        how well a state-of-the-art sequence-to-sequence neural 
                new programming tasks may require us to implement code                   program synthesis model could perform on our dataset. 
                we have seen before (like adding up all the elements in an               We  used  the  BART  (Lewis  et  al.,  2019)  pre-trained 
                array), but in a different context.                                      transformer  model  as  a  base,  and  fne-tuned  it  on  our 
                To judge the performance of a program for a single task, we              dataset to output programs.  The model takes as input 
                evaluate its performance on unseen test cases. This allows               the function header (which describes the type signature), 
