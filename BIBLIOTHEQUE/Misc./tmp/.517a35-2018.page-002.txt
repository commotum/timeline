                    PLDI’18, June 18–22, 2018, Philadelphia, PA, USA                                                     WoosukLee,KihongHeo,RajeevAlur,andMayurNaik
                    context-free grammar [21], probabilistic higher-order gram-                                     Iter.                     Enumerated programs                             Counterex.
                    mar[6], a log-bilinear model [1], a decision tree model [28],                                     1     “.”                                                                    “-.”
                    andaneuralnetwork[5].                                                                             2    “.”, “-”,x, “-” + “-”, “.” + “-”, · · · , “.” + “.”                 “308-916”
                        To address the second challenge, we target probabilistic                                           |   {z   } |                                  {z                                  }
                    higher order grammars (PHOG) [6], a powerful probabilistic                                                size 1                    size 3
                    modelthat generalizes probabilistic context-free grammars                                         3    “.”, “-”,x, · · · ,x + “.”, Rep(x, “.”, “-”),   Rep(x,“-”,“.”)
                    byallowingconditioningofeachproductionrulebeyondthe                                                     Table 1. Enumeration using an unguided search.
                    parent non-terminal. It thereby allows capturing rich con-
                    texts to effectively distinguish likely programs from unlikely                                  • Implementation atop an open-source tool and evaluation
                    ones. We learn the model from known solutions of synthesis                                          onbenchmarkproblemsfromavarietyofwidelyapplica-
                    problems that were solved by existing techniques. A direct                                          ble domains. The results demonstrate significant perfor-
                    application, however, suffers from overfitting the model to                                         mancegainsoverexisting synthesis techniques.
                    specifications in those synthesis problems. We propose a
                    novel learning method inspired by transfer learning [23, 24]                                    2 Overview
                    to learn the model from features of specifications. The fea-                                    Weillustrate our approach on the problem of synthesizing a
                    turesareprovidedbyadomainexpertandareakintodomain                                               certain string transformation program. The desired program
                    knowledge used to guide synthesis in existing techniques,                                       is a function f that takes as input a string denoted x and
                    such as features of input-output examples [21] or abstract                                      outputs a string with each hyphen in x replaced by a dot.
                    semantics of programs [33].                                                                         Weformulatethis problem as an instance of the syntax-
                        WeimplementedourapproachinatoolcalledEuphony                                                guided synthesis (SyGuS) problem [3]. The formulation com-
                    thatwebuiltatopEUSolver[4],anopen-sourcestate-of-the-                                           prises a syntactic specification, in the form of a context-free
                    art search-based synthesizer. We evaluate Euphony on 1,167                                      grammar that constrains the space of possible programs,
                    benchmarkproblems from three widely applicable domains:                                         and a semantic specification, in the form of a logical formula
                    string manipulation (end-user programming problems), bit-                                       which defines a correctness condition that f must satisfy.
                    vector manipulation (efÏcient low-level algorithms), and cir-                                   Thesyntactic specification for f is the grammar:
                    cuit transformation (attack-resistant crypto circuits). For                                                       S →x | “-” | “.” | S + S | Rep(S,S,S)                             (1)
                    each of these domains, we observe that it sufÏces to train
                    Euphonyusingeasily obtainable solutions—those that can                                          where S is the start symbol, + is the string concatenation
                    be generated by EUSolver in under 10 minutes. These solu-                                       operator, and Rep(s,t1,t2) is a new string where each oc-
                    tions comprise 762 (∼ 65%) of our benchmark problems.                                           currence of substring t1 in s is replaced by string t2. The
                        Thetrained Euphony is able to solve 236 new problems                                        semantic specification for f follows the programming by ex-
                    in 11 minutes on average per problem, compared to only 87                                       ample (PBE)paradigmandcomprisesinput-outputexamples
                    byEUSolverusing29minutesonaverage.EUSolverfails                                                 given as a logical formula:1
                    to solve the remaining problems even after 6 hours—a conse-                                         f (“-.”) = “..” ∧ f (“308-916”) = “308.916” ∧ f (“1”) = “1”                     (2)
                    quence of the fact that the search space grows exponentially                                    Asolution to this synthesis problem is Rep(x,“-”,“.”).
                    with program size, despite the use of powerful techniques                                           Wenextillustrate how a typical search-based synthesizer
                    to optimize the search (see Section 3.4). We also compare                                       finds this solution using the CEGIS procedure that combines
                    Euphony to FlashFill [12], a synthesizer tailored to the                                        a search algorithm with a verification oracle. It maintains
                    string manipulation domain that is shipped with Microsoft                                       a finite set of program inputs pts that is initially empty. In
                    PowerShell. Euphony outperforms FlashFill on 20 out of                                          each iteration, it searches for a candidate program that is
                    22synthesisproblemsandis10xfasteronaverage.Euphony                                              correct on the inputs in pts, and verifies the correctness of
                    thus provides significant performance gains that are comple-                                    the program according to the given semantic specification.
                    mentary to those achieved by existing general-purpose and                                       If correct, it returns the program; otherwise, it adds new
                    domain-specific synthesizers.                                                                   counterexample inputs to pts and repeats the process. The
                        Wesummarizethemaincontributionsofourwork:                                                   overall performance of this procedure depends heavily on
                    • A general approach to accelerate search-based program                                         the search algorithm it uses to find candidate programs.
                       synthesisbyusingaprobabilisticmodeltoguidethesearch                                              Table 1 shows an execution of a state-of-the-art such algo-
                       towardslikely programs. It targets the widely-used SyGuS                                     rithm [32] on our example problem. It enumerates programs
                       formulation and supports a wide range of models.                                             generated by the given grammar in order of size. We step
                    • Amethodbasedontransferlearningthatenablestolearna                                             through its execution of the CEGIS iterations.
                       powerful model called probabilistic higher order grammar
                       (PHOG)fromknownsolutionswithoutoverfitting.                                                  1Our approach is also applicable to SyGuS instances that use semantic
                                                                                                                    specification ∀x : ... instead of input-output examples; we evaluate it on
                                                                                                                    both kinds of synthesis problems.
