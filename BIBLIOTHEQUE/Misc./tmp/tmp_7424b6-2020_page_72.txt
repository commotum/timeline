              [MBXS17] Bryan McCann, James Bradbury, Caiming Xiong, and Richard Socher. Learned in translation: Con-
                      textualized word vectors. In Advances in Neural Information Processing Systems, pages 6294–6305,
                      2017.
              [MCCD13] TomasMikolov,KaiChen,GregCorrado,andJeffreyDean. Efﬁcient estimation of word representations
                      in vector space. arXiv preprint arXiv:1301.3781, 2013.
                  +
              [MCH 16] NasrinMostafazadeh,NathanaelChambers,XiaodongHe,DeviParikh,DhruvBatra,LucyVanderwende,
                      Pushmeet Kohli, and James Allen. A corpus and evaluation framework for deeper understanding of
                      commonsensestories. arXiv preprint arXiv:1604.01696, 2016.
              [MCKS18] TodorMihaylov,PeterClark,TusharKhot,andAshishSabharwal. Canasuitofarmorconductelectricity?
                      a new dataset for open book question answering. ArXiv, abs/1809.02789, 2018.
              [MKAT18] Sam McCandlish, Jared Kaplan, Dario Amodei, and OpenAI Dota Team. An empirical model of
                      large-batch training, 2018.
                  +
             [MKM 94] MitchellMarcus,GraceKim,MaryAnnMarcinkiewicz,RobertMacIntyre,AnnBies,MarkFerguson,
                      Karen Katz, and Britta Schasberger. The penn treebank: annotating predicate argument structure.
                      In Proceedings of the workshop on Human Language Technology, pages 114–119. Association for
                      Computational Linguistics, 1994.
              [MKXS18] Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. The natural language
                      decathlon: Multitask learning as question answering. arXiv preprint arXiv:1806.08730, 2018.
               [MPL19] RThomasMcCoy,ElliePavlick, and Tal Linzen. Right for the wrong reasons: Diagnosing syntactic
                      heuristics in natural language inference. arXiv preprint arXiv:1902.01007, 2019.
             [MWZ+18] Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson,
                      Elena Spitzer, Inioluwa Deborah Raji, and Timnit Gebru. Model cards for model reporting, 2018.
               [NBR20] Moin Nadeem, Anna Bethke, and Siva Reddy. Stereoset: Measuring stereotypical bias in pretrained
                      language models. arXiv preprint arXiv:2004.09456, 2020.
                [NK19] TimothyNivenandHung-YuKao. Probingneuralnetworkcomprehensionofnaturallanguagearguments.
                      arXiv preprint arXiv:1907.07355, 2019.
                [Nor09] Peter Norvig. Natural language corpus data, 2009.
            [NvNvdG19] MalvinaNissim, Rik van Noord, and Rob van der Goot. Fair is better than sensational: Man is to doctor
                      as womanis to doctor. arXiv preprint arXiv:1905.09866, 2019.
             [NWD+19] YixinNie,AdinaWilliams,EmilyDinan,MohitBansal,JasonWeston,andDouweKiela. Adversarial
                      nli: A new benchmark for natural language understanding. arXiv preprint arXiv:1910.14599, 2019.
                [oR16] University of Regensburg. Fascha, 2016.
               [PCC18] Mohammad Taher Pilehvar and Jose Camacho-Collados. WIC: 10,000 example pairs for evaluating
                      context-sensitive representations. arXiv preprint arXiv:1808.09121, 2018.
                                      ´
               [PFB18] Jason Phang, Thibault Fevry, and Samuel R. Bowman. Sentence encoders on STILTs: Supplementary
                      training on intermediate labeled-data tasks. arXiv preprint arXiv:1811.01088, 2018.
              [PHR+18] AdamPoliak,Aparajita Haldar, Rachel Rudinger, J. Edward Hu, Ellie Pavlick, Aaron Steven White, and
                      BenjaminVanDurme. Collectingdiversenaturallanguageinferenceproblemsforsentencerepresentation
                      evaluation. In Proceedings of EMNLP, 2018.
                  +                 ´
              [PKL 16] DenisPaperno, German Kruszewski, Angeliki Lazaridou, Quan Ngoc Pham, Raffaella Bernardi, Sandro
                                                            ´
                      Pezzelle, Marco Baroni, Gemma Boleda, and Raquel Fernandez. The lambada dataset: Word prediction
                      requiring a broad discourse context. arXiv preprint arXiv:1606.06031, 2016.
              [PNZtY18] MatthewE.Peters, Mark Neumann, Luke Zettlemoyer, and Wen tau Yih. Dissecting contextual word
                      embeddings: Architecture and representation, 2018.
                [Pos18] Matt Post. A call for clarity in reporting BLEU scores. arXiv preprint arXiv:1804.08771, 2018.
                                                  72
