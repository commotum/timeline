                         Nested Learning: The Illusion of Deep Learning
                                                  Architectures
                               Ali Behrouz           MeisamRazaviyayn          Peiling Zhong
                             Google Research          Google Research         Google Research
                                  USA                      USA                     USA
                         alibehrouz@google.com     rezavyayn@google.com     peilinz@google.com
                                                     VahabMirrokni
                                                     Google Research
                                                          USA
                                                  mirrokni@google.com
                                                       Abstract
                            Overthelast decades, developing more powerful neural architectures and simul-
                            taneously designing optimization algorithms to effectively train them have been
                            the core of research efforts to enhance the capability of machine learning models.
                            Despite the recent progresses, particularly in developing Language Models (LMs),
                            there are fundamental challenges and unanswered questions about how such models
                            can continually learn/memorize, self-improved, and find “effective solutions,”. In
                            this paper, we present a new learning paradigm, called Nested Learning (NL), that
                            coherently represents a model with a set of nested, multi-level, and/or parallel
                            optimization problems, each of which with its own “context flow”. NL reveals
                            that existing deep learning methods learns from data through compressing their
                            owncontext flow, and explain how in-context learning emerges in large models.
                            NLsuggests a path (a new dimension to deep learning) to design more expressive
                            learning algorithms with more “levels”, resulting in higher-order in-context learn-
                            ing abilities. In addition to its neuroscientifically plausible and mathematically
                            white-box nature, we advocate for its importance by presenting three core contribu-
                            tions: (1) Deep Optimizers: Based on NL, we show that well-known gradient-based
                            optimizers (e.g., Adam, SGD with Momentum, etc.) are in fact associative memory
                            modules that aim to compress the gradients with gradient descent. Building on this
                            insight, we present a set of more expressive optimizers with deep memory and/or
                            morepowerfullearning rules; (2) Self-Modifying Titans: Taking advantage of NL’s
                            insights on learning algorithms, we present a novel sequence model that learns
                            how to modify itself by learning its own update algorithm; and (3) Continuum
                            MemorySystem: Wepresentanewformulationformemorysystemthatgeneral-
                            izes the traditional viewpoint of “long-term/short-term memory”. Combining our
                            self-modifying sequence model with the continuum memory system, we present a
                            learning module, called HOPE, showing promising results in language modeling,
                            continual learning, and long-context reasoning tasks.
                     1   Introduction
                     This version of the paper has been extensively summarized to fit the page limit of NeurIPS camera
                     ready, and some materials, experiments, discussions, and methods are moved to appendix, which
                     might make some parts hard to follow or cause inconsistencies. To avoid such cases, please read our
                     arXiv version instead [1].
                     39th Conference on Neural Information Processing Systems (NeurIPS 2025).
