               10                                                                Transactions of the Institute of Measurement and Control 00(0)
               Table 1. 3D object detection results on nuScenes Val set.
               Method                Modality             Backbone      NDS        mAP         mATE       mASE       mAOE       mAVE       mAAE
               SSN                   LiDAR                –             0.569      0.463       –          –          –          –          –
               CenterPoint-Voxel     LiDAR                –             0.655      0.582       –          –          –          –          –
               PointPainting         LiDAR & Camera       –             0.583      0.464       0.388      0.271      0.498      0.247      0.111
               FCOS3D                Camera               R101          0.415      0.343       0.725      0.263      0.422      1.298      0.153
               PGD                   Camera               R101          0.428      0.369       0.638      0.261      0.439      1.263      0.185
               DETR3D                Camera               R101          0.425      0.346       0.773      0.268      0.383      0.842      0.216
               BEVFormer             Camera               R101          0.448      0.375       0.725      0.272      0.391      0.802      0.211
               RetentiveBEV          Camera               R101          0.517      0.416       0.673      0.274      0.372      0.394      0.198
               DD3D                  Camera               V2-99         0.477      0.418       0.572      0.249      0.369      1.014      0.124
               DETR3D                Camera               V2-99         0.48       0.412       0.641      0.255      0.389      0.865      0.133
               BEVFormer             Camera               V2-99         0.495      0.435       0.589      0.254      0.402      0.843      0.142
                               a
               SparseBEV(SOTA)       Camera               V2-99         0.627      0.543       0.502      0.244      0.324      0.251      0.126
               RetentiveBEV          Camera               V2-99         0.556      0.467       0.578      0.256      0.372      0.477      0.127
               a
                Data from original paper/project. Bolded texts refer to best performance within specific metrics.
               Table 2. 3D object detection results on nuScenes Val set.
               Method                 Modality      Backbone       NDS         mAP         mATE        mASE        mAOE        mAVE        mAAE
               FCOS3D                 Camera        R101           0.415       0.343       0.724       0.263       0.422        1.292      0.153
               PGD                    Camera        R101           0.428       0.366       0.688       0.248       0.434        1.264      0.185
               DETR3D                 Camera        R101           0.423       0.347       0.772       0.267       0.383        0.897      0.217
               BEVFormer              Camera        R101           0.447       0.376       0.734       0.272       0.391        0.763      0.211
                               a
               SparseBEV(SOTA)        Camera        R101           0.592       0.501       0.562       0.265       0.321        0.243      0.195
               RetentiveBEV           Camera        R101           0.518       0.411       0.674       0.274       0.372       0.455       0.198
               a
                Data from original paper/project. Bolded texts refer to best performance within specific metrics.
               3D object detection                                                      Local Attention confines its interaction to designated
               In Tables 1 and 2, we have detailed and contrasted the perfor-            anchor points for each BEV query, enhancing focus
               mance outcomes of various networks executed on the                        on vital information by assigning higher weight to sig-
               nuScenes test and validation data sets. Notably, VoVNet-99                nificant features within its limited receptive field,
               was enhanced with additional data sets during its pre-training            thereby outperforming global attention.
               phase for depth estimation tasks, potentially influencing its            Manhattan Attention (MaSA) skillfully decomposes
               comparative results.                                                      the global perspective while preserving essential prior
                  According to the insights drawn from Tables 1 and 2,                   information. By offering a wider receptive field than
               RetentiveBEV surpasses DETR and BEVFormer across all                      local attention and diminishing the influence of distant
               key metrics on the nuScenes data set. It also demonstrates                irrelevant data, MaSA achieves the optimal balance
               performance nearing that of LiDAR-based methods on cer-                   between computational efficiency and scope of aware-
               tain metrics, highlighting its advanced capabilities in both              ness, making it the most effective among the tested
               detection accuracy and efficiency.                                        attention strategies.
                                                                                     In Table 5, we delve into the performance impacts of vary-
               Ablation study                                                     ing configurations, utilizing an R101-DCN backbone with
                                                                                  900 3 1600 pixel input images on a V100 GPU. Key vari-
               The efficacy of the retentive mechanism is illustrated in Table    ables include the following:
               4, showcasing how various attention mechanisms influence
               the model’s performance. Notably:                                        Multi-Scale Feature Utilization: When enabled, fea-
                                                                                         tures extracted from the original camera images by the
                     Global Attention operates on a comprehensive scale,                backbonearefurther processed by FPN for downsam-
                      engaging with extensive features, which might dilute               pling; otherwise, features are fed directly into the neck
                      the emphasis on crucial information due to its vast                network without additional scaling.
                      memory consumption and excessively broad receptive                BEVQueryResolution: Adjustments to the resolution
                      field.                                                             can influence detail capture and performance.
