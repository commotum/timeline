                   Tim Green, Trevor Back, Paul Natsev, et al.        The ki-       [51] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
                   netics human action video dataset.       In arXiv preprint            Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and
                   arXiv:1705.06950, 2017. 1, 2, 5, 6                                    Peter J Liu. Exploring the limits of transfer learning with a
              [35] Evangelos Kazakos, Arsha Nagrani, Andrew Zisserman, and               uniﬁed text-to-text transformer. JMLR, 2020. 2
                   Dima Damen. Epic-fusion: Audio-visual temporal binding           [52] Prajit Ramachandran, Niki Parmar, Ashish Vaswani, Irwan
                   for egocentric action recognition. In ICCV, 2019. 8                   Bello, Anselm Levskaya, and Jonathon Shlens. Stand-alone
              [36] Nikita Kitaev, Łukasz Kaiser, and Anselm Levskaya. Re-                self-attention in vision models. In NeurIPS, 2019. 1, 2
                   former: The efﬁcient transformer. In ICLR, 2020. 2               [53] MichaelSRyoo,AJPiergiovanni,MingxingTan,andAnelia
              [37] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.               Angelova. Assemblenet: Searching for multi-stream neural
                   Imagenet classiﬁcation with deep convolutional neural net-            connectivity in video architectures. In ICLR, 2020. 8
                   works. In NeurIPS, volume 25, 2012. 1, 2                         [54] ZhuoranShen,IrwanBello,RavitejaVemulapalli,XuhuiJia,
              [38] Alina Kuznetsova, Hassan Rom, Neil Alldrin, Jasper Ui-                and Ching-Hui Chen. Global self-attention networks for im-
                   jlings, Ivan Krasin, Jordi Pont-Tuset, Shahab Kamali, Stefan          age recognition. In arXiv preprint arXiv:2010.03019, 2021.
                   Popov, Matteo Malloci, Tom Duerig, et al. The open im-                2
                   ages dataset v4: Uniﬁed image classiﬁcation, object detec-       [55] Karen Simonyan and Andrew Zisserman. Two-stream con-
                   tion, and visual relationship detection at scale. IJCV, 2020.         volutional networks for action recognition in videos.   In
                   5                                                                     NeurIPS, 2014. 2, 4
              [39] Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin             [56] Aravind Srinivas, Tsung-Yi Lin, Niki Parmar, Jonathon
                   Gimpel, Piyush Sharma, and Radu Soricut. Albert: A lite               Shlens, Pieter Abbeel, and Ashish Vaswani.      Bottleneck
                   bert for self-supervised learning of language representations.        transformers for visual recognition. In CVPR, 2021. 2
                   In ICLR, 2020. 2                                                 [57] Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhi-
                                                                                         nav Gupta. Revisiting unreasonable effectiveness of data in
              [40] Ivan Laptev. On space-time interest points. IJCV, 64(2-3),            deep learning era. In ICCV, 2017. 5, 8
                   2005. 2                                                          [58] LinSun,KuiJia,Dit-YanYeung,andBertramEShi. Human
              [41] Yan Li, Bin Ji, Xintian Shi, Jianguo Zhang, Bin Kang, and             action recognition using factorized spatio-temporal convolu-
                   Limin Wang. Tea: Temporal excitation and aggregation for              tional networks. In ICCV, 2015. 2
                   action recognition. In CVPR, 2020. 7, 8                          [59] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet,
              [42] Ji Lin, Chuang Gan, and Song Han. Tsm: Temporal shift                 Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent
                   modulefor efﬁcient video understanding. In ICCV, 2019. 8              Vanhoucke, and Andrew Rabinovich. Going deeper with
              [43] Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan,                     convolutions. In CVPR, 2015. 1
                   KaimingHe,ManoharPaluri,YixuanLi,AshwinBharambe,                 [60] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon
                   andLaurensVanDerMaaten. Exploringthelimitsofweakly                    Shlens, and Zbigniew Wojna. Rethinking the inception ar-
                   supervised pretraining. In ECCV, 2018. 8                              chitecture for computer vision. In CVPR, 2016. 7
              [44] Mathew Monfort, Alex Andonian, Bolei Zhou, Kandan Ra-            [61] Yi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen,
                   makrishnan, Sarah Adel Bargal, Tom Yan, Lisa Brown,                   Dara Bahri, Philip Pham, Jinfeng Rao, Liu Yang, Sebas-
                   Quanfu Fan, Dan Gutfreund, Carl Vondrick, et al. Moments              tian Ruder, and Donald Metzler.     Long range arena: A
                   in time dataset: one million videos for event understanding.          benchmark for efﬁcient transformers.     In arXiv preprint
                   PAMI,42(2):502–508, 2019. 1, 6                                        arXiv:2011.04006, 2020. 2
              [45] Daniel Neimark, Omri Bar, Maya Zohar, and Dotan As-              [62] Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Met-
                   selmann.   Video transformer network.    In arXiv preprint            zler. Efﬁcient transformers: A survey. In arXiv preprint
                   arXiv:2102.00719, 2021. 2, 4                                          arXiv:2009.06732, 2020. 2
              [46] Joe Yue-Hei Ng, Matthew Hausknecht, Sudheendra Vi-               [63] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco
                                                                                                                                  ´  ´
                   jayanarasimhan, Oriol Vinyals, Rajat Monga, and George                Massa, Alexandre Sablayrolles, and Herve Jegou. Training
                   Toderici. Beyond short snippets: Deep networks for video              data-efﬁcient image transformers & distillation through at-
                   classiﬁcation. In CVPR, 2015. 2                                       tention. In arXiv preprint arXiv:2012.12877, 2020. 1, 2, 6
              [47] Zizheng Pan, Bohan Zhuang, Jing Liu, Haoyu He, and Jian-         [64] Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani,
                   fei Cai. Scalable visual transformers with hierarchical pool-         and Manohar Paluri. Learning spatiotemporal features with
                   ing. In arXiv preprint arXiv:2103.10619, 2021. 2                      3dconvolutional networks. In ICCV, 2015. 2
                                                                                    [65] Du Tran, Heng Wang, Lorenzo Torresani, and Matt Feis-
              [48] Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz                  zli.  Video classiﬁcation with channel-separated convolu-
                   Kaiser, Noam Shazeer, Alexander Ku, and Dustin Tran. Im-              tional networks. In ICCV, 2019. 2, 8
                   age transformer. In ICML, 2018. 1, 2                             [66] Du Tran, Heng Wang, Lorenzo Torresani, Jamie Ray, Yann
              [49] Will Price and Dima Damen.        An evaluation of action             LeCun,andManoharPaluri. Acloserlookatspatiotemporal
                   recognition models on epic-kitchens.     In arXiv preprint            convolutions for action recognition. In CVPR, 2018. 2
                   arXiv:1908.00867, 2019. 8                                        [67] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-
              [50] Zhaofan Qiu, Ting Yao, Chong-Wah Ngo, Xinmei Tian, and                reit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia
                   TaoMei. Learning spatio-temporal representation with local            Polosukhin. Attention is all you need. In NeurIPS, 2017. 1,
                   and global diffusion. In CVPR, 2019. 8                                2, 3, 4, 5, 6
                                                                                 6845
