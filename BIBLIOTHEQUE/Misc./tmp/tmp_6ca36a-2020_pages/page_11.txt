        References
        Abdalghani Abujabal, Mohamed Yahya, Mirek Riedewald, and Gerhard Weikum. 2017. Automated template
         generation for question answering over knowledge graphs. In Proceedings of the 26th International Conference
         on World Wide Web, WWW ’17, page 1191–1200, Republic and Canton of Geneva, CHE. International World
         WideWebConferencesSteeringCommittee.
        Rakesh Agrawal, Tomasz Imieliundeﬁnedski, and Arun Swami. 1993. Mining association rules between sets of
         items in large databases. In Proceedings of the 1993 ACM SIGMOD International Conference on Management
         of Data, SIGMOD ’93, page 207–216, New York, NY, USA. Association for Computing Machinery.
        JonathanBerant,AndrewChou,RoyFrostig,andPercyLiang. 2013. SemanticparsingonFreebasefromquestion-
         answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,
         pages 1533–1544, Seattle, Washington, USA, October. Association for Computational Linguistics.
        AntoineBordes,NicolasUsunier, SumitChopra, andJasonWeston. 2015. Large-scale simple question answering
         with memory networks. volume abs/1506.02075.
        Jifan Chen and Greg Durrett. 2019. Understanding dataset design choices for Multi-hop reasoning. In Proceed-
         ings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics:
         HumanLanguageTechnologies,Volume1(LongandShortPapers),pages4026–4032,Minneapolis,Minnesota,
         June. Association for Computational Linguistics.
        Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading Wikipedia to answer open-domain
         questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume
         1: Long Papers), pages 1870–1879, Vancouver, Canada, July. Association for Computational Linguistics.
        Wenhu Chen, Hanwen Zha, Zhi yu Chen, Wenhan Xiong, Hong Wang, and Wei Wang. 2020. HybridQA: A
         dataset of multi-hop question answering over tabular and textual data. ArXiv, abs/2004.07347.
        Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirec-
         tional transformers for language understanding. In Proceedings of the 2019 Conference of the North American
         ChapteroftheAssociationforComputationalLinguistics: HumanLanguageTechnologies,Volume1(Longand
         Short Papers), pages 4171–4186, Minneapolis, Minnesota, June. Association for Computational Linguistics.
        Dennis Diefenbach, Thomas Tanon, Kamal Singh, and Pierre Maret. 2017. Question answering benchmarks for
         Wikidata. 10.
               ´
        Luis Antonio Galarraga, Christina Teﬂioudi, Katja Hose, and Fabian Suchanek. 2013. AMIE: Association rule
         mining under incomplete evidence in ontological knowledge bases. In Proceedings of the 22nd International
         Conference on World Wide Web, WWW ’13, page 413–422, New York, NY, USA. Association for Computing
         Machinery.
        NaoyaInoue, Pontus Stenetorp, and Kentaro Inui. 2020. R4C: A benchmark for evaluating RC systems to get the
         right answer for the right reason. In Proceedings of the 58th Annual Meeting of the Association for Computa-
         tional Linguistics, pages 6740–6750, Online, July. Association for Computational Linguistics.
        PeterJansen,NiranjanBalasubramanian,MihaiSurdeanu,andPeterClark. 2016. What’sinanexplanation? Char-
         acterizing knowledge and inference requirements for elementary science exams. In Proceedings of COLING
         2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 2956–2965,
         Osaka, Japan, December. The COLING 2016 Organizing Committee.
        Robin Jia and Percy Liang. 2017. Adversarial examples for evaluating reading comprehension systems. In
         Proceedingsofthe2017ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages2021–2031,
         Copenhagen, Denmark, September. Association for Computational Linguistics.
        Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke
         Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A robustly optimized BERT pretraining approach. vol-
         umeabs/1907.11692.
        Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Prismatic Inc, Steven J. Bethard, and David
         Mcclosky. 2014. The Stanford CoreNLP natural language processing toolkit. In In ACL, System Demonstra-
         tions.
        SewonMin,EricWallace,SameerSingh,MattGardner,HannanehHajishirzi,andLukeZettlemoyer. 2019. Com-
         positional questions do not necessitate multi-hop reasoning. In Proceedings of the 57th Annual Meeting of the
         Association for Computational Linguistics, pages 4249–4257, Florence, Italy, July. Association for Computa-
         tional Linguistics.
                              6619
