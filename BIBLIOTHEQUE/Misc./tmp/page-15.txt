                                           15
    References
     1. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.
      In: CVPR. (2016)
     2. Nair, V., Hinton, G.E.: Rectiﬁed linear units improve restricted boltzmann ma-
      chines. In: ICML. (2010)
     3. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
      Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: ImageNet Large
      Scale Visual Recognition Challenge. IJCV (2015)
     4. Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll´ar, P.,
      Zitnick, C.L.: Microsoft COCO: Common objects in context. In: ECCV. (2014)
     5. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation
      (1997)
     6. Srivastava, R.K., Greﬀ, K., Schmidhuber, J.: Highway networks. In: ICML work-
      shop. (2015)
     7. Srivastava, R.K., Greﬀ, K., Schmidhuber, J.: Training very deep networks. In:
      NIPS. (2015)
     8. Ioﬀe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by
      reducing internal covariate shift. In: ICML. (2015)
     9. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.,
      Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural
      computation (1989)
    10. Krizhevsky, A.: Learning multiple layers of features from tiny images. Tech Report
      (2009)
    11. Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R.:
      Improving neural networks by preventing co-adaptation of feature detectors.
      arXiv:1207.0580 (2012)
    12. Clevert, D.A., Unterthiner, T., Hochreiter, S.: Fast and accurate deep network
      learning by exponential linear units (ELUs). In: ICLR. (2016)
    13. Graham, B.: Fractional max-pooling. arXiv:1412.6071 (2014)
    14. Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M.: Striving for simplic-
      ity: The all convolutional net. arXiv:1412.6806 (2014)
    15. Lin, M., Chen, Q., Yan, S.: Network in network. In: ICLR. (2014)
    16. Lee, C.Y., Xie, S., Gallagher, P., Zhang, Z., Tu, Z.: Deeply-supervised nets. In:
      AISTATS. (2015)
    17. Romero, A., Ballas, N., Kahou, S.E., Chassang, A., Gatta, C., Bengio, Y.: Fitnets:
      Hints for thin deep nets. In: ICLR. (2015)
    18. Mishkin, D., Matas, J.: All you need is a good init. In: ICLR. (2016)
    19. Szegedy, C., Vanhoucke, V., Ioﬀe, S., Shlens, J., Wojna, Z.: Rethinking the incep-
      tion architecture for computer vision. In: CVPR. (2016)
    20. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D.,
      Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. In: CVPR. (2015)
    21. Szegedy, C., Ioﬀe, S., Vanhoucke, V.: Inception-v4, inception-resnet and the impact
      of residual connections on learning. arXiv:1602.07261 (2016)
    22. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale
      image recognition. In: ICLR. (2015)
    23. He, K., Zhang, X., Ren, S., Sun, J.: Delving deep into rectiﬁers: Surpassing human-
      level performance on imagenet classiﬁcation. In: ICCV. (2015)
