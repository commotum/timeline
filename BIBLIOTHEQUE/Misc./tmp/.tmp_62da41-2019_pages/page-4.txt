                                                  Banino, Balaguer, Blundell
                                                    N
                                               L=XpL(y,yˆ )+βKL(p ||p (λ ))                                   (3)
                                                        n       n     |     n{zG p }
                                                   n=1                      L
                                                   |     {z      }           Reg
                                                         L
                                                          Rec
                        where L is a pre-deﬁned loss for the prediction (usually mean squared error, or cross-
                    entropy); and λp is a hyper-parameter that deﬁnes a geometric prior distribution p (λp) on
                                                                                                        G
                    the halting policy (truncated at N). LRec is the expectation of the pre-deﬁned reconstruction
                    loss L across halting steps. L     is the KL divergence between the distribution of halting
                                                   Reg
                    probabilities p  and the prior (a geometric distribution truncated at N, parameterized by
                                   n
                    λp). This hyper-parameter deﬁnes a prior on how likely it is that the network will halt at
                    each step. This regularisation serves two purposes. First, it biases the network towards the
                    expected prior number of steps 1/λp. Second, it provides an incentive to give a non-zero
                    probability to all possible number of steps, thus promoting exploration.
                    2.5 Evaluation sampling
                    At evaluation, the network samples on a step basis from the halting Bernoulli random
                    variable Λ ∼ B(p = λ ) to decide whether to continue or to halt. This process is repeated
                              n            n
                    on every step n until a “halt” outcome is sampled, at which point the output y = y
                                                                                                                n
                    becomes the ﬁnal prediction of the network. If a maximum number of steps N is reached,
                    the network is automatically halted and produces a prediction y = y .
                                                                                          N
                    3. Results
                    3.1 Parity
                    In this section we are reporting results on the parity task as introduced in the original ACT
                    paper (Graves, 2016). Out of the four tasks presented in that paper we decided to focus on
                    parity as it was the one showing greater beneﬁt from adaptive compute. In our instantiation
                    of the parity problem the input vectors had 64 elements, of which a random number from
                    1 to 64 were randomly set to 1 or −1 and the rest were set to 0. The corresponding target
                    was 1 if there was an odd number of ones and 0 if there was an even number of ones. We
                    refer the reader to the original ACT paper for speciﬁc details on the tasks (Graves, 2016).
                    Also, please refer to Appendix B for further training and evaluation details.
                        In ﬁgure 1a we can see that PonderNet achieved better accuracy than ACT on the parity
                    task and it did so with a more eﬃcient use of thinking time (1a at the bottom). Moreover,
                    if we consider the total computation time during training (ﬁgure 1c) we can see that, in
                    comparison to ACT, PonderNet employed less computation and achieved higher score.
                        Another analysis we performed on this version of the parity task was to look at the
                    eﬀect of the prior probability on performance. In ﬁgure 2b we show that the only case
                    where PonderNet could not solve the task is when the prior (λp) was set to 0.9, that is when
                    the average number of thinking steps given as prior was roughly 1 (1/0.9). Interestingly,
                    when the prior (λp) was set to 0.1, hence starting with a prior average thinking time of 10
                    steps (1/0.1), the network managed to overcome this and settled to a more eﬃcient average
                    thinking time of roughly 3 steps (ﬁgure 2c). These results are important as they show that
                                                                  4
