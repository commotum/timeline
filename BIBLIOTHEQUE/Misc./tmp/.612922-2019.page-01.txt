                                         DROP:AReadingComprehensionBenchmark
                                         Requiring Discrete Reasoning Over Paragraphs
                                                               ♣                       ♦∗                      ♥
                                               DheeruDua ,YizhongWang ,PradeepDasigi ,
                                                                  ♥+                      ♣                           ♠
                                         Gabriel Stanovsky           , Sameer Singh , and Matt Gardner
                                                        ♣University of California, Irvine, USA
                                                          ♦Peking University, Beijing, China
                                    ♥Allen Institute for Artiﬁcial Intelligence, Seattle, Washington, USA
                                      ♠Allen Institute for Artiﬁcial Intelligence, Irvine, California, USA
                                              +University of Washington, Seattle, Washington, USA
                                                                     ddua@uci.edu
                                           Abstract                               this new benchmark, which we call DROP, a sys-
                                                                                  temis given a paragraph and a question and must
                        Reading comprehension has recently seen                   performsomekindofDiscreteReasoningOverthe
                        rapidprogress, withsystemsmatchinghumans                  text in the Paragraph to obtain the correct answer.
                        onthemostpopulardatasetsforthetask. How-                     These questions that require discrete reasoning
                        ever, a large body of work has highlighted                (such as addition, sorting, or counting; see Table 1)
                        the brittleness of these systems, showing that            are inspired by the complex, compositional ques-
                        there is much work left to be done. We in-                tions commonly found in the semantic parsing lit-
                        troduce a new English reading comprehension
                        benchmark, DROP, which requires Discrete                  erature. We focus on this type of questions because
                        Reasoning Over the content of Paragraphs. In              they force a structured analysis of the content of the
                        this crowdsourced, adversarially-created, 96k-            paragraph that is detailed enough to permit reason-
                        question benchmark, a system must resolve                 ing. Our goal is to further paragraph understand-
                        referencesinaquestion,perhapstomultiplein-                ing; complex questions allow us to test a system’s
                        put positions, and perform discrete operations            understanding of the paragraph’s semantics.
                        over them (such as addition, counting, or sort-              DROP is also designed to further research on
                        ing). These operations require a much more
                        comprehensiveunderstandingofthecontentof                  methods that combine distributed representations
                        paragraphs than what was necessary for prior              with symbolic, discrete reasoning. In order to
                        datasets.   We apply state-of-the-art methods             do well on this dataset, a system must be able to
                        from both the reading comprehension and se-               ﬁndmultiple occurrences of an event described in
                        mantic parsing literatures on this dataset and            a question (presumably using some kind of soft
                        showthatthebestsystemsonlyachieve32.7%                    matching), extract arguments from the events, then
                        F on our generalized accuracy metric, while
                          1                                                       perform a numerical operation such as a sort, to
                        expert human performance is 96.4%. We ad-                 answer a question like “Who threw the longest
                        ditionally present a new model that combines
                        reading comprehension methods with simple                 touchdown pass?”.
                        numerical reasoning to achieve 47.0% F .                     Weconstructed this dataset through crowdsourc-
                                                                   1
                                                                                  ing, ﬁrst collecting passages from Wikipedia that
                    1   Introduction                                              are easy to ask hard questions about, then encour-
                    The task of reading comprehension, where sys-                 aging crowd workers to produce challenging ques-
                    tems must understand a single passage of text well            tions. This encouragement was partially through
                    enough to answer arbitrary questions about it, has            instructions given to workers, and partially through
                    seen signiﬁcant progress in the last few years, so            the use of an adversarial baseline: we ran a base-
                    muchthat the most popular datasets available for              line reading comprehension method (BiDAF) (Seo
                    this task have been solved (Chen et al., 2016; De-            et al., 2017) in the background as crowd workers
                    vlin et al., 2019). We introduce a substantially              werewritingquestions,requiringthemtogiveques-
                    morechallenging English reading comprehension                 tions that the baseline system could not correctly
                    dataset aimed at pushing the ﬁeld towards more                answer. This resulted in a dataset of 96,567 ques-
                    comprehensive analysis of paragraphs of text. In              tions from a variety of categories in Wikipedia,
                                                                                  with a particular emphasis on sports game sum-
                        ∗                                                         maries and history passages. The answers to the
                        WorkdoneasaninternattheAllenInstituteforArtiﬁcial
                    Intelligence in Irvine, California.                           questions are required to be spans in the passage or
                                                                             2368
                                                      Proceedings of NAACL-HLT 2019, pages 2368–2378
                                                                               c
                                Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics
