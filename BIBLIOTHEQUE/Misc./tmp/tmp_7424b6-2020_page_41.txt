        state-of-the-art ﬁne-tuned systems, as well as generating high-quality samples and strong qualitative performance at
        tasks deﬁned on-the-ﬂy. We documented roughly predictable trends of scaling in performance without using ﬁne-tuning.
        Wealsodiscussed the social impacts of this class of model. Despite many limitations and weaknesses, these results
        suggest that very large language models may be an important ingredient in the development of adaptable, general
        language systems.
        Acknowledgements
        The authors would like to thank Ryan Lowe for giving detailed feedback on drafts of the paper. Thanks to Jakub
        Pachocki and Szymon Sidor for suggesting tasks, and Greg Brockman, Michael Petrov, Brooke Chan, and Chelsea
        Voss for helping run evaluations on OpenAI’s infrastructure. Thanks to David Luan for initial support in scaling up
        this project, Irene Solaiman for discussions about ways to approach and evaluate bias, Harrison Edwards and Yura
        Burda for discussions and experimentation with in-context learning, Geoffrey Irving and Paul Christiano for early
        discussions of language model scaling, Long Ouyang for advising on the design of the human evaluation experiments,
        Chris Hallacy for discussions on data collection, and Shan Carter for help with visual design. Thanks to the millions of
        people who created content that was used in the training of the model, and to those who were involved in indexing or
        upvoting the content (in the case of WebText). Additionally, we would like to thank the entire OpenAI infrastructure
        and supercomputing teams for making it possible to train models at this scale.
                               41
