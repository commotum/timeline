                        Table 1: Model categorization, behavioral characteristics, and accuracy as a function of
                        trace length and problem difficulty. Tasks are classified as easy or hard based on whether
                        their difficulty is below or abovethemedianacrossalltasks. Tracelengthsarelabeledshort
                        or long using the model-specific median trace length computed over the entire task set.
                                                                                            Accuracy
                         Category       Model           Behavior                       Easy          Hard
                                                                                   Short  Long   Short  Long
                                        R1                                          0.95   0.72   0.61   0.48
                         Short horizon  DAPO-32B        Shorter is always better    0.80   0.54   0.05   0.05
                                        QwQ-32B                                     0.91   0.70   0.58   0.58
                                        GPT-OSS-120B    Shorter is better for easy  0.92   0.85   0.48   0.53
                         Longhorizon    Qwen3-32B       problemswhilelongeris       0.75   0.63   0.22   0.45
                                        R1-32B          better for hard problems    0.92   0.62   0.33   0.34
                         Non-reasoning  Qwen3-235B      Shorter is always better    0.90   0.52   0.51   0.20
                                        DeepSeek                                    0.47   0.22   0.12   0.06
                        the beam size N increases (Figure 1). For short-horizon models such as R1 and QwQ-32B,
                        accuracy drops sharply once N becomes larger than 2; for non-reasoning models there is
                        a similar, although milder, trend of performance drops as N increases. Even long-horizon
                        models like GPT-OSS-120B, and Qwen3-32B fail to benefit from beam expansion: their
                        accuracy curves flatten or decline as N increases. Since total token consumption—and
                        therefore total compute—increases with beam width, these results reveal a clear case of
                        inverse compute scaling, where allocating more test-time compute via larger beams either
                        harmsaccuracyoryieldsnobenefit.
                           Finding
                           Beamsearch performance degrades or remains the same with increasing beam size
                           for reasoning-focused datasets like AIME and GPQA.
                        3.2  Correlation of trace length with quality
                        It is crucial to understand how the trace length correlates with quality (as measured
                        through accuracy) in order to obtain a deeper understanding of length-based filtering
                        strategies like FFS and LFS. FFS and LFS are based on two diametrically opposite view-
                        points: shorter is better and longer is better. To investigate which hypothesis (or hypotheses)
                        hold for a given model, we report the accuracy for a given interval of trace lengths and
                        problem difficulties (Table 1). Note that the problem difficulty is measured by averaging
                        the accuracy over all models and traces (Section 2.5), while the reported accuracy is mea-
                        suredbyaveragingoveralloutputsforthespecificmodel. Akeyconsiderationisthatprob-
                        lem difficulty is confounded with trace length (Figure 3): short traces typically arise from
                        easier problems, whereas long traces tend to correspond to harder ones. To mitigate this
                        confounding effect, we restrict our analysis to tasks for which both short and long traces
                        areavailable. Foreachsuchdataset,wecomputeasingleaccuracyvalueforshortandlong
                        traces separately, and then average these values across datasets, thereby preventing differ-
                        ences in dataset size from disproportionately influencing the aggregated results. Based
                        on the ordering between these reported accuracies, we broadly classify the six reasoning
                        modelsaseithershort-horizonorlong-horizon. Whilethetwonon-reasoningmodelsboth
                        show short-horizon behavior, we choose to keep them separate from short-horizon mod-
                        els due to the significant differences in the post-training techniques employed (instruction
                        tuning vs. RL).
                        Acrossallmodels,weobserveaconsistentinvariant: foranygiventrace-lengthbucket,the
                        reportedaccuracyisalwayshigheroneasyproblemsthanonhardones. Thispatternisex-
                        pected,asproblemdifficultyisdefinedthroughaggregatedaccuracy,andharderquestions
                        naturally exhibit lower correctness rates.
                                                                  6
