                                                        Test-Time Learning for Large Language Models
               Table 3. Comparison experimental results on the ReasoningBench.     Table 4. Experimental results for the component of our proposed
                                                   ReasoningBench                  methodontheDomainBenchoftheAdaptEval. TheSELmeans
                  Method                   GSM8K       MetaMath     Logiqa         “Sample Efficient Learning Strategy” and the (·) indicates relative
                                                                                   improvement over the result in the previous column.
                  Llama3.2-3B-Instruct      0.7756      0.7976       0.4194          Version        Llama3-8B    Ours (w/o SEL)        Ours
                    •Tent                   0.7726      0.7412       0.4012
                    •EATA                   0.0032      0.0310       0.0284          Geography        0.2450       0.3190(+30.2%)  0.3212(+0.7%)
                    •COME                   0.7710      0.7308       0.4196          Agriculture      0.0834       0.1255(+50.5%)  0.1319(+5.1%)
                    •TLM(Ours)             0.9096       0.8818       0.4572          Medicine         0.1265       0.2326(+83.9%)  0.2372(+2.0%)
                  Llama3-8B-Instruct        0.7610      0.6912       0.4550          Finance          0.2329       0.3222(+38.3%)  0.3242(+0.6%)
                    •Tent                   0.7578      0.6550       0.4378          #Backwards          –            5000          4772(-4.6%)
                    •EATA                   0.0250      0.5454       0.2192
                    •COME                   0.7479      0.6460       0.2180
                    •TLM(Ours)              0.8074      0.7006       0.4868
                  Llama2-13B-chat           0.3458      0.2498       0.3992        rule, with a batch size of 1 and the learning rate of 5e−5/
                    •Tent                   0.2706      0.0040       0.2566        5e−5/1e−6forDomainBench/InstructionBench/ Reason-
                    •EATA                   0.3392      0.0572       0.2606                                                                     3
                    •COME                   0.3272      0.2646       0.2462        ingBench. The λ and P in Eqn. 6 are set to 0.10 and e .
                    •TLM(Ours)              0.3508      0.2576       0.4124                                  0
                  Qwen2.5-7B-Instruct       0.8378      0.7430       0.5952        Toimprovethestability of outputs produced by LLMs, we
                    •Tent                   0.8455      0.7412       0.5934        apply greedy decoding with a temperature of 0 across all
                    •EATA                   0.7098      0.0070       0.2172        experiments. More details in Supp. C.2. The source code is
                    •COME                   0.8556      0.7559       0.5908        available at https://github.com/Fhujinwu/TLM
                    •TLM(Ours)              0.8424      0.7560       0.6046
                                                                                   5.2. Comparison Experiments
                                                                                   Wecompare our proposed TLM, the original LLM, Tent,
               evaluate the LLM adaptability to specialized fields. 2) In-         EATA,andCOMEtodemonstratethesuperiorperformance
               structionBench contains three general-purpose instruction-          of our method. We conduct experiments on different types
               following datasets: Alpaca-GPT4, Dolly, and Instruction-            of datasets, including DomainBench, InstructionBench, and
               Wild, and focuses on the LLM adaptability to instruction-           ReasoningBench, as summarized in Table 2 and 3. More
               based tasks. 3) ReasoningBench comprises three reasoning            detailed results can be found in Supp. D.
               capability datasets: GSM8K, MetaMath, and Logiqa, and               OurproposedTLM isconsistentlybetterthantheorig-
               aims to assess the LLM logical reasoning and problem-               inal LLMs. From Table 2 and 3, our method consistently
               solving abilities. These datasets collectively form a diverse       outperforms the original LLMs across all types of datasets
               and challenging evaluation suite, designed to thoroughly            and different LLM architectures. For instance, on the four
               assess the effectiveness of TLM in adapting LLMs to tasks           datasets of DomainBench, the proposed TLM achieves at
               requiring vertical knowledge, instruction-following capabil-        least a 20.00% improvementovertheoriginalLLMs. Specif-
               ities, and logical reasoning under distribution shifts. More        ically, on the Geography dataset, our proposed TLM im-
               details can be found in Supp. B.                                    proves performance by a relative 20.79% (0.2395 →
               Metrics. We use Rouge-Lsum (R-Lsum) (Lin, 2004) as the              0.2893) compared to Llama3.2-3B-Instruct.
               evaluation metric for DomainBench and InstructionBench,             Superior performance on Domain Knowledge Adapta-
               while Exact Match (EM) (Chang et al., 2024) is used for             tion. To evaluate the effectiveness of our proposed TLM in
               ReasoningBench. More metrics can be found in Supp. C.1.             adapting to vertical domain knowledge, we conduct experi-
               LLMsandBaseline. WeuseadiverserangeofLLMsof                         mentsonDomainBench,whichincludesfourdatasets. From
               varying sizes and types, including Llama3.2-3B-Instruct,            Table 2, the results demonstrate that the proposed TLM out-
               Llama3-8B-Instruct (Dubey et al., 2024), Llama2-13B-Chat            performs the original LLMs, Tent, and EATA, achieving
               (Touvron et al., 2023a), and Qwen2.5-7B-Instruct (Yang              significant performance improvements. For example, in
               et al., 2024). We evaluate our TLM against the baseline             test-time updating of model parameters on Qwen2.5-7B-
               methods, Tent (Wang et al., 2021), EATA (Niu et al., 2022a),        Instruct, the proposed method yields a relatively 37.32%
               and COME(Zhangetal.,2025). They are state-of-the-art                (0.1203 → 0.1652) improvement on the Agriculture dataset
               TTAmethodsthatupdatemodelparametersusingunlabeled                   compared to the EATA.
               data. WeadaptTent,EATA,andCOMEtotheofflinesetting                   Superior performance on instruction-based task. As
               for a fair comparison. The implementation details can be            shown in Table 2, our proposed TLM achieves substan-
               found in the Supp. C.                                               tial improvements over the original LLMs and Tent across
               Implementation Details. We use AdamW as the update                  all instruction-based datasets. For instance, on the Alpaca-
                                                                                7
