484 » Unified Theories of Cagnition

neuroscience and cognitive psychology is connectionism. For all
I know, Jerry Feldman, in using the term new connectionism
(Feldman, 1979}, had in mind a double meaning—not only the con-
nectivity of neural networks, but a more intimate connection fi-
nally attained between brain and behavior. Let me, then, remark
on what I think is the relationship between Soar and connection-
ism (McClelland, Rumelhart, & the PDP Research Group, 1986;
Rumelhart, McClelland, & the PDP Research Group, 1986).

We need to distinguish three aspects of connectionism, which is,
after all, not all of a piece. First, connectionism is a commitment to
a particular neural-like computational technology. In a nutshell,
this technology consists of excitatory-inhibitory summing networks
with thresholds for behaving; and adjusting weights or thresholds
by experience for learning. Such ‘‘neural networks,"* as they are
called, are naturally parallel in operation and also consist of very
large numbes of elements—hence the massive parallelism of which
the connectionists always speak. It is unclear how realistic this is as
a model of biological neural circuit technology. In fact, its idealiza-
tions and its mismatch in level (basically, a neuron-level model is
stretched to cover neural-circuit-level systems) have given rise to a
vocal subgroup within connectionism that wants to convert the
endeavor into a study of general dynamic systems (Smolensky,
1988). Nevertheless, it is certainly a more realistic model of neural
technology than many other underlying technologies that could be
taken as the base for the cognitive band. In particular, it realizes
massive parallelism, fixed connectivity networks, and a continuous
medium, all of which seem important.

Second, connectionism is interested in a particular class of com-
putations that it deems natural to carry out with that technology.
Any even moderately general computational technology can be
used to realize a wide range of algorithms. The focus in connection-
ism is on constraint-satisfaction systems with hill climbing as the
major method for seeking equilibrium solutions. This focus persists
even across the very substantial differences in how knowledge is
encoded in the networks, namely, point representations, in which
each node in the net corresponds to a semantically meaningful con-
cept, and distributed representations, in which each node partici-
pates in many concepts and each concept is therefore spread across
many nodes. There is more variation in the algorithms to be used
for learning, such as the back-propagation model currently under-

