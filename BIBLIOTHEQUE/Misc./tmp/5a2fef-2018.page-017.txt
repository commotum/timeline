                                         With viewport                                Without Viewport
                                                      Figure 10: Mini Pacman Results.
                         Weusedatotalof20keysand20locks(i.e., colors) in our sampling pool to produce each level. Three main
                         factors determined the difﬁculty of the level: (1) the path length (i.e., number of locks) to the gem; (2) the
                         numberofdistractor branches; and (3) the path lengths of the distractor branches. For training we used solution
                         path lengths of at least 1 and up to 5, ensuring that an untrained agent would have a small probability of reaching
                         the goal by chance, at least on the easier levels. We sampled the number of distractor branches to be between 0
                         and 5, with a length of 1.
                         Theviewport observation was processed through two convolutional layers, with 12 and 24 kernels, and with
                         2×2kernelsizesandastrideof1. Eachlayer used a ReLU non-linearity. We used two extra feature maps to
                         tag the convolutional output with absolute spatial position (x and y) of each pixel/cell, with the tags comprising
                         evenly spaced values between −1 and 1. The resulting stack was then passed to the RMC, containing four
                         memories, four heads, a total memory size of 1024 (divided across heads and memories), a single pass of self
                         attention per step and scalar memory gating. For the baseline, we replaced the RMC with a 5 × 5 ConvLSTM
                         with 64 output channels, with 2 × 2 kernels and stride of 1.
                         Weusedthis architecture in an actor-critic set-up, using the distributed Importance Weighted Actor-Learner
                         Architecture [47]. The agent consists of 100 actors, which generate trajectories of experience, and one learner,
                         whichdirectly learns a policy π and a baseline function V , using the actors’ experiences. The model updates
                         were performed on GPU using mini-batches of 32 trajectories provided by the actors via a queue. The agent had
                         an entropy cost of 0.005, discount (γ) of 0.99 and unroll length of 40 steps. The learning rate was tuned, taking
                         values between 1e−5 and 2e−4. Informally, we note that we could replicate these results using an A3C setup,
                         though training took longer.
                         Theagentreceived a reward of +10 for collecting the gem, +1 for opening a box in the solution path and −1 for
                         opening a distractor box. The level was terminated immediately after collecting the gem or opening a distractor
                         box.
                         A.3.1  Results
                         Wetrained an Importance Weighted Actor-Learner Architectures agent augmented with the RMC on BoxWorld
                         levels that required opening at least 1 and up to 5 boxes. The number of distractor branches was randomly
                         sampled from 0 to 5. This agent achieved high performance in the task, correctly solving 98% of the levels after
                         1e9steps. The same agent augmented instead with a ConvLSTM performed signiﬁcantly worse, reaching only
                         73%.
                         A.4   LanguageModeling
                         Wetrained the Recurrent Memory Core with Adam, using a learning rate of 0.001 and gradients were clipped to
                         have a maximum L2 norm of 0.1. Backpropagation-through-time was truncated to a window-length of 100. The
                         model was trained with 6 Nvidia Tesla P100 GPUs synchronously. Each GPU trained with a batch of 64 and so
                         the total batch size was 384. We used 512 (with 0.5 dropout) as the word embedding sizes, and tied the word
                         embedding matrix parameters to the output softmax.
                         Wesweptoverthefollowing model architecture parameters:
                               • Total units in memory {1000,1500,2000,2500,3000}
                               • Attention heads {1,2,3,4,5}
                                                                     17
