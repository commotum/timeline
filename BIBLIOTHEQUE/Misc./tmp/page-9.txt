                                      Table 4: Per-pixel vs. mask classiﬁcation for semantic segmentation. All models use 150 queries
                                      for a fair comparison. We evaluate the models on ADE20K val with 150 categories. 4a: PerPixel-
                                      Baseline+ and MaskFormer-ﬁxed use similar ﬁxed matching (i.e., matching by category index), this
                                      result conﬁrms that the shift from per-pixel to mask classiﬁcation is the key. 4b: bipartite matching is
                                      not only more ﬂexible (can make less prediction than total class count) but also gives better results.
                                                   (a) Per-pixel vs. mask classiﬁcation.                   (b) Fixed vs. bipartite matching assignment.
                                                                                            St                                                               St
                                                                         mIoU            PQ                                                 mIoU          PQ
                                                  PerPixelBaseline+    41.9           28.3               MaskFormer-ﬁxed                 43.7          30.3
                                                  MaskFormer-ﬁxed      43.7 (+1.8)    30.3 (+2.0)        MaskFormer-bipartite (ours) 44.2 (+0.5)       33.4 (+3.1)
                                      Number of queries. The table to the right                                                   ADE20K        COCO-Stuff    ADE20K-Full
                                                                                                                                           St             St              St
                                      shows results of MaskFormer trained with a                               # of queries     mIoU PQ        mIoU PQ        mIoU PQ
                                      varying number of queries on datasets with dif-                       PerPixelBaseline+    41.9   28.3    34.2   24.6    13.9    9.0
                                      ferent number of categories. The model with                                   20           42.9   32.6    35.0   27.6    14.1    10.8
                                     100queriesconsistentlyperformsthebestacross                                    50           43.9   32.7    35.5   27.9    15.4    11.1
                                      the studied datasets. This suggest we may not                                100           44.5   33.4    37.1   28.9    16.0    11.9
                                      need to adjust the number of queries w.r.t. the                              150           44.2   33.4    37.0   28.9    15.5    11.5
                                      numberofcategories or datasets much. Interest-                               300           43.5   32.3    36.1   29.1    14.2    10.3
                                      ingly, even with 20 queries MaskFormer outper-                              1000           35.4   26.7    34.4   27.6     8.0     5.8
                                      forms our per-pixel classiﬁcation baseline.
                                      Wefurther calculate the number of classes which are on average present in a training set image.
                                      Weﬁndthesestatistics to be similar across datasets despite the fact that the datasets have different
                                      numberoftotal categories: 8.2 classes per image for ADE20K (150 classes), 6.6 classes per image
                                      for COCO-Stuff-10K (171 classes) and 9.1 classes per image for ADE20K-Full (847 classes). We
                                      hypothesize that each query is able to capture masks from multiple categories.
                                      Theﬁguretothe right shows the num-
                                      ber of unique categories predicted by                        25
                                      each query (sorted in descending or-                         20
                                                                                              by   15
                                      der) of our MaskFormer model on the                          10
                                      validation sets of the corresponding                         5
                                      datasets. Interestingly, the number of                     set0   0            20            40            60            80           100
                                                                                              predicted                     (a) ADE20K(150classes)
                                      unique categories per query does not                         35
                                                                                                 alidation30
                                      follow a uniform distribution: some                        v 25
                                                                                              classes20
                                      queries capture more classes than oth-                     on15
                                                                                                   10
                                                                                                   5
                                      ers.   We try to analyze how Mask-                      uniquequery00          20            40            60            80           100
                                      Former queries group categories, but                    of                        (b) COCO-Stuff-10K (171 classes)
                                      wedonotobserveanyobviouspattern:                           each100
                                                                                                   80
                                      there are queries capturing categories                  Number60
                                      with similar semantics or shapes (e.g.,                      40
                                                                                                   20
                                     “house” and “building”), but there are                         0   0            20            40            60            80           100
                                      also queries capturing completely dif-                                              (c) ADE20K-Full (847 classes)
                                      ferent categories (e.g., “water” and “sofa”).
                                      NumberofTransformerdecoderlayers. Interestingly,MaskFormerwithevenasingleTransformer
                                      decoder layer already performs well for semantic segmentation and achieves better performance than
                                      our 6-layer-decoder PerPixelBaseline+. For panoptic segmentation, however, multiple decoder layers
                                      are required to achieve competitive performance. Please see the appendix for a detailed discussion.
                                      5     Discussion
                                      Ourmaingoalistoshowthatmaskclassiﬁcation is a general segmentation paradigm that could be a
                                      competitive alternative to per-pixel classiﬁcation for semantic segmentation. To better understand its
                                      potential for segmentation tasks, we focus on exploring mask classiﬁcation independently of other
                                      factors like architecture, loss design, or augmentation strategy. We pick the DETR [3] architecture
                                      as our baseline for its simplicity and deliberately make as few architectural changes as possible.
                                      Therefore, MaskFormer can be viewed as a “box-free” version of DETR.
                                                                                                         9
