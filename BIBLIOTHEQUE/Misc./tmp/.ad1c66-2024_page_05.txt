                 T. Han et al.                                                                                                              International Journal of Applied Earth Observation and Geoinformation 133 (2024) 104105 
                 Fig. 6. Pipeline of weighted feature formation process. The proposed method is able to adaptively feedback the graph with structural importance according to the weighted
                 features, and adjust the graph by dynamically updating the weights.
                 shown in Fig. 5. Given the input feature Ì†µÌ∞πÌ†µÌ±† at Ì†µÌ±† stage, max pooling
                 is performed within the neighborhood of current center point. The
                 processing of graph pooling is formulated as follows:
                 Ì†µÌ∞π‚Ä≤Ì†µÌ±† = Ì†µÌ±öÌ†µÌ±éÌ†µÌ±• ‚àí Ì†µÌ±ùÌ†µÌ±úÌ†µÌ±úÌ†µÌ±ôÌ†µÌ±ñÌ†µÌ±õÌ†µÌ±î(Ì†µÌ±á Ì†µÌ±† ; Ì†µÌ±ó ‚àà Ì†µÌ±Å(Ì†µÌ±ñ))                                                         (1)
                                                    Ì†µÌ±ñÌ†µÌ±ó
                 where Ì†µÌ±Å represents the number of points in the local point set Ì†µÌ±É =
                                                              3
                 {Ì†µÌ±ÉÌ†µÌ±õ|Ì†µÌ±õ = 1,2,‚Ä¶,Ì†µÌ±Å;Ì†µÌ±ÉÌ†µÌ±õ ‚àà R }, Ì†µÌ±ó denotes the neighbors of the center
                 point Ì†µÌ±ñ, and Ì†µÌ±áÌ†µÌ±† represents the output of AGT block. As per Eq. (1),
                 the relative positional relationships within the local neighborhood can
                 embed spatial information into neighbor features in a non-learnable
                 manner. Following PointMeta (Lin et al., 2023), max pooling as a
                 special form of self-attention, exhibits sparsity and comparable feature                                                                         Fig. 7. Illustration of graph attention with details.
                 aggregation capability to learnable aggregation functions.
                       Through layer-wise graph pooling for point cloud down-sampling,
                 the output feature dimensions at each stage are respectively [Ì†µÌ±Å,32],                                                     is represented as Ì†µÌª•Ì†µÌ±ì               = Ì†µÌ∞π ‚àí Ì†µÌ∞π . Therefore, the weighted feature of
                 [Ì†µÌ±Å‚àï4,64], [Ì†µÌ±Å‚àï16,128], [Ì†µÌ±Å‚àï64,256], and [Ì†µÌ±Å‚àï256,512], where the first                                                                                     Ì†µÌ±ñÌ†µÌ±ó       Ì†µÌ±ñ      Ì†µÌ±ó
                 parameter represents the number of points, the second represents the                                                      neighboring point Ì†µÌ±ó with respect to vertex Ì†µÌ±ñ is formulated as Eq. (2):
                 feature channel dimension, and Ì†µÌ±Å denotes the number of points in the                                                     Ì†µÌª•Ì†µÌ∞π   =Ì†µÌ±ÄÌ†µÌ∞øÌ†µÌ±É(Ì†µÌª•Ì†µÌ±ì         ‚äïÌ†µÌª•Ì†µÌ±ù )                                                                         (2)
                 original input point cloud.                                                                                                   Ì†µÌ±ñÌ†µÌ±ó                 Ì†µÌ±ñÌ†µÌ±ó       Ì†µÌ±ñÌ†µÌ±ó
                       For the point-wise segmentation, we adopt the U-Net framework                                                       where ‚äï denotes the feature concatenation by channels. We implicitly
                 to design network that couples the encoder and decoder. The role of                                                       embed spatial information with relative positional relationships into
                 decoder is to interpolate the learned features with nearest neighbor                                                      the features. Later, different weights for various similarities are con-
                 interpolation to match the resolution of original point cloud. During                                                     structed based on relative position and feature differences, as shown in
                 this process, in Ì†µÌ±† stage, we search for three nearest neighbors of Ì†µÌ±† ‚àí 1                                                Eq. (3):
                 stage. Then, we calculate the weighted sum of features for these three                                                    Ì†µÌ±ä = Ì†µÌ±íÌ†µÌ±•Ì†µÌ±ù(Ì†µÌ∞πÌ†µÌ±ñÌ†µÌ±ó,Ì†µÌ±ò)                                                                                      (3)
                 nearest neighbors‚Äô distance to achieve feature mapping. The decoder                                                          Ì†µÌ±ñÌ†µÌ±ó   ‚àëÌ†µÌ±íÌ†µÌ±•Ì†µÌ±ù(Ì†µÌ∞πÌ†µÌ±ó,Ì†µÌ±ò)
                 is organized with a series of interpolation modules corresponding to                                                      where Ì†µÌ±ò represents the Ì†µÌ±òth channel to ensure the independence of
                 the encoder. These modules perform continuous interpolation to map                                                        channel features. Simultaneously, normalization is used to eliminate
                 down-sampled point set to the scale of the layer with higher reso-                                                        spatial differences caused by different scales. In contrast to traditional
                 lution. Therefore, the decoder stages are labeled to correspond with
                 the encoder as {Ì†µÌ±Ü‚Ä≤,Ì†µÌ±Ü‚Ä≤,Ì†µÌ±Ü‚Ä≤,Ì†µÌ±Ü‚Ä≤,Ì†µÌ±Ü‚Ä≤}. Additional skip connections fuse the                                                convolutional features, the obtained Ì†µÌ±äÌ†µÌ±ñÌ†µÌ±ó is a covariance matrix that
                                              1    2    3     4    5                                                                       records the relationships of point features. As shown in Fig. 6, the
                 features of corresponding scales between the encoder and decoder. In                                                      weighted feature is able to adaptively allocate weights for feature ag-
                 the final stage of the decoder, feature vector is computed for each point,                                                gregation based on the spatial position of points and feature differences,
                 and then MLP is employed to generate final segmentation results with                                                      preserving the spatial structure of objects.
                 Ì†µÌ±ÅÌ†µÌ±êÌ†µÌ±ôÌ†µÌ±† dimension.                                                                                                            Inspired by Point Transformer (Zhao et al., 2021), we design graph
                 3.2. Adaptive graph transformer block                                                                                     attention layer, as shown in Fig. 7. The input to this layer includes
                                                                                                                                           Ì†µÌ∞πÌ†µÌ±ñ, weighted feature Ì†µÌ±äÌ†µÌ±ñÌ†µÌ±ó, and the relative position Ì†µÌª•Ì†µÌ±ùÌ†µÌ±ñÌ†µÌ±ó. Attention
                       The Adaptive Graph Transformer (AGT) block is illustrated in                                                        calculation is performed using Ì†µÌ∞πÌ†µÌ±ñ as the query, Ì†µÌ±äÌ†µÌ±ñÌ†µÌ±ó as key and value,
                 Fig. 4(b). This module consists of multiple layers, including MLP,                                                        and Ì†µÌª•Ì†µÌ±ùÌ†µÌ±ñÌ†µÌ±ó as the position embedding, as description in Eq. (4):
                 graph attention layer, position embedding, graph pooling, and residual                                                    Ì†µÌ∞¥Ì†µÌ±°Ì†µÌ±°Ì†µÌ±õ = Ì†µÌ±†Ì†µÌ±úÌ†µÌ±ìÌ†µÌ±°Ì†µÌ±öÌ†µÌ±éÌ†µÌ±•((Ì†µÌºôÌ†µÌ∞πÌ†µÌ±ñ + Ì†µÌª•Ì†µÌ±ùÌ†µÌ±ñÌ†µÌ±ó) ‚ãÖ Ì†µÌºëÌ†µÌ±äÌ†µÌ±ñÌ†µÌ±ó)Ì†µÌ±äÌ†µÌ±ñÌ†µÌ±ó                                             (4)
                 connections. Given an input set of points Ì†µÌ±É = {Ì†µÌ±ÉÌ†µÌ±õ|Ì†µÌ±õ = 1,2,‚Ä¶,Ì†µÌ±Å;Ì†µÌ±ÉÌ†µÌ±õ ‚àà
                 R3}, where Ì†µÌ±Å denotes the number of points. Its corresponding features                                                    where Ì†µÌºô and Ì†µÌºë denote the MLP function. Relative position Ì†µÌª•Ì†µÌ±ùÌ†µÌ±ñÌ†µÌ±ó as
                 are formulated as Ì†µÌ∞πÌ†µÌ±É ‚àà RÌ†µÌ±ë, where Ì†µÌ±ë denotes the dimension of features.                                                 explicit position embedding is able to avoid the issue of imbalanced
                 We construct graph Ì†µÌ∞∫ = (Ì†µÌ±â,Ì†µÌ∞∏) in the point cloud, Ì†µÌ±â ‚àà Ì†µÌ±É represents                                                    neighborpoints‚Äôfeature caused by implicit position embedding. Finally,
                 the set of vertices, and Ì†µÌ∞∏ ‚äÜ |Ì†µÌ±â | √ó |Ì†µÌ±â | represents edge sets. Due to the                                              the output of graph attention is formulated as Eq. (5):
                 density-independent nature of the fixed-radius sampling strategy with                                                     Ì†µÌ±á   =Ì†µÌ±ÅÌ†µÌ±úÌ†µÌ±üÌ†µÌ±ö(Ì†µÌ∞¥Ì†µÌ±°Ì†µÌ±°Ì†µÌ±õ + Ì†µÌºôÌ†µÌ∞π )                                                                            (5)
                 point cloud, we employ the fix-radius farthest point sampling strategy                                                      Ì†µÌ±ñÌ†µÌ±ó                            Ì†µÌ±ñ
                 to select Ì†µÌ±Å(Ì†µÌ±ñ) = {Ì†µÌ±ó;(Ì†µÌ±ó,Ì†µÌ±ñ) ‚àà Ì†µÌ∞∏} ‚à™ {Ì†µÌ±ñ} neighbor points for each vertex                                                    We follow the strategy of ASSANet (Qian et al., 2021), applying
                 Ì†µÌ±ñ, determining the local geometric structure of each point set. We use                                                   an MLP before determining the neighborhood to reduce floating-point
                 Ì†µÌª•Ì†µÌ±ùÌ†µÌ±ñÌ†µÌ±ó to represent the positional offset between vertex Ì†µÌ±ñ and its neighbor                                            calculations. However, this strategy cannot set relative position as input
                 vertex Ì†µÌ±ó. Moreover, we use MLP to extract features for vertex Ì†µÌ±ñ and                                                     to the MLP, so the weighted features implicitly incorporating position
                 vertex Ì†µÌ±ó, denoted as Ì†µÌ∞πÌ†µÌ±ñ and Ì†µÌ∞πÌ†µÌ±ó, respectively. The feature difference                                                 information is able to naturally handle this. In summary, given Ì†µÌ±É and
                                                                                                                                      5 
