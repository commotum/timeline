                                                                        Perceptivity                              Adaptability               Interactivity
                                 Model                    Memory Understanding        Interference   Rephrasing    Reflection   Reasoning    Questioning
                                                   Avg.     CM        SI      AR       TS     CC     CR     FR     SC     SA    MR GR IC             PI
                            Llama2-7B-Chat         6.53     7.64     6.21    7.92     8.23   8.50    8.32   8.56   8.45  4.97   1.88   3.83  5.23    5.11
                             Qwen-7B-Chat          7.12     7.65     7.75    8.73     8.42   8.76    8.89   9.16   8.49  7.28   2.25   3.57  5.41    6.24
                             ChatGLM2-6B           5.56     6.14     4.69    7.27     6.13   6.26    7.47   7.98   6.97  4.19   2.11   3.00  5.16    4.90
                             ChatGLM3-6B           6.47     7.16     5.42    8.21     7.43   8.03    8.38   8.81   7.40  5.63   2.60   3.21  6.19    5.61
                        InternLM2-Chat-7B-SFT      6.69     7.51     6.26    8.01     8.06   8.70    8.50   8.50   7.68  6.16   3.47   4.48  4.92    4.76
                               Yi-6B-Chat          6.93     7.57     5.27    8.69     8.37   8.76    8.43   8.44   7.49  7.85   2.18   3.80  7.30    6.00
                         Mistral-7B-Instruct-v0.2  6.95     7.66     5.64    8.09     8.30   9.35    8.69   8.59   8.16  7.33   2.58   4.52  5.80    5.66
                            Vicuna-13B-v1.5        6.37     7.06     5.62    7.81     7.45   8.79    7.96   7.72   7.47  6.70   2.31   4.03  5.05    4.80
                             Baize-13B-v2          6.12     6.78     5.15    7.86     7.40   8.07    7.96   8.15   7.24  6.32   1.67   3.69  4.35    4.95
                           UltraLM-13B-v2.0        4.61     4.66     4.89    5.99     6.49   8.48    2.87   2.53   6.70  5.27   1.46   2.34  4.13    4.11
                            Llama2-13B-Chat        7.15     8.03     7.11    9.00     9.39   8.81    9.07   9.11   7.63  7.60   1.75   3.16  6.07    6.23
                            Qwen-14B-Chat          7.82     8.33     8.36    9.04     9.22   9.50    9.12   9.39   8.41  7.97   3.50   4.55  8.21    6.12
                          Baichuan2-13B-Chat       7.00     7.71     6.38    8.92     8.36   9.07    9.10   8.95   7.75  6.57   2.50   3.65  6.95    5.15
                        InternLM2-Chat-20B-SFT     6.95     7.35     6.44    8.08     8.05   9.10    8.59   8.55   7.62  7.36   4.05   5.24  4.99    4.99
                              Yi-34B-Chat          8.10     8.55     6.79    9.34     9.84   9.34    9.08   9.38   9.01  9.04   4.07   5.90  8.51    6.39
                       Mixtral-8x7B-Instruct-v0.1  7.38     7.86     5.94    8.49     9.01   9.52    8.91   9.01   8.69  7.78   4.19   5.14  6.03    5.36
                                GPT-3.5            7.99     8.77     7.67    7.67     9.68   9.87    9.56   9.51   9.18  7.23   4.48   5.31  8.57    6.32
                                 GPT-4             8.86     8.88     8.99    9.58     9.83   9.98    9.54   9.57   9.36  9.52   7.15   7.17  9.00    6.64
                                  Avg.             6.92     7.52     6.37    8.26     7.72   8.24    8.36   8.44   7.98  6.93   3.61   4.84  6.22    5.52
                     Table 3: The performance of different LLMs on the 13 multi-turn dialogue tasks in our MT-Bench-101. Due to
                     space constraints, the 13 tasks are represented by their corresponding acronyms.
                                     Interference                                Interference                               Interference
                                                      Understanding                              Understanding                              Understanding
                       Paraphrasing                                Paraphrasing                               Paraphrasing
                                             0 2 4 6 8 10                                0 2 4 6 8 10                               0 2 4 6 8 10
                                                          Memory                                      Memory                                     Memory
                         Reflection                                  Reflection                                 Reflection
                                                     Questioning                                Questioning                                 Questioning
                                       Reasoning                                  Reasoning                                   Reasoning
                                Yi-6B             ChatGLM3-6B               Llama2-13B       Baichuan2-13B                GPT-4        GPT-3.5
                                ChatGLM2-6B       Mistral-7B                Qwen-14B         Vicuna-13B                   Yi-34B       Mixtral-8Ã—7B
                                                Figure 3: Performance of various LLMs for each ability dimension.
                     Chat-Specific Models             AsshowninTable3,the                  manceofmodelsshowadeclinebetweenthefirst
                     chat-specific language models Baize, and UltraLM                      turn and subsequent turns. This suggests that in
                     do not demonstrate exceptional performance on                         multi-turn dialogue tasks, models tend to exhibit a
                     our benchmark. In fact, their capabilities appear to                  greater propensity to forget the content of previous
                     be outstripped by other large language models of                      turns or to develop comprehension biases as the
                     comparablesize. Suchinsightsindicatethatdespite                       conversation progresses. Figure 4b also illustrates
                     being specialized for conversational tasks, these                     a notable decrease in performance from the first
                     chat-specific models require further development                      to the second turn in topic shift and content con-
                     to effectively handle the multi-turn scenarios.                       fusion tasks. This drop is attributed to the second
                                                                                           turn marking the onset of interference, leading to
                     Per-Turn Performance                To investigate the im-            confusion for the model. As shown in Figure 4c,
                     pact of turn count on model performance across                       wenoteanupwardtrendinmodelperformanceas
                     different tasks, we calculated the average scores                     the number of turns increases in separate input, di-
                     of models for each dialogue turn within various                       rective clarification, and proactive interaction. This
                     tasks. As shown in Figure 4a and 4b, in content                       phenomenondoesnotreflectatrueenhancementin
                     rephrasing, format rephrasing, context memory,                        performance throughout the dialogue. Rather, it oc-
                     and anaphora resolution tasks, the average perfor-                    curs because using the golden context as historical
                                                                                     7426
