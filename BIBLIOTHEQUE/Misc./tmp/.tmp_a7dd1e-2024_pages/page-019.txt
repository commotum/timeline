         Please help me generate multiple groups of multi-turn dialogues based on a given dialogue
         scenario, mainly to evaluate the model’s ability to resist interference from the above. Each round
         of dialogue requires topic shifting. For example, the first round of conversations revolves around
         a topic. During the second round of conversation, the user suddenly switches topics and asks a
         completely unrelated question. Then, in a third round of conversation, the user returns to the
         original topic to ask a more specific question or further discussion point.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
                 Figure 19: The unique prompt for the instruction clarification task.
         Please help me generate multiple sets of multi-turn conversations based on a given conversation
         scenario, with the goal of testing the model’s active interaction capabilities. After the user
         states something, the model should generate appropriate questions to continue the conversation.
         Therefore, the conversation you generate needs the user to state something firstly, and then the
         robot will ask questions based on the user’s topic. Note that the generated dialogue should be
         smooth and natural.
         Youcanrefer to these examples:
         # Example 1 #
         # Example 2 #
         # Example 3 #
                  Figure 20: The unique prompt for the proactive interaction task.
         Please act as an impartial judge following these instructions: In the following conversations, the
         response of the ‘assistant’ in the last round of conversations is the output of the large language
         model(AIassistant) that needs to be evaluated.
         Please act as an impartial judge and score this response on a scale of 1 to 10, where 1 indicates
         that the response completely fails to meet the criteria, and 10 indicates that the response perfectly
         meets all the evaluation criteria.
         Notethatonlytheresponseofthe‘assistant’ in the LAST ROUNDofconversationsistheoutputof
         the large language model (the AI assistant) that needs to be evaluated; the previous conversations
         are the ground truth history which do NOT need to be evaluated.
                     Figure 21: The initial instructions for evaluation.
                              7439
