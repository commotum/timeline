                         Published as a conference paper at ICLR 2017
                         by ﬁlling in “holes” in incomplete source code so as to match speciﬁed requirements, it is ﬂexible
                         enough for our use case as well. The function in each step and its arguments can be treated as
                         the “holes”, and the requirement to be satisﬁed is consistency with the provided set of input-output
                         examples. Sketch can utilize the neural network predictions in a Sort and add scheme as described
                         above, as the possibilities for each function hole can be restricted to the current active set.
                         λ2.   λ2 (Feseretal.,2015)isaprogramsynthesistoolfromtheprogramminglanguagescommunity
                         that combines enumerative search with deduction to prune the search space. It is designed to infer
                         smallfunctionalprogramsfordatastructuremanipulationfrominput-outputexamples,bycombining
                         functions from a provided library. λ2 can be used in our framework using a Sort and add scheme as
                         described above by choosing the library of functions according to the neural network predictions.
                         4.5  TRAINING LOSS FUNCTION
                         Weusethenegative cross entropy loss to train the neural network described in Sect. 4.3, so that its
                         predictions about each function can be interpreted as marginal probabilities. The LIPS framework
                         dictates learning q(a | E), the joint distribution of all attributes a given the input-output examples,
                         and it is not clear a priori how much DeepCoder loses by ignoring correlations between functions.
                         However, under the simplifying assumption that the runtime of searching for a program of length T
                         with C functions made available to a search routine is proportional to CT, the following result for
                         Sort and add procedures shows that their runtime can be optimized using marginal probabilities.
                         Lemma 1. For any ﬁxed program length T, the expected total runtime of a Sort and add search
                         scheme can be upper bounded by a quantity that is minimized by adding the functions in the order of
                         decreasing true marginal probabilities.
                         Proof. Predicting source code functions from input-output examples can be seen as a multi-label
                         classiﬁcation problem, where each set of input-output examples is associated with a set of relevant
                         labels (functions appearing in the ground truth source code). Dembczynski et al. (2010) showed
                         that in multi-label classiﬁcation under a so-called Rank loss, it is Bayes optimal to rank the labels
                         according to their marginal probabilities. If the runtime of search with C functions is proportional
                         to CT, the total runtime of a Sort and add procedure can be monotonically transformed so that it is
                         upper bounded by this Rank loss. See Appendix E for more details.
                         5   EXPERIMENTS
                         In this section we report results from two categories of experiments. Our main experiments (Sect. 5.1)
                         show that the LIPS framework can lead to signiﬁcant performance gains in solving IPS by demon-
                         strating such gains with DeepCoder. In Sect. 5.2 we illustrate the robustness of the method by
                         demonstrating a strong kind of generalization ability across programs of different lengths.
                         5.1  DEEPCODERCOMPAREDTOBASELINES
                         Wetrained a neural network as described in Sect. 4.3 to predict used functions from input-output
                         examplesandconstructedatestsetofP = 500programs,guaranteedtobesemanticallydisjointfrom
                         all programs on which the neural network was trained (similarly to the equivalence check described
                         in Sect. 4.2, we have ensured that all test programs behave differently from all programs used during
                         training on at least one input). For each test program we generated M = 5 input-output examples
                         involving integers of magnitudes up to 256, passed the examples to the trained neural network, and
                         fedtheobtainedpredictionstothesearchproceduresfromSect.4.4.WealsoconsideredaRNN-based
                         decoder generating programs using beam search (see Sect. 5.3 for details). To evaluate DeepCoder,
                         we then recorded the time the search procedures needed to ﬁnd a program consistent with the M
                         input-output examples. As a baseline, we also ran all search procedures using a simple prior as
                         function probabilities, computed from their global incidence in the program corpus.
                                                                                             6
                         In the ﬁrst, smaller-scale experiment (program search space size ∼ 2 × 10 ) we trained the neural
                         network on programs of length T = 3, and the test programs were of the same length. Table 1 shows
                         the per-task timeout required such that a solution could be found for given proportions of the test
                         tasks (in time less than or equal to the timeout). For example, in a hypothetical test set with 4 tasks
                                                                     6
