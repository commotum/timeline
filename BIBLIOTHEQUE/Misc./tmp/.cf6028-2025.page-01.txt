                    The Art of Scaling Test-Time Compute for Large Language
                    Models
                      AradhyeAgarwalm,ω∗ AyanSenguptaω   TanmoyChakrabortyω
                      mMicrosoft Research
                      ωIndianInstitute of Technology Delhi
                                                     Abstract
                           Test-time scaling (TTS)—the dynamic allocation of compute during infer-
                           ence—is a promising direction for improving reasoning in large language
                           models (LLMs). However, a systematic comparison of well-known TTS
                           strategiesunderidenticalconditionsismissing,andtheinfluenceofmodel
                           type and problem difficulty on performance remains unclear. To address
                           these gaps, we conduct the first large-scale study of TTS, spanning over
                           thirty billion tokens generated using eight open-source LLMs (7B to 235B
                           parameters), across four reasoning datasets. We observe three consistent
                           trends: (1) no single TTS strategy universally dominates; (2) reasoning
                           modelsexhibitdistincttrace-qualitypatternsacrossproblemdifficultyand
                           trace length, forming short-horizon and long-horizon categories; and (3)
                           for a given model type, the optimal TTS performance scales monotoni-
                           callywithcomputebudget. Basedontheseinsights,weprovideapractical
                           recipe for selecting the best TTS strategy, considering problem difficulty,
                           modeltype, and compute budget, providing a practical guide to effective
                                             1
                           inference-time scaling.
      arXiv:2512.02008v1  [cs.CL]  1 Dec 2025Figure 1: Plots of shortest (cyan), majority-voted (purple), and beam-searched (red) trace
                    performances for short-horizon (left), long-horizon (middle), and non-reasoning (right)
                    models. Short-horizon models include R1, DAPO-32B, and QwQ-32B; long-horizon mod-
                    els include andQwen3-32B,GPT-OSS-120BandR1-32B;andnon-reasoningmodelsinclude
                    Qwen3-235B-Instruct and DeepSeek-Chat. Performance is measured using average accuracy
                    on the AIME 2024–2025 and GPQA Diamond datasets. Shaded regions show the optimal
                    TTSstrategybycomputebudget: shortestforlowcompute,beamsearchformedium,ma-
                    jority voting for high. The plot illustrates that there is no free lunch for TTS strategies: no
                    single strategy is optimal and optimality depends on compute budget. This highlights the
                    needforaprincipled,model-awareapproachtodeterminethebestscalingstrategyattest-
                    time. Marker size increases with N (N ≥ 2); N is the number of parallel traces sampled.
                       ∗Correspondingauthor: aradhye.agarwal@gmail.com
                       1Thesourcecodeisavailableathttps://github.com/Aradhye2002/art_of_tts
                                                         1
