                        articles
                        Fig. 2. Final state variability. (a) Dots show    a        Aiming                               Intercept
                        final states (X1, X2) for 1,000 simulation runs
                        in each task (Results). The ‘task error’ line
                        shows the direction in which varying the final                       ask error
                        state will affect the cost function. The thick                      T
                        ellipse corresponds to ± 2 standard devia-           X2                                   X2
                        tions of the final state distribution. (b) We
                        varied the following parameters linearly, one
                        at a time: motor noise magnitude (M) from                                    1 cm                                1 cm
                        0.1 to 0.7; sensory noise magnitude (S) from
           oscience     0.1 to 0.7; sensory delay (D) from 20 ms to                        X                                   X
                        80 ms; effort penalty (R) from 0.0005 to                            1                                   1
                        0.004; movement time (T) from 410 ms to           b
                        590 ms. For each modified parameter set, we                                          )   1                           0.15
                        constructed the optimal control law (inter-           4                       M
                        cept task) and ran it for 5,000 trials. The plots
                        show the bias (that is, the average distance                                   T
           .com/natureneurbetween the two point masses at the end of                                  R
                        the movement), the ratio of the standard                                      D        0.5                             Bias (cm)
                        deviations in the task-irrelevant versus task-      Aspect ratio              S      Average s.d. (cm
           .nature      relevant directions, and the average of the           2                                                              0.05
                        two standard deviations.
                                                                                   Parameter value                   Parameter value                  Parameter value
           http://www   control law. As mentioned earlier, the serial planning/execution           trol signal can be detrimental, because both noise and effort are
                        model imposes the severe constraint that the control law must              control dependent and therefore could increase. Below we for-
           oup          execute a desired trajectory, which is planned in an open                  malize the ideas of ‘redundancy’ and ‘correction’ and show that
                             18,20–22
                        loop         . Although some feedback controllers are optimized            they are indeed related for a surprisingly general class of systems.
                        under weaker constraints imposed by intermittency30 or spe-                We then apply the minimal intervention principle to specific
                                                                              17,32
                        cific parameterizations and learning algorithms            , feedback      motor tasks.
                                                                       31,33–35
           lishing Gr   controllers derived in the LQG framework                used here are          In the simplest example of these ideas, consider the follow-
                                                                28
                        not subject to any control constraints . Realistically, the anatom-        ing one-step control problem: given the state variables x , choose
                                                                                                                                                                i
                        ical structure, physiological fluctuations, computational mech-            the control signals u that minimize the expected cost E (xfinal +
                                                                                                                          i                                      ε  1
                                                                                                     final ∗ 2       2     2                                        final =
                        anisms and learning algorithms available to the nervous system             x   – X ) + r(u     + u ) where the stochastic dynamics are x
                                                                                                    2               1     2                                         i
                        must impose information-processing constraints—whose pre-                  ax + u (1 + σε); i ∈ {1,2}, and ε are independent random vari-
                                                                                                      i    i        i                  i
                        cise form should eventually be studied in detail. However, it is           ables with mean 0 and variance 1. In other words, the (redun-
                        important to start with an idealized model that avoids extra               dant) task is to make the sum x1 + x2 of the two state variables
           2002 Nature Pubassumptions whenever possible, introducing them only when                equal to the target valueX∗, with minimal effort. Focusing for
           ©            some aspect of observed behavior is suboptimal in the idealized            simplicity on unbiased control, it is easy to show that the opti-
                        sense. Therefore we use a nonspecific ‘model’ of the lumped                mal controls minimize (r + σ 2)(u12 + u22) subject to u1 + u2 =
                                                                                                                                      ∗
                        effects of all unknown internal constraints: we adjust two scalars         –Err, where Err = a(x + x ) – X is the expected task error if u
                                                                                                                           1    2                                       1
                        that determine the sensory and motor noise magnitudes until                = u2 = 0. Then the (unique) optimal feedback control law is u1
                        the optimal control law matches the overall variability observed           = u = –Err/2. This control law acts to cancel the task error Err,
                                                                                                       2
                        in experimental data. These parameters give us little control over         which depends on x + x but not on the individual values of x
                                                                                                                         1    2                                         1
                        the structure of the variability that the model predicts.                  and x2. Therefore introducing a task-irrelevant deviation (by
                                                                                                   adding a constant to x and subtracting it from x ) does not trig-
                                                                                                                           1                            2
                        RESULTS                                                                    ger any corrective response—as the minimal intervention prin-
                        Theminimal intervention principle                                          ciple states. Applying the optimal control law to the (otherwise
                        In a wide range of tasks, variability is not eliminated, but instead       symmetric) stochastic system produces a variability pattern elon-
                        is allowed to accumulate in task-irrelevant (redundant) dimen-             gated in the redundant dimension (Fig. 1, left).
                        sions. Our explanation of this phenomenon follows from an intu-                Now consider eliminating redundancy by specifying a single
                        itive property of optimal feedback control that we call the                desired state. To form the best possible desired state, we use the
                                                                                                                                                      final   final  ∗
                        ‘minimal intervention’ principle: deviations from the average tra-         average behavior of the optimal controller: x1         =x2 = X /2. 
                        jectory are corrected only when they interfere with task perfor-           The feedback control law needed to instantiate that state is u =
                                                                                                     ∗                                                                i 
                        mance. If this principle holds, and noise perturbs the system in all       X /2 – ax; i ∈ {1,2}. This control law is suboptimal (because it
                                                                                                             i
                        directions, the interplay of noise and control processes will cause        differs from the optimal one), but it is interesting to analyze what
                        larger variability in task-irrelevant directions. If certain devia-        makes it suboptimal. Applying it to our stochastic system yields
                        tions are not corrected, then certain dimensions of the control            a variability pattern that is now symmetric (Fig. 1, right). Com-
                        space are not being used—the phenomenon interpreted as evi-                paring the two covariance ellipses (Fig. 1, middle) reveals that
                                                     26,27
                        dence for motor synergies        .                                         the optimal control law achieved low task error by allowing vari-
                            Why should the minimal intervention principle hold? An opti-           ability in the redundant dimension. That variability could be fur-
                        mal feedback controller has nothing to gain from correcting task-          ther suppressed, but only at the price of increased variability in
                        irrelevant deviations, because its only concern is task                    the dimension that matters. Therefore the optimal control law
                        performance, and, by definition, such deviations do not inter-             takes advantage of the redundant dimension by using it as a form
                        fere with performance. Moreover, generating a corrective con-              of ‘noise buffer’.
                        1228                                                                                     nature neuroscience •  volume 5  no  11  •  november 2002
