                                                                                               PVG
                                                                  Before Last LN              After Last LN
                                                             T
                                                             o
                                                             k
                                           Input             e
                                                             n
                                                             s
                                                            (196)   Dimension(192)
                                                                                              MPVG
                                                                  Before Last LN              After Last LN
                                                             T
                                                             o
                                                             k
                                                             e
                                                             n
                                                             s
                                                            (196)   Dimension(192)
                Figure 7: The visualizations and heatmaps before and after the Last LN in the PVG and MPVG methods are shown. These
                heatmaps represent a single sample. For the visualization heatmap, the norm values of each of the 196 tokens are calculated
                and visualized as heatmaps.
                variance of beta in the GAP method suggest that if counter-
                balancing by PE does not occur in the Last LN, the Last LN
                alone must remove the high-value dimensions to maintain
                balance. This indicates that, in the Layer-wise structure, the
                role of PE in maintaining balance is much more critical in
                the GAP method, where class predictions are made directly
                throughtheaverageofthetokens.AsshowninFigure2,this
                issue can lead to less accurate results in vision transformers
                because the Last LN must remove high-value dimensions.
                In conclusion, due to the difference in the extent of the bur-
                den placed on the LN to counterbalance high-value dimen-
                sions in the class token and GAP methods, the GAP method,
                where the role of PE is relatively more critical, exhibits in-
                ferior performance compared to the class token method.
                Visualization on Last LN in Non-Layer-wise and
                Layer-wise structures.
                Weprovide a more detailed figure in Last LN. As shown in
                Fig 8, (a) is identical to Fig 2 in the main paper but offers a
                visualization after applying the Last LN. (b) visualizes Fig
                5-(b) from the main paper as a heatmap. Identical to Figure
                2 in main paper, the x-axis represents the dimensions, and
                the y-axis represents the number of tokens.
                  Specifically, in Fig 8-(b), since the structure is not Layer-
                wise, there is no value in the token embedding that the PE
                counterbalances. As a result, even if PE is added in the Last
                LN, there is no such directionality, leading to a decrease
                in performance. After applying the Last LN, the correlation
                values are significantly lower than (a). In contrast, in Fig 8-
                (a), because the Layer-wise structure allows PE to counter-
                balance the token embedding values at each layer, this di-
                rectionality is maintained both before and after applying the
                Last LN.
