                       Figure 15: Plot showing the improvement of the prediction over “thinking” iterations on a 100 digit
                       addition problem.
                       Input Prompt:
                       587928785434679080355608971949871667189221012941443697496891519051264419888571617
                       0096255295233702836+4358110391552830769683978480187501721764900525218097903808750
                       786159803668915002036143168815597779644=
                       Answer:
                       919576073626374550845911684630020084191658772891994105418527595750262943203928417
                       58606474262584957001[EOS]
                       (Note that the plot is truncated.)
                                  100                                          84.9
                                 Accuracy80
                                   60                        53.0
                                   40
                                 Exact Match 209.1                                   3.5  2.1
                                    0          0.5  0.8           0.7  1.3
                                               LT                 ST              ST w/ II
                                                          Architecture Type
                                        Abacus, OOD            FIRE, OOD            NoPE, OOD
                       Figure 16: Effect of removing the masking of the loss before the “=” sign in the addition task. All
                       models perform worse when trained for 24 hours on a single Nvidia RTXA4000 if we do not mask
                       the input question in the loss function.
                       et al. [2024] with their methods, we try to the best of our abilities to faithfully reproduce their work
                       within our experimental set up, noting that perhaps a better random seed or initialization may be able
                       to produce better results for these models.
                       A.8  Additional Experimental Information
                       In this work, we consider three different model types, the classical standard transformer, standard
                       transformer with input injection, and looped transformers. We visually describe these in Figure 22.
                                                              20
