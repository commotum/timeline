           [69] Matteo Tiezzi, Michele Casoni, Alessandro Betti, Tommaso Guidi, Marco Gori, and Stefano
              Melacci. On the resurgence of recurrent models for long sequences: Survey and research
              opportunities in the transformer era. arXiv preprint arXiv:2402.08132, 2024.
           [70] Bo Peng, Eric Alcaide, Quentin Gregory Anthony, Alon Albalak, Samuel Arcadinho, Stella
              Biderman, Huanqi Cao, Xin Cheng, Michael Nguyen Chung, Leon Derczynski, Xingjian Du,
              Matteo Grella, Kranthi Kiran GV, Xuzheng He, Haowen Hou, Przemyslaw Kazienko, Jan
              Kocon, Jiaming Kong, Bartłomiej Koptyra, Hayden Lau, Jiaju Lin, Krishna Sri Ipsit Mantri,
              Ferdinand Mom, Atsushi Saito, Guangyu Song, Xiangru Tang, Johan S. Wind, Stanisław
              Wozniak, Zhenyuan Zhang, Qinghua Zhou, Jian Zhu, and Rui-Jie Zhu. RWKV: Reinventing
              RNNs for the transformer era. In The 2023 Conference on Empirical Methods in Natural
              Language Processing, 2023. URL https://openreview.net/forum?id=7SaXczaBpG.
           [71] Jimmy T.H. Smith, Andrew Warrington, and Scott Linderman. Simplified state space layers for
              sequence modeling. In The Eleventh International Conference on Learning Representations,
              2023. URLhttps://openreview.net/forum?id=Ai8Hw3AXqks.
           [72] Ramin Hasani, Mathias Lechner, Tsun-Hsuan Wang, Makram Chahine, Alexander Amini,
              and Daniela Rus. Liquid structural state-space models. In The Eleventh International Con-
              ference on Learning Representations, 2023. URL https://openreview.net/forum?id=
              g4OTKRKfS7R.
           [73] Ali Behrouz, Michele Santacatterina, and Ramin Zabih. Mambamixer: Efficient selective state
              space models with dual token and channel selection. arXiv preprint arXiv:2403.19888, 2024.
           [74] Bo Peng, Daniel Goldstein, Quentin Anthony, Alon Albalak, Eric Alcaide, Stella Biderman,
              Eugene Cheah, Xingjian Du, Teddy Ferdinan, Haowen Hou, et al. Eagle and finch: Rwkv with
              matrix-valued states and dynamic recurrence. arXiv preprint arXiv:2404.05892, 2024.
           [75] Bo Peng, Ruichong Zhang, Daniel Goldstein, Eric Alcaide, Haowen Hou, Janna Lu, William
              Merrill, Guangyu Song, Kaifeng Tan, Saiteja Utpala, et al. Rwkv-7" goose" with expressive
              dynamic state evolution. arXiv preprint arXiv:2503.14456, 2025.
           [76] Julien Siems, Timur Carstensen, Arber Zela, Frank Hutter, Massimiliano Pontil, and Riccardo
              Grazzi. Deltaproduct: Increasing the expressivity of deltanet through products of householders.
              arXiv preprint arXiv:2502.10297, 2025.
           [77] John J Hopfield. Neural networks and physical systems with emergent collective computational
              abilities. Proceedings of the national academy of sciences, 79(8):2554–2558, 1982.
           [78] Juergen Schmidhuber. Reducing the ratio between learning complexity and number of time
              varying variables in fully recurrent nets. In ICANN’93: Proceedings of the International
              Conference on Artificial Neural Networks Amsterdam, The Netherlands 13–16 September 1993
              3, pages 460–463. Springer, 1993.
           [79] Donald Olding Hebb. The organization of behavior: A neuropsychological theory. Psychology
              press, 2005.
           [80] Tsendsuren Munkhdalai and Hong Yu. Neural semantic encoders. In Proceedings of the
              conference. Association for Computational Linguistics. Meeting, volume 1, page 397. NIH
              Public Access, 2017.
           [81] Tsendsuren Munkhdalai, Alessandro Sordoni, Tong Wang, and Adam Trischler. Metalearned
              neural memory. Advances in Neural Information Processing Systems, 32, 2019.
           [82] Kazuki Irie, Imanol Schlag, Robert Csordas, and Juergen Schmidhuber. Going beyond lin-
              ear transformers with recurrent fast weight programmers. Advances in neural information
              processing systems, 34:7703–7717, 2021.
           [83] Ke Alexander Wang, Jiaxin Shi, and Emily B Fox. Test-time regression: a unifying framework
              for designing sequence models with associative memory. arXiv preprint arXiv:2501.12352,
              2025.
                               15
