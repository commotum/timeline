                                                         (N, 32)        (N/4, 64)      (N/16, 128)     (N/64, 256)     (N/256, 512)    (N/256, 512)     (N/64, 256)     (N/16, 128)       (N/4, 64)        (N, 32)      (N, D )
                                                                                                                                                                                                                             out
                                                                                                                                                                 r                 Point Transformer
                                                                                                                                                                 i                                                     MLP
                                                                                                                                                                 ha
                                                                                                                                                                 c
                                                                                                                                                                  
                                                                                                                                                                 :                  TransitionDown
                                                                                                                                                                 l
                                                                                                                                                                 be
                                                                                                                                                                 a                                             Global AvgPooling
                                                                                                                                                                 L                    TransitionUp
                                                         (N, 32)        (N/4, 64)      (N/16, 128)     (N/64, 256)     (N/256, 512)    (1, 512)  (1, D  )
                                                                                                                                                      out
                                                          Figure 3. Point transformer networks for semantic segmentation (top) and classification (bottom).
                                                             input: (x, p)                                                    input: (x, p )                                         input :(x , p )                       input :(x , p )
                                                                                                                                                 1                                            1      1     1                        2      2    2
                                                       linear                                                farthest point sampl.                                             linear                               linear
                                             point transformer                                                      kNN, mlp                                            interpolation
                                                       linear                                                localmaxpooling                                              summation
                                                             output: (y, p)                                                   output: (y, p )                                        output: (y, p )
                                                                                                                                                   2                                                      2
                                          (a) point transformer block                                             (b) transition down                                                          (c) transition up
                                                                                               Figure 4. Detailed structure design for each module.
                        3.3. Position Encoding                                                                                                  3.4. Point Transformer Block
                             Position encoding plays an important role in self-                                                                      Weconstruct a residual point transformer block with the
                        attention, allowing the operator to adapt to local structure                                                            point transformer layer at its core, as shown in Figure 4(a).
                        in the data [39]. Standard position encoding schemes for                                                                The transformer block integrates the self-attention layer,
                        sequences and image grids are crafted manually, for exam-                                                               linear projections that can reduce dimensionality and ac-
                        ple based on sine and cosine functions or normalized range                                                              celerate processing, and a residual connection. The input
                        values [39, 54]. In 3D point cloud processing, the 3D point                                                             is a set of feature vectors x with associated 3D coordinates
                        coordinates themselves are a natural candidate for position                                                             p. The point transformer block facilitates information ex-
                        encoding. We go beyond this by introducing trainable, pa-                                                               change between these localized feature vectors, producing
                        rameterizedpositionencoding. Ourpositionencodingfunc-                                                                   new feature vectors for all data points as its output. The
                        tion δ is defined as follows:                                                                                           information aggregation adapts both to the content of the
                                                                                                                                                feature vectors and their layout in 3D.
                                                               δ = θ(p −p ).                                                    (4)
                                                                               i         j                                                      3.5. Network Architecture
                        Here p and p are the 3D point coordinates for points i                                                                       We construct complete 3D point cloud understanding
                                     i              j
                        and j. The encoding function θ is an MLP with two linear                                                                networks based on the point transformer block. Note that
                        layers and one ReLU nonlinearity. Notably, we found that                                                                the point transformer is the primary feature aggregation op-
                        position encoding is important for both the attention gener-                                                            erator throughout the network. We do not use convolu-
                        ation branch and the feature transformation branch. Thus                                                                tions for preprocessing or auxiliary branches: the network is
                        Eq. 3 adds the trainable position encoding in both branches.                                                            based entirely on point transformer layers, pointwise trans-
                        Thepositionencodingθ istrainedend-to-endwiththeother                                                                    formations, and pooling. The network architectures are vi-
                        subnetworks.                                                                                                            sualized in Figure 3.
                                                                                                                                         16262
