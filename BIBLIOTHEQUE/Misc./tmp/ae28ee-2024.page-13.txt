                           Published as a conference paper at ICLR 2024
                           Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. Is your code generated by
                             chatgpt really correct? rigorous evaluation of large language models for code generation. arXiv
                             preprint arXiv:2305.01210, 2023a.
                           Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni,
                             and Percy Liang.     Lost in the middle: How language models use long contexts, 2023b.
                             arXiv:2307.03172.
                           ShangqingLiu, Yanzhou Li, Xiaofei Xie, and Yang Liu. Commitbart: A large pre-trained model for
                             github commits, 2023c.
                           Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, and Hanyu Lai et. al. Agentbench:
                             Evaluating llms as agents, 2023d.
                           Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, and Ambrosio Blanco et.
                             al. Codexglue: A machine learning benchmark dataset for code understanding and generation.
                             CoRR,abs/2102.04664, 2021.
                           Petros Maniatis, Daniel Tarlow, and Google DeepMind.          Large sequence models for soft-
                             ware development activities, 2023. URL https://blog.research.google/2023/05/
                             large-sequence-models-for-software.html.
                                         ´                               ´  ´  ´                   ´      ´
                           Fernando Martınez-Plumed, Pablo Barredo, Sean O hEigeartaigh, and Jose Hernandez-Orallo. Re-
                             search community dynamics behind popular ai benchmarks. Nature Machine Intelligence, 3:581
                             – 589, 2021. URL https://api.semanticscholar.org/CorpusID:236610014.
                           ThomasJ.McCabe. Acomplexitymeasure. IEEETransactions on Software Engineering, SE-2(4):
                             308–320, 1976. doi: 10.1109/TSE.1976.233837.
                           MartinMonperrus. Automaticsoftwarerepair. ACMComputingSurveys,51(1):1–24,jan2018. doi:
                             10.1145/3105906. URL https://doi.org/10.1145%2F3105906.
                           Manish Motwani and Yuriy Brun. Better automatic program repair by using bug reports and tests
                             together, 2023.
                           Niklas Muennighoff, Qian Liu, Armel Zebaze, Qinkai Zheng, Binyuan Hui, Terry Yue Zhuo,
                             Swayam Singh, Xiangru Tang, Leandro von Werra, and Shayne Longpre. Octopack: Instruc-
                             tion tuning code large language models, 2023.
                           Gabriel Orlanski, Kefan Xiao, Xavier Garcia, Jeffrey Hui, Joshua Howland, Jonathan Malmaud, Ja-
                             cobAustin,RishabhSingh,andMicheleCatasta. Measuringtheimpactofprogramminglanguage
                             distribution, 2023.
                           Simon Ott, Adriano Barbosa-Silva, Kathrin Blagec, Janina Brauner, and Matthias Samwald. Map-
                             ping global dynamics of benchmark creation and saturation in artificial intelligence.   Nature
                             Communications, 13, 2022. URL https://api.semanticscholar.org/CorpusID:
                             247318891.
                           Stephen Robertson, Hugo Zaragoza, et al. The probabilistic relevance framework: Bm25 and be-
                             yond. Foundations and Trends® in Information Retrieval, 3(4):333–389, 2009.
                                        `
                           Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, and Xiaoqing Ellen Tan et.
                             al. Code llama: Open foundation models for code, 2023.
                           DavidSchlangen. Languagetasksandlanguagegames: Onmethodologyincurrentnaturallanguage
                             processing research, 2019.
                           Dominik Sobania, Martin Briesch, Carol Hanna, and Justyna Petke. An analysis of the automatic
                             bug fixing performance of chatgpt, 2023.
                           Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, and Abu Awal Md Shoeb et. al. Beyond the
                             imitation game: Quantifying and extrapolating the capabilities of language models, 2023.
                           Rosalia Tufano, Luca Pascarella, Michele Tufano, Denys Poshyvanyk, and Gabriele Bavota. To-
                             wards automating code review activities, 2021.
                                                                          13
