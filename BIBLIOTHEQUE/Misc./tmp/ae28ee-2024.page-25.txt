                            Published as a conference paper at ICLR 2024
                                                            astroid   marshmallow      pvlib    pydicom     pyvista   sqlfluff
                                 P Length (Characters)      2199      1619             1790     2076        1475      2639
                                 C#Files                    252       82               294      455         866       2297
                                 C#Lines                    60K       22K              459K     170K        661K      205K
                                 δ # Files Edited           2.51      1.89             1.83     1.54        2.1       3.26
                                 δ # Func. Edited           3.03      2.11             2.89     2.23        3.0       2.71
                                 δ # Lines Edited           83.1      36.2             93.3     42.0        101.0     102.5
                                 δ # Lines Added            52.8      24.7             67.0     29.7        79.4      63.6
                                 δ # Lines Removed          30.3      11.6             26.4     12.3        21.6      38.9
                                 |T| (Fail to Pass)         23.2      53.0             19.1     24.0        8.8       14.8
                                 |T| (Pass to Pass)         182.6     242.9            107.5    176.1       96.5      239.7
                                 |T| (All)                  205.8     295.9            126.6    200.1       105.3     254.5
                            Table17: AveragenumberscharacterizingdifferentattributesofaSWE-benchtaskinstancegrouped
                            by repository for repositories in the development dataset. The same statistics presented in Table 11
                            are also shown here.
                                                                    BM25Retrieval             “Oracle” Retrieval
                                           Model                %Resolved      %Apply      %Resolved       %Apply
                                           Claude 2                1.96          43.07         4.80         62.82
                                           ChatGPT-3.5             0.17          26.33         0.52         21.80
                                           GPT-4∗                  0.00          14.83         1.74         34.00
                                           SWE-Llama7b             0.70          51.74         3.01         65.52
                                           SWE-Llama13b            0.70          53.62         3.97         66.78
                            Table 18: We compare models against each other using the BM25 and oracle retrieval settings as
                            described in Section 4. The main results table, Table 5, presents the results for the different models
                            whenusing BM25only. ∗Due to budget constraints we evaluate GPT-4 on a 25% random subset of
                            SWE-benchinthe“Oracle”andBM2527Kretrieversettings only.
                            C.4    EXTENDED TEMPORAL ANALYSIS
                            Inthissection,wepresentanextendedtemporalanalysisoftaskinstancessolvedbyyearthatfollows
                            the analysis shown in Table 7 of the evaluation section in the main paper. In Table 21, we present
                            the % Resolved statistic across models under the “Oracle” retrieval setting for 6 different temporal
                            partitions that group tasks by the years in which the issues were created. It is evident from the
                            table that there is no consistent correlation between model performance and year, supporting our
                            conclusionthatdespitehavingpotentiallyseenolderversionsofcodewithinitspre-trainingdatasets,
                            understandingandimplementinginfixesinSWE-benchisadifficulttaskthatrequiresunderstanding
                            and cannot be accomplished feasibly or consistently via memoization of observed data.
                            C.5    F2P, P2P RATE ANALYSIS
                            In the main paper results, we present the “% Resolved” statistic that indicates how many task in-
                            stances were completely solved by the different models. In this section, we provide more fine-
                            grained insight into the gap of task instances where 1. The model’s patch generation was applied
                            successfully and 2. The task instance was not resolved. Assuming a patch is applied successfully,
                            we define 6 cases in Table 22 that fully capture the distribution of all possible outcomes based on
                            the pass/fail results of F2P and P2P tests. In addition to the “Resolved” outcome that has been
                            established, we introduce five new terms. The “Breaking Resolved” outcome refers to when the
                            desired behavior of the issue has been accomplished (all F2P tests pass), but not all prior behavior is
                            maintained (not all P2P tests pass). “Partially Resolved” refers to when prior behavior of a codebase
                            wasmaintained(all P2P tests pass); however, the desired behavior is not fully accomplished (not all
                            F2Ptests pass). The “Work in Progress” case is when the desired behavior is not fully accomplished
                            (not all F2P tests pass) and the prior behavior of the codebase is not maintained (not all P2P tests
                            pass). A “No-Op” is when a code change does not have any effect on the original codebase; prior
                                                                              25
