           not necessarily claim that a single memory slot is best for language modeling, rather, we emphasize
           an interesting trade-off between number of memories and individual memory size, which may be
           a task speciﬁc ratio that can be tuned. Moreover, in program evaluation, an intermediate solution
           workedwellacross subtasks (4 slots and heads), though some performed best with 1 memory, and
           others with 8.
           Altogether, our results show that explicit modeling of memory interactions improves performance in
           a reinforcement learning task, alongside program evaluation, comparative reasoning, and language
           modeling, demonstrating the value of instilling a capacity for relational reasoning in recurrent neural
           networks.
           Acknowledgements
           WethankCaglarGulcehre,MattBotvinick,ViniciusZambaldi,CharlesBlundell,SébastienRacaniere,
           Chloe Hillier, Victoria Langston, and many others on the DeepMind team for critical feedback,
           discussions, and support.
                               9
