                   Accelerating Program Synthesis using Learned Probabilistic Models                                     PLDI’18, June 18–22, 2018, Philadelphia, PA, USA
                                  J K
                                   ϵ (t, u, κ) =     κ                                                         TCond     → ϵ |Write TCond | MoveOp TCond
                                                      J K
                              J      K                    c (t, u, κ)                (u = ϵ)                  MoveOp     → Up|Left | Right | DownFirst | DownLast | PrevDFS
                               Up · c (t, u, κ) =       J K
                                                         c (t, u1 · · ·u|u|−1, κ)   (o.w)
                                                        J K
                    J                K                    c (t, u, κ)       (v ∈ Dt. u < v)                                 Figure 10. Definition of TCond .
                      DownFirst ·c (t,u, κ) =           J K
                                                      c (t,u ·1,κ)         (o.w)
                                                         J K
                                                      c (t,u,κ) (v ∈ Dt.u < v)
                                                       J K                                                applied to the leftmost nonterminal. Using D, we synthesize
                      JDownLast ·cK(t,u, κ) =         c (t,u ·i,κ) (o.w)                                   aprogrampbest writteninadomain-specificlanguagecalled
                                                         whereu ·i ∈ Dt,u ·(i +1) < Dt
                                                                                                          TCond describedinFig.10.ThesemanticsofaTCondfunc-
                                                      J K
                                                      c (t,u,κ) (u|u| = 1)
                                                                ′                                                                     ∗
                                                         J K                                                tion is of type τ      ×N →C.Foragiventreeandanaddress
                           J         K                    c (t, u , κ)   (o.w)
                            Left · c (t, u, κ) =                  ′                                                            V
                                                         whereu =u1 ···u|u|−1 ·(u|u| −1)                   of the leftmost nonterminal, a TCond function returns the
                                                                          ′
                                                      J K
                                                      c (t,u,κ) (u < Dt)
                                                       J K      ′                                         context that will condition the production. Withpbest and a
                          J          K                    c (t, u , κ)   (o.w)
                           Right ·c (t, u, κ) =                   ′                                        given sentential form β,p(β) is defined as follows:
                                                         whereu =u1 ···u|u|−1 ·(u|u| +1)
                                                     
                                                      J K
                                                      c (t,u,κ)                (u = ν(t) )
                                                                                        1                                                   J       K
                                                         J K                                                                        p(β) = pbest (γ(β),u)
                       J             K                    c (t, ν(t)    , κ)    (o.w)
                        PrevDFS ·c (t,u, κ) =                       i−1
                                                         whereu =ν(t)
                                                                          i                               whereu istheaddressoftheleftmostnonterminalinγ(β).In
                          J          K               J K
                           Write ·c (t, u, κ) =       c (t, u, κ · t(u))                                    Section A.1.3, we will describe the domain-specific language
                                     Figure 9. Semantics of TCond .                                         andhowtosynthesizepbest.
                      Lastly, we will denote a depth-first left-to-right traversal                          Step 2: Derive a HOG. Oncepbest is synthesized, we can
                   order of t as ν(t).                                                                                         ˆ                         ˆ                  ˆ
                                                                                                            deriveaHOGGwhichis⟨N,Σ,S,R,C,p⟩whereR = {A[γ] →
                   Subtree. Let t ∈ τ           and u ∈ D . Then, t/u is called the                         β | A → β ∈ R,γ ∈ C}.
                                             V                  t              def
                   subtree atu, which is defined as follows: t/u = {(v,α) | (u ·                            Step 3: Learn a PHOG. Using the set Q of tree comple-
                                       ∗
                  v,α) ∈ t,v ∈ N }.                                                                         tion queries, we next applypbest to every production in the
                   Yield. The yieldY is a function fromτ                   intoV∗ defined as                training data, obtaining a new multiset:
                   follows.                                             V
                                                                                                                                                  J        K
                    Y(t)     = t(ϵ)                                                   (D = {ϵ})                H(Q,pbest) = {(c,r) | c = pbest (t,u,ϵ),⟨t,u,r⟩ ∈ Q}
                                                                                         t                 The derived data set consists of a number of pairs where
                    Y(t)     = Y(t/1)Y(t/2)···Y(t/j)            (1, 2, · · · , j ∈ Dt ∧ j + 1 < Dt)         each pair {(c,r)} indicates that the rule r is triggered by the
                   Y(t) is the string of the labels of the terminal nodes of t.                             contextc ∈ C. Based on this set, we can obtain the function
                      Using the function Y, let us assume we have a function                               q using maximum likelihood estimation (MLE) training. For
                  γ : V∗ → τ that takes a sentential form and returns a
                                    V                                                                       each rule A → β ∈ R and all possible context γ ∈ C, we
                   tree that yield the sentential form assuming the grammar is                              defineq(A[γ] → β) as follows:
                                                                                      ∗
                   unambiguous. For a sentential form s ∈ (N ∪γ) ,γ(s) = t                                                        |{(c,r) ∈ H(Q,p            ) | c = γ,r = A → β}|
                   such thatY(t) = s.                                                                       q(A[γ] → β) =                              best                                .
                   A.1.2      LearningSteps                                                                                               |{(c,r) ∈ H(Q,pbest) | c = γ}|
                                                                                                                           ˆ        ˆ
                                                            ˆ            ˆ                                     Finally, Gq = ⟨G,q⟩ is the resulting PHOG.
                   Recall that a PHOGisatuple ⟨G,q⟩ andG isaHOGisatuple
                                   ˆ                                        ∗
                   ⟨N,Σ,S,C,R,p⟩. The functionp : (N ∪ Σ) → C extracts a                                    A.1.3     TCondLanguage
                   contextfromagivensententialform.Theextractedcontextis                                   Thefunctionp is represented as a sequence of a simple vari-
                                                                                              ˆ
                   usedtoconditiontheproductionrules.Thefunctionq : R →                                     ant of the domain-specific language called TCond [6]. The
                     +
                   R scores production rules. We first synthesizep written in                               definition of the variant of TCond is given in Fig. 10. The
                   a domain-specific language (DSL) and obtain q. We define                                 semantics of the language is defined in Fig. 9.
                   the conditioning setC ⊆ (N ∪ Σ)∗ to be a set of sequences                                   TCondconsists of two kinds of instructions MoveOp and
                   of terminal/nonterminal symbols.                                                        WriteOp. Move instructions are for moving the current po-
                      WelearnaPHOGbydoingthefollowingsteps.                                                 sition in the tree to the parent node (Up), left sibling (Left),
                   Step 1: Synthesis of a DSL Program Conditioning the                                      right sibling (Right), first and last child (DownFirst and
                   Production. We use training data that consists of training                               DownLast), and the previous node in depth-first left-to-right
                   programs and their derivations. Let G = ⟨N,Σ,S,R⟩ be a                                   traversal order (PrevDFS). The write instruction Write ap-
                   context free grammar and D = ⟨S,Q⟩ be training data                                      pend a symbol at the currently visited node into the context
                   which is a pair of a set S ⊆ Σ∗ of programs and a set Q of                               accumulated so far. TCond functions operate on a state of
                                                                                                                           ∗
                   tree completion queries. A tree completion query is a triple                             typeτ ×N ×C meaningtriplesofatree,acurrentaddress
                                                                                                                   V
                                         ∗                                                                  of the production, and a context accumulated so far, and
                   ⟨t,u,r⟩ ∈ τ ×N ×R wheret isaparsetree,u istheaddress
                                  V                                                                         finally returns a resulting context inC.
                   of the leftmost nonterminal, and r is a production rule that
