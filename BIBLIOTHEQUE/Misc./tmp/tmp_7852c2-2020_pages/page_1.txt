                              Axial-DeepLab: Stand-Alone Axial-Attention for
                                                  Panoptic Segmentation
                                            1?            2               2                2            1
                               Huiyu Wang , Yukun Zhu , Bradley Green , Hartwig Adam , Alan Yuille ,
                                                                               2
                                                         and Liang-Chieh Chen
                                                        1 Johns Hopkins University
                                                            2 Google Research
                                    Abstract. Convolution exploits locality for eﬃciency at a cost of miss-
                                    ing long range context. Self-attention has been adopted to augment
                                    CNNs with non-local interactions. Recent works prove it possible to
                                    stack self-attention layers to obtain a fully attentional network by re-
                                    stricting the attention to a local region. In this paper, we attempt to
                                    remove this constraint by factorizing 2D self-attention into two 1D self-
                                    attentions. This reduces computation complexity and allows performing
                                    attention within a larger or even global region. In companion, we also
                                    propose a position-sensitive self-attention design. Combining both yields
                                    our position-sensitive axial-attention layer, a novel building block that
                                    one could stack to form axial-attention models for image classiﬁcation
                                    and dense prediction. We demonstrate the eﬀectiveness of our model on
                                    four large-scale datasets. In particular, our model outperforms all exist-
                                    ing stand-alone self-attention models on ImageNet. Our Axial-DeepLab
                                    improves 2.8% PQ over bottom-up state-of-the-art on COCO test-dev.
                                    This previous state-of-the-art is attained by our small variant that is
                                    3.8× parameter-eﬃcient and 27× computation-eﬃcient. Axial-DeepLab
                                    also achieves state-of-the-art results on Mapillary Vistas and Cityscapes.
                                    Keywords: bottom-up panoptic segmentation, self-attention
                              1    Introduction
                              Convolution is a core building block in computer vision. Early algorithms employ
                              convolutional ﬁlters to blur images, extract edges, or detect features. It has been
                              heavily exploited in modern neural networks [47,46] due to its eﬃciency and
                              generalization ability, in comparison to fully connected models [2]. The success
                              of convolution mainly comes from two properties: translation equivariance, and
                              locality. Translation equivariance, although not exact [93], aligns well with the
                              nature of imaging and thus generalizes the model to diﬀerent positions or to
                              images of diﬀerent sizes. Locality, on the other hand, reduces parameter counts
                              and M-Adds. However, it makes modeling long range relations challenging.
                                  Arichsetofliterature has discussed approaches to modeling long range inter-
                              actions in convolutional neural networks (CNNs). Some employ atrous convolu-
                              tions [33,74,64,12], larger kernel [67], or image pyramids [94,82], either designed
                               ? Work done while an intern at Google.
