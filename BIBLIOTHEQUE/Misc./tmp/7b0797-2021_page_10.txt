                                         Training data-efﬁcient image transformers & distillation through attention
                 lenge 2019 dataset. arXiv preprint arXiv:1707.06642,              skaya, A., and Shlens, J. Stand-alone self-attention in
                 2019.                                                             vision models. In Advances in Neural Information Pro-
               Hu, H., Gu, J., Zhang, Z., Dai, J., and Wei, Y. Relation net-       cessing Systems, 2019.
                 works for object detection. In Conference on Computer          Recht, B., Roelofs, R., Schmidt, L., and Shankar, V. Do im-
                 Vision and Pattern Recognition, 2018.                             agenet classiﬁers generalize to imagenet? arXiv preprint
               Hu, J., Shen, L., and Sun, G. Squeeze-and-excitation net-           arXiv:1902.10811, 2019.
                 works. arXiv preprint arXiv:1709.01507, 2017.                  Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S.,
               Huang, G., Sun, Y., Liu, Z., Sedra, D., and Weinberger,             Ma,S., Huang, Z., Karpathy, A., Khosla, A., Bernstein,
                 K. Q. Deep networks with stochastic depth. In European            M., Berg, A. C., and Fei-Fei, L. Imagenet large scale
                 Conference on Computer Vision, 2016.                              visual recognition challenge. International journal of
               Krause, J., Stark, M., Deng, J., and Fei-Fei, L. 3d object          ComputerVision, 2015.
                 representations for ﬁne-grained categorization. In In-         Simonyan, K. and Zisserman, A. Very deep convolutional
                 ternational IEEE Workshop on 3D Representation and                networks for large-scale image recognition. In Interna-
                 Recognition, 2013.                                                tional Conference on Learning Representations, 2015.
               Krizhevsky, A. Learning multiple layers of features from         Sun, C., Myers, A., Vondrick, C., Murphy, K., and Schmid,
                 tiny images. Technical report, CIFAR, 2009.                       C. Videobert: A joint model for video and language rep-
               Krizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet           resentation learning. In Conference on Computer Vision
                 classiﬁcation with deep convolutional neural networks.            andPattern Recognition, 2019.
                 In Advances in Neural Information Processing Systems,          Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wo-
                 2012.                                                             jna, Z. Rethinking the inception architecture for com-
               Li, L. H., Yatskar, M., Yin, D., Hsieh, C.-J., and Chang,           puter vision. Conference on Computer Vision and Pattern
                 K.-W. VisualBERT: a simple and performant baseline for            Recognition, 2016.
                 vision and language. arXiv preprint arXiv:1908.03557,          Tan, M. and Le, Q. V. Efﬁcientnet: Rethinking model
                 2019a.                                                            scaling for convolutional neural networks. arXiv preprint
               Li, X., Wang, W., Hu, X., and Yang, J. Selective kernel             arXiv:1905.11946, 2019.
                 networks. In Conference on Computer Vision and Pattern         Touvron, H., Vedaldi, A., Douze, M., and Jegou, H. Fixing
                 Recognition, 2019b.                                               the train-test resolution discrepancy. Advances in Neural
               Locatello, F., Weissenborn, D., Unterthiner, T., Mahendran,         Information Processing Systems, 2019.
                                                                                                                               ´
                 A., Heigold, G., Uszkoreit, J., Dosovitskiy, A., and Kipf,     Touvron, H., Vedaldi, A., Douze, M., and Jegou, H. Fix-
                 T. Object-centric learning with slot attention. arXiv             ing the train-test resolution discrepancy: Fixefﬁcientnet.
                 preprint arXiv:2006.15055, 2020.                                  arXiv preprint arXiv:2003.08237, 2020.
               Loshchilov, I. and Hutter, F. Fixing weight decay regular-       Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,
                 ization in adam. arXiv preprint arXiv:1711.05101, 2017.           L., Gomez, A. N., Kaiser, L., and Polosukhin, I. Atten-
               Lu, J., Batra, D., Parikh, D., and Lee, S. Vilbert: Pretraining     tion is all you need. In Advances in Neural Information
                 task-agnostic visiolinguistic representations for vision-         Processing Systems, 2017.
                 and-language tasks. In Advances in Neural Information          Wang, X., Girshick, R. B., Gupta, A., and He, K. Non-local
                 Processing Systems, 2019.                                         neural networks. Conference on Computer Vision and
               Nilsback, M.-E. and Zisserman, A. Automated ﬂower clas-             Pattern Recognition, 2018.
                 siﬁcation over a large number of classes. In Indian Con-       Wei, L., Xiao, A., Xie, L., Chen, X., Zhang, X., and Tian, Q.
                 ference on Computer Vision, Graphics and Image Pro-               Circumventing outliers of autoaugment with knowledge
                 cessing, 2008.                                                    distillation. European Conference on Computer Vision,
               Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J.,          2020.
                 Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga,      Wightman,R. Pytorchimagemodels. https://github.
                 L., et al. Pytorch: An imperative style, high-performance         com/rwightman/pytorch-image-models,
                 deep learning library. In Advances in Neural Information          2019.
                 Processing Systems, 2019.                                      Wu,B.,Xu,C.,Dai,X.,Wan,A.,Zhang,P.,Tomizuka, M.,
               Radosavovic, I., Kosaraju, R. P., Girshick, R. B., He, K., and      Keutzer, K., and Vajda, P. Visual transformers: Token-
                      ´                                                            based image representation and processing for computer
                 Dollar, P. Designing network design spaces. Conference
                 onComputerVision and Pattern Recognition, 2020.                   vision. arXiv preprint arXiv:2006.03677, 2020.
               Ramachandran, P., Parmar, N., Vaswani, A., Bello, I., Lev-       Yuan, L., Tay, F., Li, G., Wang, T., and Feng, J. Revisit
                                                                                   knowledgedistillation: a teacher-free framework. Confer-
