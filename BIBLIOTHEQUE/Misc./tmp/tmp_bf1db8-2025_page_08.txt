                                                                                                         32b
                                             InstructIT
                                             8b      27b    4b      12b    27b     Flash-LiteFlash       Qwen   R1
                                             3.1                                   2.0    2.0            R1            (high)
                        Tasks/Models         Llama   Gemma2 Gemma3  Gemma3 Gemma3  Gemini Gemini GPT4o   DistillDeepSeeko3-mini
                        BBEHMini          11.5    15.0   13.3    14.3   17.4   22.2    27.0   23.5    15.4   37.2   56.7
                      (Micro Average)
                                   Table 3: The performance of various models on BBEH Mini (micro average).
                     riplesCC                                                easoning uzzlesessions     opertiesables
                     C T  NY       LinguiniSportQAdgameQAecommendationeb of Lies                    d Sortingr
                     AR                                   HyperbatonW                               or
                     S                           Boar                   ime ArithmeticZebra P       W        Buggy T
                                            DisambiguationQA       Geometric ShapesTSpatial RShuffled ObjectsBoolean ExprDyck LanguagesObject PMultistep Arithmeticemporal SequencesObject Counting
                              Causal Understanding   Movie R                                                          T
                 Figure 4: Performance gains (absolute) of o3-mini (high) over GPT-4o on BBEH tasks. Tasks are ordered
                 bythe magnitude of improvement, with green signifying substantial gains and yellow/red signifying minimal or
                 negative gains.
                 AIME2024dataset,theperformanceofGPT4owas                 as the case where we compared general models
                 13.4%, but the o1 model increased it to 83.3% and        against reasoning models, we still observe that the
                 o3-mini (high) increased it further to 87.3%. Here,      tasks related to humour, commonsense, and causal
                 weexamine whether the same is true for various           reasoning are the ones with the least gains, and
                 types of general reasoning. In Figure 4, we com-         tasks requiring many-hop reasoning or applying
                 pare o3-mini (high) and GPT4o, as examples of            algorithms are the ones with the largest gains. A
                 reasoning and general models respectively, on each       particular exceptionistheSARCTriplestaskwhich
                 of the tasks from BBEH and sort the tasks ascend-        is a sarcasm understanding and where the gains are
                 ing based on how much o3-mini (high) gains over          large. This could in part be due to the fact that each
                 GPT4o. We observe that the tasks that gain the           example in SARC Triples is a composition of three
                 most are those involving counting, planning, arith-      sub-questions, and larger models may be better at
                 metic, and data structures and algorithms. Whereas       dealing with such composite questions.
                 the tasks that gain the least (or sometimes nega-          TheEffect of Context Length and Required
                 tively) are mostly those involving commensense,         Thinking: The tasks in BBEH come at different
                 humour, sarcasm, and causation. Our results indi-        average context lengths (see Figure 6) and may re-
                 cate that reasoning models achieve the most sig-         quire different amount of thinking (as shown using
                 nificant gains when applied to formal problems           the output length proxy in Figure 3). We use this
                 and demonstrate limited progress in handling the         property to understand the effect of context length
                 softer reasoning skills which are typically needed       andrequired thinking on reasoning vs general mod-
                 for complex, real-world scenarios.                       els, and on larger vs smaller models. To this end, in
                    ModelSizeEffect: In Figure 7 (in Appendix),           Figure 5 we compare the performance of o3-mini
                 wecompareGemini2.0FlashagainstGemini2.0                 (high) vs GPT4o and Gemini 2.0 Flash vs Gem-
                 Flash-Lite on different tasks from BBEH and sort         ini 2.0 Flash-Lite as a function of average context
                 the tasks ascending based on how much Flash gains        chance due to not generating an extractable final answer. To
                 over Flash-Lite4. While the signal is not as clear       reduce noise for this analysis, in such cases we assumed the
                                                                          performance of the model is the same as the random chance
                    4In some cases, these models perform below random     performance for the task.
                                                                     26480
