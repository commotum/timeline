                 Figure8 Exampleof2DEvaluationRendering.
                 7.3   ModelDetails
                 General Training Details. We implement both the VAE and DiT models using PyTorch [25]. We utilize
                 PyTorch’s mixed precision and replace all attention mechanisms with FlashAttention [10] to accelerate training
                 and reduce memory usage. AdamW is used as the optimizer for all models.
                Wetrain the VAE with a learning rate of 10−3, running for 20 epochs on Occ3D-Waymo and 100 epochs on
                                                                       −4
                 CarlaSC. The DiT is trained with a learning rate of 10  , and the EMA rate for DiT is set to 0.9999.
                 VAE. Our encoder projects the 4D input Q into a HexPlane, where each dimension is a compressed version of
                 the original 4D input. First, a 3D CNN is applied to each frame for feature extraction and downsampling,
                 with dimensionality reduction applied only to the spatial dimensions (X, Y , Z). Next, the Projection Module
                 projects the 4D features into the HexPlane. Each small transformer within the Projection Module consists of
                 two layers, and the attention mechanism has two heads. Each head has a dimensionality of 16, with a dropout
                 rate of 0.1. Afterward, we further downsample the T dimension to half of its original size.
                 During decoding, we first use three small transpose CNNs to restore the T dimension, then use an ESS
                 module to restore the 4D features. Finally, we apply a 3D CNN to recover the spatial dimensions and generate
                 point-wise predictions.
                 Diffusion. We set the patch size p to 2 for our DiT models. The Waymo DiT model has a hidden size of 768,
                18 DiT blocks, and 12 attention heads. The CarlaSC DiT model has a hidden size of 384, 16 DiT blocks, and
                 8 attention heads.
                 Discussion on VAEStructureImprovements. Some prior work utilizes sparse 3D structures to enhance the
                 efÏciency of their backbones. For example, XCube [30] employs a fully sparse 3D encoder, significantly
                 improving model efÏciency. Similarly, our VAE could potentially improve the 3D convolutional feature
                                                                     15
