M. Nye, A. J. Andreassen, G. Gur-Ari, H. Michalewski, J. Austin, D. Bieber,
D. Dohan, A. Lewkowycz, M. Bosma, D. Luan, et al. Show your work:
Scratchpads for intermediate computation with language models. arXiv
preprint arXiv:2112.00114, 2021.

OpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.

L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin,
C. Zhang, S. Agarwal, K. Slama, A. Ray, et al. Training language models to
follow instructions with human feedback. arXiv preprint arXiv:2203.02155,

2022.

J. Shen, Y. Yin, L. Li, L. Shang, X. Jiang, M. Zhang, and Q. Liu. Generate
& rank: A multi-task framework for math word problems. arXiv preprint

arXiv:2109.03084, 2021.

N. Stiennon, L. Ouyang, J. Wu, D. Ziegler, R. Lowe, C. Voss, A. Radford,
D. Amodei, and P. F. Christiano. Learning to summarize with human feed-
back. Advances in Neural Information Processing Systems, 33:3008-3021,
2020.

A. Stuhlmiiller and J. Byun. Supervise process, not outcomes. https: //ought .
org/updates/2022-04-06-process, 2022.

J. Uesato, N. Kushman, R. Kumar, F. Song, N. Siegel, L. Wang, A. Creswell,
G. Irving, and I. Higgins. Solving math word problems with process-and
outcome-based feedback. arXiv preprint arXiv:2211.14275, 2022.

X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, and D. Zhou. Self-consistency
improves chain of thought reasoning in language models. arXiv preprint
arXiv:2203.11171, 2022.

J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, and D. Zhou.
Chain of thought prompting elicits reasoning in large language models. arXiv
preprint arXiv:2201.11903, 2022.

E. Zelikman, Y. Wu, J. Mu, and N. Goodman. Star: Bootstrapping reason-
ing with reasoning. Advances in Neural Information Processing Systems, 35:

15476-15488, 2022.

D. M. Ziegler, N. Stiennon, J. Wu, T. B. Brown, A. Radford, D. Amodei,
P. Christiano, and G. Irving. Fine-tuning language models from human pref-
erences. arXiv preprint arXiv:1909.08593, 2019.
