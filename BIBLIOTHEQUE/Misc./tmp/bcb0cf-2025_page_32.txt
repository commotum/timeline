                     Published as a conference paper at ICLR 2025
                     F.6   DISTRIBUTION OF FPI ITERATIONS
                     WeanalyzedthedistributionofFixed-PointIteration(FPI)iterationsacrossdifferentlevelsofinputcomplexity:
                     Simple,Medium,andComplex. ThegoalwastoassesshowtheMINDmodeladjustsitsiterativecomputations
                     based on input difficulty. Table 15 provides the percentage breakdown of FPI iterations and the average
                     numberofiterations for each input complexity category.
                                    Table 15: Distribution of FPI iterations across different input complexities.
                                   Complexity     1-10    11-25   26-50    51-99    100   Avg. Iterations
                                   Simple        68.5%   24.7%    5.6%     1.1%    0.1%         8.3
                                   Medium        42.1%   35.6%    17.4%    4.3%    0.6%         19.7
                                   Complex       15.7%   32.3%    35.9%   13.8%    2.3%         37.2
                     Results and Observations   FromTable15,weobservethefollowing trends:
                            • Simple Inputs: The majority (68.5%) of simple inputs required only 1-10 iterations to converge,
                             with an average of 8.3 iterations. This demonstrates that simple inputs can be processed efficiently
                             with minimal iterative refinement.
                            • MediumInputs: Formediumcomplexityinputs,theFPIdistributionshiftstowardslongeriterations,
                             with 35.6% of inputs requiring 11-25 iterations and 17.4% requiring 26-50 iterations. The average
                             numberofiterations for medium inputs was 19.7, indicating that moderately complex inputs demand
                             moreiterative processing for accurate feature extraction.
                            • ComplexInputs: Complex inputs show the most diverse distribution of iterations. 35.9% required
                             26-50 iterations, while 32.3% required 11-25 iterations. A small percentage (2.3%) of complex
                             inputs required the maximum number of iterations (100), and the average number of iterations
                             was37.2. This suggests that the MIND model engages in more computational depth to handle the
                             intricate patterns found in these inputs.
                     This analysis highlights MIND’s capability to dynamically adapt its computational depth, using fewer
                     iterations for simpler tasks and more iterations for complex ones, thus ensuring an optimal balance between
                     computational efficiency and task accuracy.
                     G COMPUTATIONALCOSTANDLIMITATIONS
                     In a typical neural network, the computational steps are often straightforward, involving a series of matrix
                     multiplications and activation functions. In contrast, MIND model employs a more complex procedure
                     involving Fixed-Point Iteration (FPI) at each layer, in addition to the dynamic layer selection via the
                     introspection model mechanism. The computational cost can thus be broken down into the following main
                     components:
                           1. Forward pass through the prediction network
                           2. FPI computation for each dynamically-selected layer
                           3. Backward pass involving implicit differentiation
                           4. Forward and backward pass through the introspection model mechanism
                     Eachofthese steps has its own computational overhead (Liao et al., 2018; Banino et al., 2021), which can
                     growwiththecomplexity and dimensionality of the data being processed.
                                                                 32
