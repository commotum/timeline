                         AFastLearningAlgorithmforDeepBeliefNets                                                                               1533
                         reconstructed from the sampled hidden states. Computing the posterior
                         distribution over the second hidden layer, V , from the sampled binary
                                                                                                       1
                         states in the ﬁrst hidden layer, H , is exactly the same process as recon-
                                                                                   0
                         structing the data, so v1 is a sample from a Bernoulli random variable with
                                              0                i
                         probability vˆ . The learning rule can therefore be written as
                                              i
                                   ∂ log p(v0)                            
                                                      = h0 v0 −v1 .                                                                            (2.3)
                                             00              j    i       i
                                        ∂w
                                             ij
                         Thedependenceofv1 onh0 isunproblematicinthederivationofequation
                                                            i         j
                         2.3 from equation 2.2 because vˆ0 is an expectation that is conditional on h0.
                                                                             i                                                                      j
                         Since the weights are replicated, the full derivative for a generative weight
                         is obtained by summing the derivatives of the generative weights between
                         all pairs of layers:
                                   ∂ log p(v0)                                                                      
                                                     = h0 v0 −v1 + v1 h0 −h1 + h1 v1 −v2 +···                                                  (2.4)
                                        ∂w                   j   i       i           i     j        j           j   i        i
                                             ij
                              All of the pairwise products except the ﬁrst and last cancel, leaving the
                         Boltzmannmachinelearningruleofequation3.1.
                         3 Restricted Boltzmann MachinesandContrastiveDivergence
                             Learning
                         It may not be immediately obvious that the inﬁnite directed net in
                         Figure 3 is equivalent to a restricted Boltzmann machine (RBM). An RBM
                         has a single layer of hidden units that are not connected to each other and
                         have undirected, symmetrical connections to a layer of visible units. To
                         generate data from an RBM, we can start with a random state in one of
                         the layers and then perform alternating Gibbs sampling. All of the units
                         in one layer are updated in parallel given the current states of the units
                         in the other layer, and this is repeated until the system is sampling from
                         its equilibrium distribution. Notice that this is exactly the same process as
                         generating data from the inﬁnite belief net with tied weights. To perform
                         maximum likelihood learning in an RBM, we can use the difference be-
                         tween two correlations. For each weight, w , between a visible unit i and
                                                                                                  ij          
                         a hidden unit, j, we measure the correlation v0h0 when a data vector is
                                                                                                          i   j
                         clamped on the visible units and the hidden states are sampled from their
                         conditional distribution, which is factorial. Then, using alternating Gibbs
                         sampling, we run the Markov chain shown in Figure 4 until it reaches its
                                                                                                                 ∞ ∞
                         stationarydistributionandmeasurethecorrelation v h                                                . Thegradientof
                                                                                                                  i     j
                         the log probability of the training data is then
                                   ∂ log p(v0)                                  
                                                      = v0h0 − v∞h∞ .                                                                          (3.1)
                                        ∂w                   i   j         i    j
                                             ij
