                              Table 5: Matching with masks vs. boxes. We compare DETR [3] which uses box-based matching
                              with two MaskFormer models trained with box- and mask-based matching respectively. To use
                               box-based matching in MaskFormer we add to the model an additional box prediction head as in
                               DETR.Note,that with box-based matching MaskFormer performs on par with DETR, whereas with
                               mask-based matching it shows better results. The evaluation is done on COCO panoptic val set.
                                                                                                           Th       St
                                                    method              backbone   matching     PQ      PQ        PQ
                                                    DETR[3]            R50+6Enc     by box     43.4      48.2     36.3
                                                    MaskFormer(ours)   R50+6Enc     by box     43.7      49.2     35.3
                                                                       R50+6Enc     by mask    46.5      51.0     39.8
                               In this section, we discuss in detail the differences between MaskFormer and DETR and show how
                               these changes are required to ensure that mask classiﬁcation performs well. First, to achieve a
                               pure mask classiﬁcation setting we remove the box prediction head and perform matching between
                               prediction and ground truth segments with masks instead of boxes. Secondly, we replace the compute-
                               heavy per-query mask head used in DETR with a more efﬁcient per-image FPN-based head to make
                               end-to-end training without box supervision feasible.
                               Matching with masks is superior to matching with boxes. We compare MaskFormer models
                               trained using matching with boxes or masks in Table 5. To do box-based matching, we add to
                               MaskFormeranadditional box prediction head as in DETR [3]. Observe that MaskFormer, which
                               directly matches with mask predictions, has a clear advantage. We hypothesize that matching with
                               boxes is more ambiguous than matching with masks, especially for stuff categories where completely
                               different masks can have similar boxes as stuff regions often spread over a large area in an image.
                               MaskFormer mask head reduces computation. Results in Table 5 also show that MaskFormer
                               performsonparwithDETRwhenthesamematchingstrategyisused. Thissuggeststhatthedifference
                               in mask head designs between the models does not signiﬁcantly inﬂuence the prediction quality. The
                               newhead, however, has signiﬁcantly lower computational and memory costs in comparison with the
                               original mask head used in DETR. In MaskFormer, we ﬁrst upsample image features to get high-
                               resolution per-pixel embeddings and directly generate binary mask predictions at a high-resolution.
                               Note, that the per-pixel embeddings from the upsampling module (i.e., pixel decoder) are shared
                               amongallqueries. In contrast, DETR ﬁrst generates low-resolution attention maps and applies an
                               independent upsampling module to each query. Thus, the mask head in DETR is N times more
                               computationally expensive than the mask head in MaskFormer (where N is the number of queries).
                               6   Conclusion
                              The paradigm discrepancy between semantic- and instance-level segmentation results in entirely
                               different models for each task, hindering development of image segmentation as a whole. We show
                               that a simple mask classiﬁcation model can outperform state-of-the-art per-pixel classiﬁcation models,
                               especially in the presence of large number of categories. Our model also remains competitive for
                               panoptic segmentation, without a need to change model architecture, losses, or training procedure.
                              Wehopethisuniﬁcation spurs a joint effort across semantic- and instance-level segmentation tasks.
                               AcknowledgmentsandDisclosureofFunding
                              WethankRossGirshick for insightful comments and suggestions. Work of UIUC authors Bowen
                               ChengandAlexanderG.SchwingwassupportedinpartbyNSFunderGrant#1718221,2008387,
                               2045586, 2106825, MRI #1725729, NIFA award 2020-67021-32799 and Cisco Systems Inc. (Gift
                              AwardCG1377144-thanksforaccesstoArcetri).
                               References
                                [1] Pablo Arbeláez, Jordi Pont-Tuset, Jonathan T Barron, Ferran Marques, and Jitendra Malik. Multiscale
                                    combinatorial grouping. In CVPR, 2014. 2
                                [2] Holger Caesar, Jasper Uijlings, and Vittorio Ferrari. COCO-Stuff: Thing and stuff classes in context. In
                                    CVPR,2018. 2, 5
                                [3] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey
                                    Zagoruyko. End-to-end object detection with transformers. In ECCV, 2020. 1, 2, 3, 4, 5, 6, 8, 9, 10
                                                                                    10
