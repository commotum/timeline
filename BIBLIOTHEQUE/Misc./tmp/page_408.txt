396 Â® Unified Theories of Cognition

out programs (Pfefferkorn, 1971), and so on. They almost all used
annotated models, decorating the basic pure-model structure with
various flags and tags to expand the representational scope or to
control processing.

There are two plausible reasons why mental models could be
seen as conceptually distinct with respect to problem spaces. One is
the growth of the use of logic as a representation language in Al,
including its use for problem spaces (Fikes & Nilsson, 1971; Sacer-
doti, 1974, 1977; Nilsson, 1980). Indeed, by now, a movement
within AI that calls itself the logicists (Genesereth & Nilsson, 1987)
takes as axiomatic that all systems should be described in logical
form. Thus, the contrast between mental models and propositional
representations could easily be taken to be the contrast between
mental models and problem spaces, despite the massive work to the
contrary. The other reason is the focus, in early AI work in mental
models, on dynamical physical systems, such as reasoning about
balls rolling down hills (Bobrow, 1985). In contrast, the early work
on problem spaces was static; all changes were due to the thought
(or action) of the problem solver. This made the two cases seem
quite different, especially since work on the dynamical situation
focused on the issues of mentally running models that were only
qualitatively defined (envisionment) while pretty much ignoring the
other types of operators of the problem space. Mental models soon
expanded to include reasoning about light switches or temperature
shifts, but the separation was probably pretty well fixed by then.

7.2.4. Soar on Syllogisms
Let us assume that humans use annotated models as their internal
representation. This is an additional hypothesis beyond the Soar
architecture as described in Chapter 4. The basic representational
media of objects with attributes and values is neutral with respect to
the use of propositional or model representations, or any other
assumption about the way internal structure corresponds to the
external world. We ignore the issue of what gives rise to this restric-
tion. It could be genuinely architectural, or it could be due to the
way encodings are developed, say, because of operating in real
time. In any event, the emphasis here is not on the hypothesis per
se, but on exploring its incorporation into Soar.

Thus, we can now turn to syllogisms to see how Soar would do
