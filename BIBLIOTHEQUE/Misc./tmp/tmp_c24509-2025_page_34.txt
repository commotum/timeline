        [20] Zhiyuan Ma, Yuxiang Wei, Yabin Zhang, Xiangyu Zhu, Zhen Lei, and Lei Zhang. ScaleDreamer: Scalable
           text-to-3D synthesis with asynchronous score distillation. In European Conference on Computer Vision, pages
           1–19, 2024.
        [21] Kazuto Nakashima and Ryo Kurazume. Learning to drop points for LiDAR scan synthesis. In IEEE/RSJ
           International Conference on Intelligent Robots and Systems, pages 222–229, 2021.
        [22] Kazuto Nakashima and Ryo Kurazume. LiDAR data synthesis with denoising diffusion probabilistic models. In
           IEEE International Conference on Robotics and Automation, pages 14724–14731, 2024.
        [23] Kazuto Nakashima, Yumi Iwashita, and Ryo Kurazume. Generative range imaging for learning scene priors of 3D
           LiDAR data. In IEEE/CVF Winter Conference on Applications of Computer Vision, pages 1256–1266, 2023.
        [24] Lucas Nunes, Rodrigo Marcuzzi, Benedikt Mersch, Jens Behley, and Cyrill Stachniss. Scaling diffusion models to
           real-world 3D LiDAR scene completion. In IEEE/CVF Conference on Computer Vision and Pattern Recognition,
           pages 14770–14780, 2024.
        [25] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
           Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. PyTorch: An imperative style, high-performance deep
           learning library. Advances in Neural Information Processing Systems, 32:8026–8037, 2019.
        [26] William Peebles and Saining Xie. Scalable diffusion models with transformers. In IEEE/CVF International
           Conference on Computer Vision, pages 4195–4205, 2023.
        [27] Haoxi Ran, Vitor Guizilini, and Yue Wang. Towards realistic scene generation with LiDAR diffusion models. In
           IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14738–14748, 2024.
        [28] Jiawei Ren, Liang Pan, Jiaxiang Tang, Chi Zhang, Ang Cao, Gang Zeng, and Ziwei Liu. DreamGaussian4D:
           Generative 4D gaussian splatting. arXiv preprint arXiv:2312.17142, 2023.
        [29] Jiawei Ren, Kevin Xie, Ashkan Mirzaei, Hanxue Liang, Xiaohui Zeng, Karsten Kreis, Ziwei Liu, Antonio Torralba,
           Sanja Fidler, Seung Wook Kim, and Huan Ling. L4GM: Large 4d gaussian reconstruction model. arXiv preprint
           arXiv:2406.10324, 2024.
        [30] Xuanchi Ren, Jiahui Huang, Xiaohui Zeng, Ken Museth, Sanja Fidler, and Francis Williams. XCube: Large-scale
           3Dgenerative modeling using sparse voxel hierarchies. In IEEE/CVF Conference on Computer Vision and Pattern
           Recognition, pages 4209–4219, 2024.
        [31] Sara Rojas, Julien Philip, Kai Zhang, Sai Bi, Fujun Luan, Bernard Ghanem, and Kalyan Sunkavall. DATENeRF:
           Depth-aware text-based editing of nerfs. arXiv preprint arXiv:2404.04526, 2024.
        [32] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image
           synthesis with latent diffusion models. In IEEE/CVF Conference on Computer Vision and Pattern Recognition,
           pages 10684–10695, 2022.
        [33] Yichun Shi, Peng Wang, Jianglong Ye, Mai Long, Kejie Li, and Xiao Yang. MVDream: Multi-view diffusion for
           3D generation. arXiv preprint arXiv:2308.16512, 2023.
        [34] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition.
           arXiv preprint arXiv:1409.1556, 2015.
        [35] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron
           Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. Make-A-Video: Text-to-video generation
           without text-video data. In International Conference on Learning Representations, 2022.
        [36] Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual, Iurii Makarov, Filippos Kokkinos, Naman Goyal, Andrea
           Vedaldi, Devi Parikh, Justin Johnson, and Yaniv Taigman. Text-to-4D dynamic scene generation. arXiv preprint
           arXiv:2301.11280, 2023.
        [37] Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin
           Zhou, Yuning Chai, Benjamin Caine, Vijay Vasudevan, Wei Han, Jiquan Ngiam, Hang Zhao, Aleksei Timofeev,
           Scott Ettinger, Maxim Krivokon, Amy Gao, Aditya Joshi, Yu Zhang, Jonathon Shlens, Zhifeng Chen, and
           Dragomir Anguelov. Scalability in perception for autonomous driving: Waymo open dataset. In IEEE/CVF
           Conference on Computer Vision and Pattern Recognition, pages 2446–2454, 2020.
        [38] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking the
           inception architecture for computer vision. In IEEE/CVF Conference on Computer Vision and Pattern Recognition,
           pages 2818–2826, 2015.
                                  34
