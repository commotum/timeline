                                          Test-Time Learning for Large Language Models
                             Table 12. Comparison of experimental results on the Medicine dataset of DomainBench.
                 Method              BERTScore↑    BLEURT↑     BLEU↑     Rouge-1 ↑   Rouge-2 ↑   Rouge-L↑
                 Llama3.2-3B-Instruct  0.6677       -0.7668     0.0165     0.1588     0.0269      0.1037
                   •Tent               0.6322       -1.2819     0.0191     0.1897     0.0276      0.1204
                   •EATA               0.6554       -0.9669     0.0018     0.0312     0.0017      0.0178
                   •TLM(Ours)          0.7005       -0.5603     0.0463     0.2559     0.0728      0.1844
                 Llama3-8B-Instruct    0.6628       -0.7486     0.0136     0.1398     0.0343      0.0911
                   •Tent               0.5525       -1.3487     0.0014     0.0113     0.0006      0.0089
                   •EATA               0.6072       -1.1079     0.0011     0.0139     0.0011      0.0100
                   •TLM(Ours)          0.7095       -0.4781     0.0486     0.2646     0.0836      0.1889
                 Llama2-13B-chat       0.6559       -0.5971     0.0158     0.1439     0.0397      0.0956
                   •Tent               0.6235       -0.5867     0.0100     0.1250     0.0261      0.0874
                   •EATA               0.6543       -0.4349     0.0145     0.1465     0.0410      0.1007
                   •TLM(Ours)          0.6988       -0.4615     0.0512     0.2370     0.0890      0.1760
                 Qwen2.5-7B-Instruct   0.6561       -0.6598     0.0136     0.1441     0.0369      0.0909
                   •Tent               0.5884       -1.1911     0.0097     0.0548     0.0214      0.0454
                   •EATA               0.6408       -0.7171     0.0163     0.1672     0.0304      0.1202
                   •TLM(Ours)          0.7082       -0.5964     0.0623     0.2623     0.1003      0.1967
                             Table 13. Comparison of experimental results on the Finance dataset of DomainBench.
                 Method              BERTScore↑    BLEURT↑     BLEU↑     Rouge-1 ↑   Rouge-2 ↑   Rouge-L↑
                 Llama3.2-3B-Instruct  0.6809       -0.6532     0.0360     0.2425     0.0791      0.1602
                   •Tent               0.6322       -1.2819     0.0191     0.1149     0.0549      0.1084
                   •EATA               0.5028       -1.2700     0.0010     0.0150     0.0001      0.0149
                   •TLM(Ours)          0.7060       -0.5113     0.0801     0.3206     0.1255      0.2367
                 Llama3-8B-Instruct    0.6862       -0.6230     0.0407     0.2530     0.0873      0.1682
                   •Tent               0.5919       -0.9704     0.0032     0.0390     0.0072      0.0351
                   •EATA               0.6431       -1.2160     0.0149     0.1398     0.0567      0.1183
                   •TLM(Ours)          0.7153       -0.4411     0.0952     0.3514      0.1448     0.2576
                 Llama2-13B-chat       0.6814       -0.6217     0.0427     0.2591     0.0892      0.1722
                   •Tent               0.4878       -1.1973     0.0006     0.0049     0.0000      0.0049
                   •EATA               0.6203       -1.0560     0.0250     0.1241     0.0574      0.1113
                   •TLM(Ours)          0.6979       -0.5110     0.0628     0.3009     0.1104      0.2064
                 Qwen2.5-7B-Instruct   0.6978       -0.5370     0.0639     0.2969     0.1124      0.2025
                   •Tent               0.6623       -1.1316     0.0313     0.1835     0.0845      0.1533
                   •EATA               0.7103       -0.5746     0.0810     0.3127     0.1358      0.2409
                   •TLM(Ours)          0.7220       -0.3890     0.0968     0.3607     0.1487      0.2616
                                                            25
