                                                                       box     mask
                        Model          Pre-trained     Method      AP     / AP
                                                       Default       45.9 / 41.0                   0.9
                   ViT-Adapter-Ti        DeiT-Ti        LaPE         46.2 / 41.2
                                                         PVG         46.1 / 41.2                   0.8
                                                       MPVG          46.5 / 41.4
                Table 3: Performance comparison of Object Detection on                             0.7
                COCO2017. For comparison, DeiT-Ti model pretrained on
                ImageNet-1K with each method is used.                                           elation Coefficient0.6                                 DeiT-Ti
                                                                                                r                                                      DeiT-S
                           Model            Pre-trained     Method       mIoU                   Cor0.5                                                 CeiT-Ti
                                                            Default      40.55                                                                         T2T-ViT-7
                      ViT-Adapter-Ti          DeiT-Ti        LaPE        41.42                          2     3    4     5     6    7     8    9    10    11   12
                                                              PVG        41.07                                                Layer Index
                                                            MPVG 41.69                        Figure 4: Correlation coefficient between token embedding
                Table4:PerformancecomparisonofSemanticSegmentation                            and position embedding in Layer-wise. Each token embed-
                on ADE20K. For comparison, DeiT-Ti model pretrained on                        ding and position embedding is based on the values after
                ImageNet-1K with each method is used.                                         applying LN. DeiT-Ti, DeiT-S, and CeiT-Ti each have a to-
                                                                                              tal of 12 layers, but T2T-ViT-7 has 7 layers.
                our method on object detection tasks, we select the ViT-
                Adapter-Ti (Chen et al. 2022) model based on Mask R-                               Token         0     1                         
                                                                                                 Embedding                                 P
                                                                                                                 er    er ‚Ä¶      er                     72.40%
                CNN (He et al. 2017) in MMDetection framework (Chen                                       ‚äï      y     y         y     LN  GA   MLPHead
                                                                                                  Position       La    La        La
                et al. 2019). Additionally, we use the default settings and                      Embedding
                train it for 36 epochs using the 3x+MS(multi-scale training)                                             (a) DeiT-Ti + GAP                 -0.26%
                schedule. As shown in Table 3, MPVG achieves improve-
                ments of +0.6 in box AP and +0.5 in mask AP compared
                to the default setting. MPVG, in particular, demonstrates su-                      Token        0      1                         
                                                                                                 Embedding                                 P
                                                                                                                er     er ‚Ä¶      er                     72.14%
                perior performance with an increase of +0.5 in box AP and                                 ‚äï     y      y         y     LN  GA   MLPHead
                                                                                                  Position      La     La        La
                +0.4 in mask AP over PVG.                                                        Embedding
                                                                                                                   (b) DeiT-Ti + GAP + Last LN(Ì†µÌ±ùÌ†µÌ±úÌ†µÌ±† )
                Semantic Segmentation                                                                                                                 0
                On semantic segmentation, we evaluate our methods on                          Figure 5: Comparison of two methods on DeiT-Ti. (a) Struc-
                ADE20K (Zhou et al. 2019). We select the ViT-Adapter-                         ture with only GAP applied, showing 72.40% performance;
                Ti (Chen et al. 2022) model based on UperNet (Xiao et al.                     and (b) Structure with GAP and position embedding added
                2018) in MMsegmentation framework (Contributors 2020)                         to the Last LN in a non-Layer-wise structure, also showing
                and train it using the default settings. As shown in Ta-                      72.14%performance.
                ble 4, MPVGachievesanimprovementof+1.14mIoUcom-
                paredtothedefault.Furthermore,MPVGoutperformsPVG,
                achieving a performance improvement of +0.62 mIoU.                            formance of vision transformers.
                Analysis                                                                         In conclusion, several key points can be identified: (1)
                                                                                              In the initial layers, PE primarily provides positional infor-
                Through experiments on image classification, object detec-                    mation, enabling the model to understand the spatial rela-
                tion, and semantic segmentation, we demonstrate the effec-                    tionships between tokens. However, as the layers deepen,
                tiveness of MPVG.Inalltasks,MPVGnotonlyoutperforms                            PE plays a role in counterbalancing the token embedding.
                the baseline but also achieves the best performance among                     (2) This counterbalancing effect of PE has a significant im-
                all methods. This validates our hypothesis and proves that                    pact on the performance of vision transformers. Therefore,
                our method is an effective approach to maximizing PE in                       MPVGdemonstratesthatmaintainingthisdirectionisbene-
                the GAP method. Fig 4 shows that in Layer-wise structure,                     ficial for vision transformers and proves that PE can perform
                token embedding and position embedding exhibit increas-                       additional roles to sustain this effect.
                inglyopposingdirectionsasthelayersdeepen.Thissuggests                         Effect of PE in Last LN
                that PE not only provides positional information in the ini-
                tial layers but also may play a counterbalancing role that                    Weconduct additional experiments to validate our hypoth-
                becomes more pronounced in deeper layers. To further ex-                      esis. Specifically, we aim to confirm that adding PE to the
                plore this, we compare PVG and MPVG to confirm that PE                        Last LN effectively maintains the counterbalancing role of
                has a counterbalancing effect. This comparison proves that                    PE in Layer-wise structure. We compare the method using
                maintainingthecounterbalancingroleofPEimpactstheper-                          only GAP with the method that adds PE to the Last LN in
