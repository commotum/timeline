                                             Dataset    Avgtimeperepoch(s)      # of J mat-vec products   Accuracy %
                                                                                                6
                              Jacobian       MNIST               28.4                   6.0 √ó107              99.2
                               based         SVHN                92.8                   1.4 √ó10               90.1
                                                                                                8
                                            CIFAR10             530.9                   9.7 √ó10               87.9
                                             MNIST               17.6                       0                 99.4
                                JFB          SVHN                36.9                       0                 94.1
                                            CIFAR10             146.6                       0                 93.67
             Table 2: Comparison of Jacobian-based backpropagation (Ô¨Årst three rows) and our proposed JFB approach. ‚ÄúMat-vecs‚Äù denotes
             matrix-vector products.
                  % 95   Proposed Backprop (JFB)                                 %
                                                                                   99
                    90
                    85                      Jacobian-based                              Proposed Backprop (JFB)
                  Accuracy                                                       Accuracy98
                  est80                        Backprop                          est    Neumann: k = 5
                  T                                                              T      Neumann: k = 10
                    75                                                             97
                       0        250      500       750      1,000                     0        25        50        75       100
                                        Epoch                                                          Epoch
                    % 95    Proposed Backprop (JFB)                               %
                                                                                    99
                      90
                      85                     Jacobian-based                             Proposed Backprop (JFB)
                    Accuracy                                                      Accuracy98
                    est80                       Backprop                          est   Neumann: k = 5
                    T                                                             T     Neumann: k = 10
                      75                                                            97
                        0    20 40 60 80 100 120 140                                   0      10      20     30      40      50
                                       Time (hr)                                                    Time (min)
             Figure 5: CIFAR10 results using comparable networks/-          Figure 6: MNIST training using different truncations k of
             conÔ¨Ågurations, but with two backpropagation schemes: our       theNeumannseries(22)toapproximatetheinverseJacobian
             proposed JFB method (blue) and standard Jacobian-based         J‚àí1. Plots show faster training with fewer terms (fastest
                                                                             Œò
             backpropagation in (14) (green), with Ô¨Åxed point tolerance     with JFB, i.e. k = 0) and competitive test accuracy.
              = 10‚àí4. JFB is faster and gives better test accuracy.
                                                                                                 Conclusion
             HigherOrderNeumannApproximation                                This work presents a new and simple Jacobian-free back-
                                                                            propagation (JFB) scheme. JFB enables training of implicit
                                                                            networks with Ô¨Åxed memory costs (regardless of depth), is
             As explained in Section , JFB can be interpreted as an ap-     easy to code (see Figure 3), and yields efÔ¨Åcient backpropa-
             proximation to the Jacobian-based approach using a zeroth      gation. Use of JFB is theoretically justiÔ¨Åed (even when Ô¨Åxed
             order (i.e. k = 0) truncation to the Neumann series expan-     pointsareapproximatelycomputed).ExperimentsshowJFB
             sion (22) of the Jacobian inverse J‚àí1. Figure 6 compares       yields competitive results for implicit networks. Extensions
                                               Œò
             JFB with training using more Neumann series terms in the       will enable satisfaction of additional constraints for imag-
             approximation of the Jacobian inverse J‚àí1. Figure 6 shows      ing (Klibanov 1986; Fienup 1982; Heaton et al. 2020; Fung
                                                   Œò
             JFB is competitive at reduced time cost. SigniÔ¨Åcantly, JFB     and Wendy 2020; Kan, Fung, and Ruthotto 2020), geo-
             is also much easier to implement (see Figure 3). See ap-       physics (Haber 2014; Fung and Ruthotto 2019a,b), and
             pendix for more experiments with SVHN and discussion           games (Von Neumann 1959; Lin et al. 2021; Ruthotto et al.
             about code.                                                    2020).
                                                                      6654
