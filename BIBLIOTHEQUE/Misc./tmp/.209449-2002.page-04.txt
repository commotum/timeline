                                                                                                                                                       articles
                         a          Experimental data                                Optimal control           Fig. 3. Trajectory variability. Within-subject positional
                            )                                                                                  variance (left) compared to model variance (right).
                           2 0.4                                                                         0.4   Dots mark passage through the intermediate targets;
                                                              5 cm                                             the square in each inset marks the starting position.
                                                                                                               (a) In the multiple target condition A, experiment 1,
                            iance (cm                                                                          subjects moved through the black targets shown in the
                            r0.2                                                                         0.2   inset. In the constrained trajectory condition B, 16
                            a                                                                                  more targets (gray) were added. (b) In the ‘1 small’
                                                                                                               condition, experiment 3, the first intermediate target
                                                   A: 5 Targets                                                was smaller; in the ‘2 small’ condition, the second
           oscience         ositional v B: 21 Targets                                                          intermediate target was smaller.
                            P  0                                                                         0
                                5             50            95             5             50            95
                                       Path length (%)
                         b                                                                                     kinematics: whereas all paths that lead to the tar-
                           2)0.8                                                                        0.8    get appear redundant from a kinematic point of
                                                                                                               view, completing the movement from intermedi-
           .com/natureneur                                     5 cm                                            ate states far from the target (such as the mid-
                                                                                                               points of curved paths) requires larger control
                            iance (cm                                                                          signals—which are more costly and introduce
                            r0.4                                                                         0.4
           .nature          a                                                                                  more multiplicative noise.
                                                                                                                   Next we formalize the notion of ‘correcting’ a
                                                                                                                                                     –
                                                          2 Small                                              deviation ∆x away from the average x. It is natur-
                            ositional v        1 Small                                                         al to define the corrective action corr due to the
           http://www       P  0                                                                         0                                     ∗   –
                                5             50            95            5             50             95      optimal control signal u = π (t,x + ∆x) as the
                                       Path length (%)                                                         amount of state change opposite to the deviation.
           oup                                                                                                 To separate the effects of the control signal from
                           This example illustrates two additional properties of optimal        those of the passive dynamics, consider the (very general) fami-
                       feedback control that will be discussed in more detail below.            ly of dynamical systems dx  =  a(t,x)dt  +  B(t,x)udt  +
                                                                                                 k
                       First, the optimal control signals are synergetically coupled—           Σ C(t,x)udε, where a(t,x) are the passive dynamics, B(t,x) are
                                                                                                 i=1 i         i
                       not because the controller is trying to ‘simplify’ the control prob-     the control-dependent dynamics, C(t,x) are multiplicative noise
           lishing Gr                                                                                                                i
                       lem, but because the synergy is the optimal solution to that             magnitudes, and εi(t) are independent standard Brownian
                       problem. Second, the optimal control signals are smaller than            motion processes. For such systems, the expected instantaneous
                                                                                                              .                                        .       –
                       the control signals needed to instantiate the best possible desired      state change x due to the optimal control signal is x = B(t,x +
                                                                                                     ∗   –    u                                        u
                       state (Fig. 1).                                                          ∆x)π (t,x + ∆x). Now the corrective action can be defined by
                                                                                                             .                          .
                           What is redundancy, precisely? In the case of reaching, for          projecting –x on ∆x: corr(∆x) =∆x, –x .
                                                                                                              u                           u             ∗
                       example, all final arm configurations for which the fingertip is            To complete the analysis, we need to relate ∆v (∆x) and
           2002 Nature Pubat the specified target are task-equivalent, that is, they form a     corr(∆x), which in turn requires a relationship between v∗ and
                                                                                                 ∗                                                     ∗
           ©           redundant set. During the movement, however, it is not obvious           π . The latter two quantities are indeed related, and v carries all
                       what set of intermediate arm configurations should be consid-            the information needed to compute π∗—which is why it is so
                       ered task-equivalent. Therefore we propose the following more            fundamental to optimal control theory. In particular, π∗(t,x) =
                       general approach. Let the scalar function v∗                                    –1       T ∗                                    k         T
                                                                       (t,x) indicate how       –Z(t,x)   B(t,x) v (t,x), where Z(t,x) =2R(t,x) + Σ        C(t,x)
                                                                                                 ∗                  x ∗      ∗                          i=1 i    ∗
                       well the task can be completed on average (in a sense to be made         v (t,x) C(t,x), and v and v    are the gradient and Hessian of v .
                                                                                                 xx      i   ∗       x       xx                                ∗
                       precise below), given that the plant is in state x at time t. Then it    Expanding v to second order, also expanding its gradient v to
                                                                            ∗                                                                                  x
                       is natural to define all states x(t) with identical v (t,x) as being     first order, and approximating all other quantities as being con-
                                                                                                                                   –
                       task-equivalent.                                                         stant in a small neighborhood of x, we obtain
                                          ∗
                           The function v is not only needed to define redundancy, but
                                                                                                      ∗             ∗    ∗
                       also is fundamental in stochastic optimal control theory, which             ∆v (∆x) ≈ ∆x,v + v ∆x
                                                                                                                    x    xx
                                                                                                                    ∗    ∗
                       we now introduce briefly to develop our ideas. Let the instanta-            corr(∆x) ≈ ∆x,v + v ∆x       –1 T
                       neous cost for being in state x ∈ m and generating control u ∈                              x    xx    BZ B
                         n                        T
                        at time t be q(t,x) + u R(t,x) u ≥ 0, where the first term is a           where the weighted dot-product notation a,bM stands for
                                                                                                 T
                       (very general) encoding of task error, and the second term penal-        a Mb.
                                                                               ∗                                               ∗
                       izes effort. The optimal feedback control law u = π (t,x) is the            Thus both corr(∆x) and ∆v (∆x) are dot-products of the same
                       time-varying mapping from states into controls that minimizes            two vectors. When v∗+ v∗ ∆x = 0, which can happen for infi-
                                                                ∗                                                     x    xx         ∗
                       the total expected cost. The function v (t,x), known as the ‘opti-       nitely many ∆x when the Hessian vxx is singular, the deviation
                       mal cost-to-go’, is the cumulative expected cost if the plant is ini-    ∆xis redundant and the optimal control law takes no corrective
                                                                                       ∗                                           ∗
                       tialized in state x at time t, and the optimal control law π is          action. Furthermore, corr and ∆v are positively correlated, that
                       applied until the end of the movement. To complete the defini-           is, the control law resists single-trial deviations that take the sys-
                                –
                       tion, let x(t) be the average trajectory, and on a given trial let the   tem to more costly states and magnifies deviations to less costly
                                         –
                       plant be in state x + ∆x at time t. The deviation ∆x is redundant        states.
                            ∗                    ∗       ∗ –             ∗   –
                       if ∆v (∆x) = 0, where ∆v (∆x) =v (t,x + ∆x) – v (t,x).                      This analysis confirms the minimal intervention principle to
                           Returning to the case of reaching, at the end of the movement        be a very general property of optimal feedback control, explain-
                       our definition reduces to the above kinematic approach, because          ing why variability patterns elongated in task-irrelevant dimen-
                       the instantaneous cost and the cost-to-go become identical. Dur-         sions have been observed in such a wide range of experiments
                                                        ∗                                       involving different actuators and behavioral goals.
                       ing the movement, however, v depends on dynamics as well as
                       nature neuroscience •  volume 5  no  11  •  november 2002                                                                              1229
