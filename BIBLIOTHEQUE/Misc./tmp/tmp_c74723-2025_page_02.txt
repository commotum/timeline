                model the 3D geometry and its panoptic segmentation in a           class-agnostic instance segmentation jointly trained with a
                unified, end-to-end framework that performs directly multi-        semantic segmentation branch. Gao et al. [17] jointly trains
                view consistent panoptic segmentation. Existing works for          semantic class labeling with a pixel-pair affinity pyramid,
                such panoptic 3D reconstruction usually focus on single-           and Yuan et al. [71] generalizes object-contextual represen-
                image inputs [11, 74] or require posed video inputs [63].          tations to panoptic segmentation.
                   Instead, building on top of the recent 3D reconstruc-              With     the    success    of    Vision     Transformers,
                tion network MUSt3R [61], we propose PanSt3R (Panoptic             Mask2Former [15], inspired by DETR           [4], adopted a
                MUSt3R)whichjointlypredictsthe3Dscenegeometryand                   more unified approach to directly produce panoptic output,
                its panoptics from an unconstrained collection of unposed          posing the task as a mask prediction and classification
                images in a single forward pass. PanSt3R leverages two             problem.    Several recent extensions also aim for open-
                pre-trained feature extractors to encode frames in both se-        vocabulary segmentation capabilities (e.g.using a CLIP
                mantic (2D) and 3D-aware information, then directly re-            text encoder) [7, 14, 18, 20, 29, 43, 67, 70].      Recently,
                gresses 3D geometry via a 3D head, and performs multi-             several diffusion-based methods were also proposed for
                view instance mask prediction via a Mask2Former-like de-           this task [6, 56, 60, 65].
                coder. These mask predictions are finally filtered using a         3D Panoptic Segmentation is a direct extension of 2D
                lightweight novel quadratic binary optimization framework          panoptic segmentation for 3D scenes. We can distinguish
                (QUBO). This turns out to be a crucial step in our method,         between several categories of approaches. First, methods
                as we show that the standard filtering technique is poorly         that directly process an input 3D point cloud, typically ob-
                suited for multi-view predictions. Finally, we demonstrate         tained by dedicated sensors (ToF or LIDAR), thereby as-
                that it is straightforward to generate novel view panoptic         suming prior knowledge of the 3D scene geometry [21, 27,
                predictions based on the outputs of our method via simple          45, 51, 66].
                test-time uplifting of labels to 3DGS [35].                           Thesecondcategoryofmethods,closertoourapproach,
                   In summary, our main contributions are as follows. We           requires only a set of input images and respective camera
                introduce a method for joint 3D reconstruction and panop-          parameters (if not provided directly, the latter is usually
                tic segmentation, which tackles the problem with a single          obtained via standard SfM techniques [48]). Existing ap-
                forward pass. The approach is simple, fast, and operates           proaches in this category are either based on NeRF [36],
                on hundreds of images without requiring any camera pa-             or Gaussian Splatting [22], with implicit or explicit labeled
                rameters or test-time optimization. Second, we propose a           3D representations as output, respectively. These methods
                novel and mathematically grounded mask prediction merg-            typically perform 3D panoptic segmentation by lifting 2D
                ing strategy to further improve the quality of multi-view          segmentation masks obtained with pre-trained 2D panoptic
                panoptic predictions. Third, we introduce two distinct and         segmentation models (e.g.Mask2Former [15]) to 3D. Zhi
                simple approaches for novel-view synthesis with panoptic           et al. [75] showed that noisy 2D semantic segmentations
                segmentation, leveraging our framework and 3D Gaussian             can be fused into a consistent volumetric model by a NeRF,
                Splatting.  Finally, we conduct extensive evaluation and           and their model was extended to instance and panoptic seg-
                ablative studies on several datasets, obtaining state-of-the-      mentation in [16, 25, 57].
                art results, both in terms of panoptic quality and inference          Panoptic NeRF [16] starts from a set of sparse images,
                speed.                                                             coarse 3D bounding primitives and noisy 2D predictions to
                                                                                   generate panoptic labels via volumetric rendering. Panoptic
                2. Related work                                                    Neural Fields (PNF) [25] learns a panoptic radiance field
                                                                                   with a separate instance MLP and a semantic MLP by ex-
                2DPanopticSegmentationisaunificationofsemanticand                  plicitly decomposing the scene into a set of objects and
                instance segmentation tasks. Its goal is to decompose an           amorphous background. These MLPs collectively define
                image into different regions, each region corresponding to         the panoptic-radiance field describing 3D point color, se-
                an individual object (denoted as thing) or uncountable con-        mantic and instance labels. DM-NeRF [57] introduced an
                cepts like ‘sky’ or ‘ground’ (denoted as stuff). The first         object field component to learn unique codes for all indi-
                panoptic methods extended Mask R-CNN [19] to design a              vidual objects in 3D space from 2D supervision and panop-
                deformable-convolution-based semantic segmentation head            tic segmentation with an extra semantic branch parallel to
                and solve the two subtasks simultaneously [13, 23, 24, 37,         object code branch. Panoptic Lifting (PanLift) [50] relies
                64].  Another set of models [8, 40, 59, 68] build upon             on TensoRF [5] on top of which they introduce lightweight
                the DeepLab architecture [31]. Instead, [30] combines a            output heads for learning semantic and instance fields. The
                proposal attention module with a mask attention module,            core idea of Contrastive Lift [2] is a slow-fast clustering ob-
                [33] proposes an end-to-end occlusion-aware pipeline, and          jective function well suited for scenes with a large number
                [52]introducesafullydifferentiableend-to-endnetworkfor             of objects. They lift 2D segments to 3D fusing them by
                                                                              5857
