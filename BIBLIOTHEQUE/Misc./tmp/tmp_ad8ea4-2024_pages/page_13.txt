                                 Base             Model         Context     Evaluation Context Length         Avg.
                                LLM               Name          Window        4k       8k          16k
                                                 Original           4k      82.23      0            0        27.41
                                                  PI(s=4)          16k      75.22    72.61       68.81       72.21
                            LLaMA2-7B           YaRN(s=4)          16k      76.21    72.84       67.70       72.25
                                              CLEX(ms=16)          64k      53.04    49.38       49.79       50.74
                                                Ours(s=4)          16k      78.74    75.55       71.78       75.35
                                                 Original           4k      84.93      0            0        28.31
                                                  PI(s=4)          16k      76.22    72.41       66.97       71.87
                            LLaMA2-13B          YaRN(s=4)          16k      72.37    68.97       63.27       68.20
                                              CLEX(ms=16)          64k      58.27    53.69       51.48       54.48
                                                Ours(s=4)          16k      79.40    76.21       71.65       75.75
                 Table8: ComparativeperformanceanalysisofvariouscontextwindowextensionmethodsontheRULERbenchmark.
                 Thescaling factor of CLEX is dynamic, "ms" denotes the maximum scaling factor, and we set the maximum scaling
                 factor to 16 in accordance with the settings of (Chen et al., 2024).
                 long documents, with our approach achieving the          B.2.3   Perplexity
                 highest retrieval accuracy. The original LLaMA2          Perplexity is commonly employed to evaluate a
                 model, due to its limited capacity for handling long     model’s language modeling capabilities, and we
                 documents, fails to produce accurate answers when        tested the perplexity of different methods under
                 the context length exceeds 4k tokens. The infe-          non-training conditions, with the results presented
                 rior performance of CLEX may be attributed to the        in Table 10. However, perplexity often fails to re-
                 introduction of new parameters for predicting the        flect a model’s actual performance on downstream
                 scaling factor, which requires more training data to     tasks, as a model may exhibit a relatively low per-
                 fit, thereby leading to sub-optimal performance in       plexity in non-training scenarios yet perform poorly
                 scenarios with limited data.                             in real-world applications. In contrast to the de-
                                                                          crease in perplexity, we are more concerned with
                 B.2.2    Timecomplexity                                  the model’s performance on actual tasks.
                 Considering the balance between efficiency and                                         Context Length
                 performance, we also provide the time consump-               ModelSize      Method      8k        16k
                 tion of different methods, as shown in Table 9. To                             PI      8.19      9.35
                 facilitate comparison, we normalized the time con-                           YaRN      7.39      7.82
                 sumption. In comparison to a fixed scaling factor,               7B          CLEX      7.30      7.87
                 CLEXintroducesadditional parameters to predict                               Ours      7.12      7.72
                 the scaling factor, which necessitates the recalcula-                          PI      7.02      8.23
                 tion of positional encoding, thereby increasing the                          YaRN      6.06      7.77
                 training and inference times.                                    7B          CLEX      6.08      7.58
                       ModelSize      Method Train Test                                       Ours      5.91      7.39
                                          PI        1        1           Table 10: Sliding window perplexity (S = 256) on PG19
                            7B          YaRN        1        1            dataset.
                                       CLEX        1.62    1.83
                                        Ours        1        1
                                          PI        1        1            B.3   Passkey Prompt
                           13B          YaRN        1        1           Wefollowexperimental setup of Mohtashami and
                                       CLEX        1.53    1.81           Jaggi (2023); Chen et al. (2023). We separately
                                        Ours        1        1            employed our method with scaling factors of s=2
                         Table 9: Time cost of diferent methods.          ands=4toextendthecontextwindowsofLLaMA2
                                                                         7Band13Bto8kand16k,respectively. Figure 9
                                                                          shows the prompt template.
                                                                     7300
