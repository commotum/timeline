                     Sample Prompt Template                              77.5%, whereas on the second subset the two mod-
                     Let the answer to Q1 be X.                           els give an accuracy of 28.8% and 3.8%. We still
                     Q1: <Text of the question>.                          keep the first subset despite the high performance
                     Let X’ = X + (A2 - A1). Use this value to            of the o3-mini model so it can be used to distin-
                     solve Q2.                                            guish among smaller, general-purpose models.
                     Q2: <Text of the question with A2 replaced             For the new set we created, we always ask about
                     with "X’">.                                          the truthfulness of one of the people at the end of
                                                                          the chain, and another person at an earlier position
                                                                          in the chain (but still far off in the chain). Concep-
                    In some cases, the answer to a question might         tually, one would expect that if a model has made
                 contain multiple numbers, e.g. a date with three         a mistake for the person at an earlier position in
                 numbers. In those cases, we assign these values          the chain, then the chances of making a mistake for
                 to variables X, Y, and Z and use them in the later       the person at the end of the chain must be higher.
                 questions.                                              Weverified whether this is the case for our models.
                 A.21    WebofLies                                        For o3-mini, we observe that the accuracy for both
                                                                          cases is 41.2%, for Gemini 2.0 Flash it is 30% for
                 In this task, whether a specific person P1 tells the     the earlier person and 27.5% for the last person,
                 truth of lies is provided as input. Then, for other      and for Gemini 2.0 Flash-Lite it is 25.6% for the
                 people, it is specified what they say about the truth    earlier person and 21.2% for the last person, all
                 value of some other person. This forms a chain-like      showing this effect. GPT4o, however, is surpris-
                 structure that can be started from P1 and continued      ingly behaving the opposite, having an accuracy of
                 to find whether each of the people tells the truth or   19.4% for the earlier person and 25% for the last
                 lies.                                                    person.
                    Weusedtwodifferent variants for this task. The        A.22   WordSorting
                 first variant comes from the web of lies V2 from
                 LiveBench (White et al., 2024). In this variant,        TheWordSortingtaskis split into 2 sub-tasks.
                 complexity has been added to the task by specify-          The first sub-task is from the BIG-Bench Mis-
                 ingwhereeachpersonis,andthenhavingsentences              take dataset (Tyen et al., 2024). This task involves
                 such as The person at the cafe says the person at        finding the first mistake in an existing chain-of-
                 the zoo lies. The second version is created by us. In    thought sequence, used to answer a Word Sorting
                 this version, we add cyclic cases whose truth value      question in the original BBH dataset. In each exam-
                 remains unknown, but one can still infer something       ple, the target answer is either the number where
                 about them and continue the chain. For example,          the first mistake occurred, or that there are no mis-
                 consideracycliccasesuchasPerson1saysPerson2              takes in the CoT sequence. These CoT sequences
                 tells the truth. Person2 says Person1 tells the truth.   are generated by prompting PaLM 2 Unicorn (Anil
                 In this case, we cannot determine whether Person1        et al., 2023) on the original BBH dataset at temper-
                 or Person2 tell the truth or lie (so their truthfulness  ature = 0. The newline is used as a stop token so
                 remains unknown). However, if we have another            that each intermediate step can be prepended with
                 sentence Person3 says either both Person1 and Per-      ‘Thought 1: ’, ‘Thought 2: ’, etc. Further informa-
                 son2 lie or both tell the truth, we can determine        tion on the prompting and generation process can
                 that Person3 tells the truth. In both variants of the    be found in Tyen et al. (2024).
                 problems, we ask about the truthfulness of three           The second sub-task is sorting a list of words
                 of the people in the chain, so the random chance         given a new alphabet order (examples include: an
                 performance for the LiveBench subset is 1/8 since        alphabet order that is the same as English but two
                 the truthfulness of each of the three people can be      letters are swapped in the order, an alphabet order
                 either yes or no, and 1/27 for our new set given         that is the same as English but one/two letters are
                 that the values can also be unknown.                     movedtothebeginning/end of the order, or a com-
                    Weobservethat the first subset is easier than the     pletely new order). This task requires going against
                 second subset, so we included only 40 examples           a strong prior and sorting words in a non-typical
                 of subset one and 160 of subset 2. Specifically,        way. We observe an interesting failure mode for
                 o3-mini (high) gives an accuracy of 100% on sub-         this task where some models understand the new
                 set one and Gemini 2.0 Flash gives an accuracy of        alphabet order correctly but keep sorting the words
                                                                     26498
