           YassirLaaouach. HALT-cot: Model-agnosticearlystoppingforchain-of-thoughtreasoning
            via answerentropy. In4thMuslimsinMLWorkshopco-locatedwithICML2025,2025. URL
            https://openreview.net/forum?id=CX5c7C1CZa.
           Chengpeng Li, Mingfeng Xue, Zhenru Zhang, Jiaxi Yang, Beichen Zhang, Xiang Wang,
            Bowen Yu, Binyuan Hui, Junyang Lin, and Dayiheng Liu. Start: Self-taught reasoner
            withtools. arXiv preprint arXiv:2503.04625, 2025.
           Shalev Lifshitz, Sheila A. McIlraith, and Yilun Du. Multi-agent verification: Scaling test-
            time computewithmultipleverifiers. arXiv preprint arXiv:2502.20379, 2025.
           HunterLightman,VineetKosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee,
            JanLeike,JohnSchulman,IlyaSutskever,andKarlCobbe.Letâ€™sverifystepbystep. arXiv
            preprint arXiv:2305.20050, 2023.
           Tianyu Liu, Yun Li, Qitan Lv, Kai Liu, Jianchen Zhu, Winston Hu, and Xiao Sun. Pearl:
            Parallel speculative decoding with adaptive draft length, 2025. URL https://arxiv.
            org/abs/2408.11850.
           Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Ha-
                                      `
            jishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel Candes, and Tatsunori Hashimoto.
            s1: Simple test-time scaling, 2025. URL https://arxiv.org/abs/2501.19393.
           OpenAI,:,SandhiniAgarwal,LamaAhmad,JasonAi,SamAltman,AndyApplebaum,Ed-
            win Arbus, Rahul K. Arora, Yu Bai, Bowen Baker, Haiming Bao, Boaz Barak, Ally Ben-
            nett, Tyler Bertao, Nivedita Brett, Eugene Brevdo, Greg Brockman, Sebastien Bubeck,
            Che Chang, Kai Chen, Mark Chen, Enoch Cheung, Aidan Clark, Dan Cook, Marat
            Dukhan,CaseyDvorak,KevinFives,VladFomenko,TimurGaripov,KristianGeorgiev,
            Mia Glaese, Tarun Gogineni, Adam Goucher, Lukas Gross, Katia Gil Guzman, John
            Hallman, Jackie Hehir, Johannes Heidecke, Alec Helyar, Haitang Hu, Romain Huet, Ja-
            cob Huh, Saachi Jain, Zach Johnson, Chris Koch, Irina Kofman, Dominik Kundel, Ja-
            son Kwon, Volodymyr Kyrylov, Elaine Ya Le, Guillaume Leclerc, James Park Lennon,
            Scott Lessans, Mario Lezcano-Casado, Yuanzhi Li, Zhuohan Li, Ji Lin, Jordan Liss, Lily,
            Liu, Jiancheng Liu, Kevin Lu, Chris Lu, Zoran Martinovic, Lindsay McCallum, Josh Mc-
            Grath,ScottMcKinney,AidanMcLaughlin,SongMei,SteveMostovoy,TongMu,Gideon
            Myles, Alexander Neitz, Alex Nichol, Jakub Pachocki, Alex Paino, Dana Palmie, Ash-
            ley Pantuliano, Giambattista Parascandolo, Jongsoo Park, Leher Pathak, Carolina Paz,
            Ludovic Peran, Dmitry Pimenov, Michelle Pokrass, Elizabeth Proehl, Huida Qiu, Gaby
            Raila, Filippo Raso, Hongyu Ren, Kimmy Richardson, David Robinson, Bob Rotsted,
            Hadi Salman, Suvansh Sanjeev, Max Schwarzer, D. Sculley, Harshit Sikchi, Kendal Si-
            mon,KaranSinghal,YangSong,DaneStuckey,ZhiqingSun,PhilippeTillet,SamToizer,
            Foivos Tsimpourlas, Nikhil Vyas, Eric Wallace, Xin Wang, Miles Wang, Olivia Watkins,
            KevinWeil,AmyWendling,KevinWhinnery,CedricWhitney,HannahWong,LinYang,
            Yu Yang, Michihiro Yasunaga, Kristen Ying, Wojciech Zaremba, Wenting Zhan, Cyril
            Zhang, Brian Zhang, Eddie Zhang, and Shengjia Zhao. gpt-oss-120b & gpt-oss-20b
            modelcard,2025. URLhttps://arxiv.org/abs/2508.10925.
           David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang,
            Julien Dirani, Julian Michael, and Samuel R. Bowman. Gpqa: A graduate-level google-
            proof q&a benchmark, 2023. URL https://arxiv.org/abs/2311.12022.
           NoahShinn,Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik Narasimhan,
            andShunyuYao. Reflexion: Languageagentswithverbalreinforcementlearning. arXiv
            preprint arXiv:2303.11366, 2023.
           Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling llm test-time com-
            pute optimally can be more effective than scaling model parameters. arXiv preprint
            arXiv:2408.03314, 2024.
           Yuan Sui, Yufei He, Tri Cao, Simeng Han, Yulin Chen, and Bryan Hooi. Meta-reasoner:
            Dynamic guidance for optimized inference-time reasoning in large language models.
            arXiv preprint arXiv:2502.19918, 2025.
                               10
