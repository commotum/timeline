                                    Input                    GroundTruth                 Point Transformer                          Input                     GroundTruth                 Point Transformer
                                  ceiling        floor        wall         beam         column          window          door         table         chair        sofa        bookcase        board         clutter
                                                               Figure 5. Visualization of semantic segmentation results on the S3DIS dataset.
                    Figure 6. Visualization of shape retrieval results on the ModelNet40 dataset. The leftmost column shows the input query and the other
                    columns show the retrieved models.
                    Figure 7. Visualization of object part segmentation results on the ShapeNetPart dataset. The ground truth is in the top row, Point Trans-
                    former predictions on the bottom.
                    5. Conclusion                                                                                           former networks is fundamentally a set operator. We have
                                                                                                                            shownthatbeyondthisconceptualcompatibility,transform-
                         Transformers have revolutionized natural language pro-                                             ers are remarkably effective in point cloud processing, out-
                    cessing and are making impressive gains in 2D image anal-                                               performing state-of-the-art designs from a variety of fam-
                    ysis. Inspired by this progress, we have developed a trans-                                             ilies: graph-based models, sparse convolutional networks,
                    former architecture for 3D point clouds. Transformers are                                               continuous convolutional networks, and others. We hope
                    perhaps an even more natural fit for point cloud process-                                               that our workwillinspirefurtherinvestigationoftheproper-
                    ing than they are for language or image processing, be-                                                 ties of point transformers, the development of newoperators
                    cause point clouds are essentially sets embedded in a metric                                            and network designs, and the application of transformers to
                    space, and the self-attention operator at the core of trans-                                            other tasks, such as 3D object detection.
                                                                                                                      16266
