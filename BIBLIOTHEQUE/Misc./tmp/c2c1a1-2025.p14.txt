                       Figure 2: Overall structure of GPIO. First, the cross-attention between the initial latent
                       and input query enables the latent to absorb the necessary information from the input.
                       Then, the latent progressively encode the salient feature of a given data point through re-
                       peated self-attention blocks. Finally, the output query array and final latent communicate
                       via cross-attention to make proper output for each task. Dq is an arbitrarily configurable
                       output query array dimension, and E is the number of classes about a given task. The
                       number of depth or layer of self attention block is a controllable hyperparameters.
                       positional information. As shown in Figure 1, the methods are implemented
                       by concatenating the node features and positional embeddings and smooth-
                       ing the node features.  The shape of the output query array depends on the
                       given task, and we will discuss it in Section Output Query Array. The overall
                       structure of our proposed model is in Figure 2.
                       4.2. Output Query Array
                          One of the major problems of the GPIO is to incorporate the adjacency
                       matrix. The adjacency matrix that is widely utilized in GNNs is not adapt-
                       able for the GPIO. Also, the GPIO requires a flexible output structure to
                       handle the diverse graph-related tasks such as link prediction, graph classi-
                       fication, and node classification. For the flexible output array structure, we
                       utilize the output query array of Perceiver IO. The output query shape can
                                                            11
