           Synthesis, which trains a RobustFill (16) model on samples from the initial library; and Enumeration,
           which performs type-directed enumeration (23) for 24 hours per task, generating and testing up to 400
           million programs for each task. To isolate the role of compression in learning good libraries, we also
           construct two Memorize baselines. These variants extend the library by incorporating task solutions
           wholesale as new primitives; they do not attempt to compress but simply memorize solutions found
           during waking for potential reuse on new problems (cf. (36)). We evaluate memorize variants both
           with and without neural recognition models.
              Across domains, our model always solves the most held-out tasks (Fig. 6A; see Fig. S13 for
           memorization baselines) and generally solves them in the least time (mean 54.1s; median 15.0s; Fig.
           S11). These results establish that each of DreamCoder’s core components – library learning with
           refactoring and compression during the sleep-abstraction phase, and recognition model learning during
           the sleep-dreaming phase – contributes substantively to its overall performance. The synergy between
           these componentsisespecially clear in the more creative, generative structure building domains, LOGO
           graphics and tower building, where no alternative model ever solves more than 60% of held-out tasks
           while DreamCoder learns to solve nearly 100% of them. The time needed to train DreamCoder to the
           points of convergence shown in Fig. 6A varies across domains, but typically takes around a day using
           moderate compute resources (20-100 CPUs).
              Examining how the learned libraries grow over time, both with and without learned recognition
           models, reveals functionally signiﬁcant differences in their depths and sizes. Across domains, deeper
           libraries correlate well with solving more tasks (r = 0.79), and the presence of a learned recognition
           modelleads to better performance at all depths. The recognition model also leads to deeper libraries
           bythe end of learning, with correspondingly higher asymptotic performance levels (Fig. 6B, Fig. S1).
           Similar but weaker relationships hold between the size of the learned library and performance. Thus
           the recognition model appears to bootstrap “better” libraries, where “better” correlates with both the
           depth and breadth of the learned symbolic representation.
              Insight into how DreamCoder’s recognition model bootstraps the learned library comes from
           looking at how these representations jointly embed the similarity structure of tasks to be solved.
           DreamCoderﬁrstencodesataskintheactivations of its recognition network, then rerepresents that
           task in terms of a symbolic program solving it. Over the course of learning, these implicit initial
           representations realign with the explicit structure of the ﬁnal program solutions, as measured by
           increasing correlations between the similarity of problems in the recognition network’s activation
           space and the similarity of code components used to solve these problems (see Fig. S4; p < 10−4
                  2
           using χ test pre/post learning). Visualizing these learned task similarities (with t-SNE embeddings)
           suggests that, as the model gains a richer conceptual vocabulary, its representations evolve to group
           together tasks sharing more abstract commonalities (Fig. S3) – possibly analogous to how human
           domain experts learn to classify problems by the underlying principles that govern their solution rather
           than superﬁcial similarities (37,38).
           Fromlearninglibraries to learning languages
           Ourexperiments up to now have studied how DreamCoder grows from a “beginner” state given basic
           domain-speciﬁc procedures, such that only the easiest problems have simple, short solutions, to an
           “expert” state with concepts allowing even the hardest problems to be solved with short, meaningful
           programs. Now we ask whether it is possible to learn from a more minimal starting state, without
           even basic domain knowledge: Can DreamCoder start with only highly generic programming and
           arithmetic primitives, and grow a domain-speciﬁc language with both basic and advanced domain
                                                   13
