                         Published as a conference paper at ICLR 2024
                                                                             ∗
                          Model               Claude 2   ChatGPT-3.5   GPT-4     SWE-Llama7b      SWE-Llama13b
                          Applied               1078         284          76          1257             1196
                          Resolved              110           12          10           69               91
                          Breaking Resolved      26           2           3            17               10
                          Partially Resolved     15           4           3            17               10
                          WorkinProgress         20           2           1            17               16
                          No-Op                 471          174          30          716               672
                          Regression            436           90          29          421               397
                         Table 23: Categorization of model generations that applied successfully by the cases defined in
                         Table 22. As mentioned, GPT-4 was evaluated on a 25% subset (574 instances) of SWE-bench.
                         Table 24: Average edits of model generated patches in the oracle retrieval setting across all patches
                         (including unsuccessfully applied patches). For the task instances specific to each model, we calcu-
                         late the same statistics across the gold patches.
                                    Model             Total Lines  Added   Removed     Functions  Files
                                    Claude 2             27.2       6.6       3.3         1.2      1.1
                                      Gold               61.6       17.8      8.6         2.6      1.4
                                    ChatGPT-3.5          42.0       6.1       3.9         1.7      1.0
                                      Gold               44.5       12.7      5.5         2.1      1.2
                                    GPT-4                22.4       4.4       1.8         0.8      0.9
                                      Gold               50.3       14.0      6.5         2.3      1.3
                                    SWE-Llama13b         68.9       9.5       4.3         2.5      1.6
                                      Gold               61.5       17.8      8.6         2.6      1.4
                                    SWE-Llama7b          78.9       10.1      7.6         2.5      1.5
                                      Gold               65.1       18.8      9.0         2.7      1.5
                         Welookspecifically at successfully applied Claude 2 patch predictions in the “Oracle” retrieval set-
                         ting for the psf/requests repository, which several models perform best at as reflected in Fig-
                         ure 4. Per prediction, we apply the patch to the codebase, then calculate the Cyclomatic complexity
                         and Halstead complexity scores for the modified functions. Cyclomatic complexity quantifies the
                         control flow of a function, counting the number of independent execution paths through the source
                         code (McCabe, 1976). A higher Cyclomatic complexity score suggests a more complex function
                         that has higher likelihood of defects and usually suggests difficult maintainability. Halstead com-
                         plexity counts the number of operators and operands in a program (Halstead, 1977). Per prediction,
                         wealsoperform the same set of steps for the corresponding gold patch.
                         Wefindthatsoftwareengineering metrics provides automatic qualitative insights into model perfor-
                         mance. Consider the following simple case study in Figure 10. While the model patch prediction
                         (left) is fewer lines (6 instead of 11) and modifies fewer files (1 instead of 2) compared to the gold ref-
                         erence solution (right), the model’s edit places a conditional within a relatively complex and widely
                         used HTTPAdapterclass. This introduces two new potential execution outcomes, raising the Cy-
                         clomaticcomplexityofHTTPAdapterfrom3to5. Incontrast,whilelonger,thereferencesolution
                         imports intra-module dependencies, modifies a logically simpler function in get connection,
                         anddefines a new error type InvalidProxyURLtocapturethenovelbugdescribedbytheissue.
                         D ADDITIONALEXPERIMENTALDETAILS
                         D.1   RETRIEVAL DETAILS
                         Sparse retrieval. During retrieval we make a slight augmentation to the documents by pre-pended
                         files’ contents with their file paths to better enable retrieval based on filenames that may be men-
                         tioned directly in the issue.
                                                                    28
