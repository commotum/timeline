                                                     0.6                                                                  100                                                                          Difference between Short and Long CoT                                                                                                 To
                                                     0.5                                                                 ait80                                                                         understand why long solutions of QwQ, R1 and
                                                    Acc0.4                                                                  60                                                                         LIMOis not better than short solutions, we ana-
                                                     0.3                                                                    40
                                                                                                   LIMO                                                                        R1-671b
                                                     0.2                                           QwQ                   Number of W                                           R1-32b                  lyzed their differences. We observed that QwQ,
                                                                                                   R1-Distill-32b                                                              R1-14b
                                                                                                   R1-Distill-14b           20                                                 QwQ
                                                     0.1                                           R1-Distill-1.5b                                                             LIMO                    R1andLIMOallprimarilyextendsolution length
                                                            4k8k 16k               32k                        64k                   5              10              15               20
                                                                      Max Token Limitation                                                   Number of Token (k)                                       through self-revision, characterized by markers
                                                    (a) Max Token Limitation                                                (b) Frequence of “Wait”                                                    such as “Wait” and “Alternatively”. We show some
                                              Figure 3: (a): The relationship between model accuracy                                                                                                   examples of that in Appendix F. To quantify this
                                              and the generation parameter Max Token Limitation.                                                                                                       phenomenon,wecountedtheoccurrencesof“wait”
                                              (b): The relationship between solution length and the                                                                                                    in solutions of QwQ, R1 and LIMO in Figure 3b.
                                              average number of “wait” occur in a solution.                                                                                                            Theresults demonstrates a strong linear correlation
                                                                                                                                                                                                       between solution length and the frequency of self-
                                                                                                                                                                                                       correction markers for all models. This suggests
                                              significantly larger than for stronger models, such                                                                                                      that the mechanisms of self-revision may play a
                                              as R1-671b. This suggests that the invalid scaling                                                                                                       significant role in generating longer solutions.
                                              phenomenon is more pronounced in the weaker
                                              models.                                                                                                                                                  ScalingSolutionLengthwithSelf-Revision                                                                                               We
                                                                                                                                                                                                       have tried to investigate the revision behaviors in-
                                              4.2             Explaining Invalid Scaling: The Key                                                                                                      side the sampled solutions, however, it is difficult
                                                              Factor is the Failure of Self-Revision                                                                                                   to extract the initial solution and the following revi-
                                                                                                                                                                                                       sion exactly from QwQ, R1 and LIMO’s solutions.
                                              In Section 4.1, we observed the phenomenon that                                                                                                          Alternatively to that, we prompted the models to
                                              long solutions exhibit lower accuracy compared                                                                                                           continue thinking based on their sampled solutions.
                                              to short solutions. In this section, we investigate                                                                                                             QwQ,R1andLIMOoftenconcludetheirsolu-
                                              the underlying reasons for this phenomenon. We                                                                                                           tions with phrases like “final answer: ...”, and R1
                                              first analyzed how the maximum token limitation                                                                                                          additionally outputs a ‘</think>’ tag followed by a
                                              affects generation performance and confirmed that                                                                                                        final response. To facilitate smoother continuation
                                              the observed invalid scaling phenomenon was not                                                                                                          of the reasoning process, we removed the “final an-
                                              causedbyconstraintsinthemaximumtokenlength.                                                                                                              swer” portion from the solutions. We then used the
                                              Next, we examined the differences between long                                                                                                           keyword “Wait” or “Alternatively” as the prompt
                                              and short solutions, finding that long solutions ex-                                                                                                     to encourage self-revision. We calculated the prob-
                                              hibit a higher frequency of self-revision. Moreover,                                                                                                     abilities of the model predicting the next token as
                                              our analysis suggests a strong correlation between                                                                                                      “Wait” or “Alternatively” and selected the one with
                                              self-revision, solution length, and accuracy.                                                                                                            the higher probability as the prompt.
                                                                                                                                                                                                              WepromptedQwQ,R1andLIMOtocontinue
                                              MaxTokenLimitation The max token limita-                                                                                                                 reasoning for 40 additional steps on the AIME
                                              tion parameter controls the maximum number of                                                                                                            benchmark. We show the results in Figure 4c,
                                              tokens a model can generate for a question, which                                                                                                        from which we observe that the solution length
                                              plays a critical role in influencing model accuracy,                                                                                                     increase almost linearly with additional steps. Af-
                                              especially when generating long solutions. To ex-                                                                                                        ter 40 steps, the solution length of QwQ and R1 is
                                              plore its impact, we tested several max token limita-                                                                                                    almost third as their original length.
                                              tion values and compared the performance of QwQ,                                                                                                                Weshowtheaccuracyaftersequential revision
                                              R1and LIMO on the AIME benchmark. The re-                                                                                                                in Figure 4a and 4b. Our results reveal that the
                                              sults are shown in Figure 3a, which revealed that                                                                                                        accuracy of QwQ and R1-Distill-1.5b decreases
                                              16k is a key threshold: when the max token lim-                                                                                                          constantly as the number of reasoning steps in-
                                              itation is below this value, it significantly affects                                                                                                    creases, while the accuracy of R1-Distill-32b, R1-
                                              the model performance. However, increasing the                                                                                                           Distill-14b and LIMO initially improves and then
                                              max token limitation beyond 16k leads to dimin-                                                                                                          oscillates with further reasoning steps. Further anal-
                                              ishing returns, particularly for QwQ. In our other                                                                                                       ysis in Appendix C reveal that the improvement on
                                              experiments, we set the max token limitation to                                                                                                          R1-Distill-32b, R1-Distill-14b and LIMO during
                                              32k, suggesting that this parameter is not the main                                                                                                      revisions mainly comes from the revision on short
                                              cause of invalid scaling.                                                                                                                                solutions. These results corroborate our previous
                                                                                                                                                                                           4655
