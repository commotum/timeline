                     2024. Let’s verify step by step. In The Twelfth In-    Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Ku-
                     ternational Conference on Learning Representations,      mar.2024. ScalingLLMtest-timecomputeoptimally
                     ICLR2024,Vienna, Austria, May 7-11, 2024. Open-          can be more effective than scaling model parameters.
                     Review.net.                                              CoRR,abs/2408.03314.
                  Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang,             Hanshi Sun, Momin Haider, Ruiqi Zhang, Huitao
                     BochaoWu,ChengdaLu,ChenggangZhao,Chengqi                 Yang, Jiahao Qiu, Ming Yin, Mengdi Wang, Pe-
                     Deng, Chenyu Zhang, Chong Ruan, and 1 others.            ter L. Bartlett, and Andrea Zanette. 2024.     Fast
                     2024. Deepseek-v3 technical report. arXiv preprint       best-of-n decoding via speculative rejection. CoRR,
                     arXiv:2412.19437.                                        abs/2410.20290.
                  AmanMadaan, Niket Tandon, Prakhar Gupta, Skyler
                     Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,         QwenTeam.2024a. Qwen2.5technical report. arXiv
                     Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,            preprint arXiv:2412.15115.
                     Shashank Gupta, Bodhisattwa Prasad Majumder,
                     Katherine Hermann, Sean Welleck, Amir Yazdan-          QwenTeam.2024b. Qwq: Reflectdeeplyonthebound-
                     bakhsh, and Peter Clark. 2023. Self-refine: Itera-       aries of the unknown.
                     tive refinement with self-feedback. In Advances in
                    Neural Information Processing Systems 36: Annual        Ziyu Wan, Xidong Feng, Muning Wen, Stephen Marcus
                    Conference on Neural Information Processing Sys-          McAleer, Ying Wen, Weinan Zhang, and Jun Wang.
                     tems 2023, NeurIPS 2023, New Orleans, LA, USA,           2024. Alphazero-like tree-search can guide large
                    December10-16,2023.                                       language model decoding and training. In Forty-
                  Yingqian Min, Zhipeng Chen, Jinhao Jiang, Jie Chen,         first International Conference on Machine Learning,
                     Jia Deng, Yiwen Hu, Yiru Tang, Jiapeng Wang, Xi-         ICML2024,Vienna,Austria,July21-27,2024.Open-
                     aoxue Cheng, Huatong Song, and 1 others. 2024.           Review.net.
                     Imitate, explore, and self-improve: A reproduction     JunWang,MengFang,ZiyuWan,MuningWen,Jiachen
                     report on slow-thinking reasoning systems. arXiv         Zhu, Anjie Liu, Ziqin Gong, Yan Song, Lei Chen,
                     preprint arXiv:2412.09413.                               Lionel M. Ni, Linyi Yang, Ying Wen, and Weinan
                  Niklas Muennighoff, Zitong Yang, Weijia Shi, Xi-            Zhang. 2024. Openr: An open source framework
                     ang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke       for advanced reasoning with large language models.
                     Zettlemoyer, Percy Liang, Emmanuel Candès, and           CoRR,abs/2410.09671.
                    Tatsunori Hashimoto. 2025. s1: Simple test-time
                     scaling. Preprint, arXiv:2501.19393.                   Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V.
                                                                              Le, Ed H. Chi, Sharan Narang, Aakanksha Chowd-
                  OpenAI. 2024a. Learning to reason with llms.                hery, and Denny Zhou. 2023.        Self-consistency
                  OpenAI. 2024b. Openai o1 system card.                       improves chain of thought reasoning in language
                                                                              models. In The Eleventh International Conference
                  Yiwei Qin, Xuefeng Li, Haoyang Zou, Yixiu Liu, Shijie       on Learning Representations, ICLR 2023, Kigali,
                    Xia, Zhen Huang, Yixin Ye, Weizhe Yuan, Hector            Rwanda,May1-5,2023.OpenReview.net.
                     Liu, Yuanzhi Li, and Pengfei Liu. 2024. O1 repli-
                     cation journey: A strategic progress report - part 1.  YueWang,QiuzhiLiu,Jiahao Xu, Tian Liang, Xingyu
                    CoRR,abs/2410.18982.                                      Chen, Zhiwei He, Linfeng Song, Dian Yu, Juntao Li,
                                                                              Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao
                  Jiahao Qiu, Yifu Lu, Yifan Zeng, Jiacheng Guo, Ji-          Mi, and Dong Yu. 2025. Thoughts are all over the
                     ayi Geng, Huazheng Wang, Kaixuan Huang, Yue              place: Ontheunderthinkingofo1-likellms. Preprint,
                    Wu,andMengdiWang.2024. Treebon: Enhancing                 arXiv:2501.18585.
                     inference-timealignmentwithspeculativetree-search
                     and best-of-n sampling. CoRR, abs/2410.16033.          Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
                  David Rein, Betty Li Hou, Asa Cooper Stickland,             Bosma,Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le,
                     Jackson Petty, Richard Yuanzhe Pang, Julien Di-          and Denny Zhou. 2022. Chain-of-thought prompting
                     rani, Julian Michael, and Samuel R. Bowman. 2023.        elicits reasoning in large language models. In Ad-
                     GPQA:Agraduate-level google-proof q&a bench-             vances in Neural Information Processing Systems 35:
                     mark. CoRR, abs/2311.12022.                              Annual Conference on Neural Information Process-
                                                                              ing Systems 2022, NeurIPS 2022, New Orleans, LA,
                  Pier Giuseppe Sessa, Robert Dadashi, Léonard                USA,November28-December9,2022.
                     Hussenot, Johan Ferret, Nino Vieillard, Alexandre
                     Ramé, Bobak Shahriari, Sarah Perrin, Abe Friesen,      Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, James Xu
                     Geoffrey Cideron, Sertan Girgin, Piotr Stanczyk,         Zhao, Min-Yen Kan, Junxian He, and Michael Qizhe
                    AndreaMichi, Danila Sinopalnikov, Sabela Ramos,           Xie. 2023. Self-evaluation guided beam search for
                    Amélie Héliou, Aliaksei Severyn, Matt Hoffman,            reasoning. In Advances in Neural Information Pro-
                     Nikola Momchev, and Olivier Bachem. 2024.                cessing Systems 36: Annual Conference on Neural
                     BOND: aligning llms with best-of-n distillation.         Information Processing Systems 2023, NeurIPS 2023,
                    CoRR,abs/2407.14622.                                      NewOrleans, LA, USA, December 10 - 16, 2023.
                                                                       4661
