# Nested Learning: The Illusion of Deep Learning Architectures (2025)
Source: c73d4b-2025.pdf

## Core reasons
- The paper identifies that deployed LLMs are static and cannot continually acquire new capabilities beyond their immediate context.
- It proposes a Neural Learning Module under nested learning that restructures computation into interconnected components with their own gradient flow.

## Evidence extracts
- "LLMs are largely static after their initial deployment phase, meaning that they successfully perform tasks learned during pre- or post-training, but are unable to continually acquire new capabilities beyond their immediate context." (p. 2)
- "Neural Learning Module. Given the above definition of nested learning problems, we define neural learning module as a new way of representation of machine learning models that shows the model as an interconnected system of components, each of which with its own gradient flow." (p. 7)

## Classification
Class name: Computation & Reasoning Mechanism Proposal
Class code: 3

$$
\boxed{3}
$$
