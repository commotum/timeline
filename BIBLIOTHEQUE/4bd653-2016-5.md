# Variational Lossy Autoencoder (2017)
Source: 4bd653-2016.pdf

## Core reasons
- Proposes a new VAE-based modeling approach that combines variational autoencoders with autoregressive decoders to learn global representations.
- Analyzes when latent codes are used and introduces a principled mechanism to control information in the latent variables, which is a methodological contribution.

## Evidence extracts
- "In this paper, we present a simple but principled method to learn such global representations by combining Variational Autoencoder (VAE) with neural autoregressive models such as RNN, MADE and PixelRNN/CNN." (p. 1)
- "We analyze why weakening is necessary, and we propose a principled solution that takes advantage of this property to control what kind of information goes into latent variables." (p. 2)

## Classification
Class name: ML Foundations & Principles
Class code: 5

$$
\boxed{5}
$$
