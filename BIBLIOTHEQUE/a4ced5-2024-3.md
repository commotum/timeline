# An implicit factorized transformer with applications to fast prediction of three-dimensional turbulence (2024)
Source: a4ced5-2024.pdf

## Core reasons
- Proposes an implicit factorized transformer architecture for turbulence prediction, indicating a model-level transformer contribution rather than a dataset/benchmark.
- Defines computation via iterative/implicit attention updates by modeling attention iterations as a numerical solver, i.e., a mechanism that changes how computation happens.

## Evidence extracts
- "An implicit factorized transformer with applications to fast prediction of three-dimensional turbulence" (p. 1)
- "the IFactFormer models the iterations of the attention layer as a numerical solver grounded in the Euler method" (p. 3)

## Classification
Class name: Computation & Reasoning Mechanism Proposal
Class code: 3

$$
\boxed{3}
$$
