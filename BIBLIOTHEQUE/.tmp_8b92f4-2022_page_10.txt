                               Under review as a conference paper at ICLR 2025
                     486         )
                     487         %
                                 (
                     488         k 
                                 as
                                 T
                     489          
                                 C
                     490         R
                                 A
                     491          
                                 er
                                 p
                     492          
                     493         ces
                                 an
                                 t
                     494         s
                                 n
                                 I
                                  
                     495         t
                                 es
                                 T
                     496          
                     497         ed
                                 v
                                 l
                     498         So
                     499                 ViT-Vanilla   ViTARC-VT  −BorderTokens        ViTARC      −PEmixer       −2D-RPE        −OPE
                     500
                     501       Figure 7: Distribution statistics of solve rates on 100 random tasks for ablation. 7 Models
                     502       are shown: ViT-Vanilla, ViTARC-VT, and ViTARC are the models introduced in Sections 3, 4
                     503       and 5 respectively. Ablated components are prefixed as − and ablate the full model to the left,
                     504       i.e., −BorderTokens is an ablation of this component from ViTARC-VT and each of −PEmixer,
                     505       −2D-RPE,and−OPEablatetheserespectivecomponentsfromViTARC.
                     506
                     507
                     508       For our experiments, OpenCV’s contour detection (Bradski, 2000) proved sufficient for generating
                     509       object indices in the ARC tasks, demonstrating the practical effectiveness of OPE. This novel ap-
                     510       proach not only addresses challenges related to complex object shapes but also establishes a method
                     511       for injecting external objectness knowledge into vision models, enhancing their reasoning capabili-
                     512       ties.
                     513       5.1   RESULTS
                     514
                     515       Wearriveat our final model, ViTARC, which contains all the improvements mentioned in Section 4
                     516       and Section 5. The final encoding combines all three components: 2DAPE, 2DRPE, and OPE,
                     517       leveraging their complementary strengths to enhance spatial reasoning. As shown in Figure 3, the
                     518       model is a significant improvement over both the baseline ViT-Vanilla and ViTARC-VT due to the
                     519       proposed positional enhancements.
                     520       Furthermore, Figure 5(b) highlights the generalization of these improvements across tasks, with an
                     521       additional 9.02% increase in solved instances compared to ViTARC-VT. ViTARC-VT itself already
                     522       achieved a significant boost over ViT-Vanilla, culminating in a total improvement of 57.36% over
                     523       the baseline ViT-Vanilla.
                     524       Figure7furtherillustratestheimpactofeachenhancementontaskperformance. Allthreecontribute
                     525       to the overall improvement, with 2D-RPEprovidingthelargestgain, followedbyPEmixerandOPE.
                     526       Notably, without 2D-RPE, the model’s performance drops below that of ViTARC-VT. This occurs
                     527       because OPE, while effective in specific tasks, is not consistently reliable. In these cases, ViTARC
                     528       must fall back on the (x,y) embeddings from 2D-APE, which are less expressive due to their lower
                     529       dimensionalitycomparedtoViTARC-VT.Theinclusionof2D-RPErecoversthesepositionalsignals
                     530       at the attention level, ensuring robust performance even when object-based cues are insufficient.
                     531       For a comprehensive breakdown of the task-level performance and the numerical details of these
                     532       ablations, please refer to Appendix C.2.
                     533
                     534
                     535       6    CONCLUSION
                     536
                     537       This paper introduced VITARC, a Vision Transformer architecture designed to address the unique
                     538       challenges posed by the Abstraction and Reasoning Corpus. A key finding of our work is that po-
                     539       sitional information plays a critical role in visual reasoning tasks. While often overlooked when
                               adapting transformers from NLP to vision, our results demonstrate that even simple enhancements
                                                                                    10
