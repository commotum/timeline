                          Preprint, Under Review.
                          KanishkGandhi,AyushChakravarthy,AnikaitSingh, NathanLile, and Noah D. Goodman. Cognitive
                            behaviors that enable self-improving reasoners, or, four habits of highly effective stars. CoRR,
                            abs/2503.01307, 2025. doi: 10.48550/ARXIV.2503.01307. URL https://doi.org/10.
                            48550/arXiv.2503.01307.
                          AaronGrattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad
                            Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et al. The llama 3 herd of
                            models. arXiv preprint arXiv:2407.21783, 2024.
                          Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,
                            Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms
                            via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025.
                                        ¨
                          David Ha and Jurgen Schmidhuber. World models. arXiv preprint arXiv:1803.10122, 2018.
                          Danijar Hafner.  Benchmarking the spectrum of agent capabilities.   In International Confer-
                            ence on Learning Representations, 2022. URL https://openreview.net/forum?id=
                            1W0z96MFEoH.
                          Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, and James
                            Davidson. Learning latent dynamics for planning from pixels. In International conference on
                            machine learning, pp. 2555–2565. PMLR, 2019.
                          Danijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mohammad Norouzi. Dream to control: Learning
                            behaviors by latent imagination. In International Conference on Learning Representations, 2020.
                            URLhttps://openreview.net/forum?id=S1lOTC4tDS.
                          Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, and Zhiting
                            Hu. Reasoning with language model is planning with world model. In The 2023 Conference
                            onEmpirical Methods in Natural Language Processing, 2023. URL https://openreview.
                            net/forum?id=VTWWvYtF1R.
                          EdwardJHu,YelongShen,PhillipWallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,
                            WeizhuChen,etal. Lora: Low-rank adaptation of large language models. ICLR, 1(2):3, 2022.
                          Shengran Hu and Jeff Clune. Thought cloning: Learning to think while acting by imitating human
                            thinking. In Advances in Neural Information Processing Systems 37: Annual Conference on Neural
                            Information Processing Systems 2024, NeurIPS 2023, New Orleans, 2023, 2023.
                          Shengran Hu, Cong Lu, and Jeff Clune. Automated design of agentic systems. In The Thirteenth
                            International Conference on Learning Representations, 2025. URL https://openreview.
                            net/forum?id=t9U3LW7JVX.
                          Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec
                            Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. Openai o1 system card. arXiv preprint
                            arXiv:2412.16720, 2024.
                          DamjanKalajdzievski. A rank stabilization scaling factor for fine-tuning with lora. arXiv preprint
                            arXiv:2312.03732, 2023.
                          Shivaram Kalyanakrishnan, Siddharth Aravindan, Vishwajeet Bagdawat, Varun Bhatt, Harshith Goka,
                            Archit Gupta, Kalpesh Krishna, and Vihari Piratla. An analysis of frame-skipping in reinforcement
                            learning. arXiv preprint arXiv:2102.03718, 2021.
                          Aviral Kumar, Vincent Zhuang, Rishabh Agarwal, Yi Su, John D Co-Reyes, Avi Singh, Kate
                            Baumli, Shariq Iqbal, Colton Bishop, Rebecca Roelofs, Lei M Zhang, Kay McKinney, Disha
                            Shrivastava, Cosmin Paduraru, George Tucker, Doina Precup, Feryal Behbahani, and Aleksandra
                            Faust. Training language models to self-correct via reinforcement learning. In The Thirteenth
                            International Conference on Learning Representations, 2025. URL https://openreview.
                            net/forum?id=CjwERcAU7w.
                                                                      11
