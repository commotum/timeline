                          extractor fθ(·) by adopting sparse convolution. However, using sparse convolution offers only limited efÏciency
                          gains, as convolution accounts for only a small portion of our VAE. Moreover, like XCube, we cannot apply
                          sparse convolution in our decoder. In the future, we plan to explore more efÏcient operations to further
                          optimize our 3D backbone.
                          7.4 Classifier-FreeGuidance
                          Classifier-Free Guidance (CFG) [12] could improve the performance of conditional generative models without
                          relying on an external classifier. Specifically, during training, the model simultaneously learns both conditional
                          generation p(x|c) and unconditional generation p(x), and guidance during sampling is provided by the following
                          equation:
                                                                                     xˆ  =(1+w)·xˆ (c)−w·xˆ (∅) ,                                                                          (12)
                                                                                       t                     t                t
                          where xˆt(c) is the result conditioned on c, xˆt(∅) is the unconditioned result, and w is a weight parameter
                          controlling the strength of the conditional guidance. By adjusting w, an appropriate balance between the
                          accuracy and diversity of the generated scenes can be achieved.
                          7.5 DownstreamApplications
                          This section provides a comprehensive explanation of five tasks to demonstrate the capability of our 4D scene
                          generation model across various scenarios.
                          HexPlane. Since our model is based on Latent Diffusion Models, it is inherently constrained to generate results
                          that match the latent space dimensions, limiting the temporal length of unconditionally generated sequences.
                          We argue that a robust 4D generation model should not be restricted to producing only short sequences.
                          Instead of increasing latent space size, we leverage CFG to generate sequences in an auto-regressive manner. By
                          conditioning each new 4D sequence on the previous one, we sequentially extend the temporal dimension. This
                          iterative process significantly extends sequence length, enabling long-term generation, and allows conditioning
                          on any real-world 4D scene to predict the next sequence using the DiT model. Theoretically, our HexPlane
                          conditional generation can model sequence of arbitrary length, but less stable generation may occur when
                          generating very long sequences.
                          Wecondition our DiT by using the HexPlane from T frames earlier. For any condition HexPlane, we apply
                          patch embedding and positional encoding operations to obtain condition tokens. These tokens, combined with
                          other conditions, are fed into the adaLN-Zero and Cross-Attention branches to influence the main branch.
                          Layout. To control object placement in the scene, we train a model capable of generating vehicle dynamics
                          based on a bird’s-eye view sketch. We apply semantic filtering to the bird’s-eye view of the input scene,
                          marking regions with vehicles as 1 and regions without vehicles as 0. Pooling this binary image provides
                          layout information as a T ×H ×W tensor from the bird’s-eye perspective. The layout is padded to match
                          the size of the HexPlane, ensuring that the positional encoding of the bird’s-eye layout aligns with the XY
                          plane. DiT learns the correspondence between the layout and vehicle semantics using the same conditional
                          injection method applied to the HexPlane.
                          Command. While we have developed effective methods to control the HexPlane in both temporal and spatial
                          dimensions, a critical aspect of 4D autonomous driving scenarios is the motion of the ego vehicle. To address
                          this, we define four commands: STATIC, FORWARD, TURN LEFT, and TURN RIGHT, and annotate
                          our training data by analyzing ego vehicle poses. During training, we follow the traditional DiT approach of
                          injecting class labels, where the commands are embedded and fed into the model via adaLN-Zero.
                          Trajectory. For more fine-grained control of the ego vehicle’s motion, we extend the command-based conditioning
                          into a trajectory condition branch. For any 4D scene, the XY coordinates of the trajectory traj ∈ RT×2 are
                          passed through an MLP and injected into the adaLN-Zero branch.
                          Inpaint. We demonstrate that our model can handle versatile applications by training a conditional DiT for
                          the previous tasks. Extending our exploration of downstream applications, and inspired by [17], we leverage
                          the 2D structure of our latent space and the explicit modeling of each dimension to highlight our model’s
                                                                                                                                                                               X×Y
                          ability to perform inpainting on 4D scenes. During DiT sampling, we define a 2D mask m ∈ R                                                                   on the
                          XY plane, which is extended across all dimensions to mask specific regions of the HexPlane.
                                                                                                            16
