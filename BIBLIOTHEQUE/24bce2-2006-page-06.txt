              1532                                G.Hinton,S.Osindero,andY.-W.Teh
                                              etc.
                                      WT               W
                                             V2 v2
                                                     i
                                       W               WT
                                             H1 h1
                                                      j
                                      WT               W
                                             V1 v1
                                                     i
                                       W               WT
                                             H0 h0
                                                     j
                                      WT               W
                                             V0 v0
                                                     i
              Figure3: Aninﬁnitelogisticbeliefnetwithtiedweights.Thedownwardarrows
              represent the generative model. The upward arrows are not part of the model.
              Theyrepresenttheparametersthatareusedtoinfersamplesfromtheposterior
              distribution at each hidden layer of the net when a data vector is clamped
              onV.
                  0
              because the complementary prior at each layer ensures that the posterior
              distribution really is factorial.
                 Sincewecansamplefromthetrueposterior,wecancomputethederiva-
              tivesofthelogprobabilityofthedata.Letusstartbycomputingthederiva-
              tive for a generative weight, w00, from a unit j in layer H to unit i in layer
                                          ij                      0
              V (see Figure 3). In a logistic belief net, the maximum likelihood learning
               0
              rule for a single data vector, v0,is
                    ∂ log p(v0)         
                              = h0 v0 −vˆ0 ,                                  (2.2)
                         00       j i    i
                      ∂w
                         ij
              where · denotes an average over the sampled states and vˆ0 is the proba-
                                                                     i
              bility that unit i would be turned on if the visible vector was stochastically
