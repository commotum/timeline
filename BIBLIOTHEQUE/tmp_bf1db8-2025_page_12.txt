                   Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,            Alex Wang. 2018. Glue: A multi-task benchmark and
                      AbuAwalMdShoeb,AbubakarAbid,AdamFisch,                       analysis platform for natural language understanding.
                      Adam R Brown, Adam Santoro, Aditya Gupta,                    arXiv preprint arXiv:1804.07461.
                      Adrià Garriga-Alonso, et al. 2022.       Beyond the
                      imitation game: Quantifying and extrapolating the         Alex Wang, Yada Pruksachatkun, Nikita Nangia, Aman-
                      capabilities of language models.      arXiv preprint         preet Singh, Julian Michael, Felix Hill, Omer Levy,
                      arXiv:2206.04615.                                            and Samuel Bowman. 2019. Superglue: A stick-
                                                                                   ier benchmark for general-purpose language under-
                   Mirac Suzgun, Nathan Scales, Nathanael Schärli, Se-             standing systems. Advances in neural information
                      bastian Gehrmann, Yi Tay, Hyung Won Chung,                   processing systems, 32.
                      AakankshaChowdhery,QuocVLe,EdHChi,Denny
                      Zhou, et al. 2022. Challenging big-bench tasks and        YuboWang,XueguangMa,GeZhang,YuanshengNi,
                      whether chain-of-thought can solve them.       arXiv        Abhranil Chandra, Shiguang Guo, Weiming Ren,
                      preprint arXiv:2210.09261.                                  Aaran Arulraj, Xuan He, Ziyan Jiang, et al. 2024.
                   Oyvind Tafjord, Bhavana Dalvi Mishra, and Peter                 Mmlu-pro: Amorerobustandchallengingmulti-task
                      Clark. 2020. Proofwriter: Generating implications,           language understanding benchmark. arXiv preprint
                      proofs, and abductive statements over natural lan-           arXiv:2406.01574.
                      guage. arXiv preprint arXiv:2012.13048.                   Jason Weston, Antoine Bordes, Sumit Chopra, Alexan-
                   Alon Talmor, Jonathan Herzig, Nicholas Lourie, and              der M Rush, Bart Van Merriënboer, Armand Joulin,
                      JonathanBerant.2018. Commonsenseqa: Aquestion                and Tomas Mikolov. 2015. Towards ai-complete
                      answering challenge targeting commonsense knowl-             question answering: A set of prerequisite toy tasks.
                      edge. arXiv preprint arXiv:1811.00937.                       arXiv preprint arXiv:1502.05698.
                   Gemini Team, Petko Georgiev, Ving Ian Lei, Ryan              Colin White, Samuel Dooley, Manley Roberts, Arka
                      Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer,            Pal, Ben Feuer, Siddhartha Jain, Ravid Shwartz-Ziv,
                      Damien Vincent, Zhufeng Pan, Shibo Wang, et al.              Neel Jain, Khalid Saifullah, Siddartha Naidu, et al.
                      2024a. Gemini 1.5: Unlocking multimodal under-               2024. Livebench: A challenging, contamination-free
                      standing across millions of tokens of context. arXiv         llm benchmark. arXiv preprint arXiv:2406.19314.
                      preprint arXiv:2403.05530.                                Haotian Xia, Zhengbang Yang, Yuqing Wang, Rhys
                   GemmaTeam,AishwaryaKamath,JohanFerret,Shreya                   Tracy, Yun Zhao, Dongdong Huang, Zezhi Chen,
                      Pathak,NinoVieillard,RamonaMerhej,SarahPerrin,              Yan Zhu, Yuan-fang Wang, and Weining Shen.
                      Tatiana Matejovicova, Alexandre Ramé, Morgane                2024.   Sportqa: A benchmark for sports under-
                      Rivière, et al. 2025. Gemma3technicalreport. arXiv           standing in large language models. arXiv preprint
                      preprint arXiv:2503.19786.                                   arXiv:2402.15862.
                   Gemma Team, Morgane Riviere, Shreya Pathak,                  Siheng Xiong, Ali Payani, Ramana Kompella, and
                      Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupati-          Faramarz Fekri. 2024.      Large language models
                      raju, Léonard Hussenot, Thomas Mesnard, Bobak                can learn temporal reasoning.        arXiv preprint
                      Shahriari, Alexandre Ramé, et al. 2024b. Gemma 2:            arXiv:2401.06853.
                      Improving open language models at a practical size.       Yutaro Yamada, Yihan Bao, Andrew K Lampinen,
                      arXiv preprint arXiv:2408.00118.                             Jungo Kasai, and Ilker Yildirim. 2023.       Evaluat-
                   Gladys Tyen, Hassan Mansoor, Victor Carbune, Peter              ing spatial understanding of large language models.
                      Chen, and Tony Mak. 2024. LLMs cannot find rea-              arXiv preprint arXiv:2310.14540.
                      soning errors, but can correct them given the error       AnYang,BaosongYang,BeichenZhang,BinyuanHui,
                      location. In Findings of the Association for Compu-          BoZheng,BowenYu,ChengyuanLi,DayihengLiu,
                      tational Linguistics: ACL 2024, pages 13894–13908,           Fei Huang, Haoran Wei, et al. 2024a. Qwen2. 5
                      Bangkok, Thailand. Association for Computational             technical report. arXiv preprint arXiv:2412.15115.
                      Linguistics.
                   Gladys Tyen, Hassan Mansoor, Peter Chen, Tony Mak,           ZhengbangYang,HaotianXia,Jingxi Li, Zezhi Chen,
                                    ˘                                              Zhuangdi Zhu, and Weining Shen. 2024b. Sports
                      and Victor Carbune. 2023. LLMs cannot find rea-
                      soning errors, but can correct them! arXiv preprint          intelligence:  Assessing the sports understanding
                      arXiv:2311.08516.                                            capabilities of language models through question
                                                                                   answering from text to video.        arXiv preprint
                   KiranVodrahalli, SantiagoOntanon, NileshTripuraneni,            arXiv:2406.14877.
                      Kelvin Xu, Sanil Jain, Rakesh Shivanna, Jeffrey Hui,
                      Nishanth Dikkala, Mehran Kazemi, Bahare Fatemi,           Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali
                      et al. 2024. Michelangelo: Long context evaluations          Farhadi, and Yejin Choi. 2019. Hellaswag: Can
                      beyond haystacks via latent structure queries. arXiv         a machine really finish your sentence?      Preprint,
                      preprint arXiv:2409.12640.                                   arXiv:1905.07830.
                                                                          26484
