                           Wealsoexaminedtheimportance of the row and column features by multiplying the row and column
                           embeddings by zero and re-tested our trained network. At 64 steps with 17 givens, the accuracy
                           changed to 96.7%. It thus seems the network does not use the row and column position information
                           to solve the task.
                                    1.0
                                    0.8
                                    0.6                                                                   17 givens
                                                                                                          19 givens
                                   Accuracy0.4                                                            21 givens
                                                                                                          23 givens
                                                                                                          25 givens
                                    0.2                                                                   27 givens
                                                                                                          29 givens
                                                                                                          31 givens
                                    0.0                                                                   33 givens
                                         0          10         20         30         40         50         60
                                                                           Steps
                           Figure 4: Fraction of test puzzles solved as a function of number of steps. Even simple Sudokus
                           with 33 givens require about 10 steps of relational reasoning to be solved. The dashed vertical line
                           indicates the 32 steps the network was trained for. The network appears to have learned a convergent
                           relational reasoning algorithm such that more steps beyond 32 improve on the hardest Sudokus.
                           Wecompareournetworktoseveralother differentiable methods. See table 2. We train two relational
                           networks: a node and a graph centric. For details see the supplementary material. Of the two, the node
                           centric was considerably better. The node centric correspond exactly to our proposed network with
                           a single step, yet fails to solve any Sudoku. This shows that multiple steps are crucial for complex
                           relational reasoning. Our network outperforms loopy belief propagation, with parallel and random
                           messages passing updates [Bauke, 2008]. It also outperforms a version of loopy belief propagation
                           modiﬁedspeciﬁcally for solving Sudokus that uses 250 steps, Sinkhorn balancing every two steps
                           and iteratively picks the most probable digit [Khan et al., 2014]. We also compare to learning the
                           messages in parallel loopy BP as presented in Lin et al. [2015]. We tried a few variants including a
                           single step as presented and 32 steps with and without a loss on every step, but could not get it to
                           solve any 17 given Sudokus. Finally we outperform Park [2016] which treats the Sudoku as a 9x9
                           image, uses 10 convolutional layers, iteratively picks the most probable digit, and evaluate on easier
                           Sudokus with 24-36 givens. We also tried to train a version of our network that only had a loss at the
                           last step. It was harder to train, performed worse and didn’t learn a convergent algorithm.
                           Table 2: Comparison of methods for solving Sudoku puzzles. Only methods that are differentiable
                           are included in the comparison. Entries marked with an asterix are our own experiments, the rest are
                           from the respective papers.
                                         Method                                              Givens    Accuracy
                                         Recurrent Relational Network* (this work)             17       96.6%
                                         LoopyBP,modiﬁed[Khanetal.,2014]                       17       92.5%
                                         LoopyBP,random[Bauke,2008]                            17       61.7%
                                         LoopyBP,parallel [Bauke, 2008]                        17       53.2%
                                         Deeply Learned Messages* [Lin et al., 2015]           17         0%
                                         Relational Network, node* [Santoro et al., 2017]      17         0%
                                         Relational Network, graph* [Santoro et al., 2017]     17         0%
                                         DeepConvolutional Network [Park, 2016]              24-36       70%
                                                                            7
