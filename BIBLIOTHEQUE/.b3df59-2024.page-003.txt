                                          TheSurprising Effectiveness of Test-Time Training for Few-Shot Learning
                  n                                                                3.1. Data Generation
                   Test Task
                  o
                  i
                                                  Leave One Out   Direct I/O
                  t
                  a
                  r                                                                Given a task with K training input-output pairs
                  e                                                                           K
                  n                                                                {(x ,y )}      , a test-time training dataset D        can be
                                                                                       k   k                                          TTT
                  e                                                                           k=1
                    Augmentations
                  G
                                                                                   created by either following an in-context learning setup or a
                  a
                  t
                            Horizontal 

                  a                                                                direct input-output (direct I/O) setup (top row in Figure 2):
                              Flip
                                              Applied To 
                  D
                                                                      Selected
                                                                                   Leave-one-out tasks       We begin with leave-one-out in-
                    Loss on:

                                         Loss on:

                                                             Loss on:
             context learning tasks. For each pair (x ,y ), we exclude it
                    Test Output
                                         All Outputs
                                                             Inputs + Outputs                                               j   j
                  s
                  s                                                                from the set of demonstrations and treat it as a “test” exam-
                  o
                  L                                                                ple within the newly formed synthetic task:
                            LM                  LM                 LLLMM                                                         
                                                                                                dICL =     {(x ,y )}      , x , y   .
                                                                                                 j             k   k  k̸=j   j   j
                  n
                  o
                  i
                                        K Tasks                        K Tasks
                  t
                   Task Specific                  Shared                           Here, {(x ,y )}        serves as the “in-context demonstra-
                  a                                                                           k  k   k̸=j
                  z
                  i
                     Task 1                       Task 1                           tions,” and (x ,y ) is the “synthetic test example.” To in-
                                                                                                  j   j
                  r
                  e
                  t
                     Task 2                       Task 2                           crease the number of synthetic tasks, we additionally per-
                  e                                                                                                                   ICL
                  m                                                                mutetheorderofthedemonstrations in each dj .
                     Task k                       Task k
                  a
                  r
                  a
                  P                                                                Direct input-output (I/O) tasks      Rather than constructing
               Figure 2. TTT design decisions. Data generation: A test task        in-context tasks, we treat each (x ,y ) pair independently
               consists of input-output pairs {(x ,y )}. The Leave-One-Out strat-                                      k  k
                                               i  i                                as a single training instance:
               egy removes one example at a time to form in-context learning                               I/O
                                                                                                          d   =(x ,y ).
               tasks, while augmentations further expand the dataset. An alter-                            j        j  j
               native Direct I/O approach trains directly on the examples. Loss:   In this setup, the model is fine-tuned on these training pairs
               Themodelistrained with loss computed on the Test Output (only       without in-context demonstrations. While this approach
               the test-time prediction), All Outputs (including demonstration     is more computationally efficient, our results (Sections 4
               outputs), or Inputs and Outputs (all tokens). Parametrization:      and 5) show that it underperforms methods that utilize in-
               TheTask-Specific approach trains a separate adapter per task while
               the Shared approach trains a single adapter across multiple tasks.  context demonstrations.
                                                                                   DataaugmentationForcertaintasks with structured inputs
                                                                                   (e.g., ARC), we can apply invertible transformations (e.g.,
               test time. Additionally, when task-specific knowledge is            flips, rotations, color permutations) to further augment the
               available, this structure can be leveraged to further expand        TTTdataset. Let T be a set of invertible transformations.
               the dataset, as demonstrated in our experiments on ARC              For each t∈T , we have t−1(t(x)) = x, so we can apply t to
                                                                                   each training and test instance in d to yield a transformed
               (Section 4). We also explore the general case where no task-                                             j
                                                                                   task t(d ). Since these transformations preserve the core
               specific information is used, as tested on BBH (Section 5).                 j
                                                                                   relationships in the data (e.g., the input-output pattern is
               Our experiments in this paper characterize each compo-              the same, just rotated), they effectively expand the training
               nent of the TTT pipeline, investigating different design            signal. If rule-based transformations are used, the final TTT
               choices across the following stages: (1) constructing an            dataset is: DTTT = S       S t(dj).
               input-specific training dataset D        at test-time; (2) fine-                           t∈T   j
                                                  TTT
               tuning the LM by optimizing a loss function L over the              3.2. Loss Function
               dataset P           L(LM(d;θ));and(3)samplingfromthe
                          d∈D
                              TTT                                                  We optimize the standard LM loss on D            . For the in-
               updated model with an augmented inference strategy based                                                         TTT
               onself-consistency to obtain a final prediction.                    context leave-one-out setup, we experiment with 3 different
                                                                                   waystotake the loss (middle row in Figure 2):
               3. TTTDesign                                                        • Test output (no demonstration loss) The standard for-
               Thissectiondiscussesthekeydesignchoicesandchallenges                  mulation where the loss is taken over ytest:
               of applying TTT to LLMs, including how to best leverage                      label
                                                                                          L     =L (y |x ,y ,...,x ,y ,x ;θ)
               their in-context learning capabilities, how to structure data                LM       LM test     1  1        K K test
               for effective processing, what optimization objective to use,       • All outputs3 In addition to the loss on the test output,
               and how to efficiently update model parameters. We detail              3For ARC, we start the indexing at k = 2 because the under-
               these considerations in the construction of the TTT dataset         lying transformation of an ARC task cannot be inferred without
               and the optimization setup (Figure 2).                              observing at least 1 demonstration.
                                                                                3
