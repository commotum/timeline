                                                                                COCO-2017
                                    CLEVR-Mirrors                                            ShapeStacks
                                                  ?
                                Figure 4: Qualitative results. Across three datasets, optimizing SLATE with implicit differentiation leads to
                                improved image reconstructions through the slot bottleneck. Black borders indicate the ground truth image, blue
                                border indicate our method, and red borders indicate vanilla SLATE. The rest of the panels visualize attention
                                masks. In the CLEVR-Mirrors dataset, whereas vanilla SLATE misses objects, changes their size, or changes
                                their color (indicated by the circles), implicit SLATE reconstructs the ground truth more faithfully.
                                optimize signiﬁcantly better than vanilla slot attention. Whereas vanilla slot attention plateaus at
                                a cross entropy of around 130, the BB, IN, and BN variants all achieve a 10x lower cross entropy
                                loss. Moreover, BB, IN, and BN all follow the same learning curve, suggesting that the optimization
                                improvement is largely due to whether we use implicit differentiation or not, rather than the choice
                                of how we implement the implicit differentiation. The IB variant is less stable than the others, and
                               wehypothesize that this can be explained by the tendency for the ﬁxed point of Eq. 2 to become
                                increasingly hard to estimate, an issue discussed in Bai et al. [8].
                                5.3   Doesthis improvement generalize across datasets?
                               Wenowtestwhetherthisimprovedoptimization holds across different datasets. If the improvement
                               wassimplyduetoimplicit differentiation being serendipitously useful for 64x64 images CLEVR-
                                Mirror, then we should expect implicit differentiation to not help for other datasets. We focus our
                                attention on IN variant to conduct this test because it is the minimal modiﬁcation to the baseline slot
                                attention for gaining the beneﬁts of implicit differentiation, as it requires adding only one line of code
                                ontopofthebaseline slot attention implementation and does not require implementing any black-
                                boxsolvers. We henceforth refer to the IN variant as implicit slot attention (and correspondingly
                                implicit SLATE), as described in §4.3. In summary: Test: Apply implicit slot attention to CLEVR-
                               Mirror, ShapeStacks, and COCO with 96x96 image resolution. Hypothesis: Implicit slot attention
                                signiﬁcantly improves optimization across all three datasets. Result: Yes it does.
                                Results and quantitative analysis         Using the two
                                primary metrics used in Singh et al. [57], images           Table 3: Quantitative metrics for image recon-
                                generated by implicit SLATE achieve both lower              struction through the slot bottleneck.
                                pixel-wise mean-squared error and FID score [29].
                               The FID score was computed with the PyTorch-                            Data              Implicit     Vanilla
                                Ignite [18] library using the inception network from              CLEVR(FID)               22.19       25.89
                                the PyTorch port of the FID ofﬁcial implementation.              CLEVR(MSE)                10.66       67.04
                               All methods were trained for 250k gradient steps.                   COCO(FID)              127.79       147.48
                               Table 3 compares the FID and MSE scores of the                     COCO(MSE)              1659.15      1821.75
                                images that result from compressing the SLATE                  ShapeStacks (FID)           34.2        34.76
                                encoder’s set of discrete tokens through the slot              ShapeStacks (MSE)          108.67       312.14
                                attention bottleneck, using Image-GPT to autore-
                                gressively re-generate these image tokens one by one, and using the discrete VAE decoder to render
                                the generated image tokens. Implicit differentiation signiﬁcantly improves the quantitative image
                                                                                        7
