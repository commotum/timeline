188 = Unified Theories of Cognition

that also existed prior to the impasse. These are obtained by work-
ing backwards—by doing what is called in machine learning back-
tracing. Starting with the results, the elements that gave rise to
them are located, and then the ones that gave rise to these, and so
on. The backward search terminates when elements of the prior
context are encountered, in this case A, B, and C. Notice that this
avoids picking up elements that were used in exploring paths that
did not succeed (element 7 that fed the upper exploration). The new
chunk is added to the total set of productions and henceforth func-
tions just as any other production.®

Suppose Soar comes exactly this way again. At the particular
point when the impasse that occurred originally is about to occur
again (the left-hand solid vertical), the chunk will fire because its
conditions wilt ail be satisfied on available elements A, B, and C. It
will put its two actions, D and E, into working memory. They will
enter into the decision procedure and the impasse will not occur.
Exactly the preference elements that finally resolved the impasse
originally (at the right-hand vertical) are now all assembled ahead of
time, so problem solving will simply proceed. Consequently, the
action of a single production will have replaced all of the problem
solving that was required on the original occasion. The figure shows
only a little bit of processing, but additional impasses could occur
and further subspaces be explored, and so on, just as in Figure 4-10.
The gains in time (that is, efficiency) can be considerable—indeed,
indefinitely large. Thus chunking is a form of learning by experi-
ence, in which the results of solving problems are remembered in a
way that lets them be accessed to solve recurrences of the same
problem.

Figure 4-13 shows an actual chunk, learned during the blocks-
world task of Figure 4-10, rewritten in English. A chunk looks like
any other production (compare Figure 4-4). It knows exactly what
operator to apply if Soar is in a certain specified state and only one

8. The above description of chunking is simplified in several respects (Laird, 1986).
First, each independent result !eads to an independent chunk, so that several chunks can
be created from a single impasse. Second, chunks are created whenever the results they
capture are created. These results can never be modified or undone, in any event, so the
chunks can be built right away. Third, various processes are performed on the chun
make them more effective and efficient: conditions that can always be satisfied, hence
provide no constraint, are eliminated; additional tests are inserted to keep instantiated
variables distinct; sometimes a chunk can be divided into two independent chunks; and
the conditions of a chunk are ordered to improve efficiency of matching.

