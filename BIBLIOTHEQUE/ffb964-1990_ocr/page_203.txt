190 « Unified Theories of Cognition

powerful, as will be apparent throughout the rest of the book. But
both overgeneralization and overspecialization remain ever pres-
ent, important issues.

Now that chunking has been described, let us pick up some of the
additional points in Figure 4-11. A convenient way to think about
chunking, especially for computer scientists, is that it is permanent
caching of goal results. Building a cache avoids the processing that
was used to generate the cache. This description would be quite
accurate, except that generalization to new situations occurs—
which is not part of the notion of caching. It is important to realize
that what gets ignored is a function of the problem solving and also
a function of the representation. Whatever prior knowledge is con-
sidered in arriving at results will be included in the conditions.
If the problem solving doesn’t consider it, then it will be ignored.
On the other hand, if some knowledge is actually unnecessary, but
the representation is such that it must be considered, however
superficially, then the result will be taken to be dependent on it.
Therefore, there is a very strong dependence of the learning upon
the problem solving and the task representation.

Not only does learning depend intimately on problem solving,
problem solving depends equally strongly on learning. The chunks
get built and become operational as soon as the result is obtained.
Thus, tearning is going on ail the time and it can become effective in
the next decision cycle. Behavior is not divided cleanly into two
distinct phases—first a performance phase, then a learning phase.
The two activities are completely intertwined.

Chunking applies to all subgoals. The mechanism is completely
general. Indeed, the chunking mechanism works at the level of
productions, not in terms of problem spaces and their function. For
instance, it deals in impasse resolution, not success and failure,
semantically defined. Hence, it learns both from experiences that
succeed and those that fail. Since everything that Soar does occurs
by means of subgoals, from the most complicated concerns to the
most trivial selections, Soar can learn about all aspects of its per-
formance. Every new activity that Soar engages in will first be
encountered via an impasse, because it does not know how to pro-
ceed. It will then require problem solving in subgoals—perhaps
extensive, perhaps slight. In all cases, it will chunk the results and
thus will learn about them. Thus, Soar will learn how to implement
operators, learn search control, learn about how to get new prob-

