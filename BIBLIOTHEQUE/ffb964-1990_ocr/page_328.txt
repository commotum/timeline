316 « Unified Theories of Cognition

It is solving the problem of how to fit the external knowledge into a
context in the rest of the system, where it can be successfully used.
The external advisor is ignorant of the internal workings of Soar,
which means that communication from the advisor requires assimi-
lation. In the selection-advice case it is perhaps plausible that both
Soar and the external advisor know what knowledge is to be com-
municated—to wit, that a certain operator be applied—and so the
device of asking for this knowledge within the evaluation space,
rather than the original space, may seem to be simply a device for
getting some distance between Soar and the advice so it can be
tejected. It keeps Soar from letting the advisor grab absolute con-
trol of it. In the illustrative-example case, however, the advisor
does not know what knowledge might be useful. Indeed, what
transfers is whatever results from solving the example. The advisor
did not have to formulate this, and neither did Soar. In fact, the
advisor will never know what was actually useful, without an analy-
sis of the internal state of Soar,!

In these two examples we begin to get a sense of the multiple and
unexpected ways in which chunking enters into the life of the intel-
ligent agent, becoming an integral part of its performance and not
just something that ‘‘improves its behavior on the next trial.”

6.2. The Soar Qualitative Theory of Learning

Soar presents a definite global qualitative theory of memory, learn-
ing, and skill (Figure 6-6). In Chapter 4, when we first described
how Soar was to be taken as a theory of human cognition, we listed
many global properties of Soar that corresponded to human cogni-
tion (Figure 4-24). Naturally, several of these concerned memory,
learning, and skill. This list may be taken as a refinement and ex-
pansion of the earlier one. A little redundancy will not hurt. In
particular, it will reinforce the point that, whatever detailed predic-
tions and explanations Soar might provide, its global character is

(. This case is actually an example of what [ termed a wild subgoal (Newell, 1983),
namely, one without any predefined relation of the subgoal to the supergoal, one where
the problem solver simply attempis to exploit whatever results from solving the subgoal.
Polya's heuristic examples depend on wild subgoals and (to 1983) no Al system had the
ability to use them. That may be why no Al system has solved the examples in Polya’s
books (Polya, 1945).

