468 = Unified Theories of Cognition

the decision-time override. In the decision cycle, during the elab-
oration phase, everything pours in from recognition memory (the
production memory) until quiescence occurs, after which the deci-
sion procedure determines the choice that will occur (including
impasses). Thus, productions propose, decide disposes. The nature
of the preference system is always to permit anything proposed by
one production to be rejected by another. Thus, even if there were a
rogue production that says, under all conditions the balance beam
balances, it is always possible to create another production that will
Spot a proposal of the rogue production and reject it. Consequently,
no single production can ever grab control of Soarâ€™s behavior. With
the override, later learning can annul earlier wrong learning. Fur-
thermore, overriding occurs within the automatic level, so that the
rejected behavior never surfaces externally as something being con-
sidered.

To make the override work requires that Soar be able to learn
new productions that reject the bad learning. It also requires that it
be able to learn new correct solutions even though the other old
fearing is around. Techniques to do this have been developed
(Laird, 1988). They involve forcing an impasse following the feed-
back that some learning is incorrect, hence that all Previous sub-
spaces are suspect, and then learning new chunks to this new im-
passe. Even with these techniques, using the decision-time override
cannot be the complete solution, The elaboration phase would keep
building up. An organism that exists over a long period of time
would steadily accumulate productions that propose actions along
with the search control to negate their Proposal. Each elaboration
phase would have to recapitulate all of the bad learning that has
ever been learned in that given context. Thus, these mechanisms do
not seem sufficient, just by themselves, to solve the problem of
recovery from bad structure.

There are several possible approaches to solving this problem.
The first is to extirpate the bad structure. If it gets dug out and
thrown away, then it won't be around any longer. Most artificial
learning systems operate this way, in part because learned structure
is just data structure in computer memory anyway. However, there
are some problems with such an approach. Good stuff may get
thrown away with bad stuff. More important, the learning occurred
within a certain context and therefore exactly what should be extir-
pated may not be evident. This is not to say that the approach
cannot work; only that it has deficiencies.

