206 « Unified Theories of Cognition

learning turned on. As Soar starts this task, it is exactly the base
system. Then it begins to build chunks and these chunks are actu-
ally utilized before Soar finishes this first configuration. Instead of
taking 1,731 decision cycles, Rl-Soar takes only 485 decision cy-
cles, a substantial decrease. That is, there is within-trial transfer.
Soar feared 59 productions during this run.

Figure 4-18 shows the data for a single task. Consequently, if a
standard posttest is performed after finishing up the learning trial,
we find that Soar has learned everything it can and now takes only 7
decision cycles (the After-learning column). These are just the
moves at the very top level, which cannot be chunked because they
did not occur in response to impasses higher up. The other two
rows in the figure correspond to the top row, except with different
starting points. They show that, if the system is primed with some
other productions (here produced by hand), then chunking still pro-
vides additional within-trial transfer. In all cases, the learning is
complete in a single trial, ending up with the same 7 decision cycles.
Even if, in the bottom row, the system is primed with all the knowl-
edge that was in R1, it still becomes faster with learning. The gains
gradually diminish with the amount of priming, from 72 percent to
34 percent to 40 percent, but that is to be expected.

That R1-Soar learns completely in a single trial seems a bit odd
for a task as complex as configuring Waxes. There is a reason for
such speed, and it comports well with theories about human learn-
ing. The theory of chunking in human cognition (as described
briefly in Chapter 1) has the human continually constructing chunks
that are symbolized groups of the symbols that are available in
immediate experience. The chunks then become available in im-
mediate experience at a later time, to build up yet additional
chunks. Thus, the chunk hierarchy builds up one level at a time by
multiple experiences through the same part of the world, Soar,
however, learns chunks at all levels simultaneously. It can do so
because it can keep the memory of the antecedent conditions for
each impasse until that impasse is resolved. This could require an
indefinitely long delay, with a consequent requirement for large
amounts of intermediate memory. Soar can also run with what is
called bottom-up chunking, which creates chunks only for impasses
that have no subimpasses—no chunking occurs if anything inter-
Tupts the learning experience. This scheme requires little short-
term memory but requires multiple trials to learn the full behavior,

