              Accelerating Program Synthesis using Learned Probabilistic Models             PLDI’18, June 18–22, 2018, Philadelphia, PA, USA
              const since “-” appears in the output examples. Now that            Algorithm1CEGISwithGuidedSearch
                     O
              the assigned probability is higher than that of the other pro-       Function cegis(Gq,Φ)
              duction rules, the search is guided toward the solution.             1: pts := ∅
                 The rest of the paper is organized as follows. Section 3          2: repeat
              presents our weighted search algorithm. Section 4 describes          3:   P := weighted_search(Gq,pts,Φ)
              howaPHOGislearnedfromtrainingdata.Section5presents                   4:   cex := verify(P,Φ)
              our experimental results. Section 6 discusses related work           5:    if cex = ⊥ then
              and Section 7 concludes. Proofs of all stated theorems are           6:      return P
              provided in the Appendix.                                            7:    endif
                                                                                   8:    pts := pts ∪ {cex}
              3 WeightedSearchAlgorithm                                            9: until false
              In this section, we describe our weighted search algorithm          C. Í         q(A → β | c) = 1. In other words, the context
              based on A* search. We first formulate our problem of guid-               A→β∈R
              ing search-based synthesis using the CEGIS procedure with           can be computed by applying the function p on a current
              a probabilistic program model. We then present a basic algo-        sentential form, and it allows conditioning the expansion of
              rithm that prioritizes likely solution candidates. Lastly, we       a next production rule associated with a probability.
              extend it with two orthogonal optimizations that are widely            Thefunctionq allows assessing the probability of a given
              used by existing search strategies.                                 program. SupposeG is unambiguous and S(= s0) ⇒ s1 ⇒
                                                                                  · · · ⇒ P(= sn) is a unique derivation of a program P where
              3.1   Preliminaries                                                 r0, · · · ,rn−1 are the rules applied at each step. Then, the
              Context-free Grammar. A context-free grammar G is a                 probability of a program P under a statistical program model
                                                                                                                   Î
                                                                                  Gq is defined to be Pr(Gq,P) =     n−1q(ri | p(si)). This form
              quadruple ⟨N,Σ,R,S⟩ where N is a finite set of nonterminal                                             i=0
              symbols, Σ is a finite set of terminal symbols, R is a finite       of probabilistic models is general enough to capture various
                                     ∗                                            statistical program models such as n-grams [2], PCFG [21],
              subset of N ×(N ∪Σ) where each member (A,β) is called a             PHOG[6],andaneuralnetwork-basedmodel[5].
              productionandiswrittenasA → β,andS isthestartsymbol                    Algorithm 1 depicts the CEGIS procedure with a slight
              in N. A sequence of non-terminal and terminal symbols in            difference. Instead of a CFG, the algorithm takes a statistical
                      ∗
              (N ∪Σ) is called a sentential form. Throughout the paper,           program model Gq, which is used to guide the search. In
              for brevity, we only consider leftmost derivations, that is,        each iteration, the algorithm calls the weighted_search
              derivations in which productions are always applied to the          procedure which returns the next element correct on pts
              leftmost non-terminal symbol. Furthermore, we assume the            from P (line 3). Then the result expression P is verified by
              grammarisunambiguousinthesensethatforall sentences,                 theverifyprocedure(line4).IftheexpressionP satisfiesthe
              there exists a unique leftmost derivation.                          specification Φ, it is returned (line 6). Otherwise, a counterex-
              Syntax-Guided Synthesis. The syntax-guided synthesis                ample input pointcex (i.e., an input on which P is incorrect)
              problem [3] is to find a program P that implements a de-            is picked and added to the set of points pts (line 8), and the
              sired specification Φ. Programs are written in a language P         process is repeated.
              describedbyacontext-freegrammarG,andspecificationina                   Let σ be a (possibly infinite) sequence of candidate solu-
                                                                        J K       tions generated by weighted_search at each iteration, and
              decidable theory T. We assign a deterministic semantics P           pts thesetofinputsinthei-thiteration.weighted_search
              to each program P ∈ P = L(G). A specification is a formula              i
                   J K                                                            should satisfy three criteria:
              Φ(x, P (x)) in theory T that relates program inputs to out-         • Prioritization : ∀i ≤ j. Pr(G ,σ ) ≥ Pr(G ,σ ).
              puts.GivenaspecificationΦ,theprogramsynthesistaskisto                                           q  i        q  j
                                                                                                                  J  K
                                                                                  • Correctness : ∀i. ∀x ∈ pts . Φ(x, σi (x))
                                                                    J K                                     i
              find a program P ∈ P such that the formula ∀x.Φ(x, P (x))                                           J K                  J  K
              is valid modulo T.                                                  • Completeness:∃P ∈ P. ∀x. Φ(x, P (x)) =⇒ ∀x. Φ(x, σ⊣ (x)).
                                                                                  where σ⊣ denotes the last element of σ. In other words, a
              3.2   CEGISwithGuidedSearch                                         desirable procedure should generate candidates in order of
              Our synthesis problem is the same as the syntax-guided              likelihood and eventually find a solution if one exists.
              synthesis problem except that a statistical program model is
              given instead of a CFG, which is defined as follows.
              Statistical Program Model. A statistical program model              3.3   WeightedEnumerativeSearch
              Gq = ⟨G,C,p,q⟩ofacontext-freegrammarG isaprobability                In this section, we present an instance of the abstract pro-
              distribution over programs in a language generated by G             cedure weighted_search used in Algorithm 1. We call the
              whereC is a finite conditioning set, p is a function of type        instance weighted enumerative search. Let us begin by in-
                       ∗                               +
              (N ∪ Σ) → C, and q : R × C → R scores rules such                    troducing necessary notations.
              that they form a probability distribution, i.e., ∀A ∈ N,c ∈
