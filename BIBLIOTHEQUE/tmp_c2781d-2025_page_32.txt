                     Preprint, Under Review.
                     D APPENDIX
                     D.1  QUALITATIVE RESULTS
                     In this section, we present further qualitative examples to illustrate the capabilities and limitations of
                     our SFT+RLdynamically planning agent.
                     First, Figure 11 showcases successful human-agent collaboration, detailing how human-provided
                     high-level plans guided the agent to a game-winning Crafter trajectory after approximately 20
                     attempts. Next, we demonstrate its autonomous dynamic planning. Figure 12 shows the agent
                     interrupting an ongoing task and adaptively replanning to acquire critical food supplies when its
                     health is low. Figure 13 further illustrates its dynamic planning capabilities, observing the agent
                     employing multi-stage tactics: initially planning to craft a weapon, then devising a new plan to
                     strategically position itself before engaging enemies. Finally, Figure 14 presents an execution failure,
                     showing how an otherwise sound plan to craft an item falters because the agent fails to verify all
                     necessary prerequisitesâ€”specifically, by not ensuring a required furnace is accessible. This is akin to
                     the knowing-doing gap identified in BALROG (Paglieri et al., 2025a).
                     Figure11: Human-AgentCollaborationinCrafter. Thisfigureillustratesasuccessfulhuman-agent
                     collaboration, where human-provided plans guided the RL-trained planning agent to complete the
                     gamebyminingdiamond.
                                                           32
