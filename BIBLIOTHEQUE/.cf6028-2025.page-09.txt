                        increases with larger k; thus, in both compute regimes we set k = N, which corresponds to
                        MV@N.Underlow-computeconditionswhere N = 1,MV@Nreducestosimpledecoding
                        (SD) without any aggregation.
                        For low-difficulty settings, we instead use FFS, since long-horizon models prefer shorter
                        traces for easier problems. As with short-horizon models, FFS-k scales positively with k,
                        so we employ a large k when compute is high and a small k when compute is low. In
                        these settings, performance improves as N decreases (in contrast to short-horizon models,
                        where larger N is beneficial). Therefore, we set N = k, which yields the MV@N strategy.
                        Underlowcompute,thisresultsink = 1andthussimpledecoding(SD),whileunderhigh
                        computeitcorrespondstoMVwithalargesamplesize.
                        Interestingly, although the model types exhibit distinct behavior across different task dif-
                        ficulties, the optimal TTS strategy is ultimately independent of the problem difficulty, as
                        showninthefinalrecipe(Table2).
                           Finding
                           TheoptimalTTSstrategyisindependentoftaskdifficulty.
                        6  Conclusion
                        Ourlarge-scale study demonstrates there is no single optimal test-time scaling (TTS) strat-
                        egy for enhancing LLM reasoning. The most effective approach is contingent on a crucial
                        interplay between the model’s training methodology, problem difficulty, and the available
                        compute budget. We find that different model families exhibit distinct behaviors: short-
                        horizonmodelsconsistentlyfavorshorter,concisetraces,whilelong-horizonmodelsben-
                        efit from longer, more deliberate reasoning for harder problems while concise reasoning
                        for easier problems. Critically, beam search consistently proves suboptimal for complex
                        reasoning. Our work provides a practical framework for practitioners, underscoring that
                        maximizing performance requires a nuanced, model-aware approach to inference rather
                        than a universal strategy.
                        References
                        AradhyeAgarwal,AyanSengupta,andTanmoyChakraborty. Firstfinishsearch: Efficient
                          test-time scaling in large language models, 2025. URL https://arxiv.org/abs/2505.
                          18149.
                        Markus Besta, Nora Blach, Alexander Kubicek, Robin Gerstenberger, Malte Podstawski,
                          et al. Graph of thoughts: Solving elaborate problems with large language models. In
                          AAAI2024,2024.
                                                                 ˇ´
                        Yuri Chervonyi, Trieu H. Trinh, Miroslav Olsak, Xiaomeng Yang, Hoang Nguyen, Marcelo
                          Menegali, Junehyuk Jung, Vikas Verma, Quoc V. Le, and Thang Luong. Gold-medalist
                          performance in solving olympiad geometry with alphageometry2, 2025. URL https:
                          //arxiv.org/abs/2502.03544.
                                                           ¨
                        Aryo Pradipta Gema, Alexander Hagele, Runjin Chen, Andy Arditi, Jacob Goldman-
                          Wetzler, Kit Fraser-Taliente, Henry Sleight, Linda Petrini, Julian Michael, Beatrice Alex,
                          Pasquale Minervini, Yanda Chen, Joe Benton, and Ethan Perez. Inverse scaling in test-
                          time compute, 2025. URL https://arxiv.org/abs/2507.14417.
                        Soumya Suvra Ghosal, Souradip Chakraborty, Avinash Reddy, Yifu Lu, Mengdi Wang,
                          Dinesh Manocha, Furong Huang, Mohammad Ghavamzadeh, and Amrit Singh Bedi.
                          Doesthinkingmorealwayshelp? mirageoftest-timescalinginreasoningmodels,2025.
                          URLhttps://arxiv.org/abs/2506.04210.
                        Michael Hassid, Gabriel Synnaeve, Yossi Adi, and Roy Schwartz. Don’t overthink it.
                          preferring shorter thinking chains for improved llm reasoning, 2025.   URL https:
                          //arxiv.org/abs/2505.17813.
                                                                 9
