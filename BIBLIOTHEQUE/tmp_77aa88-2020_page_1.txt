                        Published as a conference paper at ICLR 2021
                         SHARPNESS-AWAREMINIMIZATIONFOREFFICIENTLY
                         IMPROVING GENERALIZATION
                          Pierre Foret ∗                    Ariel Kleiner              Hossein Mobahi
                          Google Research                   Google Research            Google Research
                          pierre.pforet@gmail.com           akleiner@gmail.com         hmobahi@google.com
                          BehnamNeyshabur
                          Blueshift, Alphabet
                          neyshabur@google.com
                                                              ABSTRACT
                                In today’s heavily overparameterized models, the value of the training loss pro-
                                vides few guarantees on model generalization ability. Indeed, optimizing only
                                the training loss value, as is commonly done, can easily lead to suboptimal
                                model quality. Motivated by prior work connecting the geometry of the loss
                                landscape and generalization, we introduce a novel, effective procedure for in-
                                stead simultaneously minimizing loss value and loss sharpness. In particular,
                                our procedure, Sharpness-Aware Minimization (SAM), seeks parameters that lie
                                in neighborhoods having uniformly low loss; this formulation results in a min-
                                max optimization problem on which gradient descent can be performed efﬁ-
                                ciently. We present empirical results showing that SAM improves model gen-
                                eralization across a variety of benchmark datasets (e.g., CIFAR-{10, 100}, Ima-
                                geNet, ﬁnetuning tasks) and models, yielding novel state-of-the-art performance
                                for several. Additionally, we ﬁnd that SAM natively provides robustness to la-
                                bel noise on par with that provided by state-of-the-art procedures that speciﬁ-
                                cally target learning with noisy labels. We open source our code at https:
                                //github.com/google-research/sam.
                         1   INTRODUCTION
                        Modern machine learning’s success in achieving ever better performance on a wide range of tasks
                        has relied in signiﬁcant part on ever heavier overparameterization, in conjunction with developing
                        ever more effective training algorithms that are able to ﬁnd parameters that generalize well. Indeed,
                        manymodernneuralnetworkscaneasilymemorizethetrainingdataandhavethecapacitytoreadily
        arXiv:2010.01412v3  [cs.LG]  29 Apr 2021overﬁt (Zhang et al., 2016). Such heavy overparameterization is currently required to achieve state-
                        of-the-art results in a variety of domains (Tan & Le, 2019; Kolesnikov et al., 2020; Huang et al.,
                        2018). In turn, it is essential that such models be trained using procedures that ensure that the
                        parameters actually selected do in fact generalize beyond the training set.
                        Unfortunately, simply minimizing commonly used loss functions (e.g., cross-entropy) on the train-
                        ing set is typically not sufﬁcient to achieve satisfactory generalization. The training loss landscapes
                        of today’s models are commonly complex and non-convex, with a multiplicity of local and global
                        minima, and with different global minima yielding models with different generalization abilities
                        (Shirish Keskar et al., 2016). As a result, the choice of optimizer (and associated optimizer settings)
                        from among the many available (e.g., stochastic gradient descent (Nesterov, 1983), Adam (Kingma
                        &Ba, 2014), RMSProp (Hinton et al.), and others (Duchi et al., 2011; Dozat, 2016; Martens &
                        Grosse, 2015)) has become an important design choice, though understanding of its relationship
                        to model generalization remains nascent (Shirish Keskar et al., 2016; Wilson et al., 2017; Shirish
                        Keskar & Socher, 2017; Agarwal et al., 2020; Jacot et al., 2018). Relatedly, a panoply of methods
                        for modifying the training process have been proposed, including dropout (Srivastava et al., 2014),
                           ∗WorkdoneaspartoftheGoogleAIResidencyprogram.
                                                                    1
