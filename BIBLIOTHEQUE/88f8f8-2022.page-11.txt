                                                                                                        Point Primitive Transformer                 11
                                           4D Semantic Segmentation on Synthia 4D dataset. Setup. Synthia
                                           4D [34] is a synthetic dataset for outdoor autonomous driving. It creates 3D
                                           videos with the Synthia dataset, which consists of six videos of driving scenarios
                                           in whichobjectsandcamerasaremoving.Weusethesametraining/validation/test
                                           split as previous work, with 19,888/815/1,886 frames, respectively.
                                                 Table 1. Evaluation for semantic segmentation on Synthia 4D dataset [34]
                                            Method            Frames Bldn Road SdwlkFenceVegittn Pole Car T.SignPedstrnBicycl Lane T.LightmIoU
                                            3D MinkNet14 [6]     1   89.39 97.68 69.43 86.52 98.11 97.26 93.50 79.45  92.27   0.00 44.61 66.69 76.24
                                            4D MinkNet14 [6]     3   90.13 98.26 73.47 87.19 99.10 97.50 94.01 79.04 92.62    0.00 50.01 68.14 77.24
                                            PointNet++ [32]      1   96.88 97.72 86.20 92.75 97.12 97.09 90.85 66.87  78.64   0.00 72.93 75.17 79.35
                                            MeteorNet-m [28]     2   98.22 97.79 90.98 93.18 98.31 97.45 94.30 76.35  81.05   0.00 74.09 75.92 81.47
                                            MeteorNet-l [28]     3   98.10 97.72 88.65 94.00 97.98 97.65 93.83 84.07 80.90    0.00 71.14 77.60 81.80
                                            P4Transformer [10]   1   96.76 98.23 92.11 95.23 98.62 97.77 95.46 80.75  85.48   0.00 74.28 74.22 82.41
                                            P4Transformer [10]   3   96.73 98.35 94.03 95.23 98.28 98.01 95.60 81.54  85.18   0.00 75.95 79.07 83.16
                                            PPTr(ours)           1   97.14 98.42 94.12 97.00 99.59 97.86 98.54 79.68  89.20   0.00 77.26 77.42 83.85
                                            PPTr(ours)          30   98.01 98.6395.2697.03 99.70 97.9598.76 81.99     91.20   0.00 78.29 77.09 84.49
                                                 Result. Table 1 shows our method outperforms the state-of-the-art meth-
                                           ods. OurPPTrwith1framecanachieve0.69%improvementovertheP4Transformer
                                           with 3 frames, which demonstrates the effectiveness of the hierarchical structure.
                                           Whenusingthememorypooltointegrate temporal information from 30 frames,
                                           we can achieve 1.33% improvement over previous state-of-the-art methods. It is
                                           worth mentioning that our method is the first to integrate point clouds of 30
                                           frames, which is 10 times that of previous methods. And we also demonstrate
                                           that longer point cloud sequences are valuable for 4D semantic segmentation.
                                           4D Semantic Segmentation on HOI4D. Setup. In order to further verify
                                           the effectiveness of our method, we select the HOI4D dataset for experiments,
                                           which is a large-scale 4D egocentric dataset to catalyze the research of category-
                                           level human-object interaction. It provides frame-wise annotations for 4D point
                                           cloud semantic segmentation. Since the dataset has not been released yet, we
                                           sent an email to the author team to request 1000 sequences, which includes 30k
                                           frames of the point cloud. The train/test split is the same as HOI4D.
                                                 Result. As shown in Table 2, our method outperforms previous methods
                                           on this more challenging dataset. Compared with P4transformer, the mIoU goes
                                           up from 59.61% to 68.07% and 61.97% to 68.54% in the case of single frame and
                                           3 frames respectively, demonstrating the effectiveness of the hierarchical design
                                           again. Due to the limitation of computational resources, P4Transformer can
                                           use up to 3 frames, but our method can integrate 30 frames of spatio-temporal
                                           information. The improvement from 61.97% to 70.13% further confirms that
                                           with our proposed primitive memory pool, we can better leverage the long-term
                                           temporal information to boost the 4D segmentation performance.
