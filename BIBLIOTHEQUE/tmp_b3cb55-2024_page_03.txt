              Figure 1: High Level overview of our pipeline. We retrain an LLM on public ARC-AGI
              data, which is then finetuned an additional time on the hidden test cases. Subsequently,
              this model predicts several solution candidates from which we select two using an algo-
              rithmic approach. All blue rectangles are calculated in the 12h timelimit of the kaggle
              notebook. At several parts in our pipeline we "augment" (Aug) the data by applying
              transformations to the examples.
              tion scores. We also use data augmentations at train, inference and scoring,
              substantially increasing our score. The key components of our pipeline are
              outlined below:
              Datasets:
              In addition to the ofÏcial ARC-AGI dataset, which is divided into “pub-
              lic training”, “public evaluation”, and “private evaluation” subsets, we also
              utilize the Re-ARC dataset by Hodel [11]. This extended dataset is de-
              rived from the public training dataset using custom generators written in
              a domain-specific language (DSL), allowing for the creation of additional,
              diverse examples. Since the Re-ARC dataset is a superset of the public
              ARC-AGI public training dataset, we choose to replace the public training
              data with Re-ARC.
              Weadditionally use Concept-ARC and ARC-Heavy [12, 13], which we intro-
              duce in Section 3.1.
              Data Representation:
              In order to represent the ARC-AGI puzzles in a denser format, we modify
              the tokenizer and embedding layers by reducing the number of tokens sig-
              nificantly to only 64 symbols, allowing us to encode the data succinctly and
              transparently for the LLM. More detailed information regarding our data
              modeling approach can be found in Section 3.2.
              Augmentation:
              While data augmentations are commonly used to increase dataset sizes, our
                                  3
