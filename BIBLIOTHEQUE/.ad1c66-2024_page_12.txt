           T. Han et al.                                                                  International Journal of Applied Earth Observation and Geoinformation 133 (2024) 104105 
                                             Fig. 16. The representative visualizations results of proposed method on the Toronto 3D dataset.
                  Fig. 17. Per-class IoU improvements of ASGFormer over different methods on two dataset, where ASGFormer is compared with Point Transformer and 3D-GCN.
           approach is superior in addressing the issue of adherent structures.          and 2.3% over Point Transformer and Point Transformer V2, respec-
           While SPT performs well in architectural structures (such as walls            tively. The proposed method is able recognize all facade components
           and beams) using super point Transformer, it tends to systematically          and achieves the best performance across six categories. The recogni-
           aggregate points with similar structures when constructing super point        tion of structurally similar and adhesive facade elements highlights the
           graph, for instance, the boards on the wall.                                  robust semantic segmentation of the proposed graph and Transformer
               ScanNet: Quantitative evaluation results for comprehensive test-          framework. Notably, the proposed method is able to recognize compo-
           ing and class-level comparison are shown in Tables 1 and 4, respec-           nents across eight categories (with significant differences in the number
           tively. ASGFormer has an mIoU advantage of 2.2% over Point Trans-             of points in different categories). This indicates that the proposed
           former. Even more exciting is that we achieve improvements of 0.4%            method has a good ability to handle class imbalance issues caused by
           (GemoGCNN), 13.9% (SegGCN), 11.8% (SPH3D-GCN), 11.0% (HPEIN)                  the numberofpoints.However,itstillperformspoorlywhenaddressing
           over the previous series of graph-based methods. Our method achieves          class imbalance due to uneven position distribution.
           the top rank in fourteen out of twenty categories. Specifically, there is        Toronto 3D & Semantic KITTI: The overall evaluation results are
           a clear advantage in the segmentation results related to the structural       shown in Table 1. Most current methods used for indoor point cloud
           parts of buildings and furniture adhering to buildings. However, similar      semantic segmentation are difficult to transfer and apply to outdoor
           to S3DIS, our method is not well-suited for segmenting small ans              scenes. Therefore, we compared some of these methods. As shown in
           tiny structure, such as shower and sink. The comparisons of per-class         Table 1, our proposed method achieves mIoU of 81.6% and 70.1%
           IoU with 3D-GCN and Point Transformer are presented in Fig. 17(b).            for Toronto 3D and Semantic KITTI datasets, respectively. Compared
           In summary, our method achieves high-precision semantic segmenta-             against the latest method, such as Point Transformer V2 & V3, ASG-
           tion through the dynamic graph Transformer with adaptive structure            Former exhibits performance decrease of 4.1% and 2.5%, but it still
           weights. The major contribution is the ability to segment structurally        surpasses most of the previous methods. Subsequently, we compared a
           connected building components and indoor objects.                             series of methods from the Toronto 3D benchmark, most of which are
               City-Facade: Quantitative evaluation results of City-Facade are           designed for outdoor scenes. As shown in Table 6, we achieved the best
                                                                                         results in three categories, demonstrating the potential of the proposed
           shown in Tables 1 and 5. ASGFormer has an mIoU advantage of 6.2%              method in outdoor point cloud semantic segmentation.
                                                                                     12 
