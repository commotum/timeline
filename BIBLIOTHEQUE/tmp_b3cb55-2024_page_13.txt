                          Sampling        Llama-rearc          Llama-mix           Nemo-mix
                                          all 400 tasks          100 tasks           100 tasks
                                        A       B      R      A     B      R     A      B      R
                          Greedy      51.00   60.00  10:51   51.5  65.5  2:36   59.0   75.0   3:49
                          Stochastic  50.50   59.50  10:58   50.5  65.5  2:39   58.5   72.0   3:55
                          DFS 17%     51.25   61.50   7:21   51.5  66.5  1:51   60.5   76.5   2:35
                          DFS 10%     51.00   63.50   9:54   51.5  73.0  2:34   60.5   80.0   3:40
                        Table 5: Percentage of correct solutions sampled for 100 randomly split-off tasks of the
                        ARC-AGI public evaluation set (full public evaluation set is used for Llama-rearc) using
                        different sampling strategies on 16 augmented versions (transposition and rotations, as
                        well as randomly permuted colors) of the task. The first column (A) denominates the
                        number of tasks correctly solved by the two best-scoring guesses of the model, while the
                        second column (B) represents the number of tasks for which the correct solution was
                        present among the candidates obtained during the inference run. Runtimes (column R),
                        hh:mm for inference on an Nvidia H100 GPU are given in parentheses. Note that there
                        might be some conceptual leakage from the 300 evaluation tasks used in training of Llama-
                        Mix and Nemo-Mix, possibly inflating their scores a little.
                        Using this algorithm we are able to generate the correct solution pretty well
                        – in up to 80% of the cases on eval! However, we see a big drop in score
                        when selecting two of these candidates, as we have no way to reliably choose
                        the correct solution from our large number of candidates (yet).
                        3.6    Selection Strategies
                        Figure 6: Illustration of the idea behind our candidate scoring. Depending on the aug-
                        mentation used, the model is able to "see" places of high uncertainty more clear. In this
                        example, the wrong line is barely visible in the transposed version of the task, but when
                        rotating by 180° the model can clearly see that something is wrong. As a result, aggre-
                        gating these scores provides a highly effective way to filter wrong candidates.
                        Once we have generated a set of solution candidates, the next step is to
                        determine which ones to submit. Our pipeline up to this point is capable of
                        generating candidates that have a good chance of including the correct solu-
                        tion, but to consider a task solved, we must identify it among the candidates,
                                                            13
