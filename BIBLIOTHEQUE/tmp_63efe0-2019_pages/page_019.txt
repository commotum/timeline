                                    Published as a conference paper at ICLR 2020
                                    F ACTIONREPEAT
                                      1000     Acrobot Swingup        1000     Cartpole Balance       1000 Cartpole Balance Sparse    1000    Cartpole Swingup
                                       800                             800                             800                             800
                                       600                             600                             600                             600
                                     Episode Return400                 400                             400                             400
                                       200                             200                             200                             200
                                         0                               0                               0                               0
                                           0.0 0.2  0.4  0.6  0.8  1.0    0.0  0.2  0.4  0.6 0.8  1.0     0.0  0.2  0.4 0.6  0.8  1.0     0.0  0.2 0.4  0.6  0.8  1.0
                                      1000 Cartpole Swingup Sparse 1000          Cheetah Run          1000        Cup Catch           1000       Finger Spin
                                       800                             800                             800                             800
                                       600                             600                             600                             600
                                     Episode Return400                 400                             400                             400
                                       200                             200                             200                             200
                                         0                               0                               0                               0
                                           0.0 0.2  0.4  0.6  0.8  1.0    0.0  0.2  0.4  0.6 0.8  1.0     0.0  0.2  0.4 0.6  0.8  1.0     0.0  0.2 0.4  0.6  0.8  1.0
                                      1000     Finger Turn Easy       1000     Finger Turn Hard       1000       Hopper Hop           1000      Hopper Stand
                                       800                             800                             800                             800
                                       600                             600                             600                             600
                                     Episode Return400                 400                             400                             400
                                       200                             200                             200                             200
                                         0                               0                               0                               0
                                           0.0 0.2  0.4  0.6  0.8  1.0    0.0  0.2  0.4  0.6 0.8  1.0     0.0  0.2  0.4 0.6  0.8  1.0     0.0  0.2 0.4  0.6  0.8  1.0
                                      1000    Pendulum Swingup        1000      Quadruped Run         1000     Quadruped Walk         1000      Reacher Easy
                                       800                             800                             800                             800
                                       600                             600                             600                             600
                                     Episode Return400                 400                             400                             400
                                       200                             200                             200                             200
                                         0                               0                               0                               0
                                           0.0 0.2  0.4  0.6  0.8  1.0    0.0  0.2  0.4  0.6 0.8  1.0     0.0  0.2  0.4 0.6  0.8  1.0     0.0  0.2 0.4  0.6  0.8  1.0
                                      1000       Reacher Hard         1000        Walker Run          1000       Walker Stand         1000       Walker Walk
                                       800                             800                             800                             800
                                       600                             600                             600                             600
                                     Episode Return400                 400                             400                             400
                                       200                             200                             200                             200
                                         0                               0                               0                               0
                                           0.0 0.2  0.4  0.6  0.8  1.0    0.0  0.2  0.4  0.6 0.8  1.0     0.0  0.2  0.4 0.6  0.8  1.0     0.0  0.2 0.4  0.6  0.8  1.0
                                                Environment Steps 1e6           Environment Steps 1e6           Environment Steps 1e6          Environment Steps 1e6
                                        Repeat 1      Repeat 2     Repeat 4      A3C (1e9 steps, proprio)  D4PG (1e9 steps)     PlaNet (1e6 steps)   SLAC (3e6 steps)
                                    Figure 12: Robustness of Dreamer to different control frequencies. Reinforcement learning methods
                                    can be sensitive to this hyper parameter, which could be ampliﬁed when learning dynamics models
                                    at the control frequency of the environment. For this experiment, we train Dreamer with different
                                    amounts of action repeat. The areas show one standard deviation across 2 seeds. We used a previous
                                    hyper parameter setting for this experiment. We ﬁnd that a value of R = 2 works best across tasks.
                                                                                                  19
