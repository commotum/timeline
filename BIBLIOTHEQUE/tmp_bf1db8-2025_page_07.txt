                                                                                                             32b
                                                          InstructIT
                                                          8b    27b   4b     12b   27b    Flash-LiteFlash    Qwen  R1
                                                          3.1                             2.0   2.0          R1           (high)
                       Tasks/Models          RandomQwen-2.5-7B-InstructLlamaGemma2Gemma3Gemma3Gemma3GeminiGeminiGPT4oDistillDeepSeeko3-mini
                       BoardgameQA        33.3   31.0  31.5  39.5   34.5  33.0   37.0  29.5   42.5  41.0  36.0   75.5  53.0
                    Boolean Expressions   20.0   22.0  18.0  25.0   23.0  25.5   22.0  24.0   27.0  22.5  17.5   55.5  67.0
                       BuggyTables         0.0   1.5    0.0   0.5   0.5    0.0   0.0    1.5   3.5   0.5    0.5   4.5   59.5
                    Causal Understanding  38.0   40.0  37.0  45.5   46.0  49.0   51.5  52.5   52.0  54.0  54.5   54.5  54.0
                     DisambiguationQA     21.0   34.2  36.7  45.0   33.3  41.7   49.2  50.0   48.3  51.7  52.5   50.0  58.3
                      DyckLanguages        1.4   1.0    4.5   2.0   3.5    8.5   4.5    6.5   14.0  8.0   18.0   56.0  55.0
                     Geometric Shapes      6.2   41.5  25.5  31.0   18.0  32.5   26.5  30.0   35.0  22.5   4.5   1.5   52.5
                        Hyperbaton         0.0   0.5    2.0   4.0   2.0    2.5   3.5    6.5   4.5   7.5    3.0   6.0   32.0
                         Linguini          0.0   2.5    3.0   7.0   1.0    6.0   9.0   12.5   15.5  15.5   6.0   19.5  17.0
                   MovieRecommendation    10.0   24.5  30.0  40.0   35.0  44.5   55.0  51.5   59.5  61.0  46.0   59.5  84.0
                    Multistep Arithmetic   0.0   0.0    0.5   0.0   0.0    0.5   1.5    7.5   9.5   5.5   36.0   46.5  73.0
                          NYCC            10.0   13.0  13.0  13.5   7.0   11.5   15.0  13.5   11.0  23.0  10.5   20.0  16.0
                      Object Counting      0.0   0.0    0.0   0.0   0.0    0.5   0.0    4.0   11.0  6.5    4.0   76.5  90.0
                      Object Properties    1.6   0.0    0.5   0.0   0.5    1.5   0.5    0.5   1.5   0.0    0.0   0.0   56.5
                       SARCTriples        12.5   17.5  16.5  21.0   14.0  26.0   24.0  27.0   37.5  38.5  22.0   28.5  24.0
                      Shuffled Objects    14.3   8.0    9.5  12.0   1.0    7.0   5.0   15.0   9.0   14.0   2.0   6.0   49.5
                     Spatial Reasoning     5.2   0.0    1.0   7.0   4.0   10.5   13.0  10.5   18.5  14.0  14.5   37.0  48.5
                         SportQA           0.0   5.0    1.5  10.0   2.5   12.5   20.0  18.5   23.0  25.0  19.5   29.0  26.5
                    Temporal Sequences     0.0   0.5    9.5   1.5   1.0    0.0   1.5    1.0   0.5   0.0    0.5   0.0   68.5
                      TimeArithmetic       0.5   18.5   4.0  15.5   9.5   23.5   46.5  45.0   48.0  45.5  56.5   77.0  76.5
                        WebofLies          5.5   2.5    5.5   6.5   12.0  22.0   21.0  14.0   18.5  14.5  13.0   29.5  43.0
                       WordSorting         4.3   4.0    2.5   3.5   4.5    6.0   7.5   12.5   26.0  22.0  36.0   68.0  77.5
                       Zebra Puzzles      15.4   19.0   2.5  23.0   10.0  19.5   30.0  32.0   44.5  32.0   1.5   8.0   67.5
                   BBEH(MicroAverage)      8.4   12.5  10.6  14.8   11.0  16.3   18.8  19.7   23.9  22.3  19.2   34.9  54.2
                  BBEH(HarmonicMean)       2.4   3.0    3.6   4.0   3.4    4.5   4.9    8.0   9.8   6.0    5.2   6.8   44.8
                            Table 2: The performance of various models on the individual tasks and overall on BBEH.
                 ence Thinking model achieves a (micro) average         baseline to have a high performance. In Table 2, we
                 accuracy of 32.8% and a harmonic average accu-         provide the results of a random baseline for each
                 racy of 20.2% on BBEH. Note that some model            of the tasks in BBEH and the entire dataset. As can
                 accuracies are even below random performance.          be viewed, the random baseline has a performance
                 Uponchecking, we observe that these are mostly         of 8.4% for BBEH which leaves substantial room
                 cases where models could not solve the problem         for comparing models of various size.
                 in their effective output token lengths and started      Finally, looking at the accuracies of the models
                 degenerating after a point, so no final answer could   onvarioustasks,wecanseethatvariousmodelsare
                 be extracted from their solution.                      goodatdifferent types of reasoning. For example,
                   Secondly, the harmonic mean accuracies reveal        DeepSeekR1significantly outperforms other mod-
                 an even larger headroom: the best general-purpose      els on BoardgameQA, o3-mini (high) significantly
                 modelhavingaharmonicmeanaccuracyof9.8%                 outperforms other models on Temporal Sequences
                 andthebestreasoning-specialized model having an        and Object Properties, GPT4o significantly outper-
                 accuracy of 44.8%. Interestingly, while DeepSeek       forms other models on NYCC, and GPT4o and
                 R1performsbetter than all general-purpose mod-         Gemini 2.0 Flash significantly outperform other
                 els in terms of micro average accuracy, given its      models on SARCTriples.
                 low performance on some of our tasks it performs       4.3  Further Analyses of the Results
                 worse than two of the general-purpose models in        General-Purpose vs Reasoning Models: With
                 terms of harmonic mean accuracy.                       the introduction of reasoning models that leverage
                   Thirdly, as mentioned in Section 2, the problems     test-time compute for thinking, a tremendous jump
                 in the original BBH dataset suffered from having       in performance was observed on reasoning tasks
                 a small output space, thus allowing for a random       involving math and coding. For example, on the
                                                                   26479
