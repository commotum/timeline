                      Model                  Sharing    Segment    Classiﬁcation             Question Answering               Avg
                                                                      XNLI         XQuAD        MLQA       TyDiQA-GoldP
                      DIET-REL                  -        input         68.0       68.1 / 52.8  57.7 / 42.7    63.3 / 50.9    57.6
                      DIET-REL              head-wise    input         67.7       66.2 / 51.0  56.0 / 41.1    60.1 / 45.9    55.4
                      DIET-REL             layer-wise    input         68.0       68.6 / 53.3  58.1 / 43.1    61.3 / 48.2    57.2
                      DIET-REL                  -       per-head       68.4       69.4 / 54.4  58.6 / 43.5    62.4 / 49.3    58.0
                      DIET-REL              head-wise   per-head       67.8       66.0 / 50.5  55.5 / 40.4    59.2 / 44.6    54.7
                      DIET-REL             layer-wise   per-head       68.1       68.7 / 53.8  58.4 / 43.2    61.0 / 48.4    57.3
                      DIET-ABS (dp=64)          -        input         68.0       67.4 / 50.5  57.8 / 42.3    61.3 / 46.8    56.3
                      DIET-ABS (dp=64)          -       per-head       67.9       67.5 / 52.4  57.3 / 42.3    61.6 / 46.8    56.5
                      DIET-ABS (dp=128)         -       per-head       68.1       68.2 / 52.0  57.9 / 42.6    61.5 / 47.6    56.8
                      DIET-ABS (dp=512)         -       per-head       68.5       68.0 / 52.0  57.7 / 42.4    61.6 / 48.4    56.9
                      DIET-ABS (dp=64)     layer-wise    input         68.0       69.3 / 53.1  59.3 / 43.9    63.2 / 48.6    57.9
                      DIET-ABS (dp=64)     layer-wise   per-head       68.4       69.3 / 53.2  59.4 / 44.1    63.3 / 48.6    58.0
                      DIET-ABS (dp=128)    layer-wise   per-head       68.5       70.0 / 53.6  59.8 / 44.5    64.6 / 51.5    58.9
                      DIET-ABS (dp=256)    layer-wise   per-head       68.4       69.9 / 53.8  59.6 / 44.2    62.8 / 49.1    58.3
                      DIET-ABS (dp=512)    layer-wise   per-head       67.8       69.0 / 53.2  58.4 / 43.0    62.5 / 48.8    57.5
                  Table 5: Ablation study on XTREME: We run decoupled positional attention ablation study to understand the
                  effect of 1) sharing positional attention parameters across layers and heads 2) segment attention added at per-head
                  3) performance of relative and absolute 4) absolute positional attention rank dp from 64 to 512.
                                                                    English                        Multilingual
                                                         Parameters     +∆      GLUE     Parameters     +∆      XTREME
                             Devlin et al. (2018)          110.1M        -       84.8      178.9M        -         55.3
                             Shawetal. (2018)              112.9M      +2.5%     85.2      181.7M      +1.7%       57.9
                             DIET-REL                      109.9M      +0.0%     85.2      178.7M      +0.0%       58.0
                             DIET-REL (share)              109.7M      +0.0%     85.0      178.5M      +0.0%       57.3
                             DIET-ABS (d =128)             128.6M     +16.8%     85.3      197.4M     +10.0%       56.8
                                          p
                             DIET-ABS (d =128, share)      111.3M      +1.1%     85.2      180.1M      +0.6%       58.9
                                          p
                  Table 6: Model Parameters: We list the number of model parameters and performance for different position en-
                  coding approaches. We observe that sharing hurts the performance of DIET-REL with negligible beneﬁt in the
                  number of parameters. On the contrary, the regularization effect of sharing makes DIET-ABS more stable with
                  lesser parameters to achieve competitive performance.
                  the performance of DIET-ABS. We summarize the               Appendix C for segment attention visualization.
                  key settings along with the number of model pa-             RankofAbsolutePositionalAttention              Thede-
                  rameters in Table 6. For DIET-REL, sharing brings           sign of DIET-ABS allows to learn higher rank at-
                  little effect on saving parameters, and hurts the per-      tention matrices as shown in Theorem 1. To under-
                  formance. Hence, we recommend no sharing for                standtheeffectofabsolutepositionalattentionrank
                  relative positional encodings (DIET-REL). On the            (d ) in practice, we conduct experiments varying
                  other hand, it is necessary to share parameters for           p
                                                                              the rank from d = 64 to d = 512. We present
                  DIET-ABS in order to keep the number of parame-                              p             p
                  ters low. Interestingly, sharing has regularization         the results in Table 5. We notice that the perfor-
                  effect on DIET-ABS, making the model perform                manceimprovesasweincreasetherankfrom64to
                  better. We choose layer-wise sharing over head-            128. However there is a performance saturation in
                  wise sharing for its better performance.                    further increasing it to 512. We present a visualiza-
                                                                              tion of the rank of the positional attention matrix
                  Segment Encoding Our novel segment encod-                   in Appendix B.
                  ing design further improves the model perfor-               4.5   Positional Attention Pattern Visualization
                  mance showed in Table 5. Both relative and ab-
                  solute decoupled positional attention models ben-           Wenextvisualize the learned positional attention
                  eﬁt from moving the segment encoding from in-               patterns of DIET-ABS in Figure 4. We ﬁrst note
                  put to per-head: DIET-REL (+0.4%), layer-wise               that DIET-ABS has learned to capture the relative
                  shared DIET-REL (+0.1%), DIET-ABS (+0.2%),                  positional relations between inputs. Also note that,
                  layer-wise shared DIET-ABS (+0.1%). See Ap-                 for the the index zero (the [CLS] token), decoupled
                  pendix D for the results of GLUE benchmark and              absolute positional attention usually learns a spe-
                                                                         2981
