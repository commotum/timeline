                                                              Generative Pretraining from Pixels
               Child, R., Gray, S., Radford, A., and Sutskever, I. Gen-           Gomez,A.N.,Ren,M.,Urtasun,R., and Grosse, R. B. The
                  erating long sequences with sparse transformers. arXiv             reversible residual network: Backpropagation without
                  preprint arXiv:1904.10509, 2019.                                   storing activations. In Advances in neural information
                                                                                     processing systems, pp. 2214–2224, 2017.
               Coates, A., Ng, A., and Lee, H. An analysis of single-
                  layer networks in unsupervised feature learning. In Pro-        Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,
                  ceedings of the fourteenth international conference on            Warde-Farley, D., Ozair, S., Courville, A., and Bengio,
                  artiﬁcial intelligence and statistics, pp. 215–223, 2011.         Y. Generative adversarial nets. In Advances in neural
                                                                                     information processing systems, pp. 2672–2680, 2014.
               Cubuk, E., Zoph, B., Mane, D., Vasudevan, V., and Le, Q. V.
                  Autoaugment: Learning augmentation strategies from              Goyal, P., Mahajan, D., Gupta, A., and Misra, I. Scaling and
                  data, 2019.                                                        benchmarking self-supervised visual representation learn-
                                                                                     ing. In Proceedings of the IEEE International Conference
               Dai, A. M.andLe,Q.V. Semi-supervisedsequencelearning.                 onComputerVision, pp. 6391–6400, 2019.
                  In Advances in neural information processing systems,           Graves, A. and Jaitly, N. Towards end-to-end speech recog-
                  pp. 3079–3087, 2015.                                               nition with recurrent neural networks. In International
               Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. Bert:            conference on machine learning, pp. 1764–1772, 2014.
                  Pre-training of deep bidirectional transformers for lan-        He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R. Mo-
                  guage understanding. arXiv preprint arXiv:1810.04805,              mentumcontrast for unsupervised visual representation
                  2018.                                                              learning. arXiv preprint arXiv:1911.05722, 2019.
               Dinh, L., Krueger, D., and Bengio, Y. Nice: Non-linear               ´
                  independent components estimation.         arXiv preprint       Henaff, O. J., Razavi, A., Doersch, C., Eslami, S., and Oord,
                  arXiv:1410.8516, 2014.                                            A. v. d. Data-efﬁcient image recognition with contrastive
                                                                                     predictive coding.    arXiv preprint arXiv:1905.09272,
               Doersch, C., Gupta, A., and Efros, A. A. Unsupervised                 2019.
                  visual representation learning by context prediction. In        Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X.,
                  Proceedings of the IEEE International Conference on                Botvinick, M., Mohamed, S., and Lerchner, A. beta-
                  ComputerVision, pp. 1422–1430, 2015.                              vae: Learning basic visual concepts with a constrained
               Donahue, J. and Simonyan, K. Large scale adversarial rep-            variational framework. 2017.
                  resentation learning. In Advances in Neural Information         Hinton, G. E., Osindero, S., and Teh, Y.-W. A fast learning
                  Processing Systems, pp. 10541–10551, 2019.                         algorithm for deep belief nets. Neural computation, 18
                                 ¨     ¨                                            (7):1527–1554, 2006.
               Donahue, J., Krahenbuhl, P., and Darrell, T. Adversarial
                  feature learning. arXiv preprint arXiv:1605.09782, 2016.        Hjelm, R. D., Fedorov, A., Lavoie-Marchildon, S., Grewal,
               Dosovitskiy, A., Fischer, P., Springenberg, J. T., Riedmiller,        K., Bachman, P., Trischler, A., and Bengio, Y. Learning
                  M., and Brox, T. Discriminative unsupervised feature               deep representations by mutual information estimation
                  learning with exemplar convolutional neural networks.              and maximization. arXiv preprint arXiv:1808.06670,
                  IEEEtransactions on pattern analysis and machine intel-            2018.
                  ligence, 38(9):1734–1747, 2015.                                 Howard, J. and Ruder, S.        Universal language model
                                                                                     ﬁne-tuning for text classiﬁcation.        arXiv preprint
               Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-A., Vin-           arXiv:1801.06146, 2018.
                  cent, P., and Bengio, S. Why does unsupervised pre-
                  training help deep learning? Journal of Machine Learn-          Huang, P.-S., Avron, H., Sainath, T. N., Sindhwani, V., and
                  ing Research, 11(Feb):625–660, 2010.                               Ramabhadran, B. Kernel methods match deep neural net-
                                                                                    works on timit. In 2014 IEEE International Conference
               Gidaris, S., Singh, P., and Komodakis, N. Unsupervised rep-           on Acoustics, Speech and Signal Processing (ICASSP),
                  resentation learning by predicting image rotations. arXiv          pp. 205–209. IEEE, 2014.
                  preprint arXiv:1803.07728, 2018.
                                                                                  Huang, Y., Cheng, Y., Bapna, A., Firat, O., Chen, D., Chen,
               Glorot, X. and Bengio, Y. Understanding the difﬁculty                 M., Lee, H., Ngiam, J., Le, Q. V., Wu, Y., et al. Gpipe:
                  of training deep feedforward neural networks. In Pro-              Efﬁcient training of giant neural networks using pipeline
                  ceedings of the thirteenth international conference on             parallelism. In Advances in Neural Information Process-
                  artiﬁcial intelligence and statistics, pp. 249–256, 2010.          ing Systems, pp. 103–112, 2019.
