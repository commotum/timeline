                         Model              Overall    Count    Exist   Compare     Query    Compare
                                                                        Numbers   Attribute  Attribute
                         Human                92.6      86.7    96.6      86.5       95.0       96.0
                         Q-type baseline      41.8      34.6    50.2      51.0       36.0       51.3
                         LSTM                 46.8      41.7    61.1      69.8       36.8       51.8
                         CNN+LSTM             52.3      43.7    65.2      67.1       49.3       53.0
                         CNN+LSTM+SA          68.5      52.2    71.1      73.5       85.3       52.3
                         CNN+LSTM+SA*         76.6      64.4    82.7      77.4       82.6       75.4
                         CNN+LSTM+RN          95.5     90.1     97.8      93.6      97.9       97.1
                          * Our implementation, with optimized hyperparameters and trained fully end-to-end.
                  Table 1: Results on CLEVR from pixels. Performances of our model (RN) and previously
                  reported models [16], measured as accuracy on the test set and broken down by question category.
                  ﬁne-tuning, very large LSTMs for language encoding, and further processing modules, such as stacked
                  or iterative attention, or large fully connected layers (upwards of 4000 units, often) [15].
                  5    Results
                  5.1   CLEVRfrom pixels
                  Our model achieved state-of-the-art performance on CLEVR at 95.5%, exceeding the best model
                  trained only on the pixel images and questions at the time of the dataset’s publication by 27%, and
                  surpassing human performance in the task (see Table 1 and Figure 3).
                     These results – in particular, those obtained in the compare attribute and count categories –
                  are a testament to the ability of our model to do relational reasoning. In fact, it is in these categories
                  that state-of-the-art models struggle most. Furthermore, the relative simplicity of the network
                  components used in our model suggests that the diﬃculty of the CLEVR task lies in its relational
                  reasoning demands, not on the language or the visual processing.
                  Results using privileged training information A more recent study reports overall perfor-
                  mance of 96.9% on CLEVR, but uses additional supervisory signals on the functional programs
                  used to generate the CLEVR questions [16]. It is not possible for us to directly compare this
                  to our work since we do not use these additional supervision signals. Nonetheless, our approach
                  greatly outperforms a version of their model that was not trained with these extra signals, and even
                  versions of their model trained using 9K or 18K ground-truth programs. Thus, RNs can achieve
                  very competitive, and even super-human results under much weaker and more natural assumptions,
                  and even in situations when functional programs are unavailable.
                  5.2   CLEVRfrom state descriptions
                  To demonstrate that the RN is robust to the form of its input, we trained our model on the state
                  description matrix version of the CLEVR dataset. The model achieved an accuracy of 96.4%. This
                  result demonstrates the generality of the RN module, showing its capacity to learn and reason
                  about object relations while being agnostic to the kind of inputs it receives – i.e., to the particular
                  representation of the object features to which it has access. Therefore, RNs are not necessarily
                  restricted to visual problems, and can thus be applied in very diﬀerent contexts, and to diﬀerent
                  tasks that require relational reasoning.
                                                               7
