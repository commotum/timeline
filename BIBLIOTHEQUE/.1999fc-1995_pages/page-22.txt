SUPPORT- VECTOR NETWORKS 295

From conditions (62) and (64) one can also conclude that to maximize (60)
3 = Omax = Max(Q1,..., Qe).

Substituting this value of 6 into (60) we obtain

; , oeklk-! 1
woay=ari—[> ATDA+ (= (1-2) | (66)

To find the soft margin hyperplane one can therefore either find the maximum of the quadratic
form (51) under the constraints (61) and (65), or one has to find the maximum of the convex
function (60) under the constraints (61) and (56). For the experiments reported in this paper
we used k = 2 and solved the quadratic programming problem (51).

For the case of F(u) = u the same technique brings us to the problem of solving the
following quadratic optimization problem: minimize the functional

1
W(A) = Al1— 5A'DA,

under the constraints

and
A'TY =0.

The general solution for the case of a monotone convex function F (u) can also be obtained
from this technique. The soft margin hyperplane has a form

£
w= ) Oi ViXi,
i=t

where At = (#°,..., a?) is the solution of the following dual convex programming prob-
lem: maximize the functional

under the constraints

ATY =0,
A> 0,
where we denote
fu) = F'(u).

For convex monotone functions F(u) with F(0) = 0 the following inequality is valid:
uF'(u) > F(u).

Therefore the second term in square brackets is positive and goes to infinity when oy,, goes
to infinity.
