SUPPORT-VECTOR NETWORKS 289

4 4 8 5

Figure 7. Vabeled examples of errors on the training set for the 2nd degree polynomial support-vector classifier.

The training time for construction of polynomial classifiers does not depend on the de-
gree of the polynomial—only the number of support vectors. Even in the worst case it is
faster than the best performing neural network, constructed specially for the task, LeNet1
(LeCun, et al., 1990). The performance of this neural network is 5.1% raw error. Polyno-
mials with degree 2 or higher outperform LeNet1.

6.2.2. Experiments with the NIST Database. The NIST database was used for benchmark
studies conducted over just 2 weeks. The limited time frame enabled only the construction
of 1 type of classifier, for which we chose a 4th degree polynomial with no pre-processing.
Our choice was based on our experience with the US Postal database.

Table 3 lists the number of support vectors for each of the 10 classifiers and gives the
performance of the classifier on the training and test sets. Notice that even polynomials
of degree 4 (that have more than 10° free parameters) commit errors on this training set.
The average frequency of training errors is 0.02% ~ 12 per class. The 14 misclassified test
patterns for classifier 1 are shown in Fig. 8. Notice again how the upper bound (5) holds
for the obtained number of support vectors.

The combined performance of the ten classifiers on the test set is 1.1% error. This result
should be compared to that of other participating classifiers in the benchmark study. These
other classifiers include a linear classifier, a k = 3-nearest neighbor classifier with 60,000
prototypes, and two neural networks specially constructed for digit recognition (LeNet1
and LeNet4). The authors only contributed with results for support-vector networks. The
results of the benchmark are given in Fig. 9.

We conclude this section by citing the paper (Bottou, et al., 1994) describing results of
the benchmark:

For quite a long time LeNet1 was considered state of the art.... Through a series
of experiments in architecture, combined with an analysis of the characteristics of
recognition error, LeNet4 was crafted. ...

The support-vector network has excellent accuracy, which is most remarkable, be-
cause unlike the other high performance classifiers, it does not include knowledge

Table 3. Results obtained for a 4th degree polynomial classifier on the NIST database. The size of the training
set is 60,000, and the size of the test set is 10,000 patterns.

CLO Cli cL.2 ch3 C4 ch5 Cl6 chy cs cs

Supp. patt. 1379 989 1958 1900 1224 2024 1527 2064 2332 2765
Error train 7 16 8 11 2 4 8 16 4 1
Error test 19 14 35 35 36 49 32 4B 48 63

