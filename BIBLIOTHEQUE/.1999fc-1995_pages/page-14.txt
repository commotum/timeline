SUPPORT-VECTOR NETWORKS 287

7 4 7

Figure 6. Examples of patterns with labels from the US Postal Service digit database.

bullets. In the figure we indicate support patterns with a double circle, and errors with a
cross. The solutions are optimal in the sense that no 2nd degree polynomials exist that make
less errors. Notice that the numbers of support patterns relative to the number of training
patterns are small.

6.2. Experiments with Digit Recognition

Our experiments for constructing support-vector networks make use of two different data-
bases for bit-mapped digit recognition, a small and a large database. The small one is a US
Postal Service database that contains 7,300 training patterns and 2,000 test patterns. The
resolution of the database is 16 x 16 pixels, and some typical examples are shown in Fig. 6.
On this database we report experimental research with polynomials of various degree.

The large database consists of 60,000 training and 10,000 test patterns, and is a 50-50
mixture of the NISTâ€™ training and test sets. The resolution of these patterns is 28 x 28
yielding an input dimensionality of 784. On this database we have only constructed a 4th
degree polynomial classifier. The performance of this classifier is compared to other types
of learning machines that took part in a benchmark study (Bottou, 1994).

In all our experiments ten separators, one for each class, are constructed. Each hyper-
surface makes use of the same dot product and pre-processing of the data. Classification of
an unknown patterns is done according to the maximum output of these ten classifiers.

6.2.1. Experiments with US Postal Service Database. The US Postal Service Database
has been recorded from actual mail pieces and results from this database have been reported
by several researchers. In Table 1 we list the performance of various classifiers collected

Table I, Performance of various classifiers collected from publications and own experiments. For references
see text.

Classifier Raw error, %
Human performance 2.5
Decision tree, CART 17
Decision tree, C4.5 16

Best 2 layer neural network 6.6

Special architecture 5 layer network 5.1

