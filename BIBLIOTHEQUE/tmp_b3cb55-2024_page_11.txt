                                             Initial Fine-Tune   Secondary Fine-Tune
                                                  Locally        Locally   On Kaggle
                         Batch size                  4              2           2
                         Gradient acc. steps         2              2           2
                         LoRA rank                  256            64          64
                         LoRA α                      24            16          16
                         LR(LoRAadapters)           1e−4          1e−4        1e−4
                         LR(embeddings)             1e−5          1e−5        1e−5
                         Number of Epochs        see Table 3       48          32
                         LRschedule                cosine         cosine     cosine
                         LRwarmup phase             25%           25%       100 steps
                         Weight decay                off           off        0.01
                         Model quantization         4 bit         4 bit       4 bit
                         Train on 1st output         no            yes         yes
                      Table 4: Training parameters for initial as well as secondary fine-tuining. Parameters for
                      Kaggle were chosen differently due to time and memory constraints.
                      While this can achieve good results, we found both sampling strategies to be
                      sub-optimal for generating correct solutions to a given task. We attribute
                      these shortcomings to several reasons:
                      Greedy Sampling: Greedy sampling is straightforward but presents two
                      major issues. First, it offers no guarantees regarding the final sampling prob-
                      ability of the generated solution. It is entirely possible for greedy sampling to
                      produce a solution with very low overall probability: a single high-confidence
                      mistake by the LLM can lead to an undesirable sequence, thereby preventing
                      a successful continuation. Second, greedy sampling inherently lacks variabil-
                      ity, yielding only a single result for a given input.
                      Stochasic Sampling: Standard stochastic sampling techniques introduce
                      more variability but can also repeatedly return the same solution. Moreover,
                      we have no guarantee that the best solution is sampled. If the optimal solu-
                      tion has, for example, a 10% sampling probability, we may need to sample
                      excessively to generate this specific solution. Given that inference is partic-
                      ularly slow – especially for longer tasks – this approach can quickly become
                      computationally prohibitive, even more so within the limitations of a Kaggle
                      notebook.
                      While there are several alternative sampling schemes, such as sampling with
                      temperature or beam search, we found that a custom sampling algorithm
                      produced the best results for the benchmark:
                      Weemployadepth-firstsearch(DFS)toexploreallpossiblepathsthrough
                                                      11
