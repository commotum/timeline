# The Art of Scaling Test-Time Compute for Large Language Models (2025)
Source: cf6028-2025.pdf

## Core reasons
- The paper positions its contribution as a large-scale empirical study of test-time scaling strategies across many models and datasets, emphasizing measurement rather than a new architecture.
- It evaluates models on established reasoning benchmarks (AIME and GPQA Diamond), underscoring benchmark-based assessment as the core contribution.

## Evidence extracts
- "these gaps, we conduct the first large-scale study of TTS, spanning over
thirty billion tokens generated using eight open-source LLMs (7B to 235B
parameters), across four reasoning datasets. We observe three consistent" (p. 1)
- "We evaluate models on two complementary reasoning benchmarks—AIME and GPQA
Diamond—whichtogether cover both symbolic-numerical and conceptual reasoning do-
mains." (p. 4)

## Classification
Class name: Data, Benchmarks & Measurement
Class code: 4

$$
\boxed{4}
$$
