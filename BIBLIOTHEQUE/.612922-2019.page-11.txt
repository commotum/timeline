                  Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish    MinJoon Seo, Aniruddha Kembhavi, Ali Farhadi, and
                    Sabharwal. 2018. Can a suit of armor conduct elec-      Hannaneh Hajishirzi. 2017. Bidirectional attention
                    tricity? a new dataset for open bookquestionanswer-     ﬂowformachinecomprehension. ICLR.
                    ing. In EMNLP.                                        Gabriel Stanovsky, Julian Michael, Luke S. Zettle-
                  Pasquale Minervini and Sebastian Riedel. 2018. Ad-        moyer, and Ido Dagan. 2018. Supervised open in-
                    versarially regularising neural nli models to integrate formation extraction. In NAACL-HLT.
                    logical background knowledge. In CoNLL.                      ˇ
                                                                          Simon Suster and Walter Daelemans. 2018. Clicr: a
                  Bhavana Dalvi Mishra, Lifu Huang, Niket Tandon,           dataset of clinical case reports for machine reading
                    Wen-tau Yih, and Peter Clark. 2018. Tracking state      comprehension.
                    changes in procedural text: A challenge dataset and   Alon Talmor and Jonathan Berant. 2018. The web as
                    models for process paragraph comprehension.             a knowledge-base for answering complex questions.
                  Arvind Neelakantan, Quoc V. Le, and Ilya Sutskever.       In NAACL-HLT.
                    2016.   Neural programmer: Inducing latent pro-       Johannes Welbl, Pontus Stenetorp, and Sebastian
                    grams with gradient descent. ICLR.                      Riedel. 2018. Constructing datasets for multi-hop
                  SimonOstermann, Ashutosh Modi, Michael Roth, Ste-         reading comprehension across documents.     TACL,
                    fan Thater, and Manfred Pinkal. 2018. Mcscript: a       6:287–302.
                    novel dataset for assessing machine comprehension     Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-
                    using script knowledge. LREC Proceedings, 2018.         gio, William W. Cohen, Ruslan Salakhutdinov, and
                  AnusriPampari,PreethiRaghavan,JenniferLiang,and           ChristopherD.Manning.2018. Hotpotqa: Adataset
                    Jian Peng. 2018. emrqa: A large corpus for question     for diverse, explainable multi-hop question answer-
                    answering on electronic medical records.                ing. In EMNLP.
                                       ´                                  PengchengYinandGrahamNeubig.2017. Asyntactic
                  Denis Paperno, German Kruszewski, Angeliki Lazari-        neural model for general-purpose code generation.
                    dou, Quan Ngoc Pham, Raffaella Bernardi, San-           In ACL’17.
                    dro Pezzelle, Marco Baroni, Gemma Boleda, and
                                 ´
                    Raquel Fernandez. 2016.      The lambada dataset:     AdamsWeiYu,DavidDohan,Minh-ThangLuong,Rui
                    Wordprediction requiring a broad discourse context.     Zhao, Kai Chen, Mohammad Norouzi, and Quoc V.
                    ACL.                                                    Le. 2018.    Qanet: Combining local convolution
                  Panupong Pasupat and Percy Liang. 2015. Composi-          with global self-attention for reading comprehen-
                    tional semantic parsing on semi-structured tables. In   sion. ICLR.
                    ACL.                                                  John M. Zelle and Raymond J. Mooney. 1996. Learn-
                  Jeffrey Pennington, RichardSocher, andChristopherD.       ing to parse database queries using inductive logic
                    Manning.2014. Glove: Globalvectorsforwordrep-           programming. In AAAI/IAAI, Vol. 2.
                    resentation. In EMNLP.                                Rowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin
                  Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt        Choi. 2019. From recognition to cognition: Visual
                    Gardner, Christopher Clark, Kenton Lee, and Luke        commonsensereasoning. CVPR, abs/1811.10830.
                    Zettlemoyer. 2018. Deep contextualized word repre-    RowanZellers,YonatanBisk,RoySchwartz,andYejin
                    sentations. In NAACL-HLT.                               Choi. 2018. Swag: A large-scale adversarial dataset
                  Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.       for grounded commonsense inference. In EMNLP.
                    Know what you don’t know: Unanswerable ques-          LukeS.ZettlemoyerandMichaelCollins.2005. Learn-
                    tions for squad. In ACL.                                ing to map sentences to logical form: Structured
                  PranavRajpurkar,JianZhang,KonstantinLopyrev,and           classiﬁcation with probabilistic categorial grammars.
                    Percy Liang. 2016. Squad: 100, 000+ questions for       In UAI.
                    machine comprehension of text. In EMNLP.              Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng
                  Siva Reddy, Danqi Chen, and Christopher D. Manning.       Gao, Kevin Duh, and Benjamin Van Durme. 2019.
                    2019. Coqa: A conversational question answering         ReCoRD:Bridgingthegapbetweenhumanandma-
                    challenge. TACL.                                        chine commonsense reading comprehension.
                  Scott E. Reed and Nando de Freitas. 2016.    Neural
                    programmer-interpreters. ICLR.
                  Amrita Saha, Rahul Aralikatte, Mitesh M. Khapra, and
                    Karthik Sankaranarayanan. 2018. Duorc: Towards
                    complex language understanding with paraphrased
                    reading comprehension. In ACL.
                                                                     2378
