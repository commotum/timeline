# Self-Consistency Improves Chain of Thought Reasoning in Language Models (2023)
Source: 8b8cf9-2022.pdf

## Core reasons
- Introduces a new inference-time decoding strategy (self-consistency) to improve reasoning over chain-of-thought, replacing greedy decoding.
- Proposes a computation mechanism that samples multiple reasoning paths and aggregates answers by marginalizing for consistency.

## Evidence extracts
- "In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting." (p. 1)
- "Finally, we aggregate the answers by marginalizing out the sampled reasoning paths and choosing the answer that is the most consistent among the generated answers." (p. 3)

## Classification
Class name: Computation & Reasoning Mechanism Proposal
Class code: 3

$$
\boxed{3}
$$
