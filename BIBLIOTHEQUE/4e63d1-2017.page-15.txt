                    D KmaxGradientApproximation
                    NTPsallowustocalculate the gradient of proof success scores with respect to subsymbolic repre-
                    sentations and rule parameters. While backpropagating through this large computation graph will
                    give us the exact gradient, it is computationally infeasible for any reasonably-sized KB. Consider
                    the parameterized rule θ1:(X,Y) :– θ2:(X,Z),θ3:(Z,Y) and let us assume the given KB contains
                    1 000 facts with binary predicates. While X and Y will be bound to the respective representations
                    in the goal, Z we will be substituted with every possible second argument of the 1 000 facts in the
                    KBwhenprovingtheﬁrstatominthebody. Moreover, for each of these 1 000 substitutions, we will
                    again need to compare with all facts in the KB when proving the second atom in the body of the rule,
                    resulting in 1 000 000 proof success scores. However, note that since we use the max operator for
                    aggregating the success of different proofs, only subsymbolic representations in one out of 1 000 000
                    proofs will receive gradients.
                    Toovercomethis computational limitation, we propose the following heuristic. We assume that when
                    unifying the ﬁrst atom with facts in the KB, it is unlikely for any uniﬁcation successes below the top
                    Ksuccesses to attain the maximum proof success when unifying the remaining atoms in the body of
                    a rule with facts in the KB. That is, after the uniﬁcation of the ﬁrst atom, we only keep the top K
                    substitutions and their success scores, and continue proving only with these. This means that all other
                    partial proofs will not contribute to the forward pass at this stage, and consequently not receive any
                    gradients on the backward pass of backpropagation. We term this the K max heuristic. Note that we
                    cannot guarantee anymore that the gradient of the proof success is the exact gradient, but for a large
                    enough K wegetaclose approximation to the true gradient.
                    E TrainingDetails
                    WeuseADAM[67]withaninitiallearningrateof0.001andamini-batch size of 50 (10 known and
                    40corrupted atoms) for optimization. We apply an ` regularization of 0.01 to all model parameters,
                                                          2
                    and clip gradient values at [−1.0,1.0]. All subsymbolic representations and rule parameters are
                    initialized using Xavier initialization [68]. We train all models for 100 epochs and repeat every
                    experiment on the Countries corpus ten times. Statistical signiﬁcance is tested using the independent
                    t-test. All models are implemented in TensorFlow [69]. We use a maximum proof depth of d = 2
                    and add the following rule templates where the number in front of the rule template indicates how
                    often a parameterized rule of the given structure will be instantiated. Note that a rule template such
                    as #1(X,Y):–#2(X,Z),#2(Z,Y)speciﬁesthatthetwopredicaterepresentations in the body are
                    shared.
                    Countries S1
                    3 #1(X,Y):–#1(Y,X).
                    3 #1(X,Y):–#2(X,Z),#2(Z,Y).
                    Countries S2
                    3 #1(X,Y):–#1(Y,X).
                    3 #1(X,Y):–#2(X,Z),#2(Z,Y).
                    3 #1(X,Y):–#2(X,Z),#3(Z,Y).
                    Countries S3
                    3 #1(X,Y):–#1(Y,X).
                    3 #1(X,Y):–#2(X,Z),#2(Z,Y).
                    3 #1(X,Y):–#2(X,Z),#3(Z,Y).
                    3 #1(X,Y):–#2(X,Z),#3(Z,W),#4(W,Y).
                    Kinship, Nations & UMLS
                    20#1(X,Y):–#2(X,Y).
                    20#1(X,Y):–#2(Y,X).
                    20#1(X,Y):–#2(X,Z),#3(Z,Y).
                                                        15
