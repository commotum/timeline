                                     Cosine Similarity(Ì†µÌ≤ÑÌ†µÌ≤çÌ†µÌ≤î_Ì†µÌ≤ïÌ†µÌ≤êÌ†µÌ≤åÌ†µÌ≤ÜÌ†µÌ≤è        ,  Ì†µÌ≤ÑÌ†µÌ≤çÌ†µÌ≤î_Ì†µÌ≤ïÌ†µÌ≤êÌ†µÌ≤åÌ†µÌ≤ÜÌ†µÌ≤è  )         Cosine Similarity(Ì†µÌ≤ÇÌ†µÌ≤óÌ†µÌ≤à_Ì†µÌ≤ïÌ†µÌ≤êÌ†µÌ≤åÌ†µÌ≤ÜÌ†µÌ≤è          ,  Ì†µÌ≤ÇÌ†µÌ≤óÌ†µÌ≤à_Ì†µÌ≤ïÌ†µÌ≤êÌ†µÌ≤åÌ†µÌ≤ÜÌ†µÌ≤è   )       Cosine Similarity(Ì†µÌ≤ÇÌ†µÌ≤óÌ†µÌ≤à_Ì†µÌ≤ïÌ†µÌ≤êÌ†µÌ≤åÌ†µÌ≤ÜÌ†µÌ≤è         ,  Ì†µÌ≤ÇÌ†µÌ≤óÌ†µÌ≤à_Ì†µÌ≤ïÌ†µÌ≤êÌ†µÌ≤åÌ†µÌ≤ÜÌ†µÌ≤è    )  
                                                                         Ì†µÌ≤ÉÌ†µÌ≤ÜÌ†µÌ≤áÌ†µÌ≤êÌ†µÌ≤ìÌ†µÌ≤Ü           Ì†µÌ≤ÇÌ†µÌ≤áÌ†µÌ≤ïÌ†µÌ≤ÜÌ†µÌ≤ì
                                                                = 0.4597                                                                             Ì†µÌ≤ÉÌ†µÌ≤ÜÌ†µÌ≤áÌ†µÌ≤êÌ†µÌ≤ìÌ†µÌ≤Ü             Ì†µÌ≤ÇÌ†µÌ≤áÌ†µÌ≤ïÌ†µÌ≤ÜÌ†µÌ≤ì                                         Ì†µÌ≤ÉÌ†µÌ≤ÜÌ†µÌ≤áÌ†µÌ≤êÌ†µÌ≤ìÌ†µÌ≤Ü             Ì†µÌ≤ÇÌ†µÌ≤áÌ†µÌ≤ïÌ†µÌ≤ÜÌ†µÌ≤ì
                                                                                                                                            = 0.2995                                                                   = 0.5168
                            cls_token
                                                   (a) PVG (class_token)                                                            (b) PVG (GAP)                                                                       (c) MPVG
                          Figure6:Heatmaps(averagedoverthebatchsize),betaandgammavaluesintheLastLN,andcosinesimilarityforeachmethod.
                          (a) represents the PVG using the class token. The cosine similarity refers to the similarity of the class token before and after the
                          Last LN. (b) represents the PVG using GAP. The cosine similarity refers to the similarity of the token averages in the heatmaps
                          before and after the Last LN. (c) represents the MPVG. The cosine similarity refers to the similarity of the token averages in
                          the heatmaps before and after the Last LN.
                                                                      Appendix                                                                              As shown in Fig 7, MPVG captures objects more effec-
                          ADetailedAnalysis of PE in the Last LN                                                                                       tively than PVG, even when comparing the same samples
                                                                                                                                                       before and after the Last LN. This demonstrates that PE in
                          We provide a detailed analysis of the role of position em-                                                                   the Last LN maintains the counterbalancing directionality in
                          bedding (PE) in the Last LN (LN means Layer Normaliza-                                                                       a Layer-wise structure. The Last LN‚Äôs role is alleviated by
                          tion (Ba, Kiros, and Hinton 2016)). As shown in Fig 6, (b)                                                                   sustaining this directionality, enabling a richer and more ac-
                          visualizes the gamma and beta values, which are the affine                                                                   curate understanding of the objects.
                          parameters of the Last LN, in PVG where PE is not deliv-                                                                     Analysis on Conflicting Results Between Class
                          ered to the Last LN. In (c), the gamma and beta values of the                                                                token and GAP
                          Last LN are visualized in MPVG, where PE is delivered to
                          the Last LN.                                                                                                                 In general, when the GAP method, which performs bet-
                               In PVG, upon examining the beta affine parameter, we                                                                    ter than the class token method in image classification, is
                          find that the variance of beta is 0.2387, indicating signifi-                                                                combined with the Layer-wise method, which improves the
                          cant variability. Specifically, we observe that the beta value                                                               expressiveness of PE and enhances the performance of vi-
                          counterbalances the high-value dimensions present before                                                                     sion transformers, it leads to a decrease in performance. As
                          the Last LN. In contrast, in MPVG, where PE is delivered to                                                                  we discussed, applying the GAP method in the Layer-wise
                          the Last LN, the variance of beta is much smaller at 0.0193                                                                  structure results in a conflicting result, leading to a perfor-
                          compared to PVG. This suggests that, in MPVG, the values                                                                     mancedecline.
                          beforetheLastLNarecounterbalancednotbythebetavalue                                                                                To analyze the cause, we examine the gamma and beta
                          but by the PE.                                                                                                               values of Layer Normalization (LN) in the Last LN and the
                               In conclusion, the advantage of using PE to eliminate                                                                   cosine similarity before and after the Last LN. As shown in
                          high-valuedimensionsinMPVG,ratherthanrelyingonbeta                                                                           Figure 1, (a) represents PVG with the class token method,
                          as in PVG, is as follows. In a Layer-wise structure, PE                                                                      while (b) represents PVG with the GAP method. We ob-
                          causes high-value dimensions to become more pronounced                                                                       servedthatthevarianceofthebetavalue,anaffineparameter
                          across dimensions. This suggests that PE counterbalances                                                                     in the Last LN, is lower in (a) compared to (b). Additionally,
                          these high-value dimensions, taking over the role of LN in                                                                   when observing the heatmaps before and after the Last LN,
                          removing high-value dimensions. This phenomenon results                                                                      we noticed that there are no significant changes apart from
                          in the token embedding (x) retaining values that should have                                                                 the 0th row representing the class token. This suggests that
                          been counterbalanced by PE, even after passing through the                                                                   the Last LN primarily focuses on the class token in the class
                          layers. Compensating for these values using PE, rather than                                                                  token method.
                          relying solely on LN‚Äôs beta, allows for more accurate coun-                                                                       Specifically, when comparing the cosine similarity of (a)
                          terbalancing, leading to fewer lost features compared to us-                                                                 and(b),(a)showsavalueof0.4597,while(b)showsavalue
                          ing LN alone to remove high-value dimensions. This sug-                                                                      of 0.2995. The high cosine similarity in (a) and the low vari-
                          gests that, in the conventional Layer-wise structure, high-                                                                  ance of beta indicate that, in the Layer-wise structure of the
                          values dimensions in the Last LN were counterbalanced us-                                                                    class token method, the Last LN has less of a role in remov-
                          ing only LN. However, more accurate features can be pre-                                                                     ing high-value dimensions compared to the GAP method.
                          served by using PE to counterbalance these values.                                                                           On the other hand, the lower cosine similarity and higher
