                             [14]  ChuanLi.Llama-3.2-3B-Instruct-uncensored.Accessed:2024-11-11.2024.
                                   url:https://huggingface.co/chuanli11/Llama-3.2-3B-Instruct-
                                   uncensored.
                             [15]  Yuren Mao et al. “A Survey on LoRA of Large Language Models”. In:
                                   CoRR abs/2407.11046 (2024). doi: 10.48550/ARXIV.2407.11046.
                                   arXiv: 2407.11046. url: https://doi.org/10.48550/arXiv.2407.
                                   11046.
                             [16]  Nelson F. Liu et al. “Lost in the Middle: How Language Models Use
                                   LongContexts”.In:Trans. Assoc. Comput. Linguistics 12(2024),pp.157–
                                   173. doi: 10.1162/TACL\_A\_00638. url: https://doi.org/10.
                                   1162/tacl%5C_a%5C_00638.
                             [17]  Aaditya K. Singh and DJ Strouse. “Tokenization counts: the impact of
                                   tokenization on arithmetic in frontier LLMs”. In: CoRR abs/2402.14903
                                   (2024). doi: 10.48550/ARXIV.2402.14903. arXiv: 2402.14903. url:
                                   https://doi.org/10.48550/arXiv.2402.14903.
                             [18]  Edward J. Hu et al. LoRA: Low-Rank Adaptation of Large Language
                                   Models. 2021. arXiv: 2106.09685 [cs.CL]. url: https://arxiv.org/
                                   abs/2106.09685.
                             [19]  Daniel Franzen and Jan Disselhoff. Llama-3.2-3B-ARChitects-ReArc-
                                   bnb-4bit. 2024. url: https://huggingface.co/da-fr/Llama-3.2-
                                   3B-ARChitects-ReArc-bnb-4bit.
                             [20]  DanielFranzenandJanDisselhoff.Mistral-NeMo-Minitron-8B-ARChitects-
                                   Full-bnb-4bit. 2024. url: https://huggingface.co/da-fr/Mistral-
                                   NeMo-Minitron-8B-ARChitects-Full-bnb-4bit.
                                                                      17
