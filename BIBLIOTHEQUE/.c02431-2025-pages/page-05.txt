          APreprint.
          Figure 2: Hierarchy of 22 unique visual reasoning patterns used in compositional task solving. Each pattern is repre-
          sented as a block containing its description and parameters, with the block width reflecting the number of parameters.
          Patterns are organized under the top-level category ‘Visual Reasoning Patterns’ to highlight their structure and rela-
          tionships.
             exceeding API limits.
            • Instruction generation – For each Step in a RunConfig, get instruction scores prompts an LLM
             (defined by step.instruction model) with the training grids via src/main.py. Each response is
             scored by leave-one-out cross validation, which is another LLM call that follows the instructions.
            • Scoring – The score instructions on challenge function records per-example results, calculates a
             simple cell-wise similarity score, writes attempts to Postgres if NEON DSN is set, and keeps the top instructions
             in memory.
            • Revision and pooling – StepRevision asks the model to repair its own instructions using a rich feedback
             prompt that highlights wrong outputs. StepRevisionPool synthesizes a new plan from the best previous
             instructions and their scores. Both feed back into the scoring loop.
            • Finalpredictions–return answerreplaysthestrongestinstructionswithfinal follow modeltogen-
             erate multiple outputs per test grid. If ground-truth solutions are supplied, evaluate solutions computes
             accuracy; otherwise the guesses are ready for competition submission.
          3  OurApproach: ARC-AGICompositionalReasoning
          Weproposeafour-stageneuro-symbolic(NS)pipelinethatintegrates deterministic symbolic perception with neurally
          guidedreasoningandgeneration. Ourapproachisfoundedontheprincipleofdecomposition: weseparatetheproblem
          of ”what” is in the grid (perception) from ”how” it transforms (reasoning).
            This pipeline, depicted in Figure 1, systematically processes each ARC task:
            1. Symbolic Object Detection: Converts the raw N × M pixel grids into a structured scene graph of symbolic
             objects and their properties.
            2. Neural-Guided Hypothesis Generation: Uses a small and efficient neural model (o4-mini) to scan training
             pairs and propose a set of matching transformations, complete with parameters, from a 22-pattern library.
            3. Symbolic Rule Intersection: Apply logical intersection and synthesis to the hypotheses to find a single, con-
             sistent rule program that explains all training examples.
            4. ConstrainedLLMSolving: Feedstheoriginaltaskplusthesynthesizedrule(asa”SymbolicHint”)intoGrok-
             4, using self-consistency to generate a robust final answer.
            This decomposition enables both interpretable intermediate representations and robust final predictions. It is im-
          portant to note that this solution is highly specialized for the ARC-AGI benchmark and is not intended as a general-
          purpose reasoning system; its design choices, such as the 22-pattern library, are specifically tailored to succeed in the
          ARC-AGIcompetition.
