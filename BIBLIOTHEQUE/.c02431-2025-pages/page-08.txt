                   APreprint.
                   4    Meta-Classifier for Candidate Solution Selection
                   To generate a pool of potential solutions, we first employed two distinct methodologies. We utilized CoreThink’s
                   ARC-AGICompositional Reasoning framework to generate two candidate solutions. Concurrently, we used the ARC
                   Lang Solvertoproduceanadditionaltwocandidatesolutions.
                       With a total of four candidates, we then developed a meta-classifier using Grok 4. The purpose of this classifier
                   is to select the optimal two solutions from the set of four. This aligns with the ARC-AGI-2 evaluation metric, which
                   is pass@2.
                       To train the meta-classifier, we provided it with examples to demonstrate the characteristics of a correct solution.
                   Akeyconstraint for the classifier’s output is that the return format must be enclosed in double asterisks (   ... )
                                                                                                                              **     **
                   to allow for easy location and extraction of the final selected solutions.
                   5    Results
                   Weevaluate our neuro-symbolic flow on the ARC-AGI-2 benchmark and compare its performance against both pure
                   neural approaches and competing hybrid systems. Table 1 presents results on the official leaderboard as of October
                   26, 2025, positioning our method relative to state-of-the-art language models and other neuro-symbolic architectures.
                                                     Team/AISystem                          Score (%)
                                                     HumanPanel                                100.0
                                                     CoreThink Meta-Classifier                  30.8
                                                     J. Berman                                  29.4
                                                     NVARC                                      27.6
                                                     CoreThink Compositional Reasoner           24.4
                                                     GPT-5-Pro                                  18.3
                                                     Grok-4 (Thinking)                          16.0
                                                     Claude Opus 4 (16K)                        8.6
                                                     o3(High)                                   6.5
                                                     o4-mini (High)                             6.1
                                                     Claude Sonnet 4 (16K)                      5.9
                                                     o3-Pro (High)                              4.9
                                                     Gemini 2.5 Pro (32K)                       4.9
                   Table1: ARC-AGI-2leaderboardcomparisonasofNovember03,2025. Ourneuro-symbolicflowachievesthehighest
                   score among all systems, demonstrating the effectiveness of combining symbolic reasoning with neural generation.
                       Our Compositional Reasoner achieves a score of 24.4% on the ARC-AGI-2 benchmark, placing us in the top 3
                   submissions using proprietary models, and our Meta-Classifier achieves as score of 30.8%, establishing a new state-
                   of-the-art performance and surpassing all competing approaches. This represents an 8 percentage point improvement
                   over Grok-4 with extended thinking. Notably, our approach substantially outperforms all frontier language models in
                   their standard configurations, including Claude Opus 4[6], OpenAI’s o3 series, and Gemini 2.5 Pro[9], despite these
                   models having significantly larger parameter counts and longer context windows.
                       The performance gap between our method and pure LLM approaches highlights the fundamental limitations of
                   end-to-end neural reasoning on tasks requiring systematic generalization. While models like Grok-4 and Claude Opus
                   4 possess strong pattern recognition capabilities, they struggle to consistently apply compositional transformation
                   rules across diverse visual reasoning scenarios. Our symbolic intermediate representations enable more reliable rule
                   extraction and application, reducing the brittleness observed in purely neural solutions.
                       Comparedtootherneuro-symboliccompetitors, our four-stage pipeline’s explicit separation of perception, pattern
                   detection, constraint synthesis, and ensemble generation appears to provide stronger inductive biases. The determinis-
                   tic object detection stage eliminates perceptual ambiguity early in the pipeline, while the atomic transformation library
                   constrains the hypothesis space to compositionally interpretable operations. The self-consistency mechanism in our
                   final stage further improves robustness by aggregating multiple solution attempts, mitigating the stochastic errors
                   inherent in LLM generation.
