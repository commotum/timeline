                   APreprint.
                   tasks that are specifically designed to resist brute-force search methods and solution memorization strategies. This
                   evolution of the benchmark continues to serve as a critical testbed for measuring progress toward artificial general
                   intelligence, particularly in assessing whether systems can demonstrate genuine understanding rather than statistical
                   pattern matching.
                      ApproachestriedonARC-AGIhavelargelyinvolveddiscreteprogramsearchandtheuseoflargelanguagemodels
                   (LLMs)fine-tunedspecificallyonARC-AGItasks,oftenaugmentedwithsyntheticallygenerateddatatoovercomethe
                   limited number of official tasks. Active inference techniques, where the LLM is fine-tuned in real-time on demonstra-
                   tion examples, have unlocked significant performance improvements, as demonstrated by some of the top individual
                   submissions scoring up to 76% [10]. However, progress remains challenging due to the difficulty of tasks designed to
                   resist brute force methods, and the next promising direction is to combine discrete program search with deep learning-
                   driven intuition to better capture general reasoning abilities.
                      Building on the challenges posed by ARC-AGI-2, a variety of methodological approaches can be employed to
                   tackle the benchmark [12]. These include hybrid neuro-symbolic systems that combine perceptual learning with
                   explicit rule-based reasoning, enabling the discovery of underlying abstract transformations from minimal examples.
                   Generative models, particularly transformer-based architectures, can be leveraged to predict output grids by learning
                   patterns across input-output pairs, while attention mechanisms allow the models to focus on relevant substructures
                   and relationships. Reinforcement learning approaches may also be applied, framing task completion as a sequential
                   decision problem where actions correspond to manipulations on the grid. Furthermore, combinatorial search strategies
                   guided by domain-specific heuristics can systematically explore possible transformations while avoiding brute-force
                   enumeration, aligning with ARC-AGI-2’s emphasis on compositionality and hierarchical abstraction. Importantly,
                   successful strategies often integrate multiple paradigms—neural, symbolic, and search-based—to capture both the
                   low-level visual regularities and the high-level abstract rules that characterize ARC-AGI-2 tasks, ensuring solutions
                   generalize beyond simple pattern memorization [12].
                   2.2.1  Description Of The Test Cases
                   ARC-AGI-2, introduced in mid-2025, builds on the original by enhancing task depth and preserving the “easy for
                   humans, hard for AI” philosophy. It comprises:
                         • 1,000 public training tasks providing core knowledge priors.
                         • 120 public evaluation tasks solvable by at least two humans under identical constraints.
                         • Private test sets curated for blind benchmarking in competitions.
                      Humanparticipantsaverage 2.3minutespertask,achievingnear-perfectperformance,whileAIsystems—including
                   frontier LLMs—score in the single-digit percentages.
                   2.2.2  KeyImprovementsOverARC-AGI-1
                         • Greater rule complexity: tasks require symbolic interpretation and multi-step reasoning.
                         • Higher granularity: tasks span a broader range of difficulty and human–AI performance gaps.
                         • Human-validated quality: all tasks are empirically verified as solvable by humans.
                   2.2.3  Challenges of Grid Scale
                   Gridsupto20×20cellsincreasecombinatorialsearchspaceandprecisiondemands. Brute-forceenumerationbecomes
                   infeasible, requiring object-based symbolic abstractions.
                   2.3   Neurosymbolic Systems
                   Neurosymbolic AI represents a paradigm that seeks to combine the strengths of neural networks and symbolic rea-
                   soning systems [2, 4]. This approach acknowledges that while deep learning excels at perception, pattern recognition,
                   and learning from raw data, symbolic systems provide interpretability, logical reasoning, and the ability to work with
                   explicit knowledge representations. Neurosymbolic architectures integrate these complementary capabilities through
