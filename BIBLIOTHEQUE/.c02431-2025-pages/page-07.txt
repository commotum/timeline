               APreprint.
                         "collision_map": "horizontal bar"
                         }
                    }
                  After collecting 10 such outputs, we perform an intersection on the detected patterns to find the most stable
               hypotheses. This produces a ranked list of the top 3 most consistently detected patterns for that single sub-question.
               3.3  Stage 3: Pattern Intersection and Constraint Formation
               Thethirdstagesynthesizesasingle,coherentrulesetfromthelistsofhypothesesgeneratedinStage2. Akeychallenge
               in ARC is that a rule must apply to all sub-questions within a task. This stage finds the ”program” that consistently
               explains every sub-question.
                  Thisprocessextendstheintersectionapproachhierarchically. Stage 2 provides a list of the top 3 candidate patterns
               for each individual sub-question (using SC=10). In Stage 3, we perform a final set intersection across these top-3
               lists to find the patterns common to all sub-questions in the task.
                  For example, for a task with k = 3 sub-questions:
                    • Sub-Question1Top3(fromSC=10): {"Cavity Fill","Symmetry-Based Pattern","Horizontal
                      Fill"}
                    • Sub-Question2Top3(fromSC=10): {"Cavity Fill","Symmetry-Based Pattern","Remove
                      Objects..."}
                    • Sub-Question3Top3(fromSC=10): {"Cavity Fill","Symmetry-Based Pattern","Vertical
                      Fill"}
                    • Task-Level Intersection: {"Cavity Fill", "Symmetry-Based Pattern"}
                  This hierarchical intersection robustly identifies a small set of high-probability rules that are valid across the entire
               task. From this final set (here, {"Cavity Fill", "Symmetry-Based Pattern"}), we select the top 3 (or
               fewer) patterns to form the final hint. This ensures that the generated hint captures the complete logic, even if it is
               compositional.
                  The final output is a compact, human-readable ”Symbolic Hint” string. This hint is the critical piece of prior
               knowledge for the final solving stage.
               3.4  Stage 4: LLMSolving with Self-Consistency
               In the final stage, we leverage Grok-4, not as a pure end-to-end reasoner, but as a constrained generative model guided
               byoursymbolicpipeline.
                  Weconstruct a detailed prompt containing:
                 1. All training input/output grid pairs.
                 2. The full test input grid.
                 3. The Symbolic Hint string generated in Stage 3.
                  Thepromptexplicitly instructs Grok-4 to: ”Use the provided symbolic hint to formulate a step-by-step plan. This
               hint is believed to be the correct logic. Apply this plan to the test input grid. Output only the final solved grid in the
               specified format.”
                  This approach anchors the LLM’s reasoning, preventing it from hallucinating incorrect patterns or getting dis-
               tractedbysuperficialfeatures. Ratherthanrelyingonasingle,greedy-decodedoutput,weimplementaself-consistency
               mechanism to improve robustness. We query the model N = 5 times to generate a small ensemble of candidate solu-
               tions.
                  Wethenapplyapixel-wisemajority vote across the 5 candidate grids. For each cell (i,j), we tally the 5 proposed
               colors and select the most frequent one. In our analysis of solved tasks, we found that typically 3-4 of the 5 samples
               werepixel-identical, withthemajorityvoteeffectivelyfilteringoutminorgenerativenoisefromtheremainingsamples.
               This ensemble approach combines Grok-4’s powerful pattern application capabilities with the stabilizing effect of
               democratic aggregation, yielding a final prediction far more reliable than any single model invocation.
