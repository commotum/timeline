                APreprint.
                   Despite achieving state-of-the-art performance among AI systems, our approach still falls considerably short of
                human-level accuracy at 100%. This substantial gap underscores that abstract visual reasoning remains an open chal-
                lenge, requiring further innovations in both symbolic abstraction mechanisms and neural-symbolic integration strate-
                gies. Future work may explore richer transformation primitives, more sophisticated constraint solvers, and adaptive
                refinement of symbolic representations based on feedback from generation failures.
                6    Ablation Studies
                6.1   Analysis of the Compositional Reasoner framework
                Toquantify the individual contributions of the core components within our Compositional Reasoner (based on Core-
                Think’sframework),weconductedaseriesofablationstudiesontheARC-AGI-2publicevaluationset. Thisreasoner’s
                primary components are: (1) the Symbolic Hints generated by our pattern detection and intersection pipeline (Stages
                1–3), and (2) the Self-Consistency (SC) ensemble voting mechanism used in the final LLM solving stage (Stage 4).
                   Weevaluate four configurations to isolate the impact of these components, tracking not only their effect on accu-
                racy but also on computational cost and latency.
                      • FullModel(Reasoner): Ourcompletereasoner,whereGrok-4receivessymbolichintsandusesself-consistency
                        voting.
                      • w/oSymbolicHints: Weremovethesymbolichints(Stages1–3). Grok-4ispromptedonlywiththerawtask
                        examples, but still utilizes the self-consistency voting mechanism.
                      • w/oSelf-Consistency: Weusethefullpipeline, providing Grok-4 with symbolic hints, but take only a single,
                        greedy-decoded sample as the final answer.
                      • Baseline (LLM Only): We remove both our contributions. Grok-4 is prompted with only the raw task
                        examples and uses a single, greedy-decoded sample.
                 Compositional Reasoner Configuration   Score (%)      Est. Relative Latency        Est. Relative Cost
                 Full Model (Hints + SC)                   24.4     T    +N×T (Highest) C            +N×C (Highest)
                                                                     sym         llm             sym          llm
                 w/oSelf-Consistency (Hints)               20.5       T    +T (Medium)              C    +C (Low)
                                                                        sym    llm                   sym     llm
                 w/oSymbolicHints(SC)                      17.5          N×Tllm(High)                N×Cllm(High)
                 Baseline (LLM Only, greedy)               15.0            T   (Fastest)              C    (Lowest)
                                                                            llm                         llm
                Table2: AblationstudyoftheCompositionalReasonerontheARC-AGI-2publicevaluationset. T     /C    represent
                                                                                                     sym  sym
                the latency/cost of our symbolic hint pipeline. Tllm/Cllm represent the latency/cost of a single Grok-4 inference. N is
                the number of samples for self-consistency.
                   Theresults, presented in Table 2, clearly demonstrate the independent value of each component and the associated
                trade-offs.
                6.2   Analysis of Meta-Classifier Ensemble
                OurfinalsolutionisanensemblemodelthatcombinestheoutputsoftwodistinctsolversusingaMeta-Classifier. The
                scores included in this run come from the most recent Meta-Classifier Ensemble run, and the score variations
                are due to differences in Grok-4’s outputs.
                   Thecomponentsofthis final system are:
                      • Compositional Reasoner: CoreThink’s Compositional Reasoner which scores 20.4% in the latest run. This
                        solver generates 2 candidate solutions.
                      • ARCLangSolver: Aseparate, independent solver that also generates 2 candidate solutions, scoring 26.6%
                        in the latest run.
