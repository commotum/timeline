               [26] Z Ge, S Liu, F Wang, Z Li, and J Sun.              Yolox:        [39] Jonathan Ho, Tim Salimans, Alexey Gritsenko, William
                     Exceeding yolo series in 2021. arxiv.     arXiv preprint             Chan, Mohammad Norouzi, and David J Fleet. Video dif-
                     arXiv:2107.08430, 2021. 4, 5                                         fusion models. arXiv preprint arXiv:2204.03458, 2022. 2
               [27] Ross Girshick. Fast r-cnn. In Proceedings of the IEEE            [40] Emiel Hoogeboom, Victor Garcia Satorras, Clement Vi-
                     international conference on computer vision, pages 1440–             gnac, and Max Welling. Equivariant diffusion for molecule
                     1448, 2015. 1, 2                                                     generation in 3d. arXiv e-prints, pages arXiv–2203, 2022.
               [28] Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra             1, 2
                     Malik.  Rich feature hierarchies for accurate object de-        [41] Rongjie Huang, Zhou Zhao, Huadai Liu, Jinglin Liu,
                     tection and semantic segmentation. In Proceedings of the             Chenye Cui, and Yi Ren. Prodiff: Progressive fast diffu-
                     IEEE conference on computer vision and pattern recogni-              sion model for high-quality text-to-speech. arXiv preprint
                     tion, pages 580–587, 2014. 1                                         arXiv:2207.06389, 2022. 2
               [29] Xavier Glorot and Yoshua Bengio. Understanding the dif-          [42] Hyosoon Jang, Sangwoo Mo, and Sungsoo Ahn. Diffusion
                     ficulty of training deep feedforward neural networks. In             probabilistic models for graph-structured prediction. arXiv
                     Proceedings of the thirteenth international conference on            preprint arXiv:2302.10506, 2023. 2
                     artificial intelligence and statistics, pages 249–256. JMLR     [43] Ding Jia, Yuhui Yuan, Haodi He, Xiaopei Wu, Haojun Yu,
                     WorkshopandConferenceProceedings, 2010. 5                            Weihong Lin, Lei Sun, Chao Zhang, and Han Hu. Detrs
               [30] Shansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu,                    with hybrid matching. arXiv preprint arXiv:2207.13080,
                     and LingPeng Kong.     Diffuseq: Sequence to sequence                2022. 2
                     text generation with diffusion models.    arXiv preprint        [44] BowenJing,GabrieleCorso,ReginaBarzilay,andTommiS
                     arXiv:2210.08933, 2022. 2                                            Jaakkola. Torsional diffusion for molecular conformer gen-
                                                                                          eration. In ICLR2022 Machine Learning for Drug Discov-
               [31] Alexandros Graikos, Nikolay Malkin, Nebojsa Jojic, and                ery, 2022. 2
                     Dimitris Samaras. Diffusion models as plug-and-play pri-        [45] Justin Johnson, Ranjay Krishna, Michael Stark, Li-Jia Li,
                     ors. arXiv preprint arXiv:2206.09012, 2022. 1, 2                     David Shamma, Michael Bernstein, and Li Fei-Fei. Im-
               [32] ChunhuiGu,ChenSun,DavidARoss,CarlVondrick,Car-                        age retrieval using scene graphs.   In Proceedings of the
                     oline Pantofaru, Yeqing Li, Sudheendra Vijayanarasimhan,             IEEE conference on computer vision and pattern recogni-
                     George Toderici, Susanna Ricco, Rahul Sukthankar, et al.             tion, pages 3668–3678, 2015. 1
                     Ava: A video dataset of spatio-temporally localized atomic      [46] Zdenek Kalal, Krystian Mikolajczyk, and Jiri Matas.
                     visual actions. In Proceedings of the IEEE Conference                Tracking-learning-detection. IEEE transactions on pattern
                     on Computer Vision and Pattern Recognition, pages 6047–              analysis and machine intelligence, 34(7):1409–1422, 2011.
                     6056, 2018. 1                                                        1
               [33] Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, Bo                 [47] Boah Kim, Yujin Oh, and Jong Chul Ye. Diffusion adver-
                     Zhang, Dongdong Chen, Lu Yuan, and Baining Guo. Vec-                 sarial representation learning for self-supervised vessel seg-
                     tor quantized diffusion model for text-to-image synthesis.           mentation. arXiv preprint arXiv:2209.14566, 2022. 1, 2
                     In Proceedings of the IEEE/CVF Conference on Computer           [48] Sungwon Kim, Heeseung Kim, and Sungroh Yoon.
                     Vision and Pattern Recognition, pages 10696–10706, 2022.             Guided-tts 2: A diffusion model for high-quality adap-
                     2                                                                    tive text-to-speech with untranscribed data. arXiv preprint
               [34] Agrim Gupta, Piotr Dollar, and Ross Girshick. Lvis: A                 arXiv:2205.15370, 2022. 2
                     dataset for large vocabulary instance segmentation. In Pro-     [49] Alexander Kirillov, Kaiming He, Ross Girshick, Carsten
                                                                                                                ´
                     ceedings of the IEEE/CVF conference on computer vision               Rother, and Piotr Dollar. Panoptic segmentation. In Pro-
                     and pattern recognition, pages 5356–5364, 2019. 4, 5, 7              ceedings of the IEEE/CVF Conference on Computer Vision
               [35] WilliamHarvey,SaeidNaderiparizi,VadenMasrani,Chris-                   and Pattern Recognition, pages 9404–9413, 2019. 3
                     tian Weilbach, and Frank Wood. Flexible diffusion model-        [50] Alon Levkovitch, Eliya Nachmani, and Lior Wolf. Zero-
                     ing of long videos. arXiv preprint arXiv:2205.11495, 2022.           shot voice conditioning for denoising diffusion tts models.
                     2                                                                    arXiv preprint arXiv:2206.02246, 2022. 2
                                                              ´                      [51] Feng Li, Hao Zhang, Shilong Liu, Jian Guo, Lionel M Ni,
               [36] Kaiming He, Georgia Gkioxari, Piotr Dollar, and Ross Gir-             and Lei Zhang. Dn-detr: Accelerate detr training by intro-
                     shick. Mask r-cnn. In Proceedings of the IEEE interna-               ducing query denoising. In Proceedings of the IEEE/CVF
                     tional conference on computer vision, pages 2961–2969,               Conference on Computer Vision and Pattern Recognition,
                     2017. 1, 2, 3                                                        pages 13619–13627, 2022. 1, 2
               [37] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.           [52] Xiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy
                     Deep residual learning for image recognition. In Proceed-            Liang, and Tatsunori B Hashimoto.       Diffusion-lm im-
                     ings of the IEEE conference on computer vision and pattern           proves controllable text generation.       arXiv preprint
                     recognition, pages 770–778, 2016. 2, 3, 7, 8                         arXiv:2205.14217, 2022. 2
               [38] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising dif-        [53] Yi Li, Haozhi Qi, Jifeng Dai, Xiangyang Ji, and Yichen
                     fusion probabilistic models. Advances in Neural Informa-             Wei. Fully convolutional instance-aware semantic segmen-
                     tion Processing Systems, 33:6840–6851, 2020. 1, 2, 3, 4,             tation. In Proceedings of the IEEE conference on computer
                     8                                                                    vision and pattern recognition, pages 2359–2367, 2017. 1
                                                                                19840
