               Algorithm 1 DiffusionDet Training                                        Algorithm 2 DiffusionDet Sampling
               def train_loss(images, gt_boxes):                                        def infer(images, steps, T):
                 """                                                                      """
                 images: [B, H, W, 3]                                                     images: [B, H, W, 3]
                 gt_boxes: [B, *, 4]                                                      # steps: number of sample steps
                 # B: batch                                                               # T: number of time steps
                 # N: number of proposal boxes                                            """
                 """
                                                                                          # Encode image features
                 # Encode image features                                                  feats = image_encoder(images)
                 feats = image_encoder(images)
                                                                                          # noisy boxes: [B, N, 4]
                 # Pad gt_boxes to N                                                      pb_t = normal(mean=0, std=1)
                 pb = pad_boxes(gt_boxes) # padded boxes: [B, N, 4]
                                                                                          # uniform sample step size
                 # Signal scaling                                                         times = reversed(linespace(-1, T, steps))
                 pb = (pb * 2 - 1) * scale
                                                                                          # [(T-1, T-2), (T-2, T-3), ..., (1, 0), (0, -1)]
                 # Corrupt gt_boxes                                                       time_pairs = list(zip(times[:-1], times[1:])
                 t = randint(0, T)                  # time step
                 eps = normal(mean=0, std=1) # noise: [B, N, 4]                           for t_now, t_next in zip(time_pairs):
                 pb_crpt = sqrt(         alpha_cumprod(t)) * pb +                           # Predict pb_0 from pb_t
                             sqrt(1 - alpha_cumprod(t)) * eps                               pb_pred = detection_decoder(pb_t, feats, t_now)
                 # Predict                                                                  # Estimate pb_t at t_next
                 pb_pred = detection_decoder(pb_crpt, feats, t)                             pb_t = ddim_step(pb_t, pb_pred, t_now, t_next)
                 # Set prediction loss                                                      # Box renewal
                 loss = set_prediction_loss(pb_pred, gt_boxes)                              pb_t = box_renewal(pb_t)
                 return loss                                                              return pb_pred
                                                            Q
               alpha cumprod(t): cumulativeproductofα ,i.e.,   t  α                     linespace: generate evenly spaced values
                                                       i       i=1 i
               by image encoder, and sends these RoI-features to detec-                 explore several padding strategies, for example, repeating
               tion head to obtain box regression and classification results.           existing ground truth boxes, concatenating random boxes
               For DiffusionDet, these proposal boxes are disturbed from                or image-size boxes. Comparisons of these strategies are in
               ground truth boxes at training stage and directly sampled                Section 4.4, and concatenating random boxes works best.
               from Gaussian distribution at evaluation stage.           Follow-        Box corruption. We add Gaussian noises to the padded
               ing [10, 90, 114], our detection decoder is composed of 6                ground truth boxes. The noise scale is controlled by α (in
               cascading stages (Figure 2b). The differences between our                                                                               t
               decoder and the one in Sparse R-CNN are that (1) Diffu-                  Eq. (1)), which adopts the monotonically decreasing cosine
                                                                                        schedule for α in different time step t, as proposed in [67].
               sionDet begins from random boxes while Sparse R-CNN                                       t
               uses a fixed set of learned boxes in inference; (2) Sparse R-            Notably, the ground truth box coordinates need to be scaled
               CNNtakesasinput pairs of the proposal boxes and its cor-                 as well since the signal-to-noise ratio has a significant ef-
               responding proposal feature, while DiffusionDet needs the                fect on the performance of diffusion model [13]. We ob-
               proposal boxes only; (3) DiffusionDet can re-use the detec-              serve that object detection favors a relatively higher signal
               tor head in an iterative way for evaluation and the parame-              scaling value than image generation task [14,16,38]. More
               ters are shared across different steps, each of which is spec-           discussions are in Section 4.4.
               ified to the diffusion process by timestep embedding [38],               Training losses.       The detection detector takes as input
                                                                                        N        corrupted boxes and predicts N             predictions of
               which is called iterative evaluation, while Sparse R-CNN                    train                                     train
               uses the detection decoder only once in the forward pass.                category classification and box coordinates. We apply set
                                                                                        prediction loss [10, 90, 114] on the set of N              predic-
                                                                                                                                             train
               3.3. Training                                                            tions. We assign multiple predictions to each ground truth
                  During training, we first construct the diffusion process             by selecting the top k predictions with the least cost by an
               from ground-truth boxes to noisy boxes and then train the                optimal transport assignment method [18,25,26,98].
               model to reverse this process. Algorithm 1 provides the                  3.4. Inference
               pseudo-code of DiffusionDet training procedure.
               Ground truth boxes padding. For modern object detec-                         The inference procedure of DiffusionDet is a denoising
               tion benchmarks [20,34,57,80], the number of instances of                sampling process from noise to object boxes. Starting from
               interest typically varies across images. Therefore, we first             boxes sampled in Gaussian distribution, the model progres-
               pad some extra boxes to original ground truth boxes such                 sively refines its predictions, as shown in Algorithm 2.
               that all boxes are summed up to a fixed number Ntrain. We                Sampling step. In each sampling step, the random boxes
                                                                                    19833
