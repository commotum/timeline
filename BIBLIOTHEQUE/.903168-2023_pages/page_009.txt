                  Method              Train     Test      COCO         CrowdHuman        FPS            method                             AP50 ↑       mMR↓ Recall↑
                                      6×1      6×1      42.0           61.3               39            Faster R-CNN [74]                    85.0         50.4         90.2
                  DETR[10]            6×1      6×2      41.6 (-0.4)    62.5 (+1.2)        32            RetinaNet [56]                       81.7         57.6         88.6
                                      6×1      6×1      45.0           66.6               30            FCOS[93]                             86.1         55.2         94.3
                      Sparse          6×1      6×2      43.6 (-1.4)    60.6 (-6.0)        21            DETR[10]                             66.1         80.6           -
                  R-CNN[90]          12×1      12×1     44.7 (-0.3)    66.1 (-0.5)        21            Deformable DETR[114]                 86.7         54.0         92.5
                                      6×1      6×1      45.8           66.6               30            Sparse R-CNN[90] (500)               89.2         48.3         95.9
                  DiffusionDet        6×1      6×2      46.5 (+0.7)    69.7 (+3.1)        20            Sparse R-CNN[90] (1000)              89.7         49.1         97.5
                  DiffusionDet †      6×1      6×1      46.8 (+1.0)    71.0 (+4.4)        24            DiffusionDet (1 @ 1000)              90.1         46.5         96.2
                                                                                                        DiffusionDet (1 @ 3000)              91.2         47.7         98.4
                 Table 6. Running time vs. performance. † denotes Diffusion-                            DiffusionDet (3 @ 1000)              91.4         45.7         98.4
                 Det with 1000 boxes. #Stages×#Heads denotes the number                                             Table 7. Full tuning on CrowdHuman.
                 of stages and heads utilized during training and test phases.
                 Thedefinitions of Stage and Head are illustrated in Figure 2b.                      Random Seed Since DiffusionDet is given random boxes
                 45.8 AP as opposed to 45.0 AP on COCO. Besides, Sparse                              as input at the start of inference, one may ask whether
                 R-CNN’s utilization of the six stages twice results in a 1.4                        there is a large performance variance across different ran-
                 APdrop (from 45.0 to 43.6) on COCO and a 6.0 AP drop                                dom seeds. We evaluate the stability of DiffusionDet by
                 (from 66.6 to 60.6) on CrowdHuman. Similarly, DETR ex-                              training five models independently with the same config-
                 periences 0.4 performance drop on COCO but 1.2 perfor-                              urations except for random seed. Then, we evaluate each
                 mancegainonCrowdHuman.                                                              model instance with ten different random seeds to measure
                     When increasing the number of iteration steps, Diffu-                           the distribution of performance, inspired by [69, 96]. As
                 sionDetachievesa0.7APgainonCOCOanda3.1APgain                                        shown in Figure 4, most evaluation results are distributed
                 on CrowdHuman. And DiffusionDet obtains clear perfor-                               closely to 45.7 AP. Besides, the performance differences
                 mance gains with 1000 evaluation boxes. However, neither                            amongdifferent model instances are marginal, demonstrat-
                 DETR nor Sparse R-CNN can achieve performance gains                                 ingthatDiffusionDetisrobusttotherandomboxesandpro-
                 with additional iteration steps. Even if we expand the num-                         duces reliable results.
                 ber of stages to 12, it can cause performance degradation                           4.5. Full-tuning on CrowdHuman
                 for Sparse R-CNN.                                                                       In addition to the cross-dataset generalization evaluation
                     It is worth noting that in this work, we have utilized                          from COCO to CrowdHuman discussed in Section 4.2, we
                 the most fundamental diffusion strategy, DDIM, in our pi-                           further full-tune DiffusionDet on CrowdHuman. The com-
                 oneering exploration of using generation models for per-                            parison results are shown in Table 7. We see that Diffusion-
                 ception tasks.       Similar to the Diffusion model employed                        Detachieves superior performance compared with previous
                 in generation tasks, DiffusionDet may suffer from a rela-                           methods. For example, with a single step and 1000 boxes,
                 tively slow sampling speed. Nonetheless, a series of recent                         DiffusionDet obtains 90.1 AP , outperforming Sparse R-
                 works [17,63,77,85] have been proposed to improve the                                                                      50
                 sampling efficiency of the diffusion model. For instance,                           CNNwith1000boxes. Besides,furtherincreasing boxes to
                 the most recent consistency models [85] have proposed a                             3000anditeration steps can both bring performance gains.
                 fast one-stepgenerationmethodforthediffusionmodel. We                               5. Conclusion
                 believethatamoreadvanceddiffusionstrategycouldpoten-
                 tially address the issue of decreased speed performance of                              In this work, we propose a novel detection paradigm,
                 DiffusionDet, which we plan to explore in future work.                              DiffusionDet, by viewing object detection as a denoising
                                                                                                     diffusion process from noisy boxes to object boxes. Our
                  46.0                                                                               noise-to-box pipeline has several appealing properties, in-
                                                                                                     cluding the dynamic number of boxes and iterative evalu-
                  45.8                                     45.77                                     ation, enabling us to use the same network parameters for
                               45.76
                                             45.72                       45.72                       flexible evaluation without re-training the model. Experi-
                                                                                       45.66         ments on standard detection benchmarks show that Diffu-
                  45.6                                                                               sionDet achieves favorable performance compared to well-
                                                                                                     established detectors.
                  45.4      1             2             3              4             5               Acknowledgement.                  This    paper     is   partially     sup-
                                                Training Random Seed
                                                                                                     ported by the National Key R&D Program of China
                 Figure4. Statistical results over 5 independent training instances,                 No.2022ZD0161000 and the General Research Fund of
                 each is evaluated 10 times with different random seeds.                             HongKongNo.17200622.
                                                                                                19838
