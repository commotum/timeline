                         scale    AP     AP       AP                  case             AP     AP       AP              DDIM boxrenewal         iter 1  iter 2   iter 3
                                             50      75                                          50       75
                          0.1    38.9     54.3     42.1               Repeat          44.2     62.0     48.3                                   45.8     44.4     44.1
                          1.0    45.0     63.0     48.9               Cat Gaussian    45.8     64.1     50.4             ✓                     45.8     46.0     46.1
                          2.0    45.8     64.1     50.4               Cat Uniform     45.2     63.3     49.3                         ✓         45.8     46.3     46.3
                          3.0    45.6     63.9     50.0               Cat Full        45.7     63.9     49.9             ✓           ✓         45.8     46.5     46.6
                    (a) Signal scale. A large scaling factor        (b) GT boxes padding. Concatenating            (c) Sampling strategy. Using both DDIM and box
                    can improve detection performance.              Gaussian boxes works best.                     renewal works best.
                Table 4. DiffusionDet ablation experiments on COCO. We report AP, AP , and AP . If not specified, the default setting is: the
                                                                                                         50           75
                backbone is ResNet-50 [37] with FPN [55], the signal scale is 2.0, ground-truth boxes padding method is concatenating Gaussian random
                boxes, DDIM and box renewal are used in sampling step. Default settings are marked in gray .
                4.4. Ablation Study                                                                     train     eval     100       300      500      1000      2000
                    WeconductablationexperimentsonCOCOtostudyDif-                                            100           42.9     44.4      44.5     44.6      44.6
                fusionDet in detail. All experiments use ResNet-50 with                                      300           42.8     45.7      46.2     46.3      46.4
                FPN as the backbone and 300 random boxes for inference                                       500           41.9     45.8      46.3     46.7      46.8
                without further specification.                                                    Table 5. Matching between training and inference box num-
                Signal scaling.         The signal scaling factor controls the                    bers on COCO.DiffusionDet decouples the number of boxes dur-
                signal-to-noise ratio (SNR) of the diffusion process. We                          ing the training and inference stages and works well with flexible
                study the influence of scaling factors in Table 4a. Results                       combinations.
                demonstrate that the scaling factor of 2.0 achieves optimal
                AP performance, outperforming the standard value of 1.0                           remarkable gains when equipped with both DDIM and re-
                in image generation task [14,38] and 0.1 used for panoptic                        newal. These experiments together verify the necessity of
                segmentation [13]. We explain that it is because one box                          both DDIMandboxrenewalinthesamplingstep.
                only has four representation parameters, i.e., center coordi-
                                                                                                  Matching between N                    and N         .    As discussed
                nates (c ,c ) and box size (w,h), which is coarsely analo-                                                      train            eval
                          x   y                                                                   in Sec. 4.2, DiffusionDet has an appealing property
                gous to an image with only four pixels in image generation.
                The box representation is more fragile than the dense rep-                        of evaluating with an arbitrary number of random
                resentation, e.g., 512 × 512 mask presentation in panoptic                        boxes.     To study how the number of training boxes af-
                segmentation [14]. Therefore, DiffusionDet prefers an eas-                        fects inference performance, we train DiffusionDet with
                                                                                                  N           ∈ {100,300,500} random boxes separately
                ier training objective with an increased signal-to-noise ratio                      train
                                                                                                  and then evaluate each of these models with N                           ∈
                compared to image generation and panoptic segmentation.                                                                                            eval
                GTboxespaddingstrategy. As introduced in Section 3.3,                             {100,300,500,1000,2000}. The results are summarized
                weneedtopadadditionalboxestotheoriginalgroundtruth                                in Table 5. First, no matter how many random boxes Dif-
                boxes such that each image has the same number of boxes.                          fusionDet uses for training, the accuracy increases steadily
                                                                                                  with the N         until the saturated point at around 2000 ran-
                We study different padding strategies in Table 4b, includ-                                     eval
                ing (1) repeating original ground truth boxes evenly un-                          dom boxes. Second, DiffusionDet tends to perform better
                                                                                                  whentheN             andN         matcheswitheachother. Forex-
                til the total number reaches pre-defined value N                     ; (2)                      train          eval
                                                                               train              ample, DiffusionDet trained with Ntrain = 100 boxes be-
                padding random boxes that follow Gaussian distribution;                           havesbetterthanN               =300and500whenN                    =100.
                (3) padding random boxes that follow uniform distribution;                                                train                               eval
                (4) padding boxes that have the same size as the whole im-                        Running time vs. accuracy. We investigate the running
                age, which is the default initialization of learnable boxes                       time of DiffusionDet under multiple settings, which are
                in [90]. Concatenating Gaussian random boxes works best                           evaluatedonasingleNVIDIAA100GPUwithamini-batch
                for DiffusionDet. We use this padding strategy as default.                        size of 1. We utilize the notation #Stages×#Heads to
                                                                                                  indicate the number of stages and headsutilized during
                Sampling strategy. We compare different sampling strate-                          the training and test phases, as depicted in Figure 2b and
                gies in Table 4c. When evaluating DiffusionDet that does                          results of our investigation are presented in Table 6.
                not use DDIM, we directly take the output prediction of                               First, our findings indicate that DiffusionDet with a sin-
                the current step as input for the next step. We found that                        gle iteration step and 300 evaluation boxes demonstrate
                the AP of DiffusionDet degrades with more iteration steps                         a comparable speed to Sparse R-CNN, achieving 30 and
                when neither DDIM nor box renewal is adopted. Besides,                            31 frames per second (FPS), respectively.                 DiffusionDet
                only using DDIM or box renewal would bring slight bene-                           also showcases similar zero-shot transfer performance on
                fits at 3 iteration steps. Moreover, our DiffusionDet attains                     CrowdHumanwhileoutperforming Sparse R-CNN with an
                                                                                             19837
