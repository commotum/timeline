                                                                       Ì†µ„åµ    Gaussian Noise           Ì†µ„åµ‚Ä≤                                                                             Diffusion model.                                Diffusion models [38, 83, 84, 86] are
                                                                       Ì†µ„åµ                             Ì†µ„åµ‚Ä≤                                                                             a classes of likelihood-based models inspired by nonequi-
                                                                       Ì†µ„åµ                             Ì†µ„åµ‚Ä≤
                                                                       ‚Ñé                              ‚Ñé‚Ä≤                                                                              librium thermodynamics [86,87]. These models define a
                                                                                                                                                                                      Markovian chain of diffusion forward process by gradually
                                                                                                                                                                                      adding noise to sample data. The forward noise process is
                                                                                                                                                                                      defined as
                                                                                                                                            Class
                                                                                                                                             Box                                                                                                         ‚àö
                                                                               Image Encoder               Detection Decoder                                                                                  q(zt|z0) = N(zt| Œ±¬Øtz0,(1‚àíŒ±¬Øt)I),                                                                          (1)
                                                                                (a) Overall pipeline.                                                                                 which transforms data sample z0 to a latent noisy sample
                                                                                                                                                                                                                                                                                                                          :
                                                                                                                                                                                      z for t ‚àà {0,1,...,T} by adding noise to z . Œ±¬Ø                                                                                       =
                                                                                                                                                                                         t                                                                                                              0            t
                                                            Stage-1                                                                                                                   Q                               Q
                                      s                                                  s                                                                                                 t                                t
                                      e                                                  n
                                      x                                                  o                                 Iterative Evaluation                                                      Œ± =                            (1 ‚àí Œ≤ ) and Œ≤ represents the noise
                                      o                                                  i                                                                                                              s                                             s                    s
                                      B                                                  t                                                                                                 s=0                              s=0
                                                                                         c
                                                                                         i
                                      m   Feature                                        d
                                      o                                                                                                                                               variance schedule [38]. During training, a neural network
                                      d                        n                         Pre
                                      n                        g                         x
                                      Ra                       i
                                      	                        Al                        Bo
                                                                                         	                          1          2                   6                                  f (z ,t) is trained to predict z from z by minimizing the
                                      Ì†µ„åµ                       I                  FC                                                                                                     Œ∏       t                                                           0                    t
                                      	                        Ro                        Ì†µ„åµ                         -          -                   -                                  training objective with ‚Ñì loss [38]:
                                                                                                                                                                                                                                              2
                                                                                                                    Stage      Stage               Stage
                                                                        Ì†µ„åµ	                                                                        Head                                                                                      1                                           2
                                                                                                                                                                                                                         L             = ||f (z ,t)‚àíz || .                                                               (2)
                                                                   RoI Features                                                                                                                                              train           2         Œ∏       t                   0
                                                            (b) Details of the detection decoder/head.                                                                                At inference stage, data sample z0 is reconstructed from
                              Figure 2. DiffusionDet framework. (a) The image encoder ex-                                                                                             noise zT with the model fŒ∏ and an updating rule [38,84]
                                                                                                                                                                                      in an iterative way, i.e., z                                       ‚Üíz                       ‚Üí... ‚Üí z . More
                              tracts feature representation from an input image. The detection                                                                                                                                                     T                T‚àí‚àÜ                                      0
                              decoder takes noisy boxes as input and predicts category classifi-                                                                                      detailed formulation of diffusion models can be found in
                              cation and box coordinates. (b) The detection decoder has 6 stages                                                                                      Appendix A.
                              in one detection head, following DETR and Sparse R-CNN. Be-                                                                                                    In this work, we aim to solve the object detection task
                              sides, DiffusionDet can reuse this detection head (with 6 stages)                                                                                       via the diffusion model. In our setting, data samples are a
                                                                                                                                                                                      set of bounding boxes z = b, where b ‚àà RN√ó4 is a set of
                              multiple times, which is called ‚Äúiterative evaluation‚Äù.                                                                                                                                                         0
                                                                                                                                                                                      Nboxes. Aneuralnetworkf (z ,t,x)istrainedtopredict
                                                                                                                                                                                                                                                          Œ∏       t
                                                                                                                                                                                      z from noisy boxes z , conditioned on the corresponding
                                                                                                                                                                                         0                                                  t
                              13, 31, 47, 97], for example, Chen et al. [13] adopted Bit                                                                                              image x. The corresponding category label c is produced
                              Diffusion model [14] for panoptic segmentation [49] of im-                                                                                              accordingly.
                              ages and videos. However, despite significant interest in                                                                                               3.2. Architecture
                              this idea, there are no previous solutions that successfully
                              adapt generative diffusion models for object detection, the                                                                                                    Since the diffusion model generates data samples iter-
                              progress of which remarkably lags behind that of segmenta-                                                                                              atively, it needs to run model fŒ∏ multiple times at the in-
                              tion. We argue that this may be because segmentation tasks                                                                                              ference stage. However, it would be computationally in-
                              are processed in an image-to-image style, which is more                                                                                                 tractable to directly apply fŒ∏ on the raw image at every it-
                              conceptually similar to the image generation tasks, while                                                                                               erative step. Therefore, we propose to separate the whole
                              object detection is a set prediction problem [10] which re-                                                                                             modelintotwoparts,imageencoderanddetectiondecoder,
                              quires assigning object candidates [10, 55, 74] to ground                                                                                               where the former runs only once to extract a deep feature
                              truth objects. To the best of our knowledge, this is the first                                                                                          representation from the raw input image x, and the latter
                              workthat adopts a diffusion model for object detection.                                                                                                 takes this deep feature as condition, instead of the raw im-
                                                                                                                                                                                      age, to progressively refine the box predictions from noisy
                              3. Approach                                                                                                                                             boxes zt.
                              3.1. Preliminaries                                                                                                                                      Image encoder. Image encoder takes as input the raw im-
                                                                                                                                                                                      age and extracts its high-level features for the following
                              Object detection. The learning objective of object detec-                                                                                               detection decoder. We implement DiffusionDet with both
                              tion is input-target pairs (x,b,c), where x is the input im-                                                                                            Convolutional Neural Networks such as ResNet [37] and
                              age, b and c are a set of bounding boxes and category labels                                                                                            Transformer-based models like Swin [60]. Feature Pyramid
                              for objects in the image x, respectively. More specifically,                                                                                            Network [55] is used to generate multi-scale feature maps
                                                                                                                           i             i       i         i       i                  for both ResNet and Swin backbones following [55,60,90].
                              weformulatethei-th box in the set as b = (c ,c ,w ,h ),
                                                                                                                                         x       y
                                                   i        i
                              where (c ,c ) is the center coordinates of the bounding                                                                                                 Detection decoder. Borrowed from Sparse R-CNN [90],
                                                   x        y
                                                 i       i
                              box, (w ,h ) are width and height of that bounding box,                                                                                                 the detection decoder takes as input a set of proposal boxes
                              respectively.                                                                                                                                           to crop RoI-feature [36, 74] from feature map generated
                                                                                                                                                                             19832
