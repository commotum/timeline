                 Method                    AP AP        AP     AP    AP     AP            Method                     AP    AP     AP      AP     AP    AP
                                                   50      75     s     m      l                                              50     75      r      c     f
                                          ResNet-50 [37]                                                             ResNet-50 [37]
                 RetinaNet [101]          38.7   58.0   41.5   23.3   42.3  50.3          Faster R-CNN†             22.5   37.1    23.6    9.9   21.1   29.7
                                                                                                          †
                 Faster R-CNN [101]       40.2   61.0   43.8   24.2   43.5  52.0          Cascade R-CNN             26.3   37.8    27.8   12.3   24.9   34.1
                 Cascade R-CNN[101]       44.3   62.2   48.0   26.6   47.7  57.7          Faster R-CNN              25.2   40.6    26.9   16.4   23.4   31.1
                 DETR[10]                 42.0   62.4   44.2   20.5   45.8  61.1          Cascade R-CNN             29.4   41.4    30.9   20.0   27.7   35.4
                 Deformable DETR[114] 43.8       62.6   47.7   26.4   47.1  58.0          Sparse R-CNN              29.2   41.0    30.7   20.6   27.7   34.6
                 Sparse R-CNN[90]         45.0   63.4   48.2   26.9   47.2  59.5          DiffusionDet (1 @ 300)    29.4   40.4    31.0   22.7   27.2   34.7
                 DiffusionDet (1 @ 300)   45.8   64.1   50.4   27.6   48.7  62.2          DiffusionDet (1 @ 500)    30.5   42.1    32.1   23.3   28.1   36.3
                 DiffusionDet (4 @ 300)   46.6   65.1   51.3   28.9   49.2  62.1          DiffusionDet (1 @ 1000)   31.4   43.2    33.3   24.5   28.8   37.3
                 DiffusionDet (1 @ 500)   46.3   64.8   50.7   28.6   49.0  62.1          DiffusionDet (4 @ 300)    31.5   43.4    33.5   24.1   29.3   37.4
                 DiffusionDet (4 @ 500)   46.8   65.3   51.8   29.6   49.3  62.2                                    ResNet-101 [37]
                                          ResNet-101 [37]                                 Faster R-CNN†             24.8   39.8    26.1   13.7   23.1   31.5
                 RetinaNet [101]          40.4   60.2   43.2   24.0   44.3  52.2                          †
                                                                                          Cascade R-CNN             28.6   40.1    30.1   15.3   27.3   35.9
                 Faster R-CNN [101]       42.0   62.5   45.9   25.2   45.6  54.6          Faster R-CNN              27.2   42.9    29.1   18.8   25.4   33.0
                 Cascade R-CNN[11]        45.5   63.7   49.9   27.6   49.2  59.1          Cascade R-CNN             31.6   43.8    33.4   23.9   29.8   37.0
                 DETR[10]                 43.5   63.8   46.4   21.9   48.0  61.8          Sparse R-CNN              30.1   42.0    31.9   23.5   27.5   35.9
                 Sparse R-CNN[90]         46.4   64.6   49.5   28.3   48.3  61.6          DiffusionDet (1 @ 300)    30.9   42.1    32.6   22.4   29.9   35.8
                 DiffusionDet (1 @ 300)   46.7   65.0   51.0   29.6   49.7  63.2          DiffusionDet (1 @ 500)    31.8   43.7    33.6   23.5   30.2   37.3
                 DiffusionDet (4 @ 300)   47.4   65.8   52.0   30.1   50.4  63.1          DiffusionDet (1 @ 1000)   33.0   45.0    34.9   24.8   31.4   38.3
                 DiffusionDet (1 @ 500)   47.2   65.7   51.6   30.2   50.2  62.7          DiffusionDet (4 @ 300)    33.0   45.2    35.1   24.2   31.5   38.5
                 DiffusionDet (4 @ 500)   47.5   65.7   52.0   30.8   50.4  63.1                                     Swin-Base [60]
                                          Swin-Base [60]                                  DiffusionDet (1 @ 300)    39.5   52.3    42.0   33.0   38.5   43.5
                 Cascade R-CNN[60]        51.9   70.9   56.5   35.4   55.2  67.4          DiffusionDet (1 @ 500)    40.8   54.2    43.6   33.4   39.9   45.2
                 Sparse R-CNN             52.0   72.2   57.0   35.8   55.1  68.2          DiffusionDet (1 @ 1000)   41.9   55.7    44.8   35.3   40.6   46.2
                 DiffusionDet (1 @ 300)   52.5   71.8   57.3   35.0   56.4  69.3          DiffusionDet (4 @ 300)    42.0   55.8    44.9   34.8   40.9   46.4
                 DiffusionDet (4 @ 300)   53.3   72.8   58.6   36.6   57.0  69.2
                 DiffusionDet (1 @ 500)   53.0   72.3   58.0   35.5   56.9  69.1         Table 3. Comparisons with different object detectors on LVIS
                 DiffusionDet (4 @ 500)   53.3   72.7   58.4   36.2   56.9  69.0         v1.0 val set.     We re-implement all detectors using federated
                                                                                         loss [111] except for the rows in light gray (with †).
               Table 2.    Comparisons with different object detectors on
               COCO2017valset. [S@Neval] denotes the number of itera-
               tion steps S and number of evaluation boxes Neval. The reference          We reproduce Faster R-CNN and Cascade R-CNN based
               after each method indicates the source of its results. The method         on detectron2 [101] while Sparse R-CNN on its origi-
               without reference is our implementation.                                  nal code. We first reproduce Faster R-CNN and Cascade R-
                                                                                         CNNusingthedefaultsettingsofdetectron2,achieving
               fusionDet (1 @ 300), which adopts a single iteration step                 22.5/24.8and26.3/28.8AP(with† inTable3)withResNet-
               and 300 evaluation boxes, achieves an AP of 45.8 with a                   50/101 backbone, respectively. Further, we boost their per-
               ResNet-50 backbone, surpassing the performance of sev-                    formance using the federated loss in [111]. Since images
               eral well-established methods such as Faster R-CNN, Reti-                 in LVIS are annotated in a federated way [34], the neg-
               naNet, DETR, and Sparse R-CNN by a considerable mar-                      ative categories are sparsely annotated, which deteriorates
               gin.   Moreover, DiffusionDet can further enhance its su-                 the training gradients, especially for rare classes [92]. Fed-
               periority by increasing the number of iterations and eval-                erated loss is proposed to mitigate this issue by sampling a
               uation boxes.       Besides, DiffusionDet shows steady im-                subset S of classes for each training image that includes all
               provement when the backbone size scales up. Diffusion-                    positive annotations and a random subset of negative ones.
               DetwithResNet-101(1@300)achieves46.7. Whenusing                           Following [111], we choose |S| = 50 in all experiments.
               ImageNet-21kpre-trained Swin-Base [60] as the backbone,                   Faster R-CNN and Cascade R-CNN earn about 3 AP gains
               DiffusionDet obtains 52.5 AP, outperforming strong base-                  with federated loss. All following comparisons are based
               lines such as Cascade R-CNN and Sparse R-CNN.                             onthis loss.
                  Our current model is still lagging behind behind some                      We see that DiffusionDet attains remarkable gains us-
               well developed works like DINO [107] since it uses some                   ing more evaluation steps, with both small and large back-
               more advanced components such as deformable atten-                        bones. Moreover, we note that iterative evaluation brings
               tion [114], wider detection head. Some of these techniques                more gains on LVIS compared with COCO. For example,
               are orthogonaltoDiffusionDetandwewillexploretoincor-                      its performance increases from 45.8 to 46.6 (+ 0.8 AP) on
               poratethesetoourcurrentpipelineforfurtherimprovement.                     COCOwhilefrom 29.4 to 31.5 (+2.1 AP) on LVIS, which
                                                                                         demonstrates that our DiffusionDet would become more
                  Experimental results on LVIS are presented in Table 3.                 helpful for a more challenging benchmark.
                                                                                     19836
