             or the estimated boxes from the last sampling step are sent      nents of DiffusionDet.
             into the detection decoder to predict the category classifica-   COCO[57] dataset contains about 118K training images
             tion and box coordinates. After obtaining the boxes of the       in the train2017 set and 5K validation images in the
             current step, DDIM [84] is adopted to estimate the boxes         val2017 set. There are 80 object categories in total.
             for the next step. We note that sending the predicted boxes      Wereport box average precision over multiple IoU thresh-
             without DDIM to the next step is also an optional progres-       olds (AP), threshold 0.5 (AP  ) and 0.75 (AP   ).
             sive refinement strategy. However, it brings significant de-                                 50               75
             terioration, as discussed in Section 4.4.                        LVIS v1.0 [34] dataset is a large-vocabulary object de-
             Boxrenewal. Aftereachsamplingstep,thepredictedboxes              tection and instance segmentation dataset which has 100K
             can be coarsely categorized into two types, desired and un-      training imagesand20Kvalidationimages. LVISsharesthe
             desired predictions. The desired predictions contain boxes       samesourceimagesasCOCO,whileitsannotationscapture
             that are properly located at corresponding objects, while the    the long-tailed distribution in 1203 categories. We adopt
                                                                              MS-COCO style box metric AP, AP         and AP     in LVIS
             undesired ones are distributed arbitrarily. Directly sending                                          50         75
             these undesired boxes to the next sampling iteration would       evaluation. For LVIS, the training schedule is 210K, 250K,
             not bring a benefit since their distribution is not constructed  and 270K.
             by box corruption in training. To make inference better          CrowdHuman[80]dataset is a large dataset covering var-
             align with training, we propose the strategy of box renewal      ious crowd scenarios. It has 15K training images and 4.4K
             to revive these undesired boxes by replacing them with ran-      validation images, including a total of 470K human in-
             domboxes. Specifically, we first filter out undesired boxes      stances and 22.6 persons per image. Following previous
             withscoreslowerthanaparticularthreshold. Then,wecon-             settings [54, 90, 109, 113], we adopt evaluation metrics as
             catenate the remaining boxes with new random boxes sam-          APunderIoUthreshold0.5.
             pled from a Gaussian distribution.                               4.1. Implementation Details.
             Flexible usage. Thanks to the random boxes design, we               TheResNetandSwinbackboneareinitialized with pre-
             can evaluate DiffusionDet with an arbitrary number of ran-       trained weights on ImageNet-1K and ImageNet-21K [15],
             domboxesandthenumberofiteration times, which do not              respectively. The newly added detection decoder is ini-
             need to be equal to the training stage. As a comparison,         tialized with Xavier init [29]. We train DiffusionDet us-
             previous approaches [10,90,114] rely on the same number          ing AdamW [61] optimizer with the initial learning rate as
             of processed boxes during training and evaluation, and their              −5                            −4
             detection decoders are used only once in the forward pass.       2.5 × 10    and the weight decay as 10    . All models are
                                                                              trained with a mini-batch size 16 on 8 GPUs. The default
             3.5. Discussion                                                  training schedule is 450K iterations, with the learning rate
                                                                              divided by 10 at 350K and 420K iterations. Data augmen-
                We conduct a comparative analysis between Diffusion-          tation strategies contain random horizontal flip, scale jitter
             Det and previous multi-stage detectors [7,10,74,90]. Cas-        of resizing the input images such that the shortest side is
             cadeR-CNNadoptsathree-stagepredictionrefinementpro-              at least 480 and at most 800 pixels while the longest is at
             cess where the three stages do not share parameters and are      most 1333 [101], and random crop augmentations. We do
             used only once as a complete head during the inference           not use the EMA and some strong data augmentation like
             phase. Recent works [10,90,114] have adopted a similar           MixUp[106]orMosaic[26].
             structure as Cascade R-CNNbutwithmorestages(i.e.,six),              Attheinference stage, we report performances of Diffu-
             following the default setting of DETR [10]. While Diffu-         sionDet under diverse settings, which are combinations of
             sionDetalsoemploysthesix-stagestructurewithinitshead,            different numbers of random boxes and iteration steps. The
             the distinguishing feature is that DiffusionDet can reuse the    predictions at each sampling step are ensembled together by
             entire head multiple times to achieve further performance        NMStogetthefinalpredictions.
             gains.  However, prior works could not improve perfor-
             mancebyreusingthedetection head in most cases or could           4.2. Main Properties
             only achieve limited performance gains. More detailed re-           ThemainpropertiesofDiffusionDetlieononcetraining
             sults are in Section 4.4.                                        for all inference cases. Once the model is trained, it can
             4. Experiments                                                   be used with changing the number of boxes and the num-
                                                                              ber of iteration steps in inference, as shown in Figure 3 and
                We first show the attractive flexibility of Diffusion-        Table 1. Therefore, we can deploy a single DiffusionDet
             Det. Then we compare DiffusionDet with previous well-            to multiple scenarios and obtain a desired speed-accuracy
             established detectors on COCO[57]andCrowdHuman[80]               trade-off without re-training the network.
             dataset. Finally, we provide ablation studies on the compo-      Dynamic number of boxes. We compare DiffusionDet
                                                                          19834
