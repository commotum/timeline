# Order Matters: Sequence to Sequence for Sets (2016)
Source: 42d525-2015.pdf

## Core reasons
- Introduces a general modeling extension for handling input and output sets within the seq2seq framework, focusing on ordering and permutation handling rather than new data or benchmarks.
- Proposes a training objective that searches for optimal output orderings, which is a methodological contribution to learning and optimization rather than positional encodings or dimensional lifting.

## Evidence extracts
- "In the following two sections we discuss how to extend seq2seq to handle input sets (Section 4) and output sets (Section 5)." (p. 3)
- "Our proposed solution to deal with the aforementioned drawback is extremely simple: as we train, we let the model decide which is the best ordering in which it will apply the chain rule." (p. 8)

## Classification
Class name: ML Foundations & Principles
Class code: 5

$$
\boxed{5}
$$
