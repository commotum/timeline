# LTD-Bench: Evaluating Large Language Models by Letting Them Draw (2025)
Source: a4f810-2024.pdf

## Core reasons
- Introduces LTD-Bench as a new evaluation framework/benchmark with visual outputs for LLM spatial reasoning.
- Defines a structured benchmark dataset with 183 items across three difficulty levels (generation and recognition).

## Evidence extracts
- "To address this gap, we introduce LTD-Bench (Let Them Draw Benchmark), a novel evaluation framework that shifts LLM assessment from abstract numerical scores to directly observable visual outputs." (Section 1 Introduction)
- "Based on the design principles outlined in Section 3.1, LTD-Bench comprises a comprehensive evaluation framework with 183 distinct data distributed across three difficulty levels, as summarized in Table 1." (Section 3.2 Benchmark Structure and Task Design)

## Classification
Class name: Data, Benchmarks & Measurement
Class code: 4

$$
\boxed{4}
$$
