                TONG et al.                                                                                                                                Optoelectron. Lett. Vol.21 No.9·0551· 
                to  generate  a  re-weighting  scalar,  σ(∙)  is  the  softmax 
                                                                                                                              
                                                                                                           z     T       T
                                                                                                                             
                                                                                                                            
                                                                                                       r Q K        K
                                                                        ce
                                                                                                                   
                                                                                                           h     h       h
                                                                                                                             
                                                                                                                              
                                                                                                                                    
                function calculating along the d' dimension, and F  is 
                                                                                                                            
                                                                                      CDA                                     V ,  (14) 
                                                                                                                             
                                                                                          h                                         h
                                                                                                                              
                                                                                                                            
                the feature map processed by the previous self-attention 
                                                                                                                   
                                                                                                                 d
                                                                                                                             
                                                                                                                              
                                                                                                                            
                                                                                                                            
                                                                                                                             
                                                                                                                              
                encoding module in channel-wise transformer. The above 
                                                                                                            
                                                                                        z    S     cd    1d
                   cd            cd     cd
                                                                                      Q  z W        ,                     (15) 
                W and the  W        ,W  below are learnable matrices in 
                                                                                       h          Q
                  K              Q     V
                                                                                                   h
                    h             h     h
                                                                                                               
                                                                                             ce    cd     Nd
                channel-wise decoding module. 
                                                                                     V F W                  ,                                       (16) 
                                                                                       h            V
                                                                                                     h
                  As  shown  in  Fig.2,  the  extended  channel-wise 
                                                                                           cd
                                                                                  where z  is the output of channel-wise decoding atten-
                re-weighting strategy is proposed to simultaneously fo-
                                                                                         S     1d
                                                                                  tion, z       is  the  output  of  a  zero-initialized  vector 
                cus  on  the  global  aggregation  and  channel-wise  local 
                                                                                  processed by a simple self-attention, r(∙) denotes a du-
                aggregation as 
                                                                                                                                      
                                                                                                                           1N       d N
                                                                                  plicating  operator,  which  makes                      ,  and 
                                                                                                                          
                    cd         S    ce    S
                                               
                   z    z ,F         z 
                                     
                           cd                                                      
                                                                                        represents  the  Hadamard  product  operation.  Then, 
                                                                                   cd
                                                               S
                                                                                  z  will be processed with an FFN and layer normaliza-
                         Concat CDA,CDA ,,CDA              z ,
                                                                          (13) 
                                                          
                                       1      2          H
                                                                                  tions to generate a channel-wise global proposal repre-
                where 
                                                                                  sentation. 
                                                                                      
                                                                                                                                           
                                  Fig.2 Dual transformer encoder-decoder architecture for the proposal refinement 
                 
                                                                                       o                         prop
                  Finally, in order to aggregate the spatial information 
                                                                                                                          
                                                                                                                                                (17) 
                                                                                     c min 1,max 0,2IoU             0.5 ,
                                                                                                                         
                                                                                                                          
                and channel contextual dependencies, the point-wise and 
                                                                                  where the parameters with superscripts o and prop de-
                channel-wise proposal representations are combined by 
                                                                                  note regression objectives and proposals, respectively. 
                element-wise  addition  to  generate  the  global  proposal 
                                                                                     For the box refinement branch, the box regression ob-
                representation. It is noteworthy that following the princi-
                                                                                                     [8,11,12]
                                                                                  jectives are set as       
                ple  of  position  embedding  added  to  the  vanilla  trans-
                       [9]
                                                                                              g    prop
                former , the position embedding is not used in the dual 
                                                                                      
                                                                                             x x
                                                                                         t
                                                                                        x 
                                                                                      
                transformer because the features already contain spatial 
                                                                                               d
                                                                                                 diag
                                                                                      
                position information. 
                                                                                      
                                                                                              g     prop
                                                                                             y y
                3.4 Detect head and training objectives 
                                                                                         t
                                                                                      
                                                                                       y 
                The global proposal representation is fed into two sepa-
                                                                                      
                                                                                                d
                                                                                                 diag
                                                                                      
                rate  FFNs for confidence prediction and bounding box 
                                                                                      
                                                                                              g    prop
                                                                                                                                                     (18)
                                                                                                        ,b l,w,h ,
                                                                                                                   
                                                                                      
                                                                                             z z
                                                                                         t
                refinement,  respectively.  For  the  former,  as  done  in 
                                                                                        z 
                                                                                      
                                                                                                 prop
                                                                                               h
                Refs.[11, 12, 25], the 3D intersection-over-union (IoU) 
                                                                                      
                                                                                                    g
                between  the  proposals  and  their  corresponding 
                                                                                      
                                                                                                      
                                                                                                  b
                                                                                        t
                                                                                      
                                                                                       b log
                                                                                                      
                ground-truth (GT) boxes is adopted as the training objec-
                                                                                                   prop
                                                                                                      
                                                                                                 b
                                                                         o
                                                                                      
                                                                                                      
                tives. Given the proposals, the confidence objective c  is 
                                                                                      
                                                                                         t    g    prop
                normalized within [0, 1], shown as   
                                                                                         
                                                                                      
                                                                                      
