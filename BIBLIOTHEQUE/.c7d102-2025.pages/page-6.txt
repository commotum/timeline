                ·0552·                                                                                                                                             Optoelectron. Lett. Vol.21 No.9 
                where  the  parameters  with  superscript  g  denotes  GT         and others are treated as negative proposals. At the in-
                boxes, and d     is the diagonal length of proposal base.         ference stage, top-100 proposals are selected for the final 
                             diag
                3.5 Training losses                                               prediction. 
                                                                                  4.3 Detection performance of the KITTI dataset 
                The proposed PV-DT3D is trained end-to-end against the 
                                                                                  The commonly used “car” category of KITTI dataset is 
                first-stage  proposal  generation  loss       and  the  sec-
                                                          RPN
                                                                        [8]
                                                                                  used  for  experiments.  Tab.1  shows  the  performance 
                                             
                ond-stage refinement loss           . As the SECOND  is 
                                               RCNN
                                                                                  comparison between the proposed PV-DT3D and other 
                utilized as the 3D backbone and RPN, we adopt the same 
                                                                                  state-of-the-art methods on the official KITTI test server. 
                region proposal loss      . 
                                       RPN
                                                                                  The average precision (AP) is used for all test results, 
                                                             
                  Besides,  the  proposal  refinement  loss         is  com-
                                                                                  where the 0.7 threshold and 40 recall positions are ap-
                                                               RCNN
                                                                                  plied.  The  best  results  are  bolded  and  the  second  best 
                                                                       
                posed  of  IoU-guided  confidence  prediction  loss           
                                                                         IoU
                                                                                  ones are underlined. 
                and  box  residual  regression              .  The  binary 
                                                      
                                                       reg
                                                                                  Tab.1  Performance  comparison  with  other  Li-
                cross-entropy loss is exploited for the predicted confi-
                                                                                  DAR-based approaches on the official KITTI test set 
                                                       
                dence c to calculate confidence loss           as   
                                                         IoU
                             o               o
                                                                                                                         Car AP 3D (%) 
                       c log c  1c log 1c .         (19) 
                                                      
                                              
                    IoU
                                                                                       Type          Method 
                                                                                                                  Easy    Mod.    Hard   Mean 
                  Moreover, the box regression loss            is the same as 
                                                        
                                                          reg
                                                                                                           [3]
                                                                                                   VoxelNet       77.82   64.17  57.51   66.50 
                anchor regression loss as 
                                                                                                            [8]
                                                                                                   SECOND         84.65   75.96  68.71   76.44 
                                                                   o
                                                                                    Single-stage 
                                                                
                                                                       (20) 
                     IoU                                 r ,r   ,
                                                                                                          [13]
                                      
                                                                    
                    reg              R               smoothL1
                                                                                                   3DSSD         88.36   79.57  74.55   80.83 
                                                                                                           [22]
                                        rx,y,z,l,w,h,
                                                                                                   PVT-SSD        90.65   82.29  76.85   83.26 
                                                                                                              [4]
                where  IoU            means     that   proposals     with 
                                     
                                    R                                                            Voxel R-CNN      90.90   81.62  77.06   83.19 
                                                                                                            [20]
                IoU 
                             are used to contribute to the regression loss, 
                         R
                                                                                                   VoTr-TSD       89.90   82.09  79.14   83.71 
                                                                                                             [15]
                and r' is the predicted box residual. 
                                                                                                  Focals Conv     90.20   82.12  77.50   83.27 
                                                                                                             [7]
                                                                                                  PointRCNN       86.96   75.64  70.70   77.77 
                4. Experiments 
                                                                                                          [14]
                                                                                                    SASA          88.76   82.16  77.16   82.69 
                                                                                                            [12]
                                                                                                   PV-RCNN        90.25   81.43  76.82   82.84 
                4.1 KITTI dataset 
                                    [23]                                                                    [28]
                                                                                     Two-stage 
                                                                                                  Pyramid-PV      88.39   82.08  77.49   82.65 
                The KITTI dataset        is  utilized  for subsequent experi-
                                                                                                          [29]
                                                                                                    BADet         89.28   81.61  76.58   82.49 
                ments, which includes 7 481 training samples and 7 518 
                                                                                                           [19]
                                                                                                   M3DETR         90.28   81.73  76.96   82.99 
                test  samples.  For  ablation  experiments,  as  done  in 
                                                                                                          [30]
                                                                                                    SIENet        88.22   81.71  77.22   82.38 
                Refs.[10,  12,  26],  the  labeled  training  samples  are  di-
                                                                                                         [16]
                                                                                                     PDV          90.43   81.86  77.32   83.20 
                vided into training set with 3 712 samples and validation 
                                                                                                          [11]
                                                                                                     CT3D         87.83   81.77  77.16   82.25 
                set with 3 769 samples. 
                                                                                                      Ours        90.07   82.09  77.51   83.22 
                4.2 Implementation of experiments 
                4.2.1 RPN                                                          
                                          [8]
                The  effective  SECOND   is  considered  as  the  default            According  to  these  detection  results,  the  proposed 
                voxel-based network and RPN to generate high quality              PV-DT3D  achieves  the  best  detection  accuracy  on  the 
                proposal.  All  the  hyperparameters  of  SEOCND follow           moderate level among two-stage methods. Calculating the 
                           [27]
                PV-RCNN  for convenient comparison. For more de-                  average accuracy across all difficulty levels, it is shown 
                                                               [27]
                tails, please refer to the OpenPCDet toolbox     .                that  PV-DT3D  outperforms  other  point-voxel-based  ap-
                4.2.2 Training and inference details                              proaches,  showcasing  its  superior  performance.  When 
                                                                                                                                [11,12,16]
                A single NVIDIA 1080Ti graph processing unit (GPU) is             comparing  PV-DT3D  with  other  methods             ,  all  of 
                used  for  end-to-end  training  of  the  PV-DT3D  for  100       which  utilize  SECOND  as  the  3D  backbone,  and  the 
                epochs with Adam optimizer. The batch size and initial            PV-DT3D  consistently  demonstrates  the  best  detection 
                learning rate are set to 2 and 0.001, respectively. Cosine        results. 
                annealing  strategy  is  utilized  to  update  learning  rate.       Besides,  detection  results  of  the  PV-DT3D  and 
                Firstly, 3 072 raw points are randomly sampled by FPS.            PV-RCNN on the KITTI test set are visualized in Fig.3. 
                Then in the dual transformer, 256 internal keypoints are          Compared  with  PV-RCNN,  the  proposed  PV-DT3D 
                randomly  selected  for  subsequent  processing.  If  the         gives fewer but more reasonable detection boxes, where 
                number of internal keypoints is less than 256, dummy              fake objects are avoided. The advantages are relevant to 
                points are padded to ensure 256 points for achieving par-         the  proposal-aware  strategy  and  dual  transformer  for 
                allel  running  of  the  dual  transformer.  The  foreground      confidence prediction and accurate box refinement. 
                threshold α  and background threshold α  are set to 0.75          4.4 Ablation studies 
                            F                              B
                and  0.25.  Besides,  for  refinement,  128  proposals  are       A series of ablation studies are conducted for verifying the 
                randomly sampled into positive and negative with 1: 1             effectiveness of the point-voxel fusion features, proposal- 
                ratio, where the proposals with 3D IoU≥0.55 (i.e., α ) are        aware VSA module, and the proposed dual transformer 
                                                                       R
                considered as positive samples for subsequent regression,         aggregating point-wise and channel-wise information. For 
