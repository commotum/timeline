                ·0548·                                                                                                                                             Optoelectron. Lett. Vol.21 No.9 
                training process. 
                                                                                    An  overview  of  the  proposed  PV-DT3D  is  shown  in 
                   Experiments  on  KITTI  dataset  show  that  the 
                                                                                    Fig.1. The raw points are firstly voxelized in the form of 
                PV-DT3D achieves superior detection accuracy among 
                                                                                    region proposal networks (RPN) for high quality propos-
                point-voxel-based methods. Ablation evaluations confirm 
                                                                                    als. And the furtherest point sampling (FPS) algorithm is 
                the  effectiveness  of  the  proposed  proposal-aware  VSA 
                                                                                    adopted to select representative points to encode scene 
                module and dual transformer for 3D object detection. 
                                                                                    features. In order to take advantages of both points and 
                                                                                    voxels,  the  proposed  proposal-aware  VSA  module  en-
                2. Related work 
                                                                                    codes  multi-scale  voxel  features,  point  features  with 
                                                                                    fine-grained localization, and the information of propos-
                2.1 Point-based LiDAR 3D object detection 
                                                  [5,6]
                                                                                    als into keypoint features. Then the dual transformer in-
                Following the pioneering work         , point-based detection 
                                                                       [7]
                                                                                    vestigates  spatial  correlations  and  channel  contextual 
                methods  are  in  rapid  development.  PointRCNN   pro-
                                                                                    interactions among the large-scale points for confidence 
                posed a two-stage point-based framework for 3D object 
                                                                                    prediction and bounding-box regression. In Fig.1, BEV 
                detection,  which  generated  proposals  from  segmented 
                                                     [6]
                                                                                    represents the bird-eye view. 
                foreground points by PointNet++ . The 3D single stage 
                                            [13]
                                                                                    3.1 3D proposal generation and keypoints sampling 
                object detector (3DSSD)        presented a single-stage ap-
                                                                                    Due to the computational efficiency and high recall, the 
                proach by a novel point-sampling strategy. Based on the 
                                                                                               [8]
                                                                            [14]
                                                                                    SECOND  is adopted as the 3D backbone network and 
                3DSSD, semantics-augmented set abstraction (SASA)               
                                                                                                                     [23]
                                                                                    RPN. For the KITTI dataset          ,  given  an  N-points  3D 
                exploited  a  semantics-guided  point  sampling  algorithm 
                                                                                    scene with position coordinates and reflectance, the pro-
                for detection. 
                                                                                    posals generated by RPN include the following informa-
                2.2 Voxel-based LiDAR 3D object detection 
                                                                                                                                        prop
                                                                                             prop  prop  prop   prop  prop  prop
                                                                                                            
                                                                                                                                      
                                                                                    tion:                                       and         ,  rep-
                                                                                           x    , y   , z     ,l   , w    ,h
                Voxel-based methods aim to transform the unstructured 
                                                                                                            
                points into regular voxels, over which 3D CNNs are able 
                                                                                    resenting the center coordinate, length, width, height, and 
                to be directly applied. Generally, voxel-based approaches 
                                                                                    orientation of the proposal, respectively. The FPS strat-
                can  generate  high  quality  proposals.  The  sparsely  em-
                                                                                    egy is applied to sample n-keypoints, in such a manner 
                                                                [8]
                bedded convolutional detection (SECOND)  is an effec-
                                                                                    that  keypoints  are  uniformly  distributed  in  the  overall 
                tive  3D  sparse  convolution network to extract features 
                                                                                    scene. 
                                              [4]
                from voxels. Voxel R-CNN  used voxel region of inter-
                                                                                    3.2 Proposal-aware VSA module  
                est (RoI) pooling to extract neighboring voxel-wise fea-
                                                                                    3.2.1 Vanilla VSA module 
                                     [15]
                tures. Focals Conv        proposed a focal sparse convolu-
                                                                                                                                    [12]
                                                                                    The VSA is firstly exploited in PV-RCNN            , which en-
                tion module to enhance the capabilities of sparse CNNs. 
                                                                                    codes the multi-scale voxel features into keypoints. Spe-
                2.3 Point-voxel-based LiDAR 3D object detection 
                                                                                    cifically,  l   and  n   represent  the  k-th  level  during  3D 
                                                                                                k        k
                            [12]
                PV-RCNN  proposed VSA module aggregating voxel 
                                                                                    sparse convolution and the number of non-empty voxels 
                features and raw point features for refinement. The point 
                                                                                                                                        l      l
                                                                                                                                 l
                                                                                                                                        k       k
                                                                                                                                  k
                                                         [16]
                                                                                    at the k-th level, respectively. Denote                         
                                                                                                                               V  v ,,v
                                                                                                                                                
                density-aware        voxels       (PDV)          investigated 
                                                                                                                                        1
                                                                                                                                               n
                                                                                                                                                k
                point-density  and  proposed  point  density-aware  voxel 
                                                                                    as    the   set    of   voxel    spatial   coordinates     and 
                network to improve the multi-class accuracy. 
                                                                                               l       l
                                                                                       l
                                                                                               k        k
                                                                                        k
                                                                                                            as the set of voxel-wise features at 
                                                                                     F  f ,,f
                                                                                                        
                                                                                              1
                                                                                                       n
                2.4 Transformer in point clouds 
                                                                                                       k
                Due to the inherent permutation invariance and strong 
                                                                                    the k-th level. For a keypoint p, identify its non-empty 
                                                                                                                        i
                capacity  of  global  modeling,  transformers  have  been 
                                                                                    neighboring  voxel-wise  features  within  radius  r   and 
                                                                                                                                             k
                applied  to  point  cloud  classification  and  segmenta-
                                                                                                                                        l
                                                                                                                                         k
                                                                                                                                       v p
                                                                                    concatenate  the  local  relative  coordinates                to 
                    [17,18]                  [19-21]
                                                                                                                                         j    i
                tion     ,  object  detection      ,  and  so  on.  For  object 
                                                        [20]
                                                                                    indicate the corresponding voxel-wise features, as shown 
                detection, voxel transformer (VoTr)          presented an ef-
                                                                                    in   
                fective voxel transformer, where the sparse voxel module 
                                                                                                                  l
                                                                                                                         2
                                                                                                                   k
                and  submanifold  voxel  module  operate  on  empty  and 
                                                                                                                              
                                                                                                                 v p r
                                                                                                                   j    i     k
                                                                                                                              
                non-empty voxels, respectively. The channel-wise trans-
                                                                                                               T
                                                                                                                              
                                                                                          l        l   l             l
                                                                                                                            l
                                                                                          k        k   k              k
                                                                                                                            k
                                                                                                            
                                                                                                                                           (1) 
                                                                                        S       f  ;v    p    | v V          .
                                                                                                                              
                former architecture to constitute a two-stage 3D object 
                                                                                         i        j    j    i         j
                                                                                                            
                                                [11]
                                                                                                                              
                detection framework (CT3D)          exploited a channel-wise                                         l
                                                                                                                            l
                                                                                                                      k
                                                                                                                             k
                                                                                                                  f    F
                                                                                                                              
                                                                                                                     j
                                                                                                                              
                re-weighting  strategy  for  refinement.  The  single-stage 
                                                                                                                                     v
                                                                                                                                      l
                3D  object  detector  with  point-voxel  transformer 
                                                                                                                                      k
                                                                                       Then, the summarized voxel features  f           within the 
                                                                                                                                    i
                             [22]
                (PVT-SSD)       leveraged the strengths of both point and 
                                                                                                                             l
                                                                                                                              k
                                                                                                                            S
                                                                                    k-th  level  neighboring  voxel  set       of  p   are  used  to 
                                                                                                                                    i
                voxel features.   
                                                                                                                             i
                                                                                                                      [5]
                   However, the above methods have not fully leveraged 
                                                                                    generate features by PointNet . And the voxel features 
                                                                                       voxel
                the  potential  of  simultaneously  incorporating  both 
                                                                                     f        will  be  aggregated  at  four  convolution  levels. 
                                                                                      i
                point-wise and channel-wise transformers. Consequently, 
                                                                                    Besides  of  the  above  voxel-wise  operation,  in 
                we propose the PV-DT3D. 
                                                                                                                                   BEV
                                                                                                [12]
                                                                                                                                 f
                                                                                    PV-RCNN ,  BEV-based  features                       and  raw 
                                                                                                                                  i
                3. Methodology 
                                                                                                                     raw
                                                                                    PointNet-based    features  f        are  encoded  into  key-
                                                                                                                     i
