# BEV transformer for visual 3D object detection applied with retentive mechanism (2025)
Source: c99cc4-2025.pdf

## Core reasons
- The method centers on attention computation (spatial cross-attention and temporal self-attention) to build BEV features for 3D perception tasks.
- It introduces a retentive mechanism that decomposes attention to improve computational efficiency, aligning with a computation-mechanism contribution.

## Evidence extracts
- "Succinctly, spatial fea- tures within regions of interest (ROIs) are harvested via spatial cross-attention, while temporal dynamics are integrated using temporal self-attention, enriching the BEV with historical data." (p. 1)
- "Our spatial cross-attention is enhanced with a retentive mechanism, prioritizing information surrounding the focal points and enabling the decomposition of this attention mechanism to bolster computational efficiency." (p. 1)

## Classification
Class name: Computation & Reasoning Mechanism Proposal
Class code: 3

$$
\boxed{3}
$$
