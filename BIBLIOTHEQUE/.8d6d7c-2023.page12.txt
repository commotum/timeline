                                  SupplementaryMaterials
                                  A TrackletAssociation Module
                                  Weprovide an illustration of the proposed Tracklet Association Module (TAM) in Fig.6. The input
                                  to our TAM is constructed by concatenating the following attributes of the input tracklet pair along
                                  the feature dimension: (1) their (x,y,z) mask centroid coordinates, (2) their respective tracklet
                                  queries, (3) the frame gap between them, and (4) their mask IoU. The frame gap and mask centroid
                                  coordinates are expanded to 64-D each by applying sine/cosine activations with various frequencies.
                                  Theconcatenatedsetoffeaturesisinputtoa4-layerMLPwhichproducesascalarassociationscore
                                  for the input tracklet pair.
                                                               Mask Centroids            Queries         Frame Gap            Mask IoU
                                                                                                        t         t
                                                                                                         1         2
                                                             x
                                                                             x
                                                                                                             -
                                                                                          concatenate
                                                                                             MLP
                                                                                      Association Score
                                                        Figure 6: Illustration of the Tracklet Association Module (TAM).
                                  B DetailedQuantitative Results
                                  In this section, we first present the 3D panoptic metrics on the two benchmarks for reference and
                                  then provide the detailed class-wise metrics on the two datasets.
                                  Specifically, we present the 3D panoptic metrics on nuScenes validation set in Tab. 5. Please note
                                  that we did not include any other methods in the table since it’s unfair to directly compare with
                                  other single-scan based methods on the 3D benchmark. For completeness, we evaluate our Se-
                                  manticKITTI results using 3D panoptic metrics and report the results in Tab. 6 for both cases: eval-
                                  uating only those points which are projectable into the camera (Camera FoV) and also the Full Scan
                                  which includes all LiDAR scan points. Unsurprisingly, because of the missing camera image input,
                                  our performance on the full scan (60.7 PQ) is lower than that on the camera FoV only (64.3 PQ).
                                  Lastly, we present the detailed per-class results for: nuScenes val set (Tab. 7), nuScenes test set
                                  (Tab. 8), and SemanticKITTI val set (Tab.9).
                                                                               †      St      Th               St      Th              St      Th
                                                                     PQ     PQ     PQ      PQ       RQ     RQ       RQ       SQ     SQ      SQ
                                                4D-Former [Ours]    77.3    80.9    73.5    79.6    86.5    84.1    87.8    89.0    86.7    90.4
                                               Table 5: Results on nuScenes 3D panoptic segmentation validation benchmark
                                                                          †       St      Th              St      Th              St      Th
                                                                PQ     PQ      PQ      PQ       RQ     RQ      RQ       SQ     SQ      SQ       mIoU
                                            Full Scan          60.7    65.4    56.6    66.4    70.3    68.8     72.4    76.0    72.9    80.1    66.3
                                            CameraFoVonly      64.3    66.7    60.6    69.5    73.6    72.1     75.6    80.6    80.6    80.5    67.6
                                           Table 6: Results on SemanticKITTI 3D panoptic segmentation validation benchmark
                                                                                               12
