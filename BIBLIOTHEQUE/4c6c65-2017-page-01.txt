                                    Asimple neural network module
                                             for relational reasoning
                                           ∗                ∗
                             Adam Santoro,    David Raposo,    David G.T. Barrett,   Mateusz Malinowski,
                                        Razvan Pascanu,    Peter Battaglia,  Timothy Lillicrap
                                       adamsantoro@, draposo@, barrettdavid@, mateuszm@,
                                         razp@, peterbattaglia@, countzero@google.com
                                                              DeepMind
                                                       London, United Kingdom
                                                             Abstract
                           Relational reasoning is a central component of generally intelligent behavior, but has proven
                        diﬃcult for neural networks to learn. In this paper we describe how to use Relation Networks
                        (RNs) as a simple plug-and-play module to solve problems that fundamentally hinge on relational
                        reasoning. We tested RN-augmented networks on three tasks: visual question answering
                        using a challenging dataset called CLEVR, on which we achieve state-of-the-art, super-human
                        performance; text-based question answering using the bAbI suite of tasks; and complex reasoning
                        about dynamic physical systems. Then, using a curated dataset called Sort-of-CLEVR we show
                        that powerful convolutional networks do not have a general capacity to solve relational questions,
                        but can gain this capacity when augmented with RNs. Our work shows how a deep learning
                        architecture equipped with an RN module can implicitly discover and learn to reason about
                        entities and their relations.
                   1    Introduction
                   The ability to reason about the relations between entities and their properties is central to generally
                   intelligent behavior (Figure 1) [18, 15]. Consider a child proposing a race between the two trees
                   in the park that are furthest apart: the pairwise distances between every tree in the park must be
                   inferred and compared to know where to run. Or, consider a reader piecing together evidence to
                   predict the culprit in a murder-mystery novel: each clue must be considered in its broader context to
                   build a plausible narrative and solve the mystery.
        arXiv:1706.01427v1  [cs.CL]  5 Jun 2017Symbolic approaches to artiﬁcial intelligence are inherently relational [32, 11]. Practitioners deﬁne
                   the relations between symbols using the language of logic and mathematics, and then reason about
                   these relations using a multitude of powerful methods, including deduction, arithmetic, and algebra.
                   But symbolic approaches suﬀer from the symbol grounding problem and are not robust to small
                   task and input variations [11]. Other approaches, such as those based on statistical learning, build
                   representations from raw data and often generalize across diverse and noisy conditions [25]. However,
                   a number of these approaches, such as deep learning, often struggle in data-poor problems where the
                   underlying structure is characterized by sparse but complex relations [7, 23]. Our results corroborate
                   these claims, and further demonstrate that seemingly simple relational inferences are remarkably
                      ∗Equal contribution.
                                                                  1
