# Information Theory and Statistical Mechanics (1957)
Source: 0ac81e-1957.pdf

## Core reasons
- The paper is a physics and information theory work that reinterprets statistical mechanics via maximum-entropy inference, not a machine learning method or model.
- Its contribution is foundational and cross-disciplinary, framing entropy and probability distributions for statistical mechanics rather than proposing ML architectures, datasets, or benchmarks.

## Evidence extracts
- "Information theory provides a constructive criterion for setting up probability distributions on the basis of partial knowledge, and leads to a type of statistical inference which is called the maximum-entropy estimate." (p. 1)
- "In this paper we suggest a reinterpretation of statistical mechanics which accomplishes this, so that information theory can be applied to the problem of justification of statistical mechanics." (p. 2)

## Classification
Class name: External Foundations & Cross-Disciplinary Context
Class code: 6

$$
\boxed{6}
$$
