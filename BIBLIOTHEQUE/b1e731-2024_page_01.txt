                                   Searching Latent Program Spaces
                                     ClémentBonnet                  MatthewVMacfarlane
                               clement.bonnet16@gmail.com           University of Amsterdam
                                                                   m.v.macfarlane@uva.nl
                                                       Abstract
                            Program synthesis methods aim to automatically generate programs restricted to
                            a language that can explain a given specification of input-output pairs. While
                            purely symbolic approaches suffer from a combinatorial search space, recent
                            methods leverage neural networks to learn distributions over program structures to
                            narrow this search space significantly, enabling more efficient search. However,
                            for challenging problems, it remains difficult to train models to perform program
                            synthesis in one shot, making test-time search essential. Most neural methods
                            lack structured search mechanisms during inference, relying instead on stochastic
                            sampling or gradient updates, which can be inefficient. In this work, we propose
                            the Latent Program Network (LPN), a general algorithm for program induction
                            that learns a distribution over latent programs in a continuous space, enabling
                            efficient search and test-time adaptation. We explore how to train these networks
                            to optimize for test-time computation and demonstrate the use of gradient-based
                            search both during training and at test time. We evaluate LPN on ARC-AGI, a
                            programsynthesisbenchmarkthatevaluatesperformancebygeneralizingprograms
                            to new inputs rather than explaining the underlying specification. We show that
                            LPN can generalize beyond its training distribution and adapt to unseen tasks
                            by utilizing test-time computation, outperforming algorithms without test-time
                            adaptation mechanisms.
                     1   Introduction
                     Programsynthesisaimstoautomaticallygenerateprogramsthatsatisfyagivenspecification, typically
                     as input-output examples [Summers, 1977, Biermann, 1978]. Although symbolic approaches have
                     shownsuccess in limited domains [Gulwani, 2011, Albarghouthi et al., 2013, Osera and Zdancewic,
                     2015, Feser et al., 2015, Frankle et al., 2016], they fail to scale to modern challenges involving large
                     search spaces and complex patterns like in ARC-AGI [Chollet, 2019, Chollet et al., 2024]. To handle
                     the complexity and exponential search space of such difficult problems, neural approaches have
                     emergedthataimtolearnalgorithmsandprogramsfromdata[Graves,2014,Kurachetal.,2015,Reed
                     andDeFreitas,2015,Zarembaetal.,2016,Gauntetal.,2016,Buneletal.,2016,Bošnjaketal.,2017].
                     Such methods are required as they can significantly narrow down the programmatic search space by
                     leveraging biases learned through training, enabling more efficient search. Large language models
                     (LLMs)haveemergedasaparticularly strong architecture for program synthesis tasks, with language
                     pre-training helping to narrow the search space before any further problem-specific fine-tuning is
                     performed [Austin et al., 2021]. This can be particularly useful if generating problem-specific data is
                     too expensive or limited. However, models trained on a specific program distribution will likely only
                     generalize to problems close to this distribution and perform poorly on problems such as ARC-AGI,
                     which are specifically designed to be out of distribution for LLMs [Gendron et al., 2023]. Such
                     generative neural methods lack mechanisms for systematic search at test time, with models usually
                     resorting to stochastic sampling [Chen et al., 2021] or heuristic search [Zhang et al., 2023]. Hottung
                     et al. [2021b], Li et al. [2024a] and the ARC Prize 2024 leading team MindsAI explore fine-tuning a
                     Submitted to the ARC Prize 2024 competition [Chollet et al., 2024]. The code used in this research is open
                     source and available at https://github.com/clement-bonnet/lpn.
