                                                                                                                                            Top-1
                          (                                                                    Model            Method     #Params (M)
                            pos =pos                                                                                                       Acc(%)
                                0                                         (10)
                             pos =LN′(pos         )  (l = 1...L)                                                Default       5.717         72.14
                                l       l     l−1                                             DeiT-Ti            LaPE         5.721         72.94
               ThesubsequentprocessisthesameasinEq.(3)andEq.(4).                        (Touvron et al. 2021)    PVG          5.721         73.17
               In MPVG,wemodifyEq.(4)asfollowsaftergoingthrough                                                 MPVG          5.721         73.51
               the process of PVG:
                                                                                                                Default       22.050        79.81
                               y = LN(x       ) +LN′(pos )                (11)                 DeiT-S            LaPE         22.059        80.39
                                          L+1               0
                  To verify whether maintaining the counterbalance effect               (Touvron et al. 2021)    PVG          22.058        80.38
               of PE is beneficial, we deliver PE to the Last LN in PVG,                                        MPVG          22.059        80.61
               as shown in Eq. (11). We refer to this method as MPVG. In                                        Default       86.567        81.85
               the next section, we verify the superiority of MPVG by com-                     DeiT-B            LaPE         86.586        82.15
               paring the two methods. Also, we show that MPVG outper-                  (Touvron et al. 2021)    PVG          86.583        82.21
               forms previous approaches through experiments across var-                                        MPVG          86.584        82.42
               ious vision transformers and datasets.                                                           Default       28.589        81.37
                                       Experiment                                             Swin-Ti            LaPE         28.599        81.48
               Training Settings      All experiments are conducted on                    (Liu et al. 2021)      PVG          28.598        81.52
               an RTX 4090 with 4 GPUs using AdamW opti-                                                        MPVG          28.599        81.64
               mizer(LoshchilovandHutter2019),whileDeiT-Bistrained                                              Default       6.356         76.62
               onanRTX4090with8GPUs.                                                          CeiT-Ti            LaPE         6.361         76.89
                                                                                         (Yuan et al. 2021a)     PVG          6.361         77.14
               ImageClassification                                                                              MPVG          6.361         77.20
               Weevaluate the performance of our methods on ImageNet-                                           Default       4.310         71.76
               1K (Deng et al. 2009) and CIFAR-100 (Krizhevsky, Hin-                         T2T-ViT-7           LaPE         4.313         72.01
               ton et al. 2009). On ImageNet-1K, we conduct experiments                  (Yuan et al. 2021b)     PVG          4.312         71.91
               with DeiT (Touvron et al. 2021), Swin (Liu et al. 2021),                                         MPVG          4.313         72.28
               CeiT (Yuan et al. 2021a), and T2T-ViT (Yuan et al. 2021b).
               In the case of Swin, due to its staged architecture that gener-        Table 1: Top-1 accuracy comparison with various methods,
               ates hierarchical representations with the same feature map            usingDeiT-T,DeiT-S,DeiT-B,Swin-Ti,CeiT-Ti,T2T-ViT-7
               resolution as convolutional networks, both PVG and MPVG                onImageNet-1K.
               exceptionally include layer 0. All vision transformers are
               trained on 224×224 resolution images for 300 epochs, ex-                                                                     Top-1
               cept T2T-ViT-7, which is trained for 310 epochs.                                Model            Method     #Param(M)      Acc(%)
                  On CIFAR-100, we conduct experiments using ViT-                                               Default       3.740         74.90
               Lite(Hassanietal.2022)andT2T-ViT-7(Yuanetal.2021b).                            ViT-Lite           LaPE         3.744         75.52
               ViT-Litewastrainedfor310epochson32×32resolutionim-                       (Hassani et al. 2022)    PVG          3.742         76.67
               ages with a batch size of 128. In the case of T2T-ViT-7, we                                      MPVG          3.743         76.87
               transfer our pretrained T2T-ViTtodownstreamdatasetssuch                                          Default       4.078         83.22
               as CIFAR-100 and finetune the pretrained T2T-ViT-7 for 60                     T2T-ViT-7           LaPE         4.082         83.41
               epochs with a batch size of 128.                                          (Yuan et al. 2021b)     PVG          4.081         83.39
                  As shown in Table 1, For MPVG, the performance on                                             MPVG          4.081         83.51
               DeiT-Ti improved from 72.14% to 73.51%, representing
               an increase of approximately 1.37%. For DeiT-S, the per-               Table 2: Top-1 accuracy comparison with various methods,
               formance improved from 79.81% to 80.61%, an increase                   using ViT-Lite and T2T-ViT-7 on CIFAR-100. In the case of
               of approximately 0.80%. Additionally, there were perfor-               T2T-ViT, the results are based on fine-tuning the pretrained
               mance improvements of 0.57% in DeiT-B, 0.27% in Swin-                  model on the downstream dataset, CIFAR-100.
               Ti, 0.58% in CeiT, and 0.52% in T2T-ViT. Overall, MPVG
               outperforms the existing methods in all cases. Moreover, we
               confirm that MPVG consistently demonstrates superior per-              shows a 0.2% and 0.12% improvement over PVG for ViT-
               formancecomparedtoPVGacrossvariousvisiontransform-                     Lite and T2T-ViT-7, respectively. Overall, MPVG outper-
               ers.                                                                   forms existing methods across all cases on CIFAR-100.
                  As shown in Table 2, MVPG achieves overall perfor-
               mance improvements on CIFAR-100. Specifically, MPVG                    Object Detection
               improves the performance of ViT-Lite by 1.97%, from
               74.90% to 76.87%, and enhances the performance of T2T-                 On object detection, we evaluate our methods on COCO
               ViT-7 by 0.29% over the default. Additionally, MPVG                    2017 (Lin et al. 2014). To demonstrate the effectiveness of
