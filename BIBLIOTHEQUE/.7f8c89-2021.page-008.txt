                 194                                                                                           M.-H. Guo, J.-X. Cai, Z.-N. Liu, et al.
                 rates were 0.0001, with a cosine annealing schedule                   Table 2      Normal estimation average cosine-distance error on
                 to adjust the learning rate at every epoch.                           ModelNet40 dataset
                    Experimental results are shown in Table 1.                                  Method                   #Points             Error
                 Compared to PointNet and NPCT, SPCT makes                                   PointNet [1]                   1k                 0.47
                 a 2.8% and 1.0% improvement respectively. PCT                               PointNet++ [21]                1k                 0.29
                 achieves the best result of 93.2% overall accuracy.                         PCNN[4]                        1k                 0.19
                 Note that our network currently does not consider                           RS-CNN [40]                    1k                 0.15
                 normals as inputs which could in principle further                          NPCT                           1k                 0.24
                 improve network performance.                                                SPCT                           1k                 0.23
                 4.2     Normal estimation                on     ModelNet40                  PCT                            1k                0.13
                         dataset                                                       signiﬁcant improvement compared with PointNet and
                 The surface normal estimation is to determine the                     PCTachieves the lowest average cosine distance.
                 normal direction at each point. Estimating surface                    4.3     Part segmentation task on ShapeNet
                 normal has wide applications in, e.g., rendering. The                         dataset
                 task is challenging because it requires the approach to
                 understandtheshapescompletelyfordenseregression.                      Point cloud part segmentation is a challenging task
                 WeagainusedModelNet40asabenchmark, and used                           which aims to divide a 3D model into multiple
                 average cosine distance to measure the diﬀerence                      meaningful parts. We performed an experimental
                 between ground truth and predicted normals. For                       evaluation on the ShapeNet Parts dataset [31], which
                 all the three models, a batch size of 32.200 training                 contains 16,880 3D models with a training to testing
                 epochs were used. The initial learning rates were also                split of 14,006 to 2874. It has 16 object categories and
                 set as 0.01, with a cosine annealing schedule used                    50 part labels; each instance contains no fewer than
                 to adjust learning rate every epoch. As indicated                     two parts. Following PointNet [1], all models were
                 in Table 2, both our NPCT and SPCT make a                             downsampled to 2048 points, retaining point-wise
                                                                                       part annotation. During training, random translation
                 Table 1      Comparison with state-of-the-art methods on the          in [−0.2,0.2], and random anisotropic scaling in
                 ModelNet40 classiﬁcation dataset. Accuracy means overall accuracy.    [0.67,1.5] were applied to augment the input data.
                 All results quoted are taken from the cited papers. P = points, N =   During testing, we used a multi-scale testing strategy,
                 normals
                       Method             Input        #Points        Accuracy         where the scales are set in [0.7,1.5] with a step of
                    PointNet [1]             P            1k            89.2%          0.1. For all the three models, the batch size, training
                    A-SCN [32]               P            1k            89.8%          epochs, and the learning rates were set the same as
                    SO-Net [33]            P, N           2k            90.9%          the training of normal estimation task.
                    Kd-Net [34]              P           32k            91.8%             Table 3 shows the class-wise segmentation
                    PointNet++ [21]          P            1k            90.7%          results. The evaluation metric used is part-average
                    PointNet++ [21]        P, N           5k            91.9%          Intersection-over-Union, and is given both overall
                    PointGrid [35]           P            1k            92.0%          and for each object category. The results show that
                    PCNN[4]                  P            1k            92.3%          our SPCT makes an improvement of 2.1% and 0.6%
                    PointWeb [36]            P            1k            92.3%          over PointNet and NPCT respectively. PCT achieves
                    PointCNN [3]             P            1k            92.5%          the best results with 86.4% part-average Intersection-
                    PointConv [5]          P, N           1k            92.5%
                    A-CNN [37]             P, N           1k            92.6%          over-Union. Figure 5 shows further segmentation
                    P2Sequence [38]          P            1k            92.6%          examples provided by PointNet, NPCT, SPCT, and
                    KPConv [39]              P            7k            92.9%          PCT.
                    DGCNN[26]                P            1k            92.9%          4.4     Semantic segmentation task on S3DIS
                    RS-CNN [40]              P            1k            92.9%                  dataset
                    PointASNL [27]           P            1k            92.9%
                    NPCT                     P            1k            91.0%          The S3DIS is a indoor scene dataset for point cloud
                    SPCT                     P            1k            92.0%          semantic segmentation. It contains 6 areas and 271
                    PCT                      P            1k            93.2%          rooms. Each point in the dataset is divided into 13
