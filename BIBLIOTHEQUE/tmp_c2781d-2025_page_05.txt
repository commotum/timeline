                             Preprint, Under Review.
                             is made), compared to continuing with the existing plan p       . Conceptually, the value of generating
                                                                                          t−1
                             a new plan is rooted in its potential to reduce the agent’s uncertainty about optimal future actions
                             and to augment the context. By making strategic reasoning explicit, a new plan provides actionable
                             insights that go beyond what is implicitly encoded in the agent’s internal representation (weights and
                             activations). We formally define the planning advantage as the expected improvement in task-specific
                             value, conditioned on the decision to generate a new plan:
                                                                                     π              π
                                                  A     (c ) = E                  [V θ(c ,p ) −V θ(c ,p         )]
                                                    plan  t      p ∼ψ (·|c ,d =1)        t   t          t   t−1
                                                                   t  θ    t t
                             Here, V πθ(c ,p ) represents the expected future rewards under the new plan p , and similarly for the
                                          t   t                                                                t
                             existing plan p    . While the agent does not explicitly compute A        (c ) at each step, its decision
                                             t−1                                                   plan   t
                             policy ϕ is trained to generate outputs that approximate this benefit, as detailed in Section 3.3.
                                      θ
                             Theoverall cost of planning, C       , arises from several sources:
                                                              plan
                                                             C      =C          +C          +C
                                                               plan      tokens     latency      noise
                             These components include:
                             ComputationalCost: Thedirectcostofgeneratingaplan,proportionaltoitstokenlength: Ctokens =
                             k       · |p |. This is a direct and measurable cost that we can explicitly penalize during training.
                              tokens     t
                             Latency Cost: The cost associated with the real-world time ∆Tplan taken to plan. This is included
                             for theoretical completeness, as it is a critical factor in time-sensitive applications like robotics, where
                             its impact would be implicitly absorbed by the task reward. However, in the turn-based environments
                             used in our experiments (POGS and Crafter), the environment pauses for the agent’s turn, so this cost
                             is effectively zero (Clatency ≈ 0).
                             Instability Cost: This is a conceptual cost representing the performance degradation that can arise
                             from erratic or excessive replanning. Frequent replanning, especially with imperfect or inconsistent
                             plans, can introduce behavioral instability (e.g., inefficient backtracking, subgoal oscillation) that
                                                                                                                                  ¯
                             ultimately hinders task success. We model this conceptually as C              =k        · f  · (1 − Q ),
                                                                                                     noise     noise    p          p
                             where the negative impact of high planning frequency (fp) is magnified by low-quality plans (a low
                                                   ¯
                             average plan quality Q ). This cost is not explicitly calculated during training; instead, its effects are
                                                     p
                             implicitly penalized because they naturally lead to lower task rewards. Our backtracking analysis in
                             POGS(AppendixB)servesasanempiricalproxyforthisinstability.
                             3.2   PLAN DRIFT
                             The usefulness of an existing plan is not static; it typically diminishes over time as the agent acts
                             and the environment evolves. This decay in relevance, or plan drift, makes replanning increasingly
                             advantageous. Several factors contribute to how quickly plan drift occurs:
                             Plan Abstraction Level: High-level, conceptual plans (e.g., control the centre in chess) offer
                             robustness against minor environmental shifts and remain relevant longer, though they provide less
                             explicit guidance. Conversely, low-level detailed plans (e.g., specific move sequences) provide clearer
                             direction but become outdated quickly.
                             Planner and Model Accuracy: Plans from highly accurate models tend to be robust and endure
                             longer. In contrast, plans from imperfect models, like LLM natural language reasoning, may contain
                             inaccuracies that accelerate their decay.
                             Environment Dynamics: The environment’s volatility significantly influences plan lifespan. In
                             stable environments, plans retain value longer, while in dynamic environments with unpredictable
                             shifts (e.g., an opponent’s unexpected move), existing plans can become instantly obsolete.
                             Understanding plan drift helps explain why agents must periodically reassess when to allocate
                             compute to planning rather than following fixed planning strategies.
                                                                                 5
