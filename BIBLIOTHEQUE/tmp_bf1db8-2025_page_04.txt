                                     BBEHtask             SummaryofchangesmadeandthetaskitreplacesfromBBH                                                                                                     Mainreasoningskills
                                     Boardgame            Based on (Kazemi et al., 2023b) but with larger reasoning depth. Requires many hops of deductive reasoning as well as learning a specific           Deductive reasoning, learning on the fly,
                                     QA                   type of conflict resolution on the fly. Replaces Logical Deduction from BBH which needed only a few simple steps of deductive logic.                many-hopreasoning.
                                     Boolean      Ex-     Requires determining the truth value of an expression whose operands could themselves be textual/mathematical sub-expressions that                  Logical reasoning, many-hop reasoning.
                                     pressions            evaluate to True or False. Replaces the Boolean Expressions task from BBH which can be easily solved through one line of python code.
                                     BuggyTables          Requires understanding and reconstructing a large buggy table given the description of the bug, and then computing some conditional                 Datastructures, learningonthefly, needle
                                                          queries on it. Replaces Penguins in a table from BBH which required simple operations over small, clean tables.                                     in haystack
                                     Causal Under-        Asubsetofthecausalstories in (Nie et al., 2023) and improved examples from (Kıcıman et al., 2023). One subtask focuses on testing causal            Causal judgement/reasoning, logical rea-
                                     standing             judgment and the other on the ability to reason about necessary and sufficient causes. Replaces the Causal Judgement task from BBH.                 soning, counterfactual reasoning
                                     Disambiguation       A task created by the authors, requiring pronoun disambiguation over longer and more challenging text compared to the original                      Commonsenseunderstanding, linguistics
                                     QA                   Disambiguation QA task in BBH.                                                                                                                      knowledge.
                                     Dyck        Lan-     Involves finding errors in (potentially) faulty solutions to closing a sequence of brackets. It comes from (Tyen et al., 2023) and replaces the     Data structures, finding errors in reason-
                                     guage                Dycklanguages task from BBH which requires properly closing brackets as opposed to finding errors.                                                  ing traces.
                                     Geometric            Requires identifying the set of shapes drawn by a series of SVG commands while also dealing with distracting commands that do not                   Spatial reasoning, geometric understand-
                                     Shapes               participate in any shape. Replaces the Geometric Shapes from BBH which involved identifying a single shape.                                         ing, dealing with distractors.
                                     Hyperbaton           Requires inducing correct adjective order given examples on a new variant of English, and properly apply it to new examples. Replaces               Inductive reasoning, going against strong
                                                          Hyperbaton from BBH which required simply knowing the correct adjective order in English.                                                           prior, linguistic knowledge.
                                     Linguini             Comesfrom(Sánchezetal.,2024)andrequires linguistic reasoning and inductive reasoning to learn about a new language given some                       Inductive reasoning, linguistic knowl-
                                                          examples and then apply those learnings. Replaces Salient Translation Errors from BBH which involved simpler linguistic understanding.              edge.
                                     Movie Recom-         Given a number of sets of movies, the task is to determine which set has movies that are all likely to be liked by a specific group of people.      Reasoning through knowledge
                                     mendation            Replaces Movie Recommendation from BBH which required simple next movie recommendation.
                                     Multi-step           Requires learning new arithmetic operations and their compositions on the fly, and apply them to evaluate long expressions. Replaces the            Learning on the fly, many-hop reasoning.
                                     Arithmetic           Multi-step Arithmetic task from BBH which involved simple arithmetic over basic operations.
                                     New      Yorker      Comesfrom(Hesseletal., 2022; Zhang et al., 2024) and requires selecting the funniest caption for an image. We adopt the variant that                Humour understanding, commonsense
                                     Cartoon    Cap-      predicts the best caption only given the textual description of the image. This replaces the Ruin Names task from BBH which involved                understanding.
                                     tion (NYCC)          simpler humour understanding.
                                     Object Count-        Requires counting the number of objects of a certain type given a very long list of various objects and in presence of many types of                Long-context,     (multi-)needle    in   a
                                     ing                  distractors. Replaces the Object Counting from BBH which required simple counting in a short context.                                               haystack, dealing with distractors.
                                     Object Proper-       Requires keeping track of a large collection of objects with various properties while they go through multiple rounds of modification.              Temporal track keeping, long-range de-
                                     ties                 Replaces Colored Objects from BBH which required only recognizing the color of some objects.                                                        pendency.
                                     SARCTriples          Requires understanding sarcasm in Reddit posts and replies. Each problem requires determining the sarcastic-ness of three post/reply pairs.         Commonsense and sarcasm understand-
                                                          Replaces the Snark task in BBH which required simpler sarcasm understanding.                                                                        ing, compositional reasoning.
                                     Shuffled    Ob-      Along-context variant of the original Shuffled Objects from BBH which may also require remembering very long-range information.                     Temporal track keeping, long-context,
                                     jects                                                                                                                                                                    long-range dependency.
                                     Spatial Reason-      Adopts the SpatialLLMEval (Yamada et al., 2023) dataset requiring spatial reasoning over complex patterns and expands it to require                 Spatial understanding, many-hop reason-
                                     ing                  many-hops of reasoning. Replaces the navigation task from BBH which requires much simpler spatial understanding of navigation signals.              ing, long-range dependency.
                                     SportQA              Comes from (Xia et al., 2024) and requires reasoning combined with a high amount of sports knowledge. We use the hardest subset                     Knowledge-intensive reasoning, compo-
                                                          containing compositional questions. Replaces Sport Understanding from BBH which needed much simpler reasoning over sport knowledge.                 sitional reasoning.
                                     Temporal             Requires finding proper meeting times given multiple calendars (each corresponding to a temporal sequence) and various constraints.                 Temporal understanding, constraints sat-
                                     Sequences            Replaces the Temporal Sequence task from BBH which involves understanding only a single sequence.                                                   isfaction.
                                     Time      Arith-     ComesfromtheTestofTimebenchmark(Fatemietal.,2024)andinvolvesvariousoperations over various representations of date/time. We                         Temporal reasoning, compositional un-
                                     metic                created a compositional version of this task following (Hosseini et al., 2024). Replaces the Date Understanding task from BBH which                 derstanding.
                                                          involved significantly simpler operations over dates.
                                     WebofLies            Requires many-hop reasoning to predict the truthfulness of a set of people, and contains two subsets: one coming from the variant used in           Logical reasoning, many-hop reasoning.
                                                          LiveBench (White et al., 2024) and one novel variant that involves cases where the truthfulness of some individuals remains unknown but
                                                          newconclusions can be drawn from it nevertheless. Replaces the Web of Lies from BBH which involved simpler cases of this problem.
                                     WordSorting          Contains two subtasks: 1- sorting over a modified alphabet order, which goes against the strong prior of the model, and 2- finding errors in        Apply algorithms, Going against strong
                                                          sorting traces. Replaces the original Word Sorting task which required simple sorting.                                                              prior, Finding errors in reasoning traces.
                                     Zebra Puzzles        This is based on puzzles from (Shah et al., 2024) and requires applying various logical deduction rules to be solved. We add distracting            Constraint satisfaction, many-hop reason-
                                                          clues for extra challenge. Replaces Formal Fallacies from BBH which requires understanding formal fallacies in much simpler setups.                 ing, distractors, long-range dependency.
                                  Table 1: The tasks in BBEH in alphabetical order of the names, a high-level description of what they test for, the
                                  reasoning capabilities that they probe, and the task from BBH that they replace.
                                             solving the two problems in isolation)                                                                high diversity of original BBH dataset. In Table 1,
                                         • Knowledge-intense reasoning: the ability to                                                            weoutline a high-level description of the new tasks
                                             reason in domains where a great amount of                                                             in BBEH, how they have been constructed and
                                             domain knowledge is needed                                                                           whichtaskfromBBHthereplace,andwhatreason-
                                                                                                                                                   ing skills they target. The benchmark contains 200
                                  3 BIG-BenchExtraHard                                                                                             questions per task, except for the Disambiguation
                                                                                                                                                  QAtask where we have 120 questions. For more
                                  We create BIG-Bench Extra Hard (BBEH), a                                                                         details about the tasks and some intuitions from the
                                  dataset that tests the general reasoning capability                                                              experimental results and model failure modes, see
                                  of models on a wide array of reasoning skills. To                                                               AppendixA.Samplesfromafewofourtasksare
                                  this end, we build on the success of BBH and re-                                                                 provided in Figure 2.
                                  place each of the 23 tasks in BBH with another task
                                  that is in a similar reasoning domain and tests for                                                                   Akey challenge in creating model evaluation
                                  similar (or more) skills, but is more challenging                                                                benchmarks is ensuring they remain difficult for
                                  compared to the original one. Replacing each task                                                                frontier models. This is particularly true for rea-
                                  with another one in the same domain that tests for                                                               soning benchmarks, given the rapid progress in the
                                  similar capabilities ensures that we preserve the                                                                field over the past year, and especially for BBEH,
                                                                                                                                         26476
