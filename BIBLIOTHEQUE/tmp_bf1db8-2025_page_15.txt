                     Models       Gemma227bIT      Gemini2.0Flash-Lite   Gemini2.0Flash   GPT4o     DeepSeekR1    o3-mini (high)
                   Unknown%            77.6               67.4                73.3          82.4        39.7           65.5
                 Table 4: Percentage of unknown predictions on BoardgameQA for different models (only one third of the labels are
                  unknown).
                  not. We create this in a bottom-up fashion where        one so that the original table can be reconstructed
                 wegenerate smaller sub-expressions and then com-         basedonthatinformation. Examplesofconditional
                  bine them with logical operators. Once a large          queries include computing some statistics (count,
                  enough expression is created, we replace some of        sum, mean, stdev, median) of some columns while
                  the True and False operands with statements that        only considering rows where some columns have
                  evaluate to True or False. These could be mathe-        somespecific values.
                  matical expressions such as 24 - 2 is greater           A.4    Causal Understanding
                  than 48 / 2 (which evaluates to False) or textual
                  statements such as The capital of Canada is             In BBEHwereplacetheoriginal causal judgement
                  Ottawa (which evaluates to True). In both cases,        task in BBH with a set of questions that assess
                 we select these statements from a predefined set.        both (i) causal judgement (142 queries) and (ii) the
                 While determining the truth value of each of these       ability to determine necessary and sufficient causes
                  statements in isolation may be easy for many mod-       (58 queries). In this section we describe how these
                  els, including these statements makes it more diffi-    different sets of questions are obtained.
                  cult for models; otherwise, they can simply solve       CausalJudgement Thesequeriesarebasedon
                  the problem by generating a single line of python       the 144 causal stories included in the MoCa bench-
                  code.                                                   mark (Nie et al., 2023), which partially overlap
                    Wegenerate five expressions using the approach        with the sets of questions originally included in
                  outlined above, four of which evaluate to False         BBH.InMoCa,shortstoriesobtained from cogni-
                  and one of which evaluate to True. The job of the       tive science papers were given to 25 human annota-
                  modelisthentofindtheexpressionthatevaluatesto           tors who had to judge whether, based on the given
                 True. Since this is a five-way question, the random      story, a certain person or event caused a certain
                  chance accuracy is 20%.                                 outcome. The task was phrased as a binary task
                  A.3   BuggyTables                                       with Yes/No answers, and the ground truth label
                                                                          wasassigned according to the label chosen by the
                 The objective in this task is to be able to respond      majority of humans.
                  to conditional queries over tabular data, where the        However, the stories included complex norma-
                  information in the table are presented in a buggy       tive and logical factors, and for many of them there
                 waybutthedescriptionforthebugisalsopresented             wasalargedegree of disagreement among the hu-
                  so that the model can reconstruct the original ta-      manannotators. In cases where the human raters
                  ble based on that. As an example, we provide a          strongly disagreed on the answer (defined as hav-
                  row-major/column-major format of the table where        ing a difference of at most 20% between the “Yes”
                  the null values have been mistakenly removed, but       and “No” answers among the annotators), ques-
                 wealsoprovide the positions of the null values in        tions were additionally tagged as “Ambiguous”.
                  the original table so one can reconstruct the table     Based on this, we constructed the renewed task to
                  given the two pieces of information. As another         have 3 possible labels: Yes, No and Ambiguous.
                  example, we provide a buggy version of the table        Thelabel ambiguous was assigned to the 46 ques-
                 wheresomerandomvaluesareappendedattheend                 tions originally tagged as “Ambiguous” in MoCa.
                  of each row or each column, but we also specify         For instance, the label for example 36 in Table 5
                  howtheyhavebeenaddedsoonecanusethisinfor-               waschangedfromYestoAmbiguous,as15human
                  mation to remove them and reconstruct the original      annotators replied Yes while 10 replied No. In this
                  table. As yet another example, we provide a mark-       example we have that, on the one hand Billy was
                  downformatofthetable that mixes each two rows           asked to be in the room at 9am and cannot be given
                  of the table into one row, but also provide an expla-   the fault of entering the room and triggering the
                  nationofhoweachtworowshavebeenmergedinto                alarm. On the other hand, the alarm was set to
                                                                     26487
