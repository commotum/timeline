# Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI (2025)
Source: cc8713-2025.pdf

## Core reasons
- Proposes a self-improving evolutionary loop that changes how program synthesis is computed, combining search with iterative model updates.
- Focuses on a mechanism for search-and-learn computation rather than positional encodings, dimensional lifting, or introducing a new dataset/benchmark.

## Evidence extracts
- "SOAR,amethodthatlearnsprogramsynthesisby integrating language models into a self-improving evolutionary loop." (p. 1)
- "During the evolutionary search phase, SOAR uses an LLM to both sample candidate programs and refine them through targeted modifications, producing a diverse set of solution attempts (Section 3.2). In the learning phase, these search traces are used to fine- tune the underlying LLM, enhancing its ability to sample and refine programs for future tasks (Section 4.2)." (p. 3)

## Classification
Class name: Computation & Reasoning Mechanism Proposal
Class code: 3

$$
\boxed{3}
$$
