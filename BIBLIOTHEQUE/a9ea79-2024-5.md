# Mini-ARC: Solving Abstraction and Reasoning Puzzles with Small Transformer Models (2024)
Source: a9ea79-2024.pdf

## Core reasons
- The paper's main contribution is a Transformer-based approach to solving ARC puzzles that combines small models with test-time training and refinement, focusing on model/training methodology.
- It explicitly describes per-puzzle test-time fine-tuning as part of the method, emphasizing training/inference strategy rather than new benchmarks or positional encoding innovations.

## Evidence extracts
- "In this paper, I explain a novel approach to solving ARC puzzles that uses (1) small (67M param) Transformer models trained exclusively on ARC puz-
                 zles, (2) test-time training (TTT), and (3) refinement." (p. 1)
- "In addition to the pre-trained models, I also set up a test-time training scheme where models could be
                 fine-tuned for each individual puzzle as they solve it." (p. 4)

## Classification
Class name: ML Foundations & Principles
Class code: 5

$$
\boxed{5}
$$
