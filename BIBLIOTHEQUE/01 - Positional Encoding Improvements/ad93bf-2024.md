# Rotary Position Embedding for Vision Transformer (Not specified in the paper.)
Source: ad93bf-2024.pdf

## Core reasons
- The paper targets transformer-based vision models and explicitly aims to improve positional embedding by applying an extended RoPE.
- It critiques existing 2D RoPE with axial frequencies and introduces a modified positional encoding (RoPE-Mixed) to address that limitation.

## Evidence extracts
- "This paper aims to improve position embedding for vision transformers by applying an extended Rotary Position Embedding (RoPE) [29]." (Section 1 Introduction)
- "Although 2D RoPE using axial frequencies was used in pioneer works [7,18,19], we argue that it lacks the ability to handle diagonal directions, which are preferred in convolution networks by the square kernel. To cope with the diagonal direction of RoPE, we propose to use mixed axis frequencies for 2D RoPE, named RoPE-Mixed." (Section 1 Introduction)

## Classification
Class name: Positional Encoding Improvement Proposal
Class code: 1

$$
\boxed{1}
$$
