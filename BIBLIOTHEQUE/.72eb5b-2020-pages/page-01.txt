        Just-in-Time Learning for Bottom-Up Enumerative Synthesis
        SHRADDHABARKE,UCSanDiego,USA
        HILAPELEG,UCSanDiego,USA
        NADIAPOLIKARPOVA,UCSanDiego,USA
        Akeychallenge in program synthesis is the astronomical size of the search space the synthesizer has to
        explore. In response to this challenge, recent work proposed to guide synthesis using learned probabilistic
        models. Obtaining such a model, however, might be infeasible for a problem domain where no high-quality
        training data is available. In this work we introduce an alternative approach to guided program synthesis:
        instead of training a model ahead of time we show how to bootstrap one just in time, during synthesis, by
        learning from partial solutions encountered along the way. To make the best use of the model, we also propose
        anewprogramenumerationalgorithmwedubguidedbottom-upsearch,whichextendstheefocientbottom-up
                                                                             227
        search with guidance from probabilistic models.
          Weimplementthisapproachinatoolcalled Probe, which targets problems in the popular syntax-guided
        synthesis (SyGuS) format. We evaluate Probe on benchmarks from the literature and show that it achieves
        significant performance gains both over unguided bottom-up search and over a state-of-the-art probability-
        guided synthesizer, which had been trained on a corpus of existing solutions. Moreover, we show that these
        performance gains do not come at the cost of solution quality: programs generated by Probe are only slightly
        moreverbosethantheshortest solutions and perform no unnecessary case-splitting.
        CCSConcepts:•Softwareanditsengineering→Domainspecificlanguages;Programmingbyexam-
        ple.
        Additional Key Words and Phrases: Program Synthesis, Probabilistic models, Domain-specific languages
        ACMReferenceFormat:
        Shraddha Barke, Hila Peleg, and Nadia Polikarpova. 2020. Just-in-Time Learning for Bottom-Up Enumerative
        Synthesis. Proc. ACM Program. Lang. 4, OOPSLA, Article 227 (November 2020), 29 pages. https://doi.org/10.
        1145/3428295
        1 INTRODUCTION
        Consider the task of writing a program that satisfies examples in Fig. 1. The desired program
        must return the substring of the input string s on different sides of the dash, depending on the
        input integer n. The goal of inductive program synthesis is to perform this task automatically, i.e. to
        generate programs from observations of their behavior.
          Inductive synthesis techniques have made great strides in recent years [Feng et al. 2017a,b;
        Feser et al. 2015; Gulwani 2016; Osera and Zdancewic 2015; Shi et al. 2019; Wang et al. 2017a],
        and are powering practical end-user programming tools [Gulwani 2011; Inala and Singh 2018;
        Le and Gulwani 2014]. These techniques adopt different approaches to perform search over the
        space of all programs from a domain-specific language (DSL). The central challenge of program
        synthesis is scaling the search to complex programs: as the synthesizer considers longer programs,
        Authors’ addresses: Shraddha Barke, UC San Diego, USA, sbarke@eng.ucsd.edu; Hila Peleg, UC San Diego, USA, hpeleg@
        eng.ucsd.edu; Nadia Polikarpova, UC San Diego, USA, npolikarpova@eng.ucsd.edu.
        Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee
        provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
        the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses,
        This work is licensed under a Creative Commons Attribution 4.0 International License.
        contact the owner/author(s).
        ©2020Copyrightheldbytheowner/author(s).
        2475-1421/2020/11-ART227
        https://doi.org/10.1145/3428295
                      Proc. ACMProgram. Lang., Vol. 4, No. OOPSLA, Article 227. Publication date: November 2020.
