                              Just-in-Time Learning for Bottom-Up Enumerative Synthesis                                                                                                                                                                                               227:9
                                               Partial Solution                                     ExamplesSatisfied                                                                                    PCFGcosts
                                                                                                                              âˆ…                                          arg,"","<",">",replace,concat â†¦â†’ 3
                                                         replace-2                                                        {í µí±’0}                                   arg,"","<",">",replace â†¦â†’ 2;concat â†¦â†’ 3
                                                         replace-3                                                    {í µí±’0,í µí±’1}                                   arg,"","<",">",replace â†¦â†’ 2;concat â†¦â†’ 4
                              Fig. 10. Just-in-time learning: as the search encounters partial solutions that satisfy new subsets of examples,
                              PCFGcostsareadjustedandtherelative cost of concat, which is not present in the solution, increases.
                              irrelevant syntactic features. In our running example, there are in fact more than 3100 programs
                              that satisfy at least one of the examples í µí±’0 or í µí±’1. For instance, the program
                                                                replace (replace (replace (concat arg "<") "<" "") "<" "") ">" ""
                              satisfies í µí±’0, but contains the concat production, so if we use this program to update the PCFG,
                              wewouldsteerthesearchawayfromthefinalsolution. Hence, the core challenge is to identify
                              promising partial solutions, and only use those to update the PCFG.
                                     Acloser look at this program reveals that it has the same behavior as the shorter program
                              replace-2, but it contains an irrelevant subexpression that appends "<" to arg only to immediately
                              replace it with an empty string! In our experience, this is a common pattern: whenever a partial
                              solution í µí±â€² is larger than another partial solution í µí± but solves the same subset of examples, then í µí±â€²
                              often syntactically differs from í µí± by an irrelevant subexpression, which happens to have no effect
                              ontheinputs solved by the two programs. Following this observation, we only consider a partial
                              solution í µí± promisingÃand use it to update the PCFGÃwhen it is one of the shortest solutions that
                              covers a given subset of examples.
                                     Poweredbyjust-in-time learning, Probe is able to find the solution replace-6 within 23 seconds,
                              starting from a uniform PCFG: only a slight slowdown compared with having a biased PCFG from
                              the start. Note that EuPhony, which uses a probabilistic model learned from a corpus of existing
                              solutions, is unable to solve this benchmark even after 10 minutes.
                              4 GUIDEDBOTTOM-UPSEARCH
                              In this section, we describe our guided bottom-up search algorithm. We first formulate our problem
                              of guided search as an instance of an inductive SyGuS problem. We then present our algorithm
                              that enumerates programs in the order of decreasing likelihood.
                              4.1            Preliminaries
                              Context-free Grammar. A context-free grammar (CFG) is a quadruple G = (N,Î£,S,R), where
                              Ndenotesafinite, non-empty set of non-terminal symbols, Î£ denotes a finite set of terminals, S
                              denotes the starting non-terminal, and R is the set of production rules. In our setting, each terminal
                              í µí±¡    âˆˆ Î£ is associated with an arity arity(í µí±¡) â‰¥ 0, and each production rule R âˆˆ R is of the form
                              Nâ†’(í µí±¡ N ... N ),whereN,N ,...,N âˆˆ N,í µí±¡ âˆˆ Î£, and arity(í µí±¡) = í µí±˜6. We denote with R(N) the
                                                         1                   í µí±˜                                    1                   í µí±˜
                              set of all rules R âˆˆ R whose left-hand side is N. A sequence í µí»¼ âˆˆ (N âˆª Î£)âˆ— is called a sentential form
                              andasequenceí µí±  âˆˆ Î£âˆ— is a called a sentence. A grammar G defines a (leftmost) single-step derivation
                              relation on sentential forms: í µí± Ní µí»¼ â‡’ í µí± í µí»½í µí»¼ if N â†’ í µí»½ âˆˆ R. The reflexive transitive closure of this
                              relation is called (leftmost) derivation and written â‡’âˆ—. All grammars we consider are unambiguous,
                              i.e. every sentential form has at most one derivation.
                              6Anastute reader might have noticed that we can formalize this grammar as a regular tree grammar instead; we decided to
                              stick with the more familiar context-free grammar for simplicity.
                                                                                      Proc. ACMProgram. Lang., Vol. 4, No. OOPSLA, Article 227. Publication date: November 2020.
