2511.14761v1 [cs.CV] 18 Nov 2025

e
e

arXiv

ARC Is a Vision Problem!

Keya Hu

Abstract

The Abstraction and Reasoning Corpus (ARC) is designed
to promote research on abstract reasoning, a fundamen-
tal aspect of human intelligence. Common approaches to
ARC treat it as a language-oriented problem, addressed by
large language models (LLMs) or recurrent reasoning mod-
els. However, although the puzzle-like tasks in ARC are in-
herently visual, existing research has rarely approached the
problem from a vision-centric perspective. In this work, we
formulate ARC within a vision paradigm, framing it as an
image-to-image translation problem. To incorporate visual
priors, we represent the inputs on a “canvas” that can be
processed like natural images. It is then natural for us to
apply standard vision architectures, such as a vanilla Vi-
sion Transformer (ViT), to perform image-to-image map-
ping. Our model is trained from scratch solely on ARC
data and generalizes to unseen tasks through test-time train-
ing. Our framework, termed Vision ARC (VARC), achieves
60.4% accuracy on the ARC-1 benchmark, substantially
outperforming existing methods that are also trained from
scratch. Our results are competitive with those of leading
LLMs and close the gap to average human performance. '

1. Introduction

Learning and abstracting concepts from a small number of
demonstrations is a key feature of intelligence. The Ab-
straction and Reasoning Corpus (ARC) benchmark [12] was
designed to incentivize machine learning research aimed at
improving these capabilities. ARC consists of a collection
of puzzle-like tasks (Fig. |, top), each containing only a
few examples governed by a unique underlying transfor-
mation rule. The model is expected to make predictions
on each unseen task given a few examples. While humans
are capable of solving various ARC tasks [25, 31, 32], the
benchmark remains highly challenging for today’s leading
machine learning systems [44, 42].

The ARC problem has attracted significant attention, and
substantial progress has been made in recent years [13].

'Project webpage: https: //github.com/lillian039/VARC.

AliCy — Linlu Qiu
Rungian Wang Yeyin Eva Zhu
MIT

Xiaoman Delores Ding
Jacob Andreas Kaiming He

Test task
x y

Te Pl

( Training tasks

iia tau

Yinfer

?

Zinfer model prediction
[TASK]

Tr oi ae
5

Figure 1. The ARC benchmark (top) consists of a collection of
many different tasks, where each task has a few (e.g., 2-4) exam-
ples. We propose the Vision ARC (VARC) framework, which ad-
dresses the ARC problem as an image-to-image translation prob-
lem, from a computer vision perspective (bottom). In this illus-
tration, the underlying concepts of the three tasks can be roughly
described by humans as: “reflection” (left), “symmetry” (middle),
and “gravity” (right). These concepts are closely related to the vi-
sual and physical world.

Among a wide variety of methods, those based on large
language models (LLMs) have proven highly competi-
tive. These methods generally convert ARC inputs into se-
quences of text tokens for language modeling. Representa-
tive methods may involve inductive reasoning [54, 7, 50, 6],
transductive reasoning [1, 19, 45], or a combination of both
[35, 8, 40]. The LLMs are pre-trained on internet-scale data,
from which they learn transferable common sense.

Most recently, research on recurrent models [53, 27]
has achieved impressive results on ARC without relying on
internet-scale data. These models are trained from scratch
on ARC data only and perform inference through recurrent,
iterative reasoning. Although they do not rely on large-scale
language pre-training, these recurrent models draw strong
inspiration from the success of language modeling.

Interestingly, although the ARC puzzles are typically
presented visually, existing research has rarely framed ARC
as a vision-centric problem. In fact, many concepts in ARC
