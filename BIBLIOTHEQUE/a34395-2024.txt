                               DiffSAT: Differential MaxSAT Layer for SAT Solving
                                              YuZhang1,           Hui-Ling Zhen2,             MingxuanYuan2,               Bei Yu1
                                             1Chinese University of Hong Kong                     2 Huawei Noah‚Äôs Ark Lab
                Abstract                                                                     Thefirst end-to-end learning-based solver is NeuroSAT [16], which
                   Modernbooleansatisfiability (SAT) solvers heavily rely on the             models the SAT problem as a classification task and trains a GNN-
                conflict-driven clause learning (CDCL) framework to ef√èciently               based classifier with single-bit supervision (satisfiable or not). SAT-
                search the solution space and resolve conflicts during the search            former [17] takes CNF instances as GNN inputs and leverages a
                process. However, CDCLstill faces challenges in terms of searching           hierarchicaltransformertocapturetherelationshipsamongclauses,
                ef√èciency, particularly in complex cases with deep/symmetric/tree-           search for UNSAT cores, and determine whether the instance is
                based structures. To address this issue, numerous learning-driven            satisfied or not. In general, such learning-based methods usually
                methodshavebeenproposed.However,thesemethodsprimarily                        begin at a graph neural network to get the embedding vectors of
                focus on utilizing data-driven approaches to enhance searching               literals and clauses and end with a classifier to determine whether
                ef√èciency and decision accuracy, while overlooking the core issue            the whole problem can be satisfied or not. Meanwhile, if satisfied,
                of the state explosion within the CDCL framework itself when the             one of the satisfying assignments can be decoded from k-means
                searchstartsatthewrongpoint.Inthispaper,weintroduceDiffSAT,                  clusters of literal embeddings [16, 18]. Despite the significant im-
                a novel approach that differentiates the discrete SAT problem and            provements, current end-to-end learning-based approaches cannot
                progressively searches for satisfying assignments through the for-           beat traditional solvers in both accuracy and solving ef√èciency.
                wardandbackwardpropagationofaneuralnetworklayer.DiffSAT                         Ontheother hand, learning-aided approaches try to learn an
                initiates with an initial assignment obtained through semidefinite           ef√ècient heuristic and are integrated as a plug-in component with
                approximation and iteratively explores the solution space guided             the traditional SAT solvers. For example, NeuroCore [15] improves
                by a differential loss function. Notably, DiffSAT does not require           the variable branching heuristic in CDCL SAT solvers by predicting
                training data and can be applied to large-scale problems that have           the variables involved in the unsatisfiable core (i.e., a subset of
                not been seen before. The experimental results provide evidence              the SAT formula that remains unsatisfiable). NeuroBack [21] lever-
                that DiffSAT exhibits superior performance compared to existing              ages GNNs to predict phases (i.e., values) of variables appearing
                end-to-end learning-based SAT solvers and can be generalized to              in the majority (or even all) of the satisfying assignments that are
                solve large-scale SAT problems. Additionally, DiffSAT surpasses              essential for CDCL SAT solving. Though accelerating CDCL SAT
                state-of-the-art SAT solvers in effectively finding satisfying assign-       solvers, the upper bound performance of learning-aided solvers is
                ments for complex problems in SATCOMP-2023.                                  ultimately limited by the capabilities of the underlying backbone
                                                                                             solvers. When the input CNF contains some complex structures,
                1 Introduction                                                               such as cyclic or tree-based structures, it is easy for the CDCL SAT
                   Boolean satisfiability is the problem of determining if there ex-         solver to trap the iterative structure in an infinite loop. For instance,
                ists an assignment for all variables that satisfies a given Boolean          consider the benchmark ‚Äúsgen3-n260-s62321009-sat‚Äù from the SAT
                formula. In general, a boolean formula Ì†µÌºô can be represented as              Competition 2023 [1]. This particular SAT problem consists of only
                a conjunctive normal form (CNF) consisting of a conjunction of               260 variables and 884 clauses, making it relatively small in size.
                clauses Ì†µÌºî, each of which denotes a disjunction of literals. A lit-          However, despite its small size, it poses a significant challenge for
                eral is either a variable Ì†µÌ±• or its complement. Each variable can            state-of-the-art CDCL-based SAT solvers. None of these solvers
                                            Ì†µÌ±ñ                                               can produce a satisfying assignment within a time limit of 10,000
                be assigned a logic value, either 0 or 1. An SAT solver either finds         seconds.Thisexamplehighlightsascenariowheretheinitialsearch
                an assignment such that Ì†µÌºô is satisfied or proves that no such as-           path of a SAT solver deviates significantly from the correct path.
                signment exists, i.e., UNSAT. Particularly, the 3-SAT problem is             Consequently, the CDCL framework‚Äôs inability to rectify errors
                the first proven NP-complete problem [5]. Modern SAT solvers are             causes the solver to become trapped in an infinite loop.
                based on the CDCL algorithm, and it works as a basic engine for                 Considering the above, we introduce DiffSAT, a differential ap-
                manyapplications like circuit testing and formal verification. The           proach aimed at progressively searching for satisfying assignments
                mainadvantageofCDCL-basedsolversistheirabilitytolearnfrom                    for SAT problems. First, DiffSAT generalizes the original SAT prob-
                conflicts and use that knowledge to prune the search space more              lem into a maximum satisfiable (MaxSAT) problem and employs
                effectively. However, existing CDCL-based SAT solvers still suffer           a semidefinite approximation of the MaxSAT problem to obtain
                from exponential searching space and are unable to correct errors            aninitial solution that satisfies as many clauses as possible. Then,
                through a learning-from-mistakes system, resulting in an infinite            DiffSAT introduces a network layer, the MaxSAT layer, that differ-
                loop in solving complex SAT problems [2].                                    entiates the proposed loss function and facilitates the search for
                   Recently, a growing number of learning-based approaches have              satisfying assignments. The main contributions are summarized as:
                been studied extensively to improve SAT-solving ef√èciency, par-
                ticularly under the consideration of CNF structure learning with              ‚Ä¢ WemodeltheSATsolvingfromanovelperspective.Specifically,
                graph neural networks (GNNs). The learning-based approaches fall                 for satisfiable CNFs, we transform the SAT problem into a
                into two directions. On the one hand, the end-to-end approaches                  minimization problem and iteratively search for the satisfying
                propose to solve SAT problems from scratch in a standalone way.                  assignment in a differential manner;
                                    ‚Ä¢ Weintroduceanovelneuralnetworklayer,termedtheMaxSAT                                                                                                       graph (VCG), DiffSAT designs a loss function for each clause and
                                          layer, which integrates SAT solving into both the forward and                                                                                         treats the partially connected graph as a network layer, named the
                                          backward pass. The MaxSAT layer functions as a solver, sys-                                                                                           MaxSATlayer. Notably, the MaxSAT layer does not contain any
                                          tematically exploring the solution space and iteratively refining                                                                                     unknownparameters, as the weights of existing connections are
                                         variable assignments using gradient descent.                                                                                                           essentially the signs of variables in clauses, thereby eliminating the
                                    ‚Ä¢ Ourempiricalevaluationonrandomdatasetsdemonstratesthat                                                                                                    needfor labeled data or a neural network training phase. During
                                          DiffSAT surpasses previous end-to-end learning-based solvers                                                                                          the forward pass, the MaxSAT layer checks the satisfiability of all
                                          andachieves performance comparable to the mainstream SAT                                                                                              clauses based on the input assignment. In the backward pass, the
                                          solver, Kissat, on large benchmarks. More importantly, DiffSAT                                                                                        MaxSATlayercalculates the gradients of variables in the falsified
                                          requires significantly less runtime compared to state-of-the-art                                                                                      clauses and updates the variables with the largest absolute gradient,
                                          SATsolversinfindingsatisfyingassignmentsforsomeintricate                                                                                              thereby pushing the variable assignments towards satisfying more
                                          problems in the SAT Competition 2023.                                                                                                                 clauses. This approach allows DiffSAT to embed logic formulas
                                 2 Preliminaries                                                                                                                                                into a network layer and continuously update variable assignments
                                                                                                                                                                                                differentially, avoiding the exponential discrete search in traditional
                                 2.1            ApproximationalgorithmsforMaxSAT                                                                                                                SATsolvers and achieving ef√ècient SAT solving.
                                       In addition to exact solvers based on combinatorial search, there                                                                                        3.1            FromSATtoMaxSAT
                                 have been several approaches that explore approximation algo-                                                                                                        The MaxSAT problem serves as the optimization counterpart
                                 rithmsfortheMaxSATproblem,bothfromtheoreticalandpractical                                                                                                      to the satisfiability problem, aiming to maximize the number of
                                 perspectives. These approaches primarily aim to achieve a high ap-                                                                                             satisfied clauses. It is worth noting that if a solution to the MaxSAT
                                 proximation ratio Ì†µÌªº, which refers to the quality of the approximate                                                                                           problem can satisfy all the clauses, the variable assignment can be
                                 solution compared to the optimal solution as                                                                                                                   used to constitute a valid solution for the original SAT problem. In
                                                    Approximated objective ‚â§ Ì†µÌªº ¬∑ Optimal objective.                                                                                            the case of a SAT problem expressed in conjunctive normal form
                                 Thefirst approximation algorithm for the MaxSAT problem was                                                                                                    withÌ†µÌ±õ binary variables andÌ†µÌ±ö clauses, its MaxSAT formulation can
                                 proposed in [7], which utilized a linear programming (LP) approxi-                                                                                             be represented as follows:
                                                                                                                                                                                                                                                               Ì†µÌ±ö       Ì†µÌ±õ
                                 mationwithanapproximationratioofÌ†µÌªº = 0.75.Buildinguponthis,                                                                                                                                                                  ‚àëÔ∏Å√ú                        Àú
                                 they also introduced a semidefinite programming (SDP) approxi-                                                                                                                                         Àú     max Ì†µÌ±õ                         1{Ì†µÌ±†Ì†µÌ±ñÌ†µÌ±óÌ†µÌ≤óÌ†µÌ±ñ > 0},                                             (1)
                                 mationfortheMax2SATproblemwithanimprovedapproximation                                                                                                                         √î                        Ì†µÌ≤ó‚àà{‚àí1,1}             Ì†µÌ±ó =1 Ì†µÌ±ñ=1
                                 ratio of Ì†µÌªº = 0.878. This SDP-based approach formed the foundation                                                                                             where                is the logical ‚Äúor‚Äù symbol. TheÌ†µÌ±ö clauses can also be repre-
                                 for subsequent approximation methods in MaxSAT. Another SDP                                                                                                                                                                                      Ì†µÌ±ö√óÌ†µÌ±õ
                                 approach, presented in [6], further refined the approximation ratio                                                                                            sentedasaclausematrixÌ†µÌ±∫ ‚àà {1,‚àí1,0}                                                          , witheachelementÌ†µÌ±†Ì†µÌ±ñÌ†µÌ±ó in
                                                                                                                                                                                                                                                                   Àú
                                                                                                                                                                                                Ì†µÌ±∫ denoting the sign of variable Ì†µÌ≤óÌ†µÌ±ñ in clause Ì†µÌ±ó. For conversing to loss,
                                 toÌ†µÌªº = 0.931fortheMax2SATproblemandextendedittohandlethe                                                                                                       weformulateEquation(1) in its minimization, or unsatisfiability,
                                 Max3SATproblemwithanapproximationratioofÌ†µÌªº = 0.875 [11].                                                                                                       form as
                                                                                                                                                                                                                                                               Ì†µÌ±ö       Ì†µÌ±õ
                                 Exploiting the high approximation quality of SDP relaxation for the                                                                                                                                                          ‚àëÔ∏Å√õ                        Àú
                                 MaxSATproblem,arecentwork[20]combinedlow-ranksemidef-                                                                                                                                                   Àú    min Ì†µÌ±õ                         1{Ì†µÌ±†Ì†µÌ±ñÌ†µÌ±óÌ†µÌ±£Ì†µÌ±ñ < 0},                                             (2)
                                 inite programming with a branch-and-bound strategy, achieving                                                                                                                 √ì                        Ì†µÌ≤ó‚àà{‚àí1,1}             Ì†µÌ±ó =1 Ì†µÌ±ñ=1
                                 state-of-the-art performance for both the Max2SAT and Max3SAT                                                                                                  where                is the logical ‚Äúand‚Äù symbol. Indeed, the objective value in
                                 problems in the MAXSAT 2016 competition.                                                                                                                       Equation(2)is0ifandonlyifasatisfiablesolutioncanbefound.We
                                                                                                                                                                                                aimtodetermineacontinuousupperbound,referredtoas‚Äúloss‚Äù,for
                                 2.2            ProblemFormulation                                                                                                                              eachclauseinordertomeasureitsunsatisfiability.Thelosstakesan
                                       Deep-learning-based SAT solvers face challenges when attempt-                                                                                            upperboundof+1iftheclauseisunsatisfied,andzeroorlessifitis
                                 ing to solve SAT problems in an end-to-end manner, while tradi-                                                                                                satisfied. Therefore, the minimization problem in Equation (2) can
                                 tional CDCL SAT solvers still struggle with the exponential search                                                                                             be solved by introducing a quadratic loss function [20] as follows:
                                                                                                                                                                                                                                                       √ç
                                 spaces.Toaddresstheselimitations,weproposeanovelapproachto                                                                                                                                                                Ì†µÌ±õ            Àú     2                          2
                                 enhance end-to-end SAT solving. Our approach involves exploring                                                                                                                                   lossÌ†µÌ±ó = (              Ì†µÌ±ñ=0 Ì†µÌ±†Ì†µÌ±ñ Ì†µÌ±ó Ì†µÌ±£Ì†µÌ±ñ )    ‚àí(Ì†µÌ±öÌ†µÌ±ó ‚àí 1) ,                                             (3)
                                 adifferentiable loss function and integrating a MaxSAT solver layer                                                                                                                                                                        4Ì†µÌ±öÌ†µÌ±ó
                                                                                                                                                                                                                                                      Ì†µÌ±ö
                                 into deep learning systems. By doing so, we aim to overcome the                                                                                                                                      loss = ‚àëÔ∏ÅlossÌ†µÌ±ó,                                                                                   (3a)
                                 inherent limitations of CDCL systems when dealing with complex                                                                                                                                                      Ì†µÌ±ó =1
                                 CNFs. In this paper, our primary focus is on exploring satisfying                                                                                              whereloss istheobjectivevalueof Ì†µÌ±ó-thclause,lossistheobjective
                                 variableassignmentsforsatisfiedproblems,astacklingunsatisfiable                                                                                                                       Ì†µÌ±ó
                                 certification presents a distinct and separate challenge.                                                                                                      value of all clauses, andÌ†µÌ±öÌ†µÌ±ó is the number of literals in clause Ì†µÌ±ó, e.g.,
                                                                                                                                                                                                3 for the Max3SAT problem. The loss function in Equation (3) can
                                 3 Algorithm                                                                                                                                                    be described as a quadratic loss that takes the upper bound when
                                       TheoverviewofourproposedDiffSATisdepicted in Figure 1.                                                                                                   noliteral in clause Ì†µÌ±ó is satisfied. Specifically, for any value of Ì†µÌ±öÌ†µÌ±ó, it
                                 DiffSAT begins by generalizing the original SAT problem to its                                                                                                 can be easily verified that this quantity is equal to +1 if no literal is
                                 MaxSATformulationandthenutilizes semidefinite approximation                                                                                                    satisfied, and 0 or less if at least one literal is True. Moreover, we
                                 to find an initial solution by relaxing the discrete variables to con-                                                                                         introduce Ì†µÌ±£0 = 1 and Ì†µÌ±†0Ì†µÌ±ó = ‚àí1 in Equation (3a) to make the purely
                                 tinuous variables. Next, based on the variable-clause connection                                                                                               quadratic loss function.
                                                                                                                                                                                        2
                                                                                                     Relaxed
                                                                                                    Variables
                                                  Variables
                                                                                                                                                          SemideÔ¨Ånite
                                                                                                                                                           Relaxation                                                                                                               ...
                                                                                                                  0.7                                                                                               ...                                   ...
                                                                                                                                                  Coordinate Descent
                                                                                                                                                          Initialization
                                                                                                                                                                                                                                                         MaxSAT Layer
                                                                                                                                        Figure 1: The overview of DiffSAT architecture.
                                                                                                                                                                                                             whereÌ†µÌ≤óÌ†µÌ±è is the boolean output of Ì†µÌ≤óÌ†µÌ±ñ. Intuitively, this scheme sets
                                                                                                                                                                                                                                Ì†µÌ±ñ
                                                                                                                                                                                                             Ì†µÌ≤óÌ†µÌ±è to be true if and only if Ì†µÌ≤óÌ†µÌ±ñ is on the same side of the random
                                                                                                   unsatisÔ¨Åed 1                                                                                                 Ì†µÌ±ñ
                                                                                                                                                                                                                                                                                                                                   Ì†µÌ±ö
                                                                                                                                                                                                             hyperplaneÌ†µÌ±ü. Then, a coef√ècient vector Ì†µÌ≤î‚ä§ = {‚àí1}                                                                          is introduced
                                                                                                                                                                                                             in the weight matrix Ì†µÌ±∫ associated with the direction vector Ì†µÌ≤ó‚ä§.
                                                                                                                                                                                                             Asdiscussed inSection 2.1, SDP is a theoretical approach that has
                                                                                                                                                                                                             been introduced for approximating MaxSAT problems [9, 20] with
                                                                                                                                                                                                             high approximation ratios. We choose the leverage semidefinite
                                                                                                      satisÔ¨Åed
                                                                -3                          -1                                   0                     1                                                     approximationandtheproposedlossfunctioncanbefurtherrelaxed
                                                                2F                                                                                                                                           as the following SDP problem:
                                                                                        1F+1T                                                       2T
                                             Figure 2: The illustration of the unsatisfiability loss.                                                                                                                        min              ‚ü®Ì†µÌ±∫‚ä§Ì†µÌ±∫, Ì†µÌ±Ω‚ä§Ì†µÌ±Ω‚ü©,                    s.t. ‚à•Ì†µÌ≤óÌ†µÌ±ñ ‚à• = 1,Ì†µÌ±ñ ‚àà {‚ä§, 1, 2, . . . ,Ì†µÌ±õ},                                      (6)
                                                                                                                                                                                                                               Ì†µÌ±ò√ó(Ì†µÌ±õ+1)
                                                                                                                                                                                                                      Ì†µÌ±Ω ‚ààR                                                                    ‚àöÔ∏Å                            Ì†µÌ±ö√ó(Ì†µÌ±õ+1)
                                          Take a simple SAT problem with clauses (Ì†µÌ±£ ‚à® Ì†µÌ±£ ) ‚àß Ì†µÌ±£ as an                                                                                                       where Ì†µÌ±∫ = [Ì†µÌ≤î‚ä§,Ì†µÌ≤î1,...,Ì†µÌ≤îÌ†µÌ±õ]diag(1/ 4Ì†µÌ±öÌ†µÌ±ó) ‚àà R                                                                                       and Ì†µÌ±Ω =
                                                                                                                                                   1           2             1                                                                              Ì†µÌ±ò√ó(Ì†µÌ±õ+1)
                                   illustrating example. Based on Equation (3), the loss function for                                                                                                         [Ì†µÌ≤ó‚ä§,Ì†µÌ≤ó1, . . . , Ì†µÌ≤óÌ†µÌ±õ] ‚àà R                                     . For the Max2SAT problem, the formu-
                                   this SAT problem is                                                                                                                                                       lation of the proposed SDP relaxation is essentially the same as the
                                                                                                                                                                                                             one presented in [9]. However, the main difference lies in the fact
                                                 loss = loss + loss = (Ì†µÌ±£1 +Ì†µÌ±£2 ‚àíÌ†µÌ±£0)2 ‚àí 1 + (Ì†µÌ±£1 ‚àíÌ†µÌ±£0)2 .                                                                                                   that Equation(6)canbegeneralizedtoaccommodatelongerclauses.
                                                                         1                 2                             8                                       4                                           It has been demonstrated that this low-rank SDP formulation can
                                                                                                                                                                                                             recover the optimal SDP solution when Ì†µÌ±ò > ‚àö2Ì†µÌ±õ. To ensure the
                                   Figure 2 illustrates the loss function for the first clause, i.e., loss .                                                                                                                                                                                                                                 ‚àö
                                                                                                                                                                                           1                 global optimal solution in Equation (6), we set Ì†µÌ±ò =                                                                                2Ì†µÌ±õ + 1, as
                                   When both Ì†µÌ±£1 and Ì†µÌ±£2 are -1 (False), the quantity (Ì†µÌ±£1 + Ì†µÌ±£2 ‚àí Ì†µÌ±£0)                                                                                                      suggested in [14]. Due to the relatively slow performance of the
                                   evaluates to -3, resulting in a loss of 1 for this clause, which is                                                                                                       augmentedLagrangianmethod,especially for medium-sized SDP
                                   exactly the upper bound. However, when one or both literals equal                                                                                                         problems,weopttoemploycoordinatedescent,asproposedin[19],
                                   1 (True), (Ì†µÌ±£1 + Ì†µÌ±£2 ‚àí Ì†µÌ±£0)2 evaluates to 1, and the loss becomes 0,                                                                                                      to solve the SDP problem presented in Equation (6). This approach
                                   indicating that the clause has been satisfied. It is important to note                                                                                                    is suitable since the problem belongs to a special class of SDP with
                                   that only when the loss values of all clauses are 0, indicating that                                                                                                      diagonal constraints. Particularly, if we hold all but one Ì†µÌ±£ fixed, the
                                   eachclausehasbeensatisfied,canweachieveatotallossof0.Inthis                                                                                                                                                                                                                                      √ç Ì†µÌ±ñ
                                                                                                                                                                                                             objective term that depends on Ì†µÌ±£Ì†µÌ±ñ is given by Ì†µÌ±£‚ä§                                                                                (Ì†µÌ±∫‚ä§Ì†µÌ±∫)           Ì†µÌ±£   .
                                   simple example, whenÌ†µÌ±£ is 1 (True), the loss terms for both loss                                                                                                                                                                                                                            Ì†µÌ±ñ       Ì†µÌ±ò‚â†Ì†µÌ±ñ                Ì†µÌ±ñÌ†µÌ±ò   Ì†µÌ±ò
                                                                                            1                                                                                              1                 Recall that ‚à•Ì†µÌ≤ó ‚à• = 1, there is a simple closed-form solution for the
                                   andloss2 become0,resultinginatotallossof0.Indeed,forthecase                                                                                                                                               Ì†µÌ±ñ
                                   of anyÌ†µÌ±ö , it holds true that loss ‚â§ unsat(Ì†µÌ≤ó,Ì†µÌ≤î ) = 1,‚àÄÌ†µÌ±£ ‚àà {‚àí1,1}.                                                                                                      remainingÌ†µÌ≤óÌ†µÌ±ñ given by:
                                                        Ì†µÌ±ó                                                     Ì†µÌ±ó                              Ì†µÌ≤ã                   Ì†µÌ±ñ                                                                                                             ‚àëÔ∏Å                                              Ì†µÌ≤õ
                                                                                                                                                                                                                                        Ì†µÌ±£     := normalize(‚àí                              (Ì†µÌ±∫‚ä§Ì†µÌ±∫)           Ì†µÌ±£    ) = ‚àí              Ì†µÌ±ñ   ,                      (7)
                                                                                                                                                                                                                                           Ì†µÌ±ñ                                                            Ì†µÌ±ñÌ†µÌ±ò   Ì†µÌ±ò              ‚à•Ì†µÌ≤õ ‚à•
                                   3.2             Semidefinite Initialization                                                                                                                                                            √ç                                         Ì†µÌ±ò‚â†Ì†µÌ±ñ                                             Ì†µÌ±ñ
                                          Now,theMaxSATsolvingisequivalenttofindinganassignment                                                                                                              where Ì†µÌ≤õÌ†µÌ±ñ =                             (Ì†µÌ±∫‚ä§Ì†µÌ±∫)           Ì†µÌ±£    . The coordinate descent method iter-
                                                   Àú                        Ì†µÌ±õ                                                                                                                                                                Ì†µÌ±ò‚â†Ì†µÌ±ñ                 Ì†µÌ±ñÌ†µÌ±ò   Ì†µÌ±ò
                                   vectorÌ†µÌ≤ó ‚àà {‚àí1,1} that minimizes loss in Equation (3). By relaxing                                                                                                        ates the process described above until convergence, and it has been
                                                                                       Àú                                                        Ì†µÌ±ò
                                   each discrete variable Ì†µÌ≤óÌ†µÌ±ñ to a unit vector Ì†µÌ≤óÌ†µÌ±ñ ‚àà R , ‚à•Ì†µÌ≤óÌ†µÌ±ñ‚à• = 1, the loss                                                                                              proven to converge to the globally optimal fixed point of the Equa-
                                   function becomes                                                                                                                                                          tion (6) [19]. In practice, it is also an order of magnitude or faster
                                                                                                  ‚à•Ì†µÌ±âÌ†µÌ±†Ì†µÌ±ó ‚à•2 ‚àí (Ì†µÌ±öÌ†µÌ±ó ‚àí 1)2                                                                                   than any other state-of-the-art SDP solver for such problems.
                                                                               lossÌ†µÌ±ó =                             4Ì†µÌ±ö                          .                                      (4)
                                                                                                                           Ì†µÌ±ó                                                                                3.3             Differential MaxSAT Layer
                                          Then, we associate the continuous variables with respect to a                                                                                                             HavinggeneralizedtheoriginalsatisfiabilityproblemtoaMaxSAT
                                   unit ‚Äútruth direction‚Äù Ì†µÌ≤ó‚ä§ based on the randomized rounding [8].                                                                                                          problem, we have successfully solved it by employing semidefinite
                                   Themainideaofrandomizedroundingisthat for everyÌ†µÌ≤óÌ†µÌ±ñ, we can                                                                                                               approximation and associated coordinate descent techniques, re-
                                   takearandomhyperplanevectorÌ†µÌ±ü fromtheunitvectorandrecover                                                                                                                 sulting in fast computation. Now, our objective is to ef√èciently
                                   the relaxed variables Ì†µÌ≤óÌ†µÌ±ñ back to binary values with                                                                                                                     determine the final solution starting from the SDP solution. Rather
                                                                              ( 1,            if sign(Ì†µÌ±ü‚ä§Ì†µÌ≤óÌ†µÌ±ñ) = sign(Ì†µÌ±ü‚ä§Ì†µÌ≤ó‚ä§),                                                                               thantraining a neural network to predict the final assignments that
                                                                 Ì†µÌ≤óÌ†µÌ±è =                                                                                                                 (5)                  satisfy all clauses, an inherently complex task, we develop a novel
                                                                    Ì†µÌ±ñ           ‚àí1,          otherwise,                                                                                                     solver layer architecture, MaxSAT Layer, with the aforementioned
                                                                                                                                                                                                     3
                                           differentiable loss function in Equation (3) to ef√èciently search from                                                                                                                                             Algorithm2ThebackwardpassofMaxSATlayer
                                           theinitial solution to the final optimum. We now present the details                                                                                                                                                                            Ì†µÌ±ò              Ì†µÌ±õ                                                               Ì†µÌ±ò
                                           of the forward and backward passes of our proposed MaxSAT layer.                                                                                                                                                   Input: Ì†µÌ≤ó ‚àà R fromforwardpass,Ì†µÌ±¶ from forward pass, CNFÌ†µÌºô,
                                                   ForwardPass.Theforwardpassalgorithmisoutlined in Algo-                                                                                                                                                                 learning rate Ì†µÌ∏Ü.
                                           rithm 1. In the forward pass, the inputs consist of relaxed solutions                                                                                                                                              Output: GradientÌ†µÌ≤àÌ†µÌ±ò of Ì†µÌ≤óÌ†µÌ±ò, updated assignment Ì†µÌ≤óÌ†µÌ±ò+1.
                                           and the given CNFs Ì†µÌºô. Subsequently, the layer transforms these                                                                                                                                                         1: Ì†µÌ≤àÌ†µÌ±ò ‚Üê 0;
                                           inputs by extracting the sign of the variables, thereby casting them                                                                                                                                                    2: if Ì†µÌ±¶Ì†µÌ±ò is False then
                                                                                                                                                                                                                                                                                      ÀúÌ†µÌ±ò                     Ì†µÌ±ò
                                           to Boolean values (line 1). The layer then assesses the satisfiabil-                                                                                                                                                    3:                Ì†µÌ≤ó       ‚Üê[Ì†µÌ≤óÌ†µÌ±ñ > 0 : Ì†µÌ±ñ = 1, . . .,Ì†µÌ±õ];
                                                                  ‚Ä≤                                                                                                                                                                     ‚Ä≤                                                ‚Ä≤                     ÀúÌ†µÌ±ò                  ÀúÌ†µÌ±ò
                                           ity of Ì†µÌºô                   (line 2). If the current variable assignment satisfies Ì†µÌºô ,                                                                                                                                 4:                Ì†µÌºô       ‚ÜêÌ†µÌºô(Ì†µÌ±£1,...,Ì†µÌ±£Ì†µÌ±õ); ‚Ä≤
                                                                                                                             Ì†µÌ±ò                                                                                                                                                      ¬Ø                                                           ¬Ø
                                           the MaxSATlayer outputsÌ†µÌ±¶ as True, indicating that Ì†µÌºô is satisfied                                                                                                                                                      5:                Ì†µÌ∞º   ‚Üê{Ì†µÌ±ñ ‚àà [1,Ì†µÌ±õ]|Ì†µÌ±£Ì†µÌ±ñ ‚àà Ì†µÌºô };
                                                                                                                                                                                                                                                                                                           ¬Ø
                                           and a feasible solution for the given CNF has been identified. Con-                                                                                                                                                     6:                forÌ†µÌ±ñ ‚àà Ì†µÌ∞º do
                                                                                                                                                                                                                               Ì†µÌ±ò                                  7:                          Ì†µÌ±î      ‚ÜêÌ†µÌºï Ì†µÌ±òloss;
                                           versely, if Ì†µÌºô cannot be satisfied, the MaxSAT layer outputs Ì†µÌ±¶                                                                                                                           as                                                            Ì†µÌ±ñ               Ì†µÌ≤ó
                                           False, prompting the initiation of the backward pass to update the                                                                                                                                                      8:                endfor                            Ì†µÌ±ñ
                                           variable assignment.                                                                                                                                                                                                    9:                if ‚àÉ Ì†µÌ±î ‚â† 0 then
                                                                                                                                                                                                                                                                                                      Ì†µÌ±ñ
                                                                                                                                                                                                                                                                                                   Ì†µÌ±ò
                                                                                                                                                                                                                                                                10:                            Ì†µÌ±î        ‚Üêargmax ¬Ø‚à•Ì†µÌ±î ‚à•
                                           Algorithm1TheforwardpassofMaxSATlayer                                                                                                                                                                                                                   Ì†µÌ±ñ                                    Ì†µÌ±ñ ‚ààÌ†µÌ∞º          Ì†µÌ±ñ
                                                                                                                                                                                                                                                                11:                  else
                                                                                                                                      Ì†µÌ±ò               Ì†µÌ±õ                                                                                                       12:                            Ì†µÌ±£Ì†µÌ±ñ    := a random variable in a random falsified clause;
                                           Input: Variable assignment Ì†µÌ≤ó                                                                    ‚àà R atÌ†µÌ±ò-th epoch, conjunctive                                                                                                                         Ì†µÌ±ò
                                                                                                                                                                                                                                                                13:                            Ì†µÌ±î        := sign(Ì†µÌ±£Ì†µÌ±ñ);
                                                        normal formulaÌ†µÌºô.                                                                                                                                                                                                                          Ì†µÌ±ñ
                                           Output: Ì†µÌ±¶Ì†µÌ±ò, loss , solution Ì†µÌ≤ó‚àó.                                                                                                                                                                                   14:                  endif
                                                                                              Ì†µÌ±ó                                                                                                                                                                15: end if
                                                        ÀúÌ†µÌ±ò                     Ì†µÌ±ò
                                                1: Ì†µÌ±£           ‚Üê[Ì†µÌ≤óÌ†µÌ±ñ > 0 : Ì†µÌ±ñ = 1, . . .,Ì†µÌ±õ];                                                                                                                                                                 16: Update Ì†µÌ≤óÌ†µÌ±ò+1 ‚Üê Ì†µÌ≤óÌ†µÌ±ò ‚àí Ì†µÌ∏ÜÌ†µÌ≤àÌ†µÌ±ò;
                                                            ‚Ä≤                     ÀúÌ†µÌ±ò                  ÀúÌ†µÌ±ò
                                                2: Ì†µÌºô           ‚ÜêÌ†µÌºô(Ì†µÌ±£1,...,Ì†µÌ±£Ì†µÌ±õ);
                                                3: if Ì†µÌºô‚Ä≤ is satisfiable then
                                                4:                Ì†µÌ±¶Ì†µÌ±ò ‚Üê True;                                                                                                                                                                                withthelargest absolute gradient, i.e., ‚à•Ì†µÌ±î ‚à•. This gradient computa-
                                                5:                Ì†µÌ≤ó‚àó ‚Üê Ì†µÌ≤óÌ†µÌ±ò ;                                                                                                                                                                                                                                                                                                     Ì†µÌ±ñ
                                                                                                                                                                                                                                                              tion involves differentiating the loss function in Equation (4) with
                                                6: else                                                                                                                                                                                                       respect to Ì†µÌ±£Ì†µÌ±ñ (line 7). Define this gradient as Ì†µÌ≤àÌ†µÌ≤ä, we have
                                                7:                Ì†µÌ±¶Ì†µÌ±ò ‚Üê False;
                                                8: end if                                                                                                                                                                                                                                                                     Ì†µÌ≤àÌ†µÌ±ñ = Ì†µÌ±ΩÌ†µÌ±∫‚ä§Ì†µÌ≤îÌ†µÌ±ñ ‚àí ‚à•Ì†µÌ≤îÌ†µÌ±ñ ‚à•2Ì†µÌ≤óÌ†µÌ±ñ.                                                                                        (8)
                                                                                                                                                                                                                                                                                                                                                                                                                   ¬Ø
                                                   BackwardPass. Algorithm 2 demonstrates the implementa-                                                                                                                                                             After obtaining the gradient for all variables in Ì†µÌ∞º, the MaxSAT
                                           tion of our backward pass, which is responsible for computing                                                                                                                                                      layer selects a variable and updates its value based on two situa-
                                           the gradient of the layer inputs and deriving updates to variables                                                                                                                                                 tions: (1) If there exists a variable with a non-zero gradient (i.e.,
                                                                                                                                                                                                                                                              Ì†µÌ±î       ‚â† 0), the MaxSAT layer selects the variable with the largest
                                           that aim to satisfy more constraints in Ì†µÌºô. The primary challenge                                                                                                                                                     Ì†µÌ±ñ
                                                                                                                                                                                                                                                              absoluteÌ†µÌ±î (line 10); (2) If there is no variable satisfying the above
                                           of the backward pass involves identifying the input variable that                                                                                                                                                                               Ì†µÌ±ñ
                                           mayhavecontributed the most to the unsatisfiability of constraint                                                                                                                                                  condition, indicating that the search is stuck in a local optimum, the
                                           formulas. Let Ì†µÌ∞º represent the set of variables in satisfied clauses and                                                                                                                                           MaxSATlayerrandomlyselectsavariable from a falsified clause
                                            ¬Ø                                                                                                                                                                                                                 (line 12) and artificially assigns a gradient with the same sign as
                                           Ì†µÌ∞º   denote its complement, which represents the set of variables in                                                                                                                                               the selected variable (line 13). This criterion guides the updates
                                                                                                                                                                                                              ¬Ø
                                           falsified clauses. It has been established that variables in Ì†µÌ∞º are more                                                                                                                                           towards satisfying more clauses at each iteration, as selecting the
                                           likely to be the sources of conflict. Therefore, we select one variable                                                                                                                                            variable with the largest absolute gradient pushes the loss quantity
                                           fromthis set based on the first-order derivative of the loss function,                                                                                                                                             to decrease in the steepest direction.
                                           whichwill be discussed later, and update its value using gradient
                                                                                                                                                                              ¬Ø                                                                               4 Experiments
                                           descent. Intuitively, variables not present in Ì†µÌ∞º may have their gra-
                                                                                                                                                          ¬Ø                                                                                                           In this section, we aim to answer the following three questions
                                           dients set to zero, as their absence in Ì†µÌ∞º does not provide evidence                                                                                                                                               through a comparative analysis of the experimental results:
                                           regarding the correctness or incorrectness of their current values.
                                           Thevariable selection process in the MaxSAT layer resembles that                                                                                                                                                   RQ1: Can DiffSAT outperform end-to-end learning-based SAT
                                           of the stochastic local search (SLS) algorithm, which is commonly                                                                                                                                                              solvers on random datasets?
                                           used in solving constraint satisfaction problems (CSPs) [4]. How-                                                                                                                                                  RQ2: CanDiffSATbegeneralized to handle large-scale SAT prob-
                                           ever, the main distinction is that SLS relies on meta-heuristics for                                                                                                                                                           lems?
                                           variable selection, whereas our MaxSAT layer selects a variable in                                                                                                                                                 RQ3: CanDiffSATdemonstrate improved performance on com-
                                           a differentiable manner during backpropagation.                                                                                                                                                                                plex datasets compared to the SOTA SAT solver?
                                                   The backward pass begins by initializing the gradient to zero                                                                                                                                              4.1                 ExperimentSettings
                                           for all variables (line 1). If Ì†µÌ±¶Ì†µÌ±ò is false, indicating the presence of
                                                                                                                                                                                          ¬Ø
                                           unsatisfied clauses, we obtain the set of variables Ì†µÌ∞º that are present                                                                                                                                            EvaluationMetric. DiffSAT aims to determine the satisfying as-
                                                                                                                                                                                                                                         ¬Ø
                                           in the falsified clauses. Once we have obtained the candidate set Ì†µÌ∞º                                                                                                                                               signment for a given CNF formula. The accuracy of DiffSAT is
                                           (line 5), we proceed to select the best variable from this set using a                                                                                                                                             evaluated based on whether the variable assignments it produces
                                           criterion based on its gradient. Specifically, we compute the gradi-                                                                                                                                               can satisfy the given constraints. In contrast to DiffSAT, which
                                           ent for each variable in the candidate set and choose the variable                                                                                                                                                 directly obtains variable assignments from the layer output, both
                                                                                                                                                                                                                                                   4
                                           Table 1: Performance comparison of NeuroSAT, SATformer, and DiffSAT on random datasets.
                                                       SR(20)                         SR(50)                         SR(100)                       SR(200)                        SR(500)
                                              CV=3      CV=4      CV>5       CV=3      CV=4      CV>5      CV=3       CV=4      CV>5      CV=3       CV=4      CV>5      CV=3      CV=4       CV>5
                             NeuroSAT          86%       81%       50%        82%       44%       18%       40%        20%        4%        6%        0%         0%        0%        0%        0%
                             SATformer         98%       94%       78%        98%       84%       25%       49%        42%       10%       12%        4%         0%        0%        0%        0%
                              DiffSAT         100%      100%      100%       100%      100%      100%       100%      100%      100%       100%      100%      100%       100%      100%      100%
                    NeuroSATandSATformerapplyk-meansalgorithmtoclusterthe                                            clause constraints in the formula and the instance is more dif√ècult
                    literal embeddings into two clusters, labeled A and B. This clus-                                to solve. Generally, there would be only 1 or 2 possible satisfying
                    tering process generates two possible assignments: one assigns                                   assignments in total for satisfiable datasets withÌ†µÌ∞∂Ì†µÌ±â > 5.
                    the variables in cluster A as true and the variables in cluster B as                                 TheresultsareshowninTable1,fromwhichwehavetwoobser-
                    false, while the other reverses the assignments. If either of these                              vations. Firstly, for all datasets, DiffSAT solves more instances than
                    twoassignments satisfies the given instance, we consider the SAT                                 NeuroSATandSATformer,especiallyfordatasetswithalargenum-
                    problem to be solved.                                                                            ber of variables and a large CV ratio. For example, both NeuroSAT
                    DatasetPreparation.Totrainourlearning-basedbaselines,namely                                      and SATformer can not decode any correct satisfying solutions
                    NeuroSAT[16]andSATformer[17],wegenerateadatasetconsist-                                          of CNFs with 200 variables and CV>5, whereas DiffSAT can still
                    ing of 50,000 satisfiable and 50,000 unsatisfiable instances. These                              achieve 100% accuracy, i.e., finding satisfying solutions for all CNFs.
                    instances are generated using the same randomÌ†µÌ±ò-SAT dataset gen-                                 Thesuperior performance of the DiffSAT comes from the appro-
                    eration scheme as described in [16]. In this dataset, we use the                                 priate usage of logic structure in neural network architecture. In
                    Ì†µÌ±ÜÌ†µÌ±Ö(Ì†µÌ±õ) distribution, which represents pairs of random SAT prob-                                comparison, both NeuroSAT and SATformer solely rely on the
                    lems onÌ†µÌ±õ variables. These pairs have the following properties: one                              graph representation from data-driven structure learning, which is
                    element is satisfiable, while the other is unsatisfiable, and the only                           based on a wrong assumption that similar structures will result in
                    difference between them is a single-edge connection. During train-                               similarsearchspaces.Secondly,DiffSATcanbegeneralizedtolarger
                    ing, we sample the number of variablesÌ†µÌ±õ uniformly from the range                                problems while learning-based NeuroSAT and SATformer can only
                    of 10 to 40 (i.e., trained on Ì†µÌ±ÜÌ†µÌ±Ö(Ì†µÌ±à (10,40))). In addition to random                           deal with simplified problems, limiting their applications in prac-
                    datasets, we also incorporate complex benchmarks from the SAT                                    tice. Notably, as the problem size increases, DiffSAT maintains a
                                           1                                                                         consistent 100% accuracy, whereas both NeuroSAT and SATformer
                    Competition2023 .Thesebenchmarksareincludedtoshowcasethe                                         experience a significant decrease in accuracy. The ability to gen-
                    effectiveness of DiffSAT in solving challenging satisfiable problems.                            eralize to larger, unseen datasets remains a major challenge for
                    Implementation Details. We developed a prototype of our ap-                                      end-to-end learning-based SAT solvers, likely due to the limited
                    proach using PyTorch [13]. It is important to note that DiffSAT                                  generalization capabilities of deep neural networks. However, Diff-
                    does not have any parameters and therefore does not require any                                  SATbreaksfreefromthisdilemma,offeringanalternativeapproach
                    training labels. We set the time limit for both SAT solvers and                                  to solving SAT problems in an end-to-end manner.
                    DiffSAT as 10,000 seconds. For optimization, we utilize the Adam
                    optimizer [12] with a learning rate of 2 √ó 10‚àí1 for DiffSAT and                                  4.3      PerformanceComparisonwithKissaton
                    2√ó10‚àí3 for NeuroSAT and SATformer. The GNN message passing                                                Large-scale Datasets
                    roundsofbothNeuroSATandSATformeraresetto26duringtrain-                                               Todemonstratethescalability of DiffSAT, we address RQ2 by
                    ing and 100 during inference. For the Hierarchical Transformer                                   comparingitsruntimewithKissat[3],awidelyusedheuristic-based
                    structure in SATformer, we use literal embeddings as input tokens                                SATsolver, on large-scale random datasets. We generate the com-
                    and set the dimension of hidden state embeddings to 128. The win-                                parison datasets using theÌ†µÌ±ò-SAT dataset generation scheme, which
                    dow size is assigned to 4, and the total level of the hierarchical                               includes Ì†µÌ±ÜÌ†µÌ±Ö(2500), Ì†µÌ±ÜÌ†µÌ±Ö(5000), Ì†µÌ±ÜÌ†µÌ±Ö(7500), Ì†µÌ±ÜÌ†µÌ±Ö(10000), Ì†µÌ±ÜÌ†µÌ±Ö(15000), and
                    structure is 4. These two models are trained for 20 epochs with a                                Ì†µÌ±ÜÌ†µÌ±Ö(20000) with CV = 5. Each dataset comprises 10 satisfiable in-
                    batch size of 8 on a single Nvidia V100 GPU.                                                     stances, and we calculate the average runtime for both DiffSAT and
                    4.2      PerformanceComparisonwith                                                               Kissat in finding satisfying assignments. The runtime comparison
                             Learning-based SATSolvers                                                               results are presented in Figure 3, leading to two key observations.
                        In this section, to answer RQ1, we compare the performance                                       Firstly, DiffSAT demonstrates scalability comparable to tradi-
                    of DiffSAT with end-to-end learning-based SAT solvers, including                                 tional heuristic-based SAT solvers, enabling its practical applica-
                    NeuroSAT[16]andSATformer[17],infindingsolutions for satis-                                       tion to large-scale SAT problems. For example, in the Ì†µÌ±ÜÌ†µÌ±Ö(20000)
                    fied problems. We generate five testing datasets, including Ì†µÌ±ÜÌ†µÌ±Ö(20),                            datasetwithCV=5,whichtypicallyconsistsof20,000variablesand
                    Ì†µÌ±ÜÌ†µÌ±Ö(50), Ì†µÌ±ÜÌ†µÌ±Ö(100), Ì†µÌ±ÜÌ†µÌ±Ö(200), and Ì†µÌ±ÜÌ†µÌ±Ö(500). Each testing dataset con-                         100,000 clauses, DiffSAT successfully discovers the satisfying solu-
                    sists of 100 satisfiable instances. To better quantize the problem                               tion within a reasonable timeframe. This marks the first instance of
                    dif√èculty, we employ clause-to-variable (CV) ratio as in [17]. Here                              anend-to-end learning-based method being successfully general-
                    Ì†µÌ∞∂Ì†µÌ±â  = Ì†µÌ±ö, where Ì†µÌ±ö is the number of clauses and Ì†µÌ±õ is the num-                                 ized to handle such large-scale problems. Secondly, we observe that
                              Ì†µÌ±õ                                                                                     theruntimeofDiffSATiscomparabletothatofKissatonlarge-scale
                    ber of variables. The higherÌ†µÌ∞∂Ì†µÌ±â value means that there are more                                 datasets, highlighting its ef√èciency. Notably, while DiffSAT may
                    1https://satcompetition.github.io/2023/                                                          requiremoretimetofindsatisfyingassignmentsforrelativelysmall
                                                                                                                5
                         300                                                                  Benchmark             # Variables   # Clauses    Ì†µÌ∞∂Ì†µÌ±â            Runtime (s)
                                                                                                                                                      SBVA-CaDiCaL[?]       DiffSAT
                         225                                                           rbsat-v1150c84314gyes10         1150         84314     73.32         >10000            98.76
                       )                                                               sgen3-n260-s62321009-sat         260          884       3.4          >10000            11.83
                       Ì†µÌ±†                                                                  Schur_160_5_d34              756         28445     37.63         >10000            23.81
                       (
                         150                                                                 SCPC-900-31                900         41714     46.35         >10000            0.23
                                                                                             SCPC-900-27                900         41618     46.24          700.78           0.34
                       Runtime                                                              em_11_3_4_cmp              8713         99699     11.44          663.96           8.65
                          75                                         Kissat                    170223547                322         1449       4.5           490.06           0.53
                                                                    DiffSAT                  SCPC-1000-20              1000         51095     51.10          480.68           0.14
                                                                                       stb_588_138.apx_2_DS-ST         1176         14821     12.60          335.19           62.15
                           0                                                                 SCPC-700-86                700         27447     39.21          134.18           0.20
                            2,500 5,000 7,500 10,000          15,000        20,000           SCPC-800-44                800         34495     43.12          86.45            0.56
                                              Variable Number
                       Figure 3: Comparison of Kissat and DiffSAT                          Table 2: Experimental results of DiffSAT and the SBVA-CaDiCaL
                  datasets such as Ì†µÌ±ÜÌ†µÌ±Ö(2500), Ì†µÌ±ÜÌ†µÌ±Ö(5000), and Ì†µÌ±ÜÌ†µÌ±Ö(10000), the average                     Then, among the 7 SAT instances that both DiffSAT and SBVA-
                  runtime of DiffSAT for solving larger problems like Ì†µÌ±ÜÌ†µÌ±Ö(15000) and                   CaDiCaLcansolve, DiffSAT demonstrates faster performance in
                  Ì†µÌ±ÜÌ†µÌ±Ö(20000) is actually smaller than that of Kissat. This behavior can                finding satisfying solutions compared to SBVA-CaDiCaL. Notably,
                  be attributed to the effective search strategy employed by DiffSAT,                   for the instance ‚ÄúSCPC-900-27‚Äù, DiffSAT achieves a runtime im-
                  which involves iteratively making small changes to the current                        provement of up to 2061 times compared to SBVA-CaDiCaL. Upon
                  assignment of truth values, guided by a differential loss function to                 analyzing the solution process for this particular test case, we dis-
                  satisfy more clauses at each iteration.                                               covered that over 99% of the final variable assignments should be
                  4.4     PerformanceComparisonwithSOTASAT                                              set to 0. In the DiffSAT solving process, the initial solution obtained
                                                                                                        through solving semidefinite programming is entirely composed of
                          Solver on ComplexDatasets                                                     zeros, indicating that a significant proportion of variables require
                     ToaddressRQ3,weselectedcomplexbenchmarkswithhighCV                                 nofurther updates. In other words, we have already reached a fa-
                  ratios from SAT Competition 2023 and compared the performance                         vorable state that closely resembles the final solution. In contrast,
                  of DiffSAT with SBVA-CaDiCaL [? ], the top solver in the Main                         traditional SAT solvers rely on random initialization and need to ex-
                  (Sequential) Track of SAT Competition20232.Specifically,wechose                       plore all possible assignments for each variable before reaching the
                  4instancesthatSBVA-CaDiCaLfailedtosolvewithin10,000seconds                            final solution, resulting in exponential search spaces and reduced
                  and 7 test cases that both DiffSAT and SBVA-CaDiCaL successfully                      ef√èciency. In summary, the effectiveness of DiffSAT in handling
                  handledwithinareasonabletime.Detailedinformationaboutthese                            complex SAT problems positions it as a promising approach for
                  complex instances and the runtime comparison between DiffSAT                          real-world applications.
                  andSBVA-CaDiCaL[?]isprovidedinTable2.                                                 5 Conclusion
                     Tobeginwith, for the 4 challenging CNFs, DiffSAT managed to                            In this paper, we propose DiffSAT, a novel learning-based frame-
                  find the satisfying assignment while SBVA-CaDiCaL became stuck                        work for SAT solving. DiffSAT combines a differential MaxSAT
                  and could not prove the satisfiability of these problems within a                     layer with a semidefinite initialization, resulting in a powerful
                  reasonable time frame. Notably, these problems typically have a                       andeffective approach for solving SAT problems. Unlike existing
                  relatively small number of variables but a large number of clauses.                   learning-based SAT solvers that primarily focus on learning struc-
                  For instance, the test case ‚Äúrbsat-v1150c84314gyes10‚Äù only consists                   tural information for prediction, DiffSAT takes a step further by
                  of 1150 variables, but the total number of clauses amounts to 84314,                  differentiating the discrete SAT problem and incorporating the log-
                  resulting in an extremely high CV ratio of 73.32. In such scenarios,                  ical formulas into a network architecture. By relaxing the binary
                  it is highly probable that there is only one viable solution for this                 constraint of the problem and allowing Boolean variables to be
                  SATproblem.IftheinitialsearchpathofatraditionalSATsolverde-                           represented in a continuous domain, DiffSAT overcomes the limita-
                  viates significantly from the correct path, the inability of the CDCL                 tions of the CDCL framework and accelerates the search process
                  framework to rectify errors through a learning-from-mistakes sys-                     through the guidance of a differentiable loss function, providing
                  temcanleadtoaninfinite loop. In contrast, our proposed DiffSAT                        valuable insights for SAT solving. Experimental results showcase
                  algorithm, which is based on variable relaxation and the effective                    the superior performance of DiffSAT compared to existing end-to-
                  differentiation of a loss function, allows us to at least reach a par-                end learning-based SAT solvers. Moreover, this is the first time the
                  tially satisfied solution in intermediatesteps,ratherthancompletely                   end-to-end learning-based method could achieve comparable per-
                  failing if stuck. Furthermore, DiffSAT intelligently breaks free from                 formance with traditional SAT solvers and even outperform them
                  local optima by randomly selecting variables in falsified clauses for                 on some intricate SAT instances. We believe that our approach
                  gradient descent. These two strategies contribute to the effective-                   will serve as a foundation for differential logic learning and inspire
                  ness of DiffSAT in finding solutions for complex CNFs on which                        further innovation in the field of end-to-end SAT solving.
                  vanilla SAT solvers easily get stuck.
                  2https://satcompetition.github.io/2023/results.html
                                                                                                    6
                   References                                                                                       IEEE, 406‚Äì415.
                    [1] TomasBalyo, Marijn Heule, Markus Iser, Matti J√§rvisalo, and Martin Suda. 2023.        [12] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
                         Proceedings of SAT Competition 2023: Solver, Benchmark and Proof Checker                   mization. arXiv preprint arXiv:1412.6980 (2014).
                         Descriptions. (2023).                                                                [13] AdamPaszke,SamGross,FranciscoMassa,AdamLerer,JamesBradbury,Gregory
                    [2] BerndBecker,RolfDrechsler,andMatthiasSauer.2014. RecentAdvancesinSAT-                       Chanan,TrevorKilleen,ZemingLin,NataliaGimelshein,LucaAntiga,etal.2019.
                         based ATPG: Non-Standard Fault Models, Multi Constraints and Optimization.                 Pytorch: An imperative style, high-performance deep learning library. Advances
                         Proc. DTTIS (2014), 1‚Äì10.                                                                  in neural information processing systems 32 (2019).
                    [3] ArminBiere, Mathias Fleury, T Balyo, M Heule, M Iser, M J√§rvisalo, and M Suda.        [14] G√°bor Pataki. 1998. On the rank of extreme matrices in semidefinite programs
                         2022. Gimsatul, IsaSAT and Kissat entering the SAT competition 2022. Proc. of              andthemultiplicity of optimal eigenvalues. Mathematics of operations research
                         SATCompetition (2022), 10‚Äì11.                                                              23, 2 (1998), 339‚Äì358.
                    [4] Yi Chu, Shaowei Cai, and Chuan Luo. 2023. NuWLS: Improving local search for           [15] DanielSelsamandNikolajBj√∏rner.2019. Guidinghigh-performanceSATsolvers
                         (weighted) partial MaxSAT by new weighting techniques. In Proceedings of the               with unsat-core predictions. In Theory and Applications of Satisfiability Testing‚Äì
                         AAAIConference on Artificial Intelligence, Vol. 37. 3915‚Äì3923.                             SAT2019: 22nd International Conference, SAT 2019, Lisbon, Portugal, July 9‚Äì12,
                    [5] Stephen A Cook. 2023. The complexity of theorem-proving procedures. In                      2019, Proceedings 22. Springer, 336‚Äì353.
                         Logic, Automata, and Computational Complexity: The Works of Stephen A. Cook.         [16] DanielSelsam,MatthewLamm,BenediktB√ºnz,PercyLiang,LeonardodeMoura,
                         143‚Äì152.                                                                                   andDavidLDill. 2018. Learning a SAT solver from single-bit supervision. arXiv
                    [6] Uriel Feige and Michel Goemans. 1995. Approximating the value of two power                  preprint arXiv:1802.03685 (2018).
                         proof systems, with applications to max 2sat and max dicut. In Proceedings Third     [17] ZhengyuanShi, Min Li, Sadaf Khan, Hui-Ling Zhen, Mingxuan Yuan, and Qiang
                         Israel Symposium on the Theory of Computing and Systems. IEEE, 182‚Äì189.                    Xu. 2022. SATformer: Transformer-Based UNSAT Core Learning. In 2023
                    [7] Michel X Goemans and David P Williamson. 1994. New 34-approximation                         IEEE/ACMInternational Conference on Computer Aided Design (ICCAD) (2022).
                         algorithms for the maximum satisfiability problem. SIAM Journal on Discrete          [18] Zhengyuan Shi, Hongyang Pan, Sadaf Khan, Min Li, Yi Liu, Junhua Huang,
                         Mathematics 7, 4 (1994), 656‚Äì666.                                                          Hui-Ling Zhen, Mingxuan Yuan, Zhufei Chu, and Qiang Xu. 2023. Deepgate2:
                    [8] Michel X Goemans and David P Williamson. 1995. Improved approximation                       Functionality-aware circuit representation learning. In 2023 IEEE/ACM Interna-
                         algorithms for maximum cut and satisfiability problems using semidefinite pro-             tional Conference on Computer Aided Design (ICCAD). IEEE, 1‚Äì9.
                         gramming. J. ACM 42, 6 (1995), 1115‚Äì1145.                                            [19] Po-Wei Wang, Wei-Cheng Chang, and J Zico Kolter. 2017. The mixing method:
                    [9] Michel X Goemans and David P Williamson. 1995. Improved approximation                       low-rank coordinate descent for semidefinite programming with diagonal con-
                         algorithms for maximum cut and satisfiability problems using semidefinite pro-             straints. arXiv preprint arXiv:1706.00476 (2017).
                         gramming. Journal of the ACM (JACM) 42, 6 (1995), 1115‚Äì1145.                         [20] Po-Wei Wang and J Zico Kolter. 2019. Low-rank semidefinite programming
                   [10] ]haberlandt2023sbva Andrew Haberlandt and Harrison Green. [n.d.]. SBVA-                     for the MAX2SAT problem. In Proceedings of the AAAI Conference on Artificial
                         CADICALandSBVA-KISSAT:StructuredBoundedVariableAddition. SATCOM-                           Intelligence, Vol. 33. 1641‚Äì1649.
                         PETITION2023 ([n.d.]), 18.                                                           [21] Wenxi Wang, Yang Hu, Mohit Tiwari, Sarfraz Khurshid, Kenneth McMillan,
                   [11] HowardKarloff and Uri Zwick. 1997. A 7/8-approximation algorithm for MAX                    and Risto Miikkulainen. 2023. NeuroBack: Improving CDCL SAT Solving using
                         3SAT?.InProceedings38thAnnualSymposiumonFoundationsofComputerScience.                      Graph Neural Networks. In The Twelfth International Conference on Learning
                                                                                                                    Representations.
                                                                                                          7
