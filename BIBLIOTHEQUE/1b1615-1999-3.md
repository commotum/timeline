# Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning (1999)
Source: 1b1615-1999.pdf

## Core reasons
- The paper identifies that standard MDPs lack temporally extended actions and frames temporal abstraction as a missing capability in the usual RL setting.
- It introduces options as a generalization of primitive actions to create temporally extended courses of action within reinforcement learning.

## Evidence extracts
- "at time t affects the state and reward at time t + 1. There is no notion of a course of
action persisting over a variable period of time." (p. 2)
- "Asmentionedearlier,weusethetermoptionsforourgeneralizationofprimitiveactions
to include temporally extended courses of action." (p. 6)

## Classification
Class name: Computation & Reasoning Mechanism Proposal
Class code: 3

$$
\boxed{3}
$$
