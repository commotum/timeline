                        Published as a conference paper at ICLR 2024
                                                                     ˆ
                        LM;the LMthen generates a .patch prediction δ. In the evaluation step, the following steps are
                        performed per prediction on the target task instance:
                             1. Remove any file changes and checkout the task instance’s base commit. This sets the
                                repository to codebase C.
                             2. Activate the executable context corresponding to the task instance’s version.
                             3. Run installation command to instantiate codebase C.
                             4. Apply test patch T to codebase C.
                                                     ˆ
                             5. Apply prediction patch δ to codebase C with tests T.
                                                                                     ˆ
                             6. If the previous step fails, we attempt to fix prediction patch δ automatically and reapply it.
                             7. Run the testing script, determined from test patch T, to generate test result logs logˆ.
                                                                                                         δ
                        Steps 1 through 4 reliably do not fail due to verification during the task instance validation process.
                        If applying the prediction patch (Step 5) fails, we attempt to repair the prediction patch file by
                        removing unnecessary context lines and recalculating the header values (Step 6). If the remaining
                        patch fails again or running the test command (Step 7) fails, then the prediction is automatically
                        given a score of 0. Assuming these steps succeed, the output log logˆ can then be converted to
                                                                                        δ
                        a test-to-status mapping, identical in structure to the via the appropriate, repository-specific parser
                        introduced in § A.3.
                        Evaluation Metrics Calculation. To determine task completion, we compare the test-to-status
                        mapping parsed from logˆ with the list of tests corresponding to the FAIL TO PASS and
                                                 δ
                        PASS TO PASSkeysfromthegroundtruthtestresultsdatastructure. Determiningtaskcompletion
                        is straightforward; we check that all FAIL TO PASS and PASS TO PASS tests are found and have
                        a pass status in the evaluation test-to-status mapping. If a test is missing or has a non-pass status, it
                        is considered a fail status. As defined and used in the main paper, a task is considered solved if all
                        tests across FAIL TO PASS and PASS TO PASS pass.
                        A.5   EVALUATION TEST SET CHARACTERIZATION
                        WeincludeanexpandedformofTable1thatincludesrepositoryspecificstatisticsinTable11. Table
                        12 presents a brief description of each repository extracted from the repository’s documentation
                        along with the repository’s associated open source license. The associated licenses all permit non-
                        commercial usage of the original library source code as long as the permissions in the original
                        licenses are upheld and retained. In addition to the original statistics presented in Table 1, we
                        introduce three new values. The δ # Lines Added and δ # Lines Removed together sum up to δ Lines
                        Edited. “Added” refers to the number of new lines that are introduced, while “Removed” are pre-
                        existing lines taken out by the solution. The |T| (Pass to Pass) statistic refers to the number of tests
                        that were passing before the solution δ was applied during the validation pipeline. Unlike fail to pass
                        tests that are intended to characterize the problem statement P and determine if a revision addresses
                        the issue, pass to pass tests are included to ensure that the revision does not break or violate any
                        existing expected behavior. These tests are extracted during the validation log examination phase
                        as discussed in § A.3. We note that fail to fail tests and pass to fail tests are not considered during
                        evaluation, and those statistics are not reflected in the above table.
                        Task Instance Issue Categories.   To provide a better sense of the types of problems that
                        SWE-bench task instances include, we perform simple analyses on the issues, identified by the
                        issue numbersfield,foreachtask instance. Per issue, we inspect metadata, specifically tags, to
                        characterize the type of contribution put forth by the PR. Table 13 groups and shows several exam-
                        ples of the 2,289 tags we found across all issues. While the absolute majority of issues are associated
                        with bug fixes, SWE-bench’s task instances are associated with a diverse set of code changes with
                        purposes beyond debugging and error correction.
                        Attribute Distributions. In Figure 9, we present plots of the cumulative distribution function for
                        attributes introduced in Table 1. From these plots, we see that the median SWE-bench task instance
                        has a problem description of 140 words, and will take place within a codebase containing just shy of
                        1900files and 400K lines. The corresponding reference solution δ will usually edit a single function
                                                                   20
