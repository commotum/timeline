                4                                                                    Transactions of the Institute of Measurement and Control 00(0)
                   1.  A grid-shaped BEV query reference set, integrating            results into the feature vector represented by (x0,y0). This
                       spatiotemporal features via the attention mechanism.          comprehensive process of ‘‘temporal information aggregation,
                   2.  The Retentive-Spatial Cross-Attention (RSCA) mod-             spatial feature aggregation, forward propagation’’ is executed
                       ule, which amalgamates spatial features across multi-         six times across the network, culminating in high-dimensional
                       ple camera inputs and generates a weight decay matrix         BEVfeatures Bt for subsequent object detection or segmenta-
                       to furnish attention with spatial priors.                     tion tasks.
                                                                                         Figure 1 shows the following. (a) The decoder of
                   By integrating features generated by RetentiveBEV with            RetentiveBEV features an array of BEV queries, each deter-
                task-specific heads for various applications, such as DETR3D         mined by the grid’s resolution. It incorporates TSA that
                (Wangetal., 2021b) and OpenOccupancy (Wang et al., 2023),            synthesizes both historical and current frame data, alongside
                it is possible to detect 3D objects in an end-to-end manner.         spatial cross-attention mechanisms designed to convert 2D
                Ourcontributions are as follows:                                     image data into depth information aligned with the world
                                                                                     coordinate system. (b) The retentive mechanism operates by
                   1.  Introduced a BEV utilizing a Manhattan distance-              calculating decay weights for feature vectors along both hori-
                       based spatial decay matrix, which offers explicit spa-        zontal and vertical image axes. These weights are then com-
                       tial priors to the attention mechanism.                       bined via a Hadamard product to form a 2D decay weight
                                                                                                2d
                                                                                     matrix D , which is instrumental for conducting BEV
                   2.  AdoptedanewMaSAdecompositionapproachwithin                               nm
                       the BEV framework, enabling global information                queries. Such queries selectively engage with image data from
                                                                                                                                       2d
                                                                                     ROIs, factoring in the spatial influence of D        within these
                       modeling with linear complexity.                                                                                nm
                                                                                     interaction zones. (c) The TSA component plays a pivotal
                   We tested our network model on the Val split of the               role in merging information from both historical and current
                nuScenes data set using a single V100 GPU, achieving a com-          frames, enabling BEV queries to dynamically interact with
                prehensive NDS score of 0.558, an mAP accuracy score of              immediate surroundings and corresponding segments from
                0.423, and an inference performance of 25.3 frames per               prior frames. This facilitates a nuanced and context-aware
                second.                                                              analysis, enhancing the model’s ability to accurately interpret
                                                                                     and predict spatial dynamics.
                                                                                         For image inputs from multiple cameras (with surround-
                Methods                                                              view images collected by Nref =6 cameras as provided by the
                                                                                     nuScenes data set), the network sequentially extracts multi-
                In this research, we introduce a new method for transforming         dimensional features Ft from each camera using a backbone
                features from multi-view camera images into BEV features,            network. These features are then combined with the temporal
                offering a unified representation of the surrounding environ-        information from BEV historical frames through the TSA
                ment that enhances various autonomous driving perception             module. This combination serves as input to the RSCA mod-
                tasks. Our method, developed within the Retentive frame-             ule for aggregating spatial features. Within this module, when
                work, leverages spatiotemporal data gathered from multiple           targeting a specific area of interest in the BEV, the system
                camera perspectives. For spatial feature calculation, it incor-      first identifies the location Vhit of this area (denoted by BEV
                porates the Manhattan Cross-Attention mechanism from the             coordinates (x0,y0)) across Nref =6 images. It then calculates
                retentive approach, explicitly providing spatial priors to the                                                     2d
                                                                                     the Manhattan distance decay matrix D            for the current
                transformer and significantly reducing the computational                                                           nm
                                                                                     position in each image and proceeds with QKV query compu-
                demands for model training and inference. For temporal fea-          tations. A BEV coordinate grid samples several layers verti-
                tures, it employs an RNN-based approach to efficiently cap-                  0
                                                                                     cally (z , for j=1,2, ...,n ) and integrates these samples
                                                                                              j                     z
                ture historical BEV features, ensuring minimal computational         into the feature vector represented by (x0,y0). This ‘‘temporal
                overhead.                                                            information aggregation, spatial feature aggregation, pooling,
                                                                                     forward propagation, and pooling’’ sequence is repeated six
                Architecture                                                         times throughout the network, ultimately producing high-
                                                                                     dimensional BEV features Bt for use in subsequent target
                For image inputs from multiple cameras, where the nuScenes           detection or segmentation tasks.
                data set provides surround-view images from Nref =6 cam-                 Within the RetentiveBEV, the attention mechanism is tai-
                eras, the network starts by extracting multi-dimensional fea-        lored to engage with specific ROIs, by sampling K points near
                tures from each camera through a backbone network. These             reference points in each camera’s coordinate system, facilitat-
                features are then integrated with temporal information from          ing the calculation of attention outcomes
                historical BEV frames via a Temporal Self-Attention (TSA)
                                                                                                                 N       N
                module and fed into an RSCA module for spatial feature                                            head    key         
                                                                                                                  P P                0              ð1Þ
                                                                                        RetentiveAttnðÞq,p,x =       W       A Wxp+Dp
                aggregation. Within this module, when querying a Region Of                                              i      ij    i         ij
                                                                                                                 i =1    i =1
                Interest (ROI) in BEV, the mechanism first identifies the
                ROI’s location (in BEV grid coordinates (x0,y0)) across the              In this equation, q,p,andx are designated as the query
                images from the six cameras, calculates a Manhattan distance         vector features, reference point features, and input features,
                                2d
                decay matrix D     for these positions Vhit in each image, and       respectively. The variable i refers to the specific attention head
                                nm
                performs a QKV query calculation. Each BEV grid samples              being considered, with Nhead denoting the overall number of
                                            0
                several layers vertically (z ,j=1,2,:::,n ), incorporating the       such heads. The index j is used for the keys that are sampled,
                                            j              j
