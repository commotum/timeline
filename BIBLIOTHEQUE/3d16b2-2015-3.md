# End-To-End Memory Networks (Not specified in the paper.)
Source: 3d16b2-2015.pdf

## Core reasons
- Introduces a neural network architecture with recurrent attention over external memory, indicating a new computation mechanism for accessing and using memory.
- Emphasizes multiple computational steps ("hops") per output symbol, focusing on iterative reasoning rather than positional encoding or dimensional lifting.

## Evidence extracts
- "Weintroduceaneuralnetworkwitharecurrentattentionmodeloverapossiblylargeexternalmemory." (p. 1)
- "ItcanalsobeseenasanextensionofRNNsearch[2]tothecasewheremultiplecomputationalsteps(hops)areperformedperoutputsymbol." (p. 1)

## Classification
Class name: Computation & Reasoning Mechanism Proposal
Class code: 3

$$
\boxed{3}
$$
