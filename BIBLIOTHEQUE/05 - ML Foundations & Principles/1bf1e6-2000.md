# Policy Gradient Methods for Reinforcement Learning with Function Approximation (Not specified in the paper.)
Source: 1bf1e6-2000.pdf

## Core reasons
- The paper focuses on policy-gradient reinforcement learning with explicit policy function approximation and updates based on reward gradients.
- It provides theoretical results on policy iteration with function approximation and convergence, fitting ML foundations rather than data/benchmark or transformer categories.

## Evidence extracts
- "we approximate a stochastic policy directly using an independent function approximator with its own parameters." (p. 2)
- "Given Theorem 2, we can prove for the first time that a form of policy iteration with function approximation is convergent to a locally optimal policy." (p. 5)

## Classification
Class name: ML Foundations & Principles
Class code: 5

$$
\boxed{5}
$$
