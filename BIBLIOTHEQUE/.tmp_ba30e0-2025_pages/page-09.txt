                 References                                                                     works. IEEE Transactions on Pattern Analysis and Machine
                                 ¨                                                              Intelligence, 2015.
                  [1] Ekin Akyurek, Mehul Damani, Adam Zweiger, Linlu Qiu,                [17] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
                       Han Guo, Jyothish Pari, Yoon Kim, and Jacob Andreas.                     Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
                       Thesurprisingeffectivenessoftest-timetrainingforfew-shot                 Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-
                       learning. In ICML, 2025.                                                 vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is
                  [2] Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine                 worth 16x16 words: Transformers for image recognition at
                       Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Men-                   scale. In ICLR, 2021.
                       sch, Katherine Millican, Malcolm Reynolds, Roman Ring,             [18] ARC Prize Foundation. ARC-AGI benchmarking: Leader-
                       Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong,                  board and dataset for the ARC-AGI benchmark. https:
                       Sina Samangooei, Marianne Monteiro, Jacob L. Menick,                     //arcprize.org/leaderboard, 2025. Accessed:
                       Sebastian Borgeaud, Andy Brock, Aida Nematzadeh, Sa-                     2025-11-01.
                       hand Sharifzadeh, Mikolaj Binkowski, Ricardo Barreira,             [19] Daniel Franzen, Jan Disselhoff, and David Hartmann. Prod-
                                                                     ´
                       Oriol Vinyals, Andrew Zisserman, and Karen Simonyan.                     uct of experts with LLMs: Boosting performance on ARC is
                       Flamingo: a visual language model for few-shot learning.                 a matter of perspective. arXiv:2505.07859, 2025.
                       In NeurIPS, 2022.                                                  [20] Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Ba-
                  [3] Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan                   tra, and Devi Parikh. Making the V in VQA matter: El-
                       Klein. Learning to compose neural networks for question                  evating the role of image understanding in visual question
                       answering. In ACL, 2016.                                                 answering. In CVPR, 2017.
                  [4] Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan             [21] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song,
                       Klein. Neural module networks. In CVPR, 2016.                            Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi
                  [5] Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret                   Wang, Xiao Bi, et al.     Deepseek-R1: Incentivizing rea-
                       Mitchell, Dhruv Batra, C. Lawrence Zitnick, and Devi                     soning capability in LLMs via reinforcement learning.
                       Parikh. VQA: visual question answering. In ICCV, 2015.                   arXiv:2501.12948, 2025.
                  [6] JeremyBerman. HowIcameinfirstonARC-AGI-Pubusing                     [22] Michael Hodel.        Addressing the abstraction and rea-
                       Sonnet 3.5 with evolutionary test-time compute. Substack,                soning   corpus    via   procedural   example     generation.
                       2024. Accessed: 2025-10-13.                                              arXiv:2404.07353, 2024.
                  [7] Jeremy Berman. How I got a record 53.6% on ARC-AGI.                 [23] Ronghang Hu, Jacob Andreas, Marcus Rohrbach, Trevor
                       Substack, 2024. Accessed: 2025-10-13.                                    Darrell, and Kate Saenko. Learning to reason: End-to-end
                  [8] Jeremy Berman. How I got the highest score on ARC-AGI                     module networks for visual question answering. In ICCV,
                       again swapping Python for English. Substack, 2025.                       2017.
                        ´
                  [9] Leon Bottou and Vladimir Vapnik.        Local learning algo-        [24] Thorsten Joachims. Transductive inference for text classifi-
                       rithms. Neural Computation, 1992.                                        cation using support vector machines. In ICML, 1999.
                 [10] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Sub-               [25] Aysja Johnson, Wai Keen Vong, Brenden M. Lake, and
                       biah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakan-                  ToddM.Gureckis. Fastandflexible: Humanprograminduc-
                       tan, Pranav Shyam, Girish Sastry, Amanda Askell, Sand-                   tion in abstract reasoning tasks. arXiv:2103.05823, 2021.
                       hini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom            [26] Justin Johnson, Bharath Hariharan, Laurens van der Maaten,
                       Henighan, RewonChild, Aditya Ramesh, Daniel M. Ziegler,                  Li Fei-Fei, C. Lawrence Zitnick, and Ross B. Girshick.
                       Jeffrey Wu,ClemensWinter,ChristopherHesse,MarkChen,                      CLEVR: A diagnostic dataset for compositional language
                       Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,                 and elementary visual reasoning. In CVPR, 2017.
                       JackClark,ChristopherBerner,SamMcCandlish,AlecRad-                 [27] AlexiaJolicoeur-Martineau. Lessismore: Recursivereason-
                       ford, Ilya Sutskever, and Dario Amodei. Language models                  ing with tiny networks. arXiv:2510.04871, 2025.
                       are few-shot learners. In NeurIPS, 2020.                           [28] Diederik P Kingma and Jimmy Ba. Adam: A method for
                 [11] Xinlei Chen, Saining Xie, and Kaiming He.         An empiri-              stochastic optimization. In ICLR, 2015.
                       cal study of training self-supervised vision transformers. In      [29] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton.
                       ICCV,2021.                                                               ImageNet classification with deep convolutional neural net-
                 [12] Franc¸ois Chollet.       On the measure of intelligence.                  works. In NeurIPS, 2012.
                       arXiv:1911.01547, 2019.                                            [30] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E.
                 [13] Francois Chollet, Mike Knoop, Gregory Kamradt, and                        Howard, W. Hubbard, and L. D. Jackel. Backpropagation
                       Bryan Landers.      ARC Prize 2024:        Technical report.             applied to handwritten zip code recognition. Neural Compu-
                       arXiv:2412.04604, 2024.                                                  tation, 1989.
                 [14] Francois Chollet, Mike Knoop, Gregory Kamradt, Bryan                [31] Solim LeGris, Wai Keen Vong, Brenden M. Lake, and
                       Landers, and Henry Pinkard. ARC-AGI-2: A new challenge                   Todd M. Gureckis. H-ARC: A robust estimate of human
                       for frontier AI reasoning systems. arXiv:2505.11831, 2025.               performance on the abstraction and reasoning corpus bench-
                 [15] Prafulla Dhariwal and Alexander Quinn Nichol. Diffusion                   mark. arXiv:2409.01374, 2024.
                       models beat GANs on image synthesis. In NeurIPS, 2021.             [32] Solim LeGris, Wai Keen Vong, Brenden M. Lake, and
                 [16] Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou                        Todd M. Gureckis. A comprehensive behavioral dataset for
                       Tang. Image super-resolution using deep convolutional net-               the abstraction and reasoning corpus. Scientific Data, 2025.
                                                                                      9
