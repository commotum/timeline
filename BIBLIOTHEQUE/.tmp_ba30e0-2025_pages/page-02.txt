                                      ARC-1                                                                                    ARC-2
                                                                                                                                                                                      Combining VARCmodelsthrough ensembling [29] further
                                                                                                                                                                                      improvesaccuracyto60.4%,matchingthereportedaverage
                                                                                                                                                                                      humanperformance[31] on the ARC-1 dataset.
                                                                                                                                                                                             Wehopeour research will shed light on the ARC prob-
                                                                                                                                                                                      lem, and more broadly, on the field of abstract reasoning.
                                                                                                                                                                                      Ontheonehand,thedesignoftheARCbenchmarkisbased
                                                                                                                                                                                      on human observations and induced rules abstracted from
                                                           model prediction                            model prediction                               model prediction                the visual and physical world. It is natural to explore vision-
                                                                                                                                                                                      driven approaches for ARC. On the other hand, human rea-
                                                                                                                                                                                      soning is not confined to language or vision in isolation,
                                                                                                                                                                                      but instead should integrate information across modalities.
                                  Figure 2. Examples of unseen tasks solved by VARC. Each                                                                                             Withourcomplementaryvision-basedperspective,wehope
                                  panel shows an unseen test task, with demonstrations on the top                                                                                     the scope of abstract reasoning will be further broadened.
                                  and the model’s prediction on the bottom. VARC correctly solves                                                                                     Weinvite the vision community to study the ARC problem
                                  these challenging tasks.                                                                                                                            and to advance research on abstract reasoning.
                                  are inherently visual and physical: e.g., reflection, symme-                                                                                        2. Related Work
                                  try, and gravity, as shown in Fig. 1. Humans can solve these                                                                                        Visual reasoning. Visual reasoning is a long-standing re-
                                  tasks not merely from the demonstrations, but by reason-                                                                                            search problem. It involves not only perceiving scenes and
                                  ing through analogy to their common sense obtained from                                                                                             objects, but also inferring and abstracting the relations and
                                  external experience. Such common sense can be acquired                                                                                              transformations among them.                                                The advancement of ma-
                                  through observing the world, particularly, the visual world.                                                                                        chine learning methods has led to the development of a
                                         Motivated by its visual nature, we approach ARC from                                                                                         variety of challenging protocols, such as VQA [5, 56, 20],
                                  a vision-centric perspective. We frame each puzzle as an                                                                                            CLEVR[26],andWinoground[51].
                                  image-to-image translation problem. Abstraction and infer-                                                                                                 The visual reasoning methods developed under these
                                  encecanarisedirectlyfromvisuallearning,withoutexplicit                                                                                              protocols typically consist of a visual perception mod-
                                  linguistic intermediates. This perspective connects ARC to                                                                                          ule and a language-like recurrent module, e.g., within the
                                  classical image-to-image problems, ranging from low-level                                                                                           neuro-symbolic framework [4, 23, 3, 41]. These methods
                                  imageprocessing (e.g., [16, 43]) to high-level image under-                                                                                         have evolved into modern vision-language models (VLMs,
                                  standing (e.g., [38, 46]). With this connection, we can ap-                                                                                         e.g., [2, 33, 37]), in which images are converted into tokens
                                  ply standard vision models (e.g., Vision Transformers [17]                                                                                          and processed jointly with text.
                                  or convolutional networks [30]) to tackle the ARC problem.                                                                                                 Unlike ARC, classical visual reasoning protocols gener-
                                         We demonstrate that incorporating visual priors is cru-                                                                                      ally involve a training set and a test set, both of which can
                                  cial.         These priors include 2D spatial locality, translation                                                                                 be viewed as instances of the same task. In contrast, ARC
                                  invariance, and scale invariance. To facilitate learning these                                                                                      consists of a large collection of distinct tasks, each defined
                                  priors, we represent the inputs on a “canvas” with flexible                                                                                         byonlyafewexamples.
                                  geometric transformations, allowing the inputs to be pro-                                                                                           Approaches to ARC. Owing to the “few-shot, many-task”
                                  cessed as if they were natural images. A patch on the can-                                                                                          nature of ARC, LLMshavebeenregardedasanaturalsolu-
                                  vas can consist of exponentially many color combinations,                                                                                           tion. A newtaskcanbeconvertedintoasequenceoftokens,
                                  whichhelps reduce overfitting and encourages the model to                                                                                           treated as a prompt, and processed by LLMs via in-context
                                  learn spatial priors rather than merely memorize.                                                                                                   few-shot learning [55, 10]. We refer the reader to [13] for a
                                         With the vision-centric formulation, we train our model                                                                                      comprehensive survey.
                                  fromscratchusingARC-onlydata. Atinferencetime,when                                                                                                         Recently, recurrent models [53, 27] have been proven
                                  presented with a new, unseen task, we perform test-time                                                                                             effective for ARC, without the requirement of internet-scale
                                  training [9, 24, 49, 1, 53, 27] to adapt the model to the task,                                                                                     pre-training. These models aim to mimic the hierarchical
                                  enabling it to generalize from only a few examples.                                                                                                 and multi-timescale processing of the human brain [53] for
                                         Our framework, termed Vision ARC (VARC), shows                                                                                               reasoning. At inference time, these methods adopt test-time
                                  strong performance on the ARC benchmarks (e.g., Fig. 2).                                                                                            training [9, 24, 49] on the few demonstration examples.
                                  VARCachieves54.5%accuracyontheARC-1benchmark,                                                                                                              Related to our work, the ViT-ARC method [34] attempts
                                  using a small model with only 18 million parameters. This                                                                                           to address the ARC problem using vision models. How-
                                  result substantially surpasses the best recurrent methods                                                                                           ever, this method has only shown the ability to fit individual
                                  [53, 27] that are also trained from scratch on ARC. It is                                                                                           tasks in the training set; it is unable to generalize or solve
                                  also competitive with many popular LLM-based methods.                                                                                               any unseen test task. As such, this method has not been
                                                                                                                                                                              2
