                                                                   ARCIsaVisionProblem!
                                                  KeyaHu           Ali Cy        Linlu Qiu         XiaomanDeloresDing
                                            Runqian Wang              Yeyin Eva Zhu            Jacob Andreas            Kaiming He
                                                                                       MIT
                                              Abstract                                           Training tasks                               Test task
                  The Abstraction and Reasoning Corpus (ARC) is designed
                  to promote research on abstract reasoning, a fundamen-
                  tal aspect of human intelligence. Common approaches to
                  ARCtreat it as a language-oriented problem, addressed by
                  large language models (LLMs)orrecurrentreasoningmod-
                  els. However, although the puzzle-like tasks in ARC are in-
                  herently visual, existing research has rarely approached the
                  problem from a vision-centric perspective. In this work, we
                                                                                                                                                   model prediction
                  formulate ARC within a vision paradigm, framing it as an                                       [TASK]
                  image-to-image translation problem. To incorporate visual
                                                                                                                           VARC network
                  priors, we represent the inputs on a “canvas” that can be
                  processed like natural images. It is then natural for us to
                  apply standard vision architectures, such as a vanilla Vi-                  Figure 1. The ARC benchmark (top) consists of a collection of
                  sion Transformer (ViT), to perform image-to-image map-                      many different tasks, where each task has a few (e.g., 2-4) exam-
                  ping. Our model is trained from scratch solely on ARC                       ples. We propose the Vision ARC (VARC) framework, which ad-
                  dataandgeneralizestounseentasksthroughtest-timetrain-                       dresses the ARC problem as an image-to-image translation prob-
                  ing. Our framework, termed Vision ARC (VARC), achieves                      lem, from a computer vision perspective (bottom). In this illus-
                  60.4% accuracy on the ARC-1 benchmark, substantially                        tration, the underlying concepts of the three tasks can be roughly
                  outperforming existing methods that are also trained from                   described by humans as: “reflection” (left), “symmetry” (middle),
                                                                                              and “gravity” (right). These concepts are closely related to the vi-
                  scratch. Our results are competitive with those of leading                  sual and physical world.
                  LLMsandclosethegaptoaveragehumanperformance.1
                  1. Introduction                                                             Among a wide variety of methods, those based on large
                                                                                              language models (LLMs) have proven highly competi-
                  Learning and abstracting concepts from a small number of                    tive. These methods generally convert ARC inputs into se-
                  demonstrations is a key feature of intelligence. The Ab-                    quences of text tokens for language modeling. Representa-
                  stractionandReasoningCorpus(ARC)benchmark[12]was                            tive methods may involve inductive reasoning [54, 7, 50, 6],
          arXiv:2511.14761v1  [cs.CV]  18 Nov 2025designed to incentivize machine learning research aimed attransductive reasoning [1, 19, 45], or a combination of both
                  improving these capabilities. ARC consists of a collection                  [35,8,40]. TheLLMsarepre-trainedoninternet-scaledata,
                  of puzzle-like tasks (Fig. 1, top), each containing only a                  from which they learn transferable common sense.
                  few examples governed by a unique underlying transfor-                          Most recently, research on recurrent models [53, 27]
                  mation rule. The model is expected to make predictions                      has achieved impressive results on ARC without relying on
                  on each unseen task given a few examples. While humans                      internet-scale data. These models are trained from scratch
                  are capable of solving various ARC tasks [25, 31, 32], the                  onARCdataonlyandperforminferencethroughrecurrent,
                  benchmark remains highly challenging for today’s leading                    iterative reasoning. Although they do not rely on large-scale
                  machine learning systems [44, 42].                                          language pre-training, these recurrent models draw strong
                     TheARCproblemhasattractedsignificantattention,and                        inspiration from the success of language modeling.
                  substantial progress has been made in recent years [13].                        Interestingly, although the ARC puzzles are typically
                                                                                              presentedvisually, existing research has rarely framed ARC
                     1Project webpage: https://github.com/lillian039/VARC.                    as a vision-centric problem. In fact, many concepts in ARC
                                                                                          1
