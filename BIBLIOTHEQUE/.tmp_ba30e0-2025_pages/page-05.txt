                                                                                       nearly free to use many views. We use 510 random views
                                                                                       (details are in appendix). Predictions from different views
                                                                                       are consolidated by majority voting [1].2
                                                                       prediction
                                                                                       Pass@2accuracy. The ARC benchmark by default adopts
                                                                                       the pass@2 accuracy metric: i.e., two different solutions
                                                                                       can be produced for evaluation, and a task is considered
                                                                                       correct if one is correct. To support this metric, we adopt
                                                  TTT process                          majority voting in multi-view inference and retain the top-2
                Figure 6. Effect of test-time training. (Top): Demonstration ex-       most populated output solutions.
                amples for the current task. (Bottom left): An inference example
                x    . (Bottom right): During test-time training, the prediction
                  infer                                                                4. Implementation Details
                from x     becomes progressively more accurate, with the model
                       infer
                finally generating the correct prediction.                             Wedescribe the major implementation choices in this sec-
                                                                                       tion. The configuration details can be found in appendix.
                Test-time training (TTT). Given a single new, unseen                   Canvas. In our best-performing model, the canvas size is
                task T    ∈ T      from the test set, we perform inference
                               test                                                    64×64. In the case of ViT, the patch size is 2×2, resulting
                by test-time training.     At inference time, we are given             in a sequence length of 322. For scale augmentation, an in-
                   T             	m
                D      = (x ,y )         with both input and output accessi-
                  demo       i  i   i=1                                                teger scaling ratio is randomly sampled, such that the scaled
                ble; the model is required to make prediction for a given              grid is no larger than the canvas size. For translation aug-
                xinfer in this new task T.        The test-time training fol-          mentation, the upper-left corner is randomly sampled under
                lowed by inference can be viewed abstractly as a function              the constraint that the placed image is fully visible.
                F(x       | DT    ) 7→ y    .
                     infer   demo       infer                                          Offline training. We use the standard ARC-1 training set
                    Weperformtest-time training for each new task T inde-              T    for training: it has 400 tasks with 2-4 demo pairs each.
                pendently. It has a new task token whose parameters are                 train
                randomly initialized. As there are very few demo pairs in              Following common practice on ARC, we also expand our
                DT     (e.g., 2 to 4), we also perform data augmentation. We           training set with the RE-ARC set [22], from which we sam-
                  demo                                                                 ple 1,000 additional demo pairs per task. Put together, our
                elaborate on the details in the next section and in appendix.          full training set has about 400k sample pairs. We apply
                    In summary, at inference time, the model is initialized            translation and scale augmentation in offline training.
                fromoffline training, fine-tuned with test-time training only
                for the single new task T, and then performs inference on              Test-time training. Given an unseen task T ∈ Ttest, we
                xinfer. As the new demo pairs in DT         are very few, even         have 2-4 sample pairs in DT      . To make test-time training
                                                       demo                                                         demo
                with data augmentation, this test-time training process re-            more feasible, we also augment the single task T into mul-
                mains reasonably fast (e.g., 70 seconds per task on a single           tiple auxiliary tasks. We do this by using standard augmen-
                GPU).Fig. 6 visualizes the effect of test-time training.               tation from existing ARC methods: flip, rotation (by 90◦,
                3.5. Inference                                                         180◦, or 270◦), and color permutation. We treat each of
                                                                                       these test-time training augmentations as an auxiliary task,
                After test-time training, we apply f to x          to obtain the       each assigned a task embedding. We also apply translation
                                                       θ      infer                    and scale augmentation in test-time training, but we do not
                final prediction. This process is analogous to the classical
                recognition problems [29, 38]. Accordingly, we adopt post-             view them as a new auxiliary task (under the assumption
                processing strategies inspired by recognition methods.                 that all auxiliary tasks are translation and scale invariant).
                Single-view inference. Given x            and a single “view”
                                                     infer                             5. Experimental Results
                (i.e., with a given scale and translation), we place xinfer on
                the canvas and apply fθ to predict the output. Since one               Ourexperimentsareprimarilyconductedonthebenchmark
                output location in the raw grid may be predicted by multi-             of ARC-1 [12]. We report the pass@2 accuracy (referred
                ple pixels on the canvas (e.g., due to rescaling; see Fig. 5),         to simply as “accuracy” hereafter) in percentage (%). To
                weaggregate all predictions (from softmax outputs) at this             support pass@2 evaluation, we adopt multi-view inference.
                location by average pooling.                                           Wealsoreport final results on ARC-2 [14].
                Multi-viewinference. It was a common practice to consol-                  WeevaluateourmodelontheARC-1evaluationset(i.e.,
                idate the predictions from multiple views (e.g., see AlexNet           Teval). This set is conceptually a test set (see Fig. 3), but with
                [29]). Analogously, we adopt multi-view inference to im-               ground truth available only for computing accuracy.
                prove accuracy, where the views are sampled with different               2In majority voting, two output grids are considered “consistent” only
                augmentations. As the multi-view inference cost is negli-              when they are identical across the entire grid. The winner is the grid that
                gible compared with test-time training cost, it is virtually           is “consistent” with the largest number of other output grids.
                                                                                   5
