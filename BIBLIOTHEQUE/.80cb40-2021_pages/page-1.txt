                                 Per-Pixel Classiﬁcation is Not All You Need
                                              for Semantic Segmentation
                                                  1,2∗                       2                    1
                                     BowenCheng        Alexander G. Schwing     Alexander Kirillov
                            1Facebook AI Research (FAIR)     2University of Illinois at Urbana-Champaign (UIUC)
                                                                Abstract
                                Modernapproachestypicallyformulatesemanticsegmentationasaper-pixelclassi-
                                ﬁcation task, while instance-level segmentation is handled with an alternative mask
                                classiﬁcation. Our key insight: mask classiﬁcation is sufﬁciently general to solve
                                both semantic- and instance-level segmentation tasks in a uniﬁed manner using
                                the exact same model, loss, and training procedure. Following this observation,
                                wepropose MaskFormer, a simple mask classiﬁcation model which predicts a
                                set of binary masks, each associated with a single global class label prediction.
                                Overall, the proposed mask classiﬁcation-based method simpliﬁes the landscape
                                of effective approaches to semantic and panoptic segmentation tasks and shows
                                excellent empirical results. In particular, we observe that MaskFormer outperforms
                                per-pixel classiﬁcation baselines when the number of classes is large. Our mask
                                classiﬁcation-based method outperforms both current state-of-the-art semantic
                                (55.6 mIoUonADE20K)andpanopticsegmentation(52.7PQonCOCO)models.1
                        1   Introduction
                        The goal of semantic segmentation is to partition an image into regions with different semantic
                        categories. Starting from Fully Convolutional Networks (FCNs) work of Long et al. [28], most deep
                        learning-based semantic segmentation approaches formulate semantic segmentation as per-pixel
                        classiﬁcation (Figure 1 left), applying a classiﬁcation loss to each output pixel [8, 46]. Per-pixel
                        predictions in this formulation naturally partition an image into regions of different classes.
                        Maskclassiﬁcation is an alternative paradigm that disentangles the image partitioning and classiﬁca-
                        tion aspects of segmentation. Instead of classifying each pixel, mask classiﬁcation-based methods
                        predict a set of binary masks, each associated with a single class prediction (Figure 1 right). The
                        more ﬂexible mask classiﬁcation dominates the ﬁeld of instance-level segmentation. Both Mask
                        R-CNN[19] and DETR [3] yield a single class prediction per segment for instance and panoptic
                        segmentation. In contrast, per-pixel classiﬁcation assumes a static number of outputs and cannot
                        return a variable number of predicted regions/segments, which is required for instance-level tasks.
                        Ourkeyobservation: mask classiﬁcation is sufﬁciently general to solve both semantic- and instance-
                        level segmentation tasks. In fact, before FCN [28], the best performing semantic segmentation
                        methods like O2P [4] and SDS [18] used a mask classiﬁcation formulation. Given this perspective, a
                        natural question emerges: can a single mask classiﬁcation model simplify the landscape of effective
                        approaches to semantic- and instance-level segmentation tasks? And can such a mask classiﬁcation
                        model outperform existing per-pixel classiﬁcation methods for semantic segmentation?
                        Toaddress both questions we propose a simple MaskFormer approach that seamlessly converts any
                        existing per-pixel classiﬁcation model into a mask classiﬁcation. Using the set prediction mechanism
                        proposed in DETR [3], MaskFormer employs a Transformer decoder [37] to compute a set of pairs,
                           ∗Workpartly done during an internship at Facebook AI Research.
                           1Project page: https://bowenc0221.github.io/maskformer
                        35th Conference on Neural Information Processing Systems (NeurIPS 2021).
