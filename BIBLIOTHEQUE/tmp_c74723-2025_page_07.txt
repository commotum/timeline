                                                                                                                                   Table3. ResultsontheScanNet++valset. Wereportresultofour
                                                                                                                                   default modelPanSt3R(full)andonetrainedonlyonScanNet++.
                                                                                                                                   PanSt3R is compared with PanLift [50] and Contrastive Lift [2],
                                                                                                                                   utilizing Mask2Former [15] finetuned on ScanNet++.
                                                                                                                                           Method                               PQ       PQ        PQ        Time(min)
                                                                                                                                                                                             th         st
                                                                                                                                           PanLift [50]                        29.5      15.6      59.4          ∼500
                                                                                                                                           Contrastive Lift [2]                28.4      14.8      56.3          ∼460
                                                                                                                                           PanSt3R(ScanNet++)                  46.7      43.2      55.8          ∼2.3
                           Original Image     Panoptic Lifting   Contrastive Lift        PanSt3R        PanSt3R+LUDVIG                     +LUDVIG                             54.8      52.4      62.4           ∼35
                                                                                                                                           PanSt3R(full)                       49.1      45.8      58.7          ∼2.3
                         Figure 4. Qualitative comparison of novel-view panoptic segmen-                                                   +LUDVIG                             54.7      51.7      62.4           ∼35
                         tation on ScanNet [12] scenes. Colors and their nuances denote
                         different classes and object instances respectively.
                         perform a forward pass on rendered images with PanSt3R;                                                   Discussion. PanSt3R + LUDVIG set a new state-of-the-
                         or (ii) we utilize the LUDVIG uplifting strategy to di-                                                   art, except on Replica, where direct forward pass predic-
                         rectly construct a panoptic 3DGS-based scene representa-                                                  tion of PanSt3R on rendered views performs slightly bet-
                         tion. Given access to target-view images, PanSt3R can di-                                                 ter. On Hypersim and ScanNet, uplifting the panoptic seg-
                         rectly predict panoptic segmentation in a forward pass, in                                                mentations performs much better than direct forward with
                         principle not requiring poses or 3DGS. However, tobemore                                                  PanSt3Rduetothenoisereductioneffectofmulti-viewfea-
                         inline with the competing methods, which predict panoptic                                                 ture aggregation (Fig. 4). Notably, PanSt3R accomplishes
                         segmentation based on test poses, not images, we compute                                                  this while being far more computationallyefficientthanpre-
                         the PQ results for PanSt3R (and PanSt3R w/o QUBO) on                                                      vious methods, even when uplifting to 3DGS via LUDVIG.
                         test images rendered with vanilla 3DGS built with posed                                                   Additionally, using a simple direct prediction with PanSt3R
                                                  3                                                                                onre-rendered images is enough to outperform all previous
                         training images .                                                                                         methods on two out of three datasets (except Hypersim),
                         Comparisonwithexistingmethods. 3Dpanopticsegmen-                                                          with potentially no need for camera parameters in contrast
                         tation methods either directly process an input 3D point                                                  to existing methods.
                         cloud (see discussion in Supplementary), or they revolve
                         around the idea of performing 3D panoptic segmentation                                                    4.4. Evaluation on ScanNet++
                         by lifting 2D segmentation masks obtained with off-the
                         shelf pre-trained 2D panoptic segmentation models, often                                                  We also evaluate PanSt3R on the validation set of the
                         Mask2Former [62] pretrained on COCO [32]. Then they                                                       ScanNet++ [69]. For each of the 50 validation scenes,
                         maptheCOCOpanopticclassestothefollowing21classes:                                                         we randomly select 100 frames (only iPhone images) and
                         wall, floor, cabinet, bed, chair, sofa, table, door, window,                                              use PanSt3R to predict multi-view consistent panoptic seg-
                         counter, shelves, curtain, ceiling, refrigerator, television,                                             mentations for these images in a single forward pass. We
                         person, toilet, sink, lamp, bag and other. In general, these                                              then randomly select 50 images from the remaining pool
                         methods lift and align the 2D predictions to 3D with a test-                                              of images to serve as test views in order to evaluate the
                         time optimization of a NeRF or 3DGS.                                                                      panoptic segmentation on novel unseen viewpoints with the
                              We compare our PanSt3R variants on the PanoLift                                                      same process as used in the PanLift benchmark. A ma-
                         datasets against state-of-the art methods in Tab. 2, where                                                jor difference compared to PanLift is a much larger num-
                         DM-NeRF [57], PNF [25], PanLift [50] and Contrastive                                                      ber of classes (100 instead of 20), including small objects
                         Lift [2] are NeRF-based approaches, and PLGS [62] and                                                     (e.g.crate, paper, socket, cup, smoke detector, soap dis-
                         PCF-Lift [78] rely on 3DGS to uplift 2D panoptic segmen-                                                  penser), hence requiring much more fine-grained segmen-
                         tation masks. PanSt3R inference is performed using the full                                               tation. To better assess the performance of the models, we
                                                                                                                                   also report PQ              and PQ , denoting panoptic quality com-
                         training class set, then classes are re-mapped to the target 21                                                                   th               st
                         classes, similar to existing work. In Fig. 3 we provide vi-                                               puted separately on thing and on stuff classes.
                         sual examples for PanSt3R+LUDVIG on different datasets                                                    Comparisonwithexistingmethods. Duetoalackofpub-
                         and scenes, and in Fig. 4 we provide qualitative compar-                                                  lished results for panoptic segmentation on ScanNet++,
                         isons between PanSt3R, PanSt3R+LUDVIG, PanLift and                                                        we compare our method to PanLift [50] and Contrastive
                         Contrastive Lift.                                                                                         Lift [2] using the official code and uplift the predictions
                             3Note that prediction quality of PanSt3R is limited by the fidelity of                                of Mask2Former, finetuned on the ScanNet++ training set.
                         3DGS rendered views. Direct prediction on test images yields notably                                      To ensure a fair comparison, we also evaluate a variant of
                         better results (see Supplementary).                                                                       PanSt3R trained only on the ScanNet++ training set, de-
                                                                                                                           5862
