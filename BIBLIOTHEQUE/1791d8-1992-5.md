# Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning (1992)
Source: 1791d8-1992.pdf

## Core reasons
- Introduces and analyzes a reinforcement-learning weight-update rule (REINFORCE) for stochastic connectionist networks, focusing on gradient-following learning dynamics.
- The contribution is a learning/optimization method grounded in expected-reinforcement gradients rather than new model architectures, positional encodings, or datasets.

## Evidence extracts
- "Abstract. This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units." (p. 229)
- "These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed." (p. 229)

## Classification
Class name: ML Foundations & Principles
Class code: 5

$$
\boxed{5}
$$
