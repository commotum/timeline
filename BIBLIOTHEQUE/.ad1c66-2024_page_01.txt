                                              International Journal of Applied Earth Observation and Geoinformation 133 (2024) 104105 
                                                                     Contents lists available at ScienceDirect
                                        InternationalJournalofAppliedEarthObservationand
                                                                           Geoinformation
                                                              journal homepage: www.elsevier.com/locate/jag
            Pointcloudsemanticsegmentationwithadaptivespatialstructuregraph
            transformer✩
                                               ∗
            Ting Hana, Yiping Chena, , Jin Maa, Xiaoxue Liub, Wuming Zhanga, Xinchang Zhangc,d,e,
            HuajuanWangf
            a School of Geospatial Engineering and Science, Sun Yat-Sen University, Zhuhai, 519082, China
            b Fujian Key Laboratory of Sensing and Computing for Smart Cities, Xiamen University, Xiamen, 361005, China
            c School of Geography and Remote Sensing, Guangzhou University, Guangzhou, 510006, China
            d College of Geography and Remote sensing Sciences, Xinjiang University, Urumqi, 830046, China
            e Guangdong Urban and Rural Planning and Construction Intelligent Service Engineering Technology Research Center, Guangzhou, 511300, China
            f Zhuhai Surveying and Mapping Institution, Zhuhai, 519000, China
            A R T I C L E      I N F O                       A B S T R A C T
            Keywords:                                        With the rapid development of LiDAR and artificial intelligence technologies, 3D point cloud semantic
            Graphtransformer                                 segmentation has become a highlight research topic. This technology is able to significantly enhance the
            Point cloud                                      capabilities of building information modeling, navigation and environmental perception. However, current
            LiDAR                                            deep learning-based methods primarily rely on voxelization or multi-layer convolution for feature extraction.
            Semanticsegmentation                             These methods often face challenges in effectively differentiating between homogeneous objects or structurally
            Deeplearning                                     adherent targets in complex real-world scenes. To this end, we propose a Graph Transformer point cloud
                                                             semantic segmentation network (ASGFormer) tailored for structurally adherent objects. Firstly, ASGFormer
                                                             combines Graph and Transformer to promote global correlation understanding in the graph. Secondly, spatial
                                                             index and position embedding are constructed based on distance relationships and feature differences. Through
                                                             a learnable mechanism, the structural weights between points are dynamically adjusted, achieving adaptive
                                                             spatial structure within the graph. Finally, dummy nodes are introduced to facilitate global information
                                                             storage and transmission between layers, effectively addressing the issue of information loss at the terminal
                                                             nodes of the graph. Comprehensive experiments are conducted on the various real-world 3D point cloud
                                                             datasets, analyzing the effectiveness of proposed ASGFormer through qualitative and quantitative evaluations.
                                                             ASGFormer outperforms existing approaches with of 91.3% for OA, 78.0% for mAcc, and 72.3% for mIoU on
                                                             S3DIS dataset. Moreover, ASGFormer achieves 72.8%, 45.5%, 81.6%, 70.1% mIoU on ScanNet, City-Facade,
                                                             Toronto 3D and Semantic KITTI dataset, respectively. Notably, the proposed method demonstrates effective
                                                             differentiation of homogeneous structurally adherent objects, further contributing to the intelligent perception
                                                             and modeling of complex scenes.
            1. Introduction                                                                 environmental perception (Meyer et al., 2023; Cotella, 2023; Han et al.,
               LiDAR sensor technology is advancing rapidly. The acquisition and            2023). However, point cloud semantic segmentation still suffers from a
            processing of 3D point cloud holds significant value in the fields of com-      series of complex challenges. Point clouds with similar structures tend
            puter vision (Xiao et al., 2023), geographic spatial information (Stilla        to obscure distinct features. Specifically, the adhesion and overlap of
            and Xu, 2023) and engineering (Geng et al., 2023). As a representation          objects and structures significantly increase the difficulty of point cloud
            of 3D data, point cloud accurately captures the environmental char-             segmentation. The challenges posed by adherent objects and similar
            acteristics of the real scenes, finding widespread applications such as         structures in both indoor and outdoor scenes are shown in Fig. 1.
            building information modeling (BIM) (Liu et al., 2023b), indoor posi-               In recent years, the development of deep learning has significantly
            tioning and navigation (Jiang et al., 2023b; Li et al., 2023), and interior     advanced the analysis and perception of point cloud (Xu et al., 2023b;
             ✩ This work was supported by the National Natural Science Foundation of China under Project 42371343, and Basic and Applied Basic Research Foundation
            of Guangdong Province, China with Grant No. 2024A1515010986.
              ∗ Corresponding author.
                E-mail address: chenyp79@mail.sysu.edu.cn (Y. Chen).
            https://doi.org/10.1016/j.jag.2024.104105
            Received 8 April 2024; Received in revised form 27 July 2024; Accepted 16 August 2024
            Available online 7 September 2024 
            1569-8432/© 2024 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by- 
            nc-nd/4.0/).   
