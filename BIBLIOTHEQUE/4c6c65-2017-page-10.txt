           Supplementary Material
           Here we provide additional details on (A) related work, (B) CLEVR from pixels, (C) CLEVR from
           state descriptions, (D) Sort-of-CLEVR, (E) bAbI, and (F) Dynamic physical system reasoning. For
           each task, we provide additional information on the dataset, model architecture, training and results
           where necessary.
           A Related Work
           Since the RN is highly versatile, it can be used for visual, text-based, and state-based tasks. As such,
           it touches upon a broad range of areas in machine learning, computer vision, and natural language
           understanding. Here, we provide a brief overview of some of the most relevant related work.
           Relational reasoning
           Relational reasoning is implicit in many symbolic approaches [11, 32] and has been explicitly pursued
           using neural networks as well [4]. There is recent work applying neural networks to graphs, which are
           a natural structure for formalising relations [12, 19, 33, 37, 26, 2]. Perhaps a crucial diﬀerence between
           this work and our work here is that RNs require minimal oversight to produce their input (a set of
           objects), and can be applied successfully to tasks even when provided with relatively unstructured
           inputs coming from CNNs and LSTMs. There has also been some recent work on reasoning about
           sets, although this work does not explicitly reason about the relations of elements within sets [47].
           Grounding spatial relations
           Although grounding language in spatial percepts has a long-standing tradition, the majority of
           previous research has focused on either rule-based spatial representations or hand-engineered spatial
           features [8, 10, 20, 21, 24, 29, 38, 39]. Although there are some attempts to learn spatial relations
           using spatial templates [28, 30], these approaches are less versatile than ours.
           Visual question answering
           Visual question answering is a recently introduced task that measures a machine understanding of the
           scene through questions [1, 29]. Related to our work, we are mostly interested in the newly introduced
           CLEVR dataset [15] that distills core challenges of the task, namely relational and multi-modal
           reasoning. The majority of approaches to question answering share the same pipeline [6, 31, 36]. First,
           questions are encoded with recurrent neural networks, and images are encoded with convolutional
           neural networks. Next, both representations are combined, and the answers are either predicted or
           generated. Most successful methods also use an attention mechanism that locate important image
           regions [5, 44, 45, 46]. In our work, we follow a similar pipeline, but we use Relation Networks as a
           powerful reasoning module.
             Parallel to our work, two architectures have shown impressive results on the CLEVR dataset
           [14, 16]. Both approaches hinge on compositionality principles, and have shown they are capable of
           some relational reasoning. However, both require either designing modules, or require direct access to
           ground-truth programs. The RN module, on the other hand, is conceptually simpler, can readily be
           combined with basic neural components such as CNNs or LSTMs, can be broadly applied to various
           tasks, and achieves signiﬁcantly better results on CLEVR [15] than [14], and on par with strongly
           supervised system of [16].
           Text-based question answering
           Answering text-based questions has long been an active research area in the NLP community
           [3, 22, 27, 48]. Recently, in addition to traditional symbolic-based question answering architectures,
           we observe a growing interest in neural-based approaches to text based question answering [34, 42, 43].
           While these architectures rely on ‘memories’, we empirically show that the RN module has similar
                                       10
