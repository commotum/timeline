# ScatterFormer: Efficient Voxel Transformer with Scattered Linear Attention (2024)
Source: b0c53f-2024.pdf

## Core reasons
- Proposes a voxel transformer (ScatterFormer) for large-scale point cloud understanding, indicating a Transformer adapted to 3D spatial data.
- The method centers on voxelizing point clouds and processing them with a Transformer backbone, reflecting higher-dimensional domain modeling rather than a positional encoding tweak.

## Evidence extracts
- "Building upon the SLA and CWI modules, we propose the ScatterFormer, an innovative voxel transformer for large-scale point cloud understanding." (p. 3)
- "It begins with the input point clouds, which are voxelized and transformed into high-dimensional embeddings using a VFE layer [60]." (p. 5)

## Classification
Class name: Increasing Transformer's Dimensions
Class code: 2

$$
\boxed{2}
$$
