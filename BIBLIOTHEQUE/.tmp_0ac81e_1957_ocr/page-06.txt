625

objective sense, questions of metric transitivity would
be crucial, and unless it could be shown that the system
was metrically transitive, we would not be able to find
any solution at all. If we are content with the more
modest aim of finding subjective probabilities, metric
transitivity is irrelevant. Nevertheless, the subjective
theory leads to exactly the same predictions that one
has attempted to justify in the objective sense. The
only place where subjective statistical mechanics makes
contact with the laws of physics is in the enumeration
of the different possible, mutually exclusive states in
which the system might be. Unless a new advance in
knowledge affects this enumeration, it cannot alter
the equations which we use for inference.

Ii the subject were dropped at this pomt, however,
it would remain very difficult to understand why the
above rules of calculation are so uniformly successful
in predicting the behavior of individual systems. In
stripping the statistical part of the argument to its
bare essentials, we have revealed how little content it
really has; the amount of information available in
practical situations is so minute that it alone could
never suffice for making reliable predictions. Without
further conditions arising from the physical nature of
macroscopic systems, one would expect such great
uncertainty in prediction of quantities such as pressure
that we would have no definite theory which could be
compared with experiments. It might also be questioned
whether it is not the most probable, rather than the
average, value over the maximum-entropy distribution
that should be compared with experiment, since the
average might be the average of two peaks and itself
correspond to an impossible value.

It is well known that the answer to both of these
questions lies in the fact that for systems of very large
number of degrees of freedom, the probability distri-
butions of the usual macroscopic quantities determined
from the equations above, possess a single extremely
sharp peak which includes practically all the ‘‘mass” of
the distribution. Thus for all practical purposes average,
most probable, median, or any other type of estimate
are one and the same. It is instructive to see how, in
spite of the small amount of information given, maxi-
mum-entropy estimates of certain functions g(x) can
approach practical certainty because of the way the
possible values of x are distributed. We illustrate this
by a model in which the possible values x, are defined
as follows: let m be a non-negative integer, and ¢ a
small positive number. Then we take

i=1,2,-:+. (3-9)

According to this law, the x, increase without limit as
1c, but become closer together at a rate determined
by x. By choosing ¢ sufficiently small we can make the
density of points «; in the neighborhood of any partic-
ular value of « as high as we please, and therefore for a
continuous function f(x) we can approximate a sum as
closely as we please by an integral taken over a corre-

gy tthe €,0 epi TS 6/2",

INFORMATION THEORY AND STATISTICAL MECHANICS

sponding range of values of x,
E fled f papla)ar,

where, from (3-9), we have

p(x)=at/e.

This approximation is not at all essential, but it
simplifies the mathematics.

Now consider the problem: (A) Given (x), estimate
x’. Using our general rules, as developed in Sec. I,
we first obtain the partition function

° n}
Z0)= f p(x)e de,
0 e\tt
with X determined from (2-11),
0 n+1
(x)= —-— InZ=——-.
On a

Then we find, for the maximum-entropy estimate of 2°,

n+2
“ (3-10)

fay ZF a2 (xe tdae =
(){(2)) f (2) —

Next we invert the problem: (B) Given (x*), estimate
x. The solution is

Z(A)= [> (x) exp(—dx") dx
‘ win! 1
~ Qnt1(m/2)) ehorty”
fe) n+l

(2) = —— InZ=—,
an 2n

oe]

(x) €(a2)} = 24 | px(x) exp(—Ax?de

_ n+1\? Gn)! hat
-( 2 ) emi

The solutions are plotted in Fig. 1 for the case n= 1.
The upper “regression line” represents Eq. (3-10), and
the lower one Eq. (3-11). For other values of », the
slopes of the regression lines are plotted in Fig. 2. As
n— co, both regression lines approach the line at 45°,
and thus for large », there is for all practical purposes
a definite functional relationship between (x) and (2),
independently of which one is considered “given,” and
which one “estimated.”’ Furthermore, as increases
the distributions become sharper; in problem (A) we
find for the variance of x,

(9?) — (x= (x)?/ (+1).

(3-41)

(3-12)
