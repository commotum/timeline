E. T.

value of the function f(x):

(i(a)) = % pelle. (2-1)

On the basis of this information, what is the expectation
value of the function gia)? At first glance, the problem
seems insoluble because the given information is insuffi-

cient to determine the probabilities #;.6 Equation (2-1)
and the normalization condition

dX pi=l (2-2)

would have to be supplemented by (n— 2) more condi-
tions before (g(x)) could be found.

This problem of specification of probabilities in cases
where little or no information is available, is as old as
the theory of probability. Laplace’s “Principle of
Insufficient Reason” was an attempt to supply a
criterion of choice, in which one said that two events
are to be assigned equal probabilities if there is no
reason to think otherwise. However, except in cases
where there is an evident element of symmetry that
clearly renders the events “equally possible,” this
assumption may appear just as arbitrary as any other
that might be made. Furthermore, it has been very
fertile in generating paradoxes in the case of continu-
ously variable random quantities,® since intuitive
notions of “equally possible” are altered by a change of
variables.’ Since the time of Laplace, this way of
formulating problems has been largely abandoned,
owing to the lack of any constructive principle which
would give us a reason for preferring one probability
distribution over another in cases where both agree
equally well with the available information.

For further discussion of this problem, one must
recognize the fact that probability theory has developed
in two very different directions as regards fundamental
notions. The “objective” school of thought®® regards
the probability of an event as an objective property of
that event, always capable in principle of empirical
measurement by observation of frequency ratios in a
random experiment. In calculating a probability distri-
bution the objectivist believes that he is making

5 Vet this is precisely the problem confronting us in statistical
mechanics; on the basis of information which is grossly inadequate
to determine any assignment of probabilities. to individual
quantum states, we are asked to estimate the pressure, specific
heat, intensity of magnetization, chemical potentials, etc., of a
macroscopic system. Furthermore, statistical mechanics is amaz-
ingly successful in providing accurate estimates of these quantities.
Evidently there must be other reasons for this success, that go
beyond a mere correct statistical treatment of the problem as
stated above.

6 The problems associated with the continuous case are funda-
mentally more complicated than those encountered with discrete
random variables; only the discrete case will be considered here.

7 For several examples, see E. P. Northrop, Riddles in Mathe-
matics (D. Van Nostrand Company, Inc., New York, 1944),
Chap. 8.

®H. Cramer, Mathematical Metheds of Statistics (Princeton
University Press, Princeton, 1946).

9W. Feller, An futroduction to Probability Theory and its
Applications (John Wiley and Sons, Inc., New York, 1950).

JAYNES 622
predictions which are in principle verifiable in every
detail, just as are those of classical mechanics. The
test of a good objective probability distribution (x) is:
does it correctly represent the observable fluctuations
of x?

On the other hand, the “subjective” school of
thought!" regards probabilities as expressions of
human ignorance; the probability of an event is merely
a formal expression of our expectation that the event
will or did occur, based on whatever information is
available. To the subjectivist, the purpose of proba-
bility theory is to help us in forming plausible conclu-
sions in cases where there is not enough information
available to lead to certain conclusions; thus detailed
verification is not expected. The test of a good subjec-
tive probability distribution is does it correctly repre-
sent our state of knowledge as to the value of x?

Although the theories of subjective and objective
probability are mathematically identical, the concepts
themselves refuse to be united. In the various statistical
problems presented to us by physics, both viewpoints
are required. Needless controversy has resulted from
attempts to uphold one or the other in all cases. The
subjective view is evidently the broader one, since it is
always possible to interpret frequency ratios in this
way; furthermore, the subjectivist will admit as legiti-
mate objects of inquiry many questions which the
objectivist considers meaningless. The problem posed
at the beginning of this section is of this type, and
therefore in considering it we are necessarily adopting
the subjective point of view.

Just as in applied statistics the crux of a problem is
often the devising of some method of sampling that
avoids bias, our problem is that of finding a probability
assignment which avoids bias, while agreeing with
whatever information is given. The great advance
provided by information theory lies in the discovery
that there is a unique, unambiguous criterion for the
“amount of uncertainty’? represented by a discrete
probability distribution, which agrees with our intuitive
notions that a broad distribution represents more
uncertainty than does a sharply peaked one, and
satisfies all other conditions which make it reasonable.*
In Appendix A we sketch Shannon’s proof that the
quantity which is positive, which increases with
increasing uncertainty, and is additive for independent
sources of uncertainty, is

H(pi-+ pr) =—K Ys pi lnpi, (2-3)

where K is a positive constant. Since this is just the
expression for entropy as found in statistical mechanics,
it will be called the entropy of the probability distri-
bution £,;; henceforth we will consider the terms
“entropy” and “uncertainty” as synonymous.

10 J. M. Keynes, 4 Treatise on Probability (MacMillan Company,
London, 1921),

NHL Jeffreys, Theory of Probability (Oxford University Press,
London, 1939),
