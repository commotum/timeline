E. T. JAYNES

Z Fic. 1. Regression
A of x and x* for state
density increasing
linearly with x. To
find the maximum-
y entropy estimate of
7 either quantity given
the expectation val-
/ ue of the other,
, follow the arrows.

—>
ry
\
\

<x —>

Similar results hold in this model for the maximum-
entropy estimate of any sufficiently well-behaved
function g(x). If g(«) can be expanded in a power series
in a sufficiently wide region about the point x=(x), we
obtain, using the distribution of problem A above, the
following expressions for the expectation value and

variance of ¢:

A?(g) <ieto)-ttaye fs)
= Le) Fo t0

(g(x) =g aa SGC varie (3-13)

“(9 (3-14)

Conversely, a sufficient condition for x to be well
determined by knowledge of (g(x)) is that x be a
sufficiently smooth monotonic function of g. The ap-
parent lack of symmetry, in that reasoning from (x)
to g does not require monotonicity of g(x), is due to
the fact that the distribution of possible values has
been specified in terms of x rather than g.

As # increases, the relative standard deviations of all
sufficiently well-behaved functions go down like #74; it
is in this way that definite laws of thermodynamics,
essentially independent of the type of information given,
emerge from a statistical treatment that at first appears
incapable of giving reliable predictions. The parameter
# is to be compared with the number of degrees of
freedom of a macroscopic system.

4. SUBJECTIVE AND OBJECTIVE
STATISTICAL MECHANICS

Many of the propositions of statistical mechanics are
capable of two different interpretations. The Max-
wellian distribution of velocities in a gas is, on the one
hand, the distribution that can be realized in the
greatest number of ways for a given total energy; on
the other hand, it is a well-verified experimental fact.
Fluctuations in quantities such as the density of a gas
or the voltage across a resistor represent on the one
hand the uncertainty of our predictions, on the other
a measurable physical phenomenon. Entropy as a con-

626

cept may be regarded as a measure of our degree of
ignorance as to the state of a system; on the other
hand, for equilibrium conditions it is an experimentally
measurable quantity, whose most important properties
were first found empirically. It is this last circumstance
that is most often advanced as an argument against
the subjective interpretation of entropy.

The relation between maximum-entropy inference
and experimental facts may be clarified as follows. We
frankly recognize that the probabilities involved in
prediction based on partial information can have only
a subjective significance, and that the situation cannot
be altered by the device of inventing a fictitious
ensemble, even though this enables us to give the
probabilities a frequency mierpretation One might
then ask how such probabilities could be in any way
relevant to the behavior of actual physical systems. A
good answer to this is Laplace’s famous remark that
probability theory is nothing but ‘common. sense
reduced to calculation.” If we have little or no infor-

20

m

on

Fig. 2. Slope of
regression lines as a
function of #.

SLOPE —»
B

i
6
i

mation relevant to a certain question, common sense
tells us that no strong conclusions either way are
justified. The same thing must happen in statistical
inference, the appearance of a broed probability distri-
bution signifying the verdict, ‘‘no definite conclusion.”
On the other hand, whenever the available information
is sufficient to justify fairly strong opinions, maximum-
entropy inference gives sharp probability distributions
indicating the favored alternative. Thus, the theory
makes definite predictions as to experimental behavior
only when, and to the extent that, it leads to sharp distri-
butions.

When our distributions broaden, the predictions
become indefinite and it becomes less and less meaning-
ful to speak of experimental verification. As the avail-
able information decreases to zero, maximum-entropy
inference (as well as common sense) shades continuously
into nonsense and eventually becomes useless. Never-
theless, at each stage it still represents the best that
could have been done with the given information.

Phenomena in which the predictions of statistical
mechanics are well verified experimentally are always
those in which our probability distributions, for the
macroscopic quantities actually measured, have enor-
mously sharp peaks. But the process of maximum-
