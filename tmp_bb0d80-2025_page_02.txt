              Figure 2: Diagram depicting one pass of the Growing NCA update step and its neural network model. Adapted from (Mordv-
              intsev et al., 2020).
              et al., 2022; Sudhakaran et al., 2021), where local cellular       mark. To the best of our knowledge, this is the first time
              interactions give rise to organized structures during devel-       NCAsare used for the 2D ARC-AGI benchmark. Engram-
              opment (such as bodies and brains). Furthermore, biolog-           NCAischosen,inadditiontostandardNCAs,becauseitre-
              ical brains employ cognitive mechanisms that may mirror            lies on mechanismsforlearninglow-levelmorphologiesand
              developmental processes to facilitate reasoning, abstraction,      manipulations first, and then a regulation mechanism for de-
              and problem-solving through dynamic, iterative, and self-          ciding when and where such primitives should be activated
              organizing processes. Examples include iterative refinement        and propagated, which is considered a suitable mechanism
              of mental schemas through interactions with the environ-           for abstraction and reasoning tasks. By emulating the princi-
              ment (McVee et al., 2005; Neumann and Kopcha, 2018),               ples of biological development and cognitive development,
              hierarchical structuring to break down tasks in sub-tasks          our models aim to capture essential aspects of human-like
              (Botvinick et al., 2009; Meunier et al., 2009), and predic-        abstraction and reasoning. Our ARC-NCA approach may
              tive modeling to anticipate outcomes and proactively adjust        be considered a program synthesis approach, where a cus-
              solutions (Friston, 2003; Seth, 2014; Millidge et al., 2021).      tom NCA (a ”program”) is generated for the task at hand
              The hypothesis tested in this work is whether the develop-         with a fine-tuning process akin to test-time training. Our
              mental nature of NCAs makes them particularly suited for           proof-of-concept demonstrates that ARC-NCA may reach
              tasks like those in the ARC-AGI benchmark.                         performances comparable, and sometimes superior, to ex-
                 In the last years, most approaches for ARC-AGI relied           isting models (including ChatGPT 4.5, see results and dis-
              on discrete program search, a brute force methodology. Re-         cussion section for details), but with significantly reduced
              cently, Large Language Models (LLMs) have been utilized            computational resources. We hope that our work will spark
              in different ways, including for optimizing domain-specific        a renewed interest within the artificial life community for
              languages (Chollet et al., 2024). Further, LLMs have been          radically new approaches to abstraction and reasoning.
              used for program synthesis with the intention of generating                            Related Works
              programs in general-purpose languages, e.g., Python, that
              attempt to solve the task at hand. Test-time training, also        Theapplication of cellular automata (CA) models, and mor-
              known as inference-time fine-tuning, has been rather popu-         phogenetic models in general (Wolfram, 1997), to the ARC-
              lar in the last few months to allow inference-timeadaptations      AGI benchmark (Chollet, 2019) remains an underexplored
              based on unseen test samples. Often, hybrid approaches,            area. However, several developments in CA research sug-
              including program synthesis and transductions, i.e., direct        gest potential avenues for applying CA methodologies to
              prompting an LLM, have been combined. However, solving             ARCtasks. Inparticular, one architectural choice that opens
              the ARCisstill an open problem and the solution might still        up opportunities for learning CA rules is Neural Cellular
              lie in uncharted areas of model selection.                         Automata (Gilpin, 2019; Mordvintsev et al., 2020; Nichele
                 In this paper, we introduce ARC-NCA, a novel approach           et al., 2017), where a neural network replaces more tradi-
              that leverages the developmental dynamics of standard Neu-         tional CA lookup tables. NCA was proposed as a possible
              ral Cellular Automata (Mordvintsev et al., 2020) and an en-        embodied controller by (Variengien et al., 2021), where an
              hanced variant with hidden memory states, termed Engram-           NCA was connected to a reinforcement learning environ-
              NCA(Guichardetal.,2025),totackletheARC-AGIbench-                   ment in a closed loop, thus demonstrating a self-organising
