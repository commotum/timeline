                                          Test-Time Learning for Large Language Models
                          Table 14. Comparison of experimental results on the Alpaca-GPT4 dataset of InstructionBench.
                 Method              BERTScore↑    BLEURT↑     BLEU↑     Rouge-1 ↑   Rouge-2 ↑   Rouge-L↑
                 Llama3.2-3B-Instruct  0.7260       -0.5164     0.0953     0.3885     0.1712      0.2619
                   •Tent               0.5656       -1.5454     0.0054     0.0351     0.0032      0.0305
                   •EATA               0.6553       -1.2411     0.0220     0.1513     0.0753      0.1359
                   •TLM(Ours)          0.7523       -0.4148     0.1239     0.4170     0.2062      0.3184
                 Llama3-8B-Instruct    0.7353       -0.4655     0.1082     0.4076     0.1863      0.2796
                   •Tent               0.6712       -1.0652     0.0421     0.2193     0.1193      0.1881
                   •EATA               0.6398       -0.8220     0.0271     0.1499     0.0725      0.1332
                   •TLM(Ours)          0.7669       -0.3090     0.1479     0.4582     0.2349      0.3528
                 Llama2-13B-chat       0.7326       -0.5290     0.1091     0.4068     0.1830      0.2777
                   •Tent               0.6249       -1.4903     0.0108     0.0998     0.0444      0.0937
                   •EATA               0.5073       -0.7398     0.0094     0.0813     0.0191      0.0799
                   •TLM(Ours)          0.7386       -0.5150     0.1229     0.4311     0.1987      0.3040
                 Qwen2.5-7B-Instruct   0.7624       -0.2949     0.1556     0.4803     0.2353      0.3406
                   •Tent               0.6787       -0.9809     0.0501     0.2323     0.1315      0.2031
                   •EATA               0.0000       -1.9681     0.0000     0.0000     0.0000      0.0000
                   •TLM(Ours)          0.7829       -0.2137     0.1749     0.4919     0.2648      0.3819
                             Table 15. Comparison of experimental results on the Dolly dataset of InstructionBench.
                 Method              BERTScore↑    BLEURT↑     BLEU↑     Rouge-1 ↑   Rouge-2 ↑   Rouge-L↑
                 Llama3.2-3B-Instruct  0.7289       -0.4824     0.0946     0.3778     0.1903      0.2935
                   •Tent               0.6866       -0.5922     0.0797     0.2374     0.1398      0.2039
                   •EATA               0.5767       -1.5690     0.0027     0.0092     0.0002      0.0086
                   •TLM(Ours)          0.7334       -0.4783     0.1030     0.3878     0.1997      0.3048
                 Llama3-8B-Instruct    0.7415       -0.4088     0.1114     0.4126     0.2137      0.3222
                   •Tent               0.5905       -1.4648     0.0000     0.0036     0.0000      0.0036
                   •EATA               0.6559       -1.2475     0.0275     0.1991     0.0868      0.1661
                   •TLM(Ours)          0.7497       -0.3972     0.1194     0.4239     0.2226      0.3388
                 Llama2-13B-chat       0.7074       -0.8015     0.0743     0.3274     0.1550      0.2407
                   •Tent               0.4111       -0.7963     0.0008     0.0076     0.0000      0.0076
                   •EATA               0.5355       -0.9809     0.0076     0.0632     0.0175      0.0577
                   •TLM(Ours)          0.7108       -0.8169     0.0789     0.3411     0.1625      0.2516
                 Qwen2.5-7B-Instruct   0.7212       -0.4784     0.0911     0.3501     0.1790      0.2634
                   •Tent               0.6674       -1.1697     0.0420     0.2373     0.1036      0.1051
                   •EATA               0.6737       -1.1244     0.0491     0.2482     0.1132      0.1963
                   •TLM(Ours)          0.7216       -0.5209     0.0931     0.3567     0.1832      0.2685
                                                            26
