                  iScience                                                                                                                              ll
                  Article                                                                                                                         OPENACCESS
                  Table 10. Effect of the PST-FPN on the KITTI validation split
                  Methods                                                         PST-FPN                                                         Car-AP3D(%)
                  a                                                               Y                                                               87.04
                  b                                                               N                                                               85.69
                  Implementation details
                                                                                                                      46
                  Theexperimentalprocedureutilizedatoolbox,detailsofthatcanbereferredtoinOpenPCDet. FortheKITTIdataset,thex,y,zcoordinate
                  rangeofthepointcloudis[0,+70.4],[-40,+40],[-3.0,+1.0]andthevoxelsizeissetto[0.05,0.05,0.1].FortheWaymoOpenDataset,thex,y,z
                  coordinate range of the point cloud is set to [-75.2, +75.2], [-75.2, +75.2], [-2.0, +4.0] and the voxel size is set to [0.1, 0.1, 0.15]. For nuScenes
                  dataset,thex,y,zcoordinaterangeofthepointcloudissetto[-54.0,+54.0],[-54.0,+54.0],[-5.0,+3.0]andthevoxelsizeissetto[0.075,0.075,
                  0.2]. Post-transformationofthepointcloudintoregularizedvoxels,non-emptyvoxelsarelinearlyprojectedtoyield16-channelinitialfeatures,
                  subsequentlyinputtedintoVoxelSelf-attentionforfeaturelearning.Thechannelcountofvoxelfeaturesincreasesto32aftertheﬁrstandto64
                  afterthesecondattention-2,whileothermodulesmaintainthevoxelfeaturechannel.ThenPST-FPNprocessesfeaturelearningandoutputsa
                  feature map with 256 channels. In the center-point detection head, the feature map scale factor is set at 1/4, with a maximum detection ca-
                  pacity of 100 objects, and the permissible error distance for detected center points is 2 cm.
                     VSACwastrainedend-to-endon2NVIDIA-A30GPUsusingtheADAMoptimizer.FortheKITTIdataset,thebatchsizewassetto4,the
                  numberofepochswassetto90,themaximumlearningratewassetto0.01andthelearningrateforallmodelswas0.003,withdecayper-
                  formedbycosineannealing.FortheWaymoOpenDataset,thebatchsizewassetto2,thenumberofepochswassetto30andthemaximum
                  learning rate was set to 0.01. For the nuScenes dataset, the batch size was set to 2, the number of epochs was set to 20, and the maximum
                  learning rate was set to 0.01. During the training phase, for target assignment, we set an IoU threshold of 0.55. If the IoU between a proposal
                  andtheground-truthboxesisgreaterthantheIoUthreshold,thentheproposalisconsideredapositivesample.Otherwise,itisconsidereda
                  negativesample.Intheinferencestage,weselectedthetop128candidatesbasedonconﬁdencefornon-maximumsuppression(NMS)witha
                  threshold of 0.7. Additionally, we employed a data augmentation strategy for the 3D point cloud data, which included random ﬂipping,
                                                                                                            
                  scaling within a range of 0.95–1.05, and rotation around the X axis between 5 and 5 .
                  Comparisons on the KITTI dataset
                  ToverifythevalidityoftheVSAC,wesubmittheresultsonthetestsettotheofﬁcialKITTIwebsite.Theevaluationmetricsusedforthetestset
                  areAP|R40andAOS,whiletheevaluationmetricforthevalidationsplitisAP|R11.AsshowninTable1,weprovideadetailedoverviewofthe
                  AOSforCars at three different levels and the top performance is indicated in bold. Compared to the anchor-based method (PointPillars),
                  VSACdemonstrates superior performance in terms of orientation prediction accuracy, with AOS improvements of 2.12% for easy, 1.6% for
                  moderate, and 0.01% for hard levels. This indicates the excellent performance of VSAC in the direction prediction of car.
                     InTable2,comparedtotheone-stagemodel(SECOND),theresultsofVSACincreasedby3.14%,4.09%and6.22%in3Ddetectionineasy,
                  moderateandhardmodes,respectively.InBEVdetection,VSACalsohasanincreaseof2.67%,2.57%,and3.04%.Incomparisonwiththeone-
                  stage voxel attention model (VoTr-SSD), VSAC achieves a 3.33% improvement in Hard mode for 3D Car detection. These show that VSAC
                  demonstrates superior comprehensive performance in both 3D and BEV detection of Car.
                     In addition, as shown in Table 3, we further compare the 3D car inspection results on the KITTI validation split using AP|R11 as the metric.
                  Detection performance of VSAC surpasses most methods.
                     The precision-recall curve is an indicator of detection performance and the larger its area, the more outstanding the detection perfor-
                  mance. As shown in Figure 4, VSAC demonstrates robust performance in 3D detection, BEV detection, and AOS detection for cars.
                     Partial visualizations of the test set predictions are presented in Figure 5 for a higher-quality comparison. According to the test results,
                  VSACmissesfewobjectsincomplexenvironmentsandthepredictedvehicledirectioniscorrect.Thisindicatesa goodrobustnessandsta-
                  bility of the VSAC.
                     All in all, as our VSAC has exhibited exceptional performance on both the validation and test sets, this serves as evidence of the model’s
                  effectiveness.
                  Comparisons on the Waymo Open Dataset
                  WefurthervalidatetheeffectivenessofourapproachbyconductingexperimentsundertheWaymoOpenDatasetwithamorecomplexenvi-
                  ronment.AsshowninTable4,wecompareVSACwithotherexcellentanchor-basedobjectdetectionmethodsontheWaymovalidationset.
                  Table 11. Comparison of inference speed on the KITTI validation split
                                               10                     55                     29                      30                   39
                  Methods            SECOND               AVOD-FPN               F-PointNet             PointRCNN              PV-RCNN               VSAC(ours)
                  Speed(HZ)          20.00                10.00                  5.90                   10.00                  9.25                  14.28
                                                                                                                       iScience 27, 110759, September 20, 2024     11
