                            ll                                                                                                             iScience
                       OPENACCESS                                                                                                               Article
                 Table 4. Performance comparison on Waymo validation set
                 Methods                LEVEL-1(3D mAP)                LEVEL-1(3D mAPH)                LEVEL-2(3D mAP)               LEVEL-2(3D mAPH)
                 PointPillars13         63.3                           62.7                            55.2                          54.7
                     64
                 MVF                    62.93                          –                               –                             –
                 Pillar-OD65            69.8                           –                               –                             –
                 LaserNet66             52.1                           50.1                            –                             –
                 CVCNet67               65.2                           –                               –                             –
                 StarNet68              64.7                           56.3                            45.5                          39.6
                 RCD69                  69.0                           68.5                            –                             –
                          39
                 PV-RCNN                70.3                           69.7                            65.4                          64.8
                 VoTr-SSD23             68.9                           68.3                            60.2                          59.6
                 VSAC(ours)             71.7                           71.1                            63.7                          63.1
                    Finally, the voxel self-attention is deﬁned as:
                                                                                   X QK 
                                                                         attend              i k
                                                                        fi     =       j pﬃﬃﬃﬃ    $Vk                                         (Equation 11)
                                                                                  k˛UðiÞ     d
                    Theself-attention on voxels is an extension of 2D self-attention to 3D, where the position embedding utilizes sparse voxels and relative
                 coordinates. The normalization function j($) mentioned is the softmax function and the d indicates the length of Q.
                                                                                                                                     i
                 Pseudo spatio-temporal feature pyramid Net (PST-FPN)
                 In the processingofpseudo-images,duetothereductioninfeaturemapresolutionandincreaseinthenumberofchannels,highlightingthe
                 importanceofdifferentresolutionsandfeaturechannelsisparticularlycritical.AsshowninFigure1C,unlikethetraditionalFPN,PST-FPNadd
                 two additional components: channel attention and spatial attention with residual networks to highlight different key features.
                    Speciﬁcally, channel attention is used to highlight the key feature of the pixel in different channels. In channel attention, we ﬁrst aggre-
                 gate the information of each channel in the feature maps through max pooling and average pooling to generate two different types of
                 feature information. Then, these two types of feature information are processed by a shared multi-layer perceptron (MLP), resulting in
                 two channel feature maps. Subsequently, we fuse these two channel feature maps by element-wise addition to output feature maps
                 with enhanced representational capability. Finally, we additionally incorporate a residual network to maintain the stability of the model.
                 Spatial attention is used to highlight the key pixels in the same channel. Initially, for each feature plane, we adopt max pooling to aggre-
                 gatethefeaturemaptogeneratefeatureinformation.Subsequently,thisfeatureinformationisprocessedthroughaconvolutionallayer,
                 resulting in a feature map with enhanced semantic capability. Ultimately, we incorporate a residual network to ensure the stability of the
                 model.
                 Center-point detection head module
                 As illustrated in Figure 1D, the center-point detection head including comprising a center head, regression head, and offset head. It can
                 directly detect the center-point position and 3D dimensions of the object.
                    Firstly, the input I to the detection head is the feature map outputted by the PST-FPN, denoted as:
                                                                                 I ˛RW3H3C                                                    (Equation 12)
                 WhereW,H,andCrepresentthewidth,height,andthenumberoffeaturechannelsofthefeaturemap,respectively.
                 Table 5. Performance comparison on nuScenes dataset
                 Methods          Car       Truck      Bus       Trailer     Cons       Ped       Moto       Bike      TC       Bar       mAP        NDS
                 SECOND10         73.1      25.2       30.5      31.5        8.5        59.3      21.7       4.9       18.0     43.3      31.6       46.8
                 PointPillars13   68.4      23.0       28.2      23.4        4.1        59.7      27.4       1.1       30.8     38.9      30.5       45.3
                 SARPNET70        59.9      18.7       19.4      18.0        11.6       69.4      29.8       14.2      44.6     38.3      31.6       49.7
                 WYSIWYG34        79.1      30.4       46.6      40.1        7.1        65.0      18.2       0.1       28.8     34.7      35.0       41.9
                 SMS-Net63        80.3      49.5       61.3      35.1        12.1       71.2      28.9       4.6       46.0     48.0      43.7       57.6
                 VSAC(ours)       78.0      47.4       63.6      21.4        9.4        77.0      37.5       18.8      36.2     7.3       39.7       55.8
                 8     iScience 27, 110759, September 20, 2024
