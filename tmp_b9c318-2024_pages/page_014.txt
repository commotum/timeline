                  iScience                                                                                                                              ll
                  Article                                                                                                                         OPENACCESS
                  Table 12. Equipment information
                  Equipment                                                        Brand                                                         Modelnumber
                  INS                                                              CHCNAV                                                        410
                  IPC                                                              Advantech                                                     610L
                  GPS                                                              CHCNAV                                                        410
                  LiDAR                                                            Leishen                                                       C32
                  Camera                                                           MOKOSE                                                        UC50
                  CDC                                                              Freescale                                                     XEP100
                  Effects of pseudo spatio-temporal feature pyramid net
                  In order to demonstrate the effectiveness of the PST-FPN, we remove the channel attention and spatial attention, just using the FPN to pro-
                  cess the pseudo 2D feature maps. As shown in Table 10, we can see that AP|R40 improves by 1.35% when our algorithm adds the PST-FPN.
                  Runtime analysis
                  Inference speed is critically important for real-time applications in autonomous driving scenarios. All model experiments are trained and in-
                  ferredonasingleIntel(R)Xeon(R)Platinum8352VCPUandasingleA30(24GB)GPU.TheaverageinferencespeedofVSAConthevalidation
                  split 14.28Hz. As shown in Table 11, VSAC compares favorably to PV-RCNN (14.28 Hz vs. 9.25 Hz). Compared to the voxel-based method
                  (SECOND),thedetectionmethod(VSAC)introducesaself-attentionmechanism,whichincreasesthecomputationalcomplexityandconse-
                  quentlyreducestheinferencespeedby5.72Hz(20.00HzVS14.28Hz).However,VSACachieveshigherdetectionaccuracythanSECOND,al-
                  lowing for a good balance between detection precision and efﬁciency in autonomous driving.
                  Real vehicle detection experiment
                  AsshowninFigure6AandTable12,ourautonomousdrivingplatformprimarilyincludesanautonomousvehicle(Borgward),a32-lineLiDAR,
                  cameras,GPS,aninertialnavigationsystem(INS),achassisdomaincontroller(CDC),anindustrialpersonalcomputer(IPC),amongothercom-
                  ponents.AsshowninFigure6B,theentireautonomousdrivingplatformiscomposedofthreesystems:theperceptionsystem,thedecision
                  system,andthecontrolsystem.Thevarioussensorsoftheperceptionsystemprimarilytransmitsensoryinformationtothedecisionsystemvia
                  ROS(RobotOperating System) or CAN (Controller Area Network).
                     AsshowninFigure7,theexperimentswiththeVSACalgorithmprimarily utilized LiDAR to collect campus scene data through ROS and
                  implementedonlinedetectionontheIPC.TheperceptionresultswerethentransmittedtothedecisionsystemviaCANforfurtherprocess-
                  ing.DuetothesamplingfrequencyofLiDARbeing10Hzandthetimerequiredfordatacommunication,theinferencespeedofonlinedetec-
                  tion was 7.69Hz, which met the perception requirements of autonomous driving.
                     Figure8illustratedthereal-vehicledetectionvisualizationoftheVSACalgorithm.Images8-a2and8-b2showedcampusscenes,while8-a1
                  and8-b1displayedthe3Dobjectdetectionresultsinthosescenes.Fromthedetectionoutcomes,itwasevidentthatVSACcouldaccurately
                  detectcarsontheroad.However,detectionfailuresstilloccurredwhentheobjectsweredistantorseverelyoccluded.Thiswasbecausetar-
                  getsthatwerefarawayorheavilyobscuredreﬂectedfewerpointsinthepointcloud,hinderingtheabilityofmodeltocapturethegeometric
                  information of the objects.
                  DISCUSSION
                  In this paper, a novel single-stage 3D object detector (VSAC) for autonomous driving from raw point clouds is proposed. Firstly, a voxel self-
                  attention mechanism is proposed to build voxel relationships within a large range, thereby enhancing the model’s understanding of spatial
                  structures. Secondly, in processing compressedvoxelfeatures,proposedPST-FPNampliﬁesthemostimportantlocalinformationandprop-
                  agatesspaceinformationtothefeaturechannellevels.Then,acenter-pointdetectorheadisdesignedtoﬁne-tunetheheadingangleofthe
                  object during steering, so that the predicted heading angle is closer to the real one. Experiments on the KITTI dataset show that VSAC not
                  onlyachievesgoodperformanceindetectionaccuracy,butalsoexhibitsfavorableresultsinpredictingdirectionalaccuracy.Atthesametime,
                  VSACalsodemonstrates advanced detection performance on the nuScenes dataset and the Waymo Open Dataset.
                                                                         ROS
                                                                                  VSAC
                                                                                                              CAN
                                                                                                                        Decicion system
                                                 Lidar         Points cloud        IPC
                                                                                             Label information
                                                                     Perceptual system
                  Figure 7. Data transmission process for LiDAR object detection
                                                                                                                       iScience 27, 110759, September 20, 2024     13
