              References
               [ADG+16] Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul,
                        Brendan Shillingford, and Nando De Freitas. Learning to learn by gradient descent by gradient descent.
                        In Advances in neural information processing systems, pages 3981–3989, 2016.
                  [AI19] WeChat AI. Tr-mt (ensemble), December 2019.
                 [AJF19] Roee Aharoni, Melvin Johnson, and Orhan Firat. Massively multilingual neural machine translation. In
                        Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational
                        Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 2019.
                                                        ´
              [BBDIW20] SuLinBlodgett,SolonBarocas, Hal Daume III, and Hanna Wallach. Language (technology) is power:
                        Acritical survey of “bias” in nlp. arXiv preprint arXiv:2005.14050, 2020.
                [BCFL13] Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. Semantic parsing on freebase from
                        question-answer pairs. In Proceedings of the 2013 conference on empirical methods in natural language
                        processing, pages 1533–1544, 2013.
                    +
               [BDD 09] LuisaBentivogli, Ido Dagan, Hoa Trang Dang, Danilo Giampiccolo, and Bernardo Magnini. The ﬁfth
                        PASCALrecognizingtextual entailment challenge. 2009.
                 [BES10] Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. Sentiwordnet 3.0: an enhanced lexical
                        resource for sentiment analysis and opinion mining. In Lrec, volume 10, pages 2200–2204, 2010.
              [BHDD+06] RoyBarHaim,IdoDagan,BillDolan,LisaFerro,DaniloGiampiccolo,BernardoMagnini, and Idan
                        Szpektor. The second PASCAL recognising textual entailment challenge. 2006.
                    +
               [BHT 20] Yonatan Bisk, Ari Holtzman, Jesse Thomason, Jacob Andreas, Yoshua Bengio, Joyce Chai, Mirella
                        Lapata, Angeliki Lazaridou, Jonathan May, Aleksandr Nisnevich, et al. Experience grounds language.
                        arXiv preprint arXiv:2004.10151, 2020.
                                            ´
                 [BLC13] YoshuaBengio, Nicholas Leonard, and Aaron C. Courville. Estimating or propagating gradients through
                        stochastic neurons for conditional computation. Arxiv, 2013.
               [BZB+19] Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, and Yejin Choi. Piqa: Reasoning about
                        physical commonsense in natural language. arXiv preprint arXiv:1911.11641, 2019.
                  [Car97] Rich Caruana. Multitask learning. Machine learning, 28(1), 1997.
                  [CB78] SusanCareyandElsaBartlett. Acquiringasinglenewword. ProceedingsoftheStanfordChildLanguage
                        Conference, 1978.
               [CCE+18] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and
                        Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge. ArXiv,
                        abs/1803.05457, 2018.
               [CGRS19] Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. Generating long sequences with sparse
                        transformers, 2019.
                    +
                [CHI 18] Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, and Luke
                        Zettlemoyer. Quac : Question answering in context. Arxiv, 2018.
               [CLC+19] Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina
                        Toutanova. BoolQ: Exploring the surprising difﬁculty of natural yes/no questions. arXiv preprint
                        arXiv:1905.10044, 2019.
                    +
                [CLY 19] Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed El Kholy, Faisal Ahmed, Zhe Gan, Yu Cheng, and
                        Jingjing Liu. Uniter: Learning universal image-text representations. arXiv preprint arXiv:1909.11740,
                        2019.
                  [Cra17] Kate Crawford. The trouble with bias. NIPS 2017 Keynote, 2017.
                [DCLT18] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep
                        bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.
                                                       68
