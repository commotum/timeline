                             DensePassageRetrieval for Open-Domain Question Answering
                                                                    ∗             ˘    ∗                †
                                       Vladimir Karpukhin, Barlas Oguz, Sewon Min , Patrick Lewis,
                                                                                                    ‡
                                             Ledell Wu, Sergey Edunov, Danqi Chen , Wen-tau Yih
                                   Facebook AI              †University of Washington                 ‡Princeton University
                           {vladk, barlaso, plewis, ledell, edunov, scottyih}@fb.com
                                                            sewon@cs.washington.edu
                                                            danqic@cs.princeton.edu
                                            Abstract                                    Retrieval in open-domain QA is usually imple-
                         Open-domain question answering relies on ef-                mented using TF-IDF or BM25 (Robertson and
                         ﬁcient passage retrieval to select candidate                Zaragoza, 2009), which matches keywords efﬁ-
                         contexts, where traditional sparse vector space             ciently with an inverted index and can be seen
                         models, such as TF-IDF or BM25, are the de                  as representing the question and context in high-
                         facto method.     In this work, we show that                dimensional, sparse vectors (with weighting). Con-
                         retrieval can be practically implemented us-                versely, the dense, latent semantic encoding is com-
                         ing dense representations alone, where em-                  plementarytosparserepresentationsbydesign. For
                         beddings are learned from a small number                    example, synonyms or paraphrases that consist of
                         of questions and passages by a simple dual-                 completely different tokens may still be mapped to
                         encoder framework.       When evaluated on a                vectors close to each other. Consider the question
                         wide range of open-domain QA datasets, our                 “Whoisthebadguyinlordoftherings?”,whichcan
                         dense retriever outperforms a strong Lucene-
                         BM25system greatly by 9%-19% absolute in                    be answered from the context “Sala Baker is best
                         termsoftop-20passageretrievalaccuracy,and                   knownforportrayingthevillain Sauron in the Lord
                         helps our end-to-end QA system establish new                of the Rings trilogy.” A term-based system would
                         state-of-the-art on multiple open-domain QA                 have difﬁculty retrieving such a context, while
                                       1
                         benchmarks.                                                 a dense retrieval system would be able to better
                    1    Introduction                                                match “bad guy” with “villain” and fetch the cor-
                                                                                     rect context. Dense encodings are also learnable
                    Open-domain question answering (QA) (Voorhees,                   byadjusting the embedding functions, which pro-
                    1999) is a task that answers factoid questions us-               vides additional ﬂexibility to have a task-speciﬁc
                    ing a large collection of documents. While early                 representation. With special in-memory data struc-
                    QAsystemsareoften complicated and consist of                     tures and indexing schemes, retrieval can be done
                    multiple components (Ferrucci (2012); Moldovan                   efﬁciently using maximum inner product search
                    et al. (2003), inter alia), the advances of reading              (MIPS)algorithms(e.g., Shrivastava and Li (2014);
                    comprehension models suggest a much simpliﬁed                    Guoetal. (2016)).
                    two-stage framework: (1) a context retriever ﬁrst                   However, it is generally believed that learn-
                    selects a small subset of passages where some                    ing a good dense vector representation needs a
         arXiv:2004.04906v3  [cs.CL]  30 Sep 2020of them contain the answer to the question, andlarge number of labeled pairs of question and con-
                    then (2) a machine reader can thoroughly exam-                   texts.  Dense retrieval methods have thus never
                    ine the retrieved contexts and identify the correct              be shown to outperform TF-IDF/BM25 for open-
                    answer (Chen et al., 2017). Although reducing                    domainQAbeforeORQA(Leeetal.,2019),which
                    open-domain QA to machine reading is a very rea-                 proposes a sophisticated inverse cloze task (ICT)
                    sonable strategy, a huge performance degradation                 objective, predicting the blocks that contain the
                                                      2
                    is often observed in practice , indicating the needs             masked sentence, for additional pretraining. The
                    of improving retrieval.                                          questionencoderandthereadermodelarethenﬁne-
                         ∗Equal contribution                                         tuned using pairs of questions and answers jointly.
                        1The code and trained models have been released at           Although ORQA successfully demonstrates that
                    https://github.com/facebookresearch/DPR.
                        2For instance, the exact match score on SQuAD v1.1 drops     dense retrieval can outperform BM25, setting new
                    from above 80% to less than 40% (Yang et al., 2019a).            state-of-the-art results on multiple open-domain
