                                                                                                                       Instance Segmentation
                                                                                 ×
                                                                                                  ×
                                    Superpoint                                 Instance        Semantic
                                     Features                              Kernels & Scores     Kernels
                                                                                                                       Panoptic Segmentation
                                Flexible Pooling
                                                                         Disentangled Matching
                                                              Key &
                                    Sparse
                                                                                Transformer
                                                               Value
                                   3D U-Net
                                                                             Decoder Layer x6
                                                              Query
                                                                                                                      Semantic Segmentation
                                                             Selection
                                                                              Instance         Semantic
                                                                               Queries          Queries
              Figure 2. The OneFormer3D framework is based on SPFormer (blue), but features a number of improvements (red). Taking a 3D point
              cloudasinput,ourtrainedmodelsolves3Dinstance,3Dsemantic,and3Dpanopticsegmentationtasks. Thedottedlinedepictscomponents
              that are applied only during the training.
              pooling, that obtains superpoint features through simply av-            cordingly, it can be preferred to computationally-heavy su-
              eraging features of points in a superpoint. Superpoint fea-             perpoint clustering in resource-constrained usage scenarios.
              tures serve as keys and values for a transformer decoder                Werefer to this superpoint-based / voxel-based pooling as
              (Sec. 3.2), that also accepts learnable semantic and instance           flexible pooling. This procedure transforms an input point
              queries as inputs. The decoder captures superpoints infor-              cloud comprised of millions of points into only hundreds
              mation via a cross-attention mechanism, and outputs a set               of superpoints or thousands of voxels, which significantly
              oflearnedkernels,eachrepresentingasingleobjectmaskof                    reduces the computational cost of subsequent processing.
              an instance identity (from an instance query) or a semantic             3.2. Query Decoder
              region (from a semantic query). A disentangled matching
              strategy is adopted to train instance kernels in an end-to-             Aquery decoder takes K          +K queriesasinputsand
              end manner (Sec. 3.3). As a result, a trained OneFormer3D                                           ins      sem
                                                                                      transforms them into K          +K kernels. Then, su-
              can seamlessly solve semantic, instance, and panoptic seg-                                         ins       sem
                                                                                      perpoint features are convolved with these kernels to pro-
              mentation (Sec. 3.4).                                                   duceK       instanceandK         semanticmasks,respectively.
                                                                                              ins                 sem
              3.1. Backbone and Pooling                                               The architecture of a query decoder is inherited from SP-
                                                                                      Former [32]: similarly, six sequential transformer decoder
              Sparse 3D U-Net.        Assuming that an input point cloud              layers employ self-attention on queries and cross-attention
              contains N points, the input can be formulated as P ∈                   with keys and values from superpoint features. Semantic
              RN×6. Each 3D point is parameterized with three colors                  queries are initialized randomly, same as in existing 3D in-
              r, g, b, and three coordinates x, y, z. Following [6], we               stance segmentation methods [31, 32]. Instance queries are
              voxelize point cloud, and use a U-Net-like backbone com-                initialized through the query selection strategy.
              posed of sparse 3D convolutions to extract point-wise fea-
              tures P′ ∈ RN×C.                                                        Queryselection.      State-of-the-art 2D object detection and
                                                                                      2D instance segmentation methods [20, 46, 51] initialize
              Flexible pooling.      For a greater flexibility, we implement          queries using advanced strategies, usually referred to as
              pooling based on either superpoints or voxels. In a super-              query selection. Specifically, input queries are initialized
              point pooling scenario, superpoint features S ∈ RM×C are                with features from a transformer encoder, sampled based
              obtained via average pooling of point-wise features P′ ∈                on an objectness score. This score is estimated by the same
              RN×C w.r.t. pre-computed superpoints [18]. Without loss                 model, which is guided by an additional objectness loss
              of generality, we suppose that there are M superpoints in               during the training. The described technique is proved to
              an input point cloud. In a voxel pooling scenario, we pool              speed up the training, while jointly improving the overall
              backbone features w.r.t. voxel grid. Voxelization is a triv-            accuracy. Yet, to the best of our knowledge, a similar ap-
              ial operation with a negligible computational overhead; ac-             proach was never applied in 3D object detection or 3D seg-
                                                                                  20945
