             time- and memory footprint: training lasts longer and pro-      lier approaches can be classified into top-down proposal-
             duces different sets of model weights for each task. This       based methods [11, 15, 33, 45] or bottom-up grouping-
             drawback was eliminated in a recent OneFormer [12] –            based methods [3, 10, 13, 21, 35]. Current state-of-the-art
             a multi-task unified image segmentation approach, which         results belong to recently emerged transformer-based meth-
             outperformsexistingstate-of-the-arts in all three image seg-    ods, that outperform the predecessors in both accuracy [31]
             mentation tasks after training on a panoptic dataset jointly.   and inference speed [32]. We consider SPFormer [32] as
                Followingthesamepath,weproposeOneFormer3D,the                our baseline, and extend it, so that it solves not a single 3D
             first multi-task unified 3D segmentation framework (Fig.        instance segmentation but all three 3D segmentation tasks.
             1). Using a well-known SPFormer [32] baseline, we add
             semantic queries in parallel with instance queries in a trans-  3D Panoptic Segmentation.       Panoptic segmentation of
             former decoder to unify predicting semantic and instance        3Dpointcloudsisanunderexploredproblem,withonlyfew
             segmentation masks. Then, we identify the reasons for un-       existing solutions [23, 38, 44]; all of them being trained and
             stable performance of transformer-based 3D instance seg-        validatedonlyontheScanNetdataset. Thesemethodsapply
             mentation, and resolve the issues with a novel query se-        panoptic segmentation to a set of RGB images, lift the pre-
             lection mechanism and a new efficient matching strategy.        dicted 2D panoptic masks into 3D space, and obtain final
             Finally, we come up with a single unified model trained         3D panoptic masks through aggregation. On the contrary,
             only once, that outperforms 3D semantic, 3D instance, and       our OneFormer3D does not require additional RGB data to
             3Dpanoptic segmentation methods – even though they are          achieve state-of-the-art panoptic segmentation quality.
             specifically tuned for each task.
                Tosummarize, our contributions are as follows:               2.2. Unified 2D Image Segmentation
             • OneFormer3D–thefirstmulti-taskunified 3D segmenta-            Unified 2D segmentation has been extensively researched
               tion framework, which allows training a single model on       over the past years, resulting in a variety of methods pro-
               a common panoptic dataset to solve three segmentation         posed [4, 5, 41]. K-Net [47] uses a convolutional network
               tasks jointly;                                                with dynamic learnable instance and semantic kernels with
             • Anovelqueryselectionstrategyandanefficientmatching            bipartite matching. MaskFormer [4] is a transformer-based
               strategywithoutHungarianalgorithm,thatshouldbeused            architecture for mask classification. It was inspired by ob-
               in combination for the best quality;                          ject detection [2], where the image is first fed to the encoder
             • State-of-the-art results in 3D semantic, 3D instance, and     to obtain queries, then the decoder outputs proposals based
               3D panoptic segmentation in three indoor benchmarks:          on these queries. Mask2Former [5] extends MaskFormer
               ScanNet [8], ScanNet200 [28], and S3DIS [1].                  with learnable queries, deformable multi-scale attention in
             2. Related Work                                                 the decoder, and a masked cross-attention, setting a new
                                                                             state-of-the-art in all three segmentation tasks. However,
             2.1. 3D Point Cloud Segmentation                                all methodsmentionedabovestillrequiretrainingthemodel
             3D Semantic Segmentation.        Learning-based methods         individually for each task to achieve the best performance.
             for semantic segmentation of 3D point clouds leverage U-        OneFormer [12] was the pioneer 2D image segmentation
             Net-like models to process either 3D points (point-based)       approach,thatemploystask-conditionedjointtrainingstrat-
             or voxels (voxel-based). Point-based methods exploit hand-      egy and achieves state-of-the-art results in three segmenta-
             crafted aggregation mechanisms [22, 25, 27, 34] or trans-       tion tasks simultaneously with a single model. Similarly,
             former blocks [40, 48] for direct processing of points.         webuild OneFormer3Dfor 3D point cloud segmentation.
             Voxel-based methods transform a point cloud of an irreg-        3. Proposed Method
             ular structure to a regular voxel grid, and pass these vox-
             els through dense [11] or sparse [6] 3D convolutional net-      The general scheme of OneFormer3D is shown in Fig. 2,
             work. Considering time- and memory efficiency, we opt           with a baseline components depicted in blue and novelty
             for a sparse convolutional U-Net as a backbone, and com-        points highlighted with a red color. Our framework is in-
             bine it with a transformer decoder; to the best of our knowl-   herited from SPFormer[32], whichwasoriginallyproposed
             edge, OneFormer3D is the ever-first method using such a         to tackle 3D instance segmentation. SPFormer is chosen
             decoder to solve the 3D semantic segmentation task for in-      duetoits straightforward pipeline, fast inference, and small
             door scenes.                                                    memory footprint during both training and inference; yet,
                                                                             any modern 3D instance segmentation method with a trans-
             3DInstanceSegmentation.       Instance segmentation of 3D       former decoder can be used instead (e.g., Mask3D [31]).
             point clouds is typically addressed with 3D semantic seg-          First, a sparse 3D U-net extracts point-wise features
             mentation followed by per-point features aggregation. Ear-      (Sec. 3.1). Then, these features pass through a flexible
                                                                         20944
