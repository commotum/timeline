              ”brain”. Another interesting line of research is aiming at      an unmodified version of EngramNCA, EngramNCA v2,
              critical NCAs (Pontes-Filho et al., 2023; Guichard, 2024),      v3, and v4, modified versions of EngramNCA with ARC-
              i.e., CA models operating at the edge-of-chaos (Langton,        specific augmentations.
              1990), which could be a powerful pre-training strategy. A          WebelievethestandardNCAmodelneedsnodetailedin-
              NCA for image manipulation, named Vision Transformer            troduction. In short, it is implemented as a differentiable
              Cellular Automata (ViTCA), is proposed in (Tesfaldet et al.,    neural network embedded in a cellular automaton frame-
              2022), where attention heads are included in the model, in-     work, where each cell maintains a continuous state vec-
              spired by the transformer architecture (Vaswani et al., 2017).  tor updated through convolutional neural networks (CNNs)
              (Reimers et al., 2023) proposes a variation with local-self     with learned local update rules. The architecture is depicted
              attention, while (Kvalsund et al., 2024) presents an evolved    in Figure 2. However, EngramNCA is a relatively recent
              attention-like mechanism. In general, transformers can learn    model and thus warrants a brief introduction. Its NCA fea-
              elementary CA rules (Burtsev, 2024), opening up interest-       tures dual-state cells with distinct public (interaction-based)
              ing opportunities of potentially combining CA and LLMs          and private (memory-based) states. The model is an en-
              for ARC-AGI in the future. A work using an evolutionary         semble that includes: GeneCA, an NCA which generates
              approach is (Fischer et al., 2020), where grammatical evolu-    morphological patterns from a seed cell encoding genetic
              tion is employed for optimizing expressions in a domain-        primitives (Figure 3); GenePropCA, an NCA which propa-
              specific language for incremental image transformations.        gates and activates these genetic primitives across the cell
              AnacceleratedJAXimplementationofCA,includingNCA,                network (Figure 4), similar to RNA-based communication
              is proposed in (Faldor and Cully, 2024), where they also        (Shomrat and Levin, 2013). EngramNCA is trained in two
              attempt to employ a 1D-NCA for solving the much sim-            stages: first, GeneCA is trained to grow primitive morpholo-
              pler 1D-ARC dataset (Xu et al., 2023), an unofficial sim-       gies containing immutable private memory encodings, using
              plified adaptation of ARC-AGI composed of 1-dimensional         only publicly visible channels for coordination; then, Gene-
              rows of pixels, which significantly reduces task complex-       PropCA is trained to modulate the private memory of cells
              ity. For a recent report on popular attempts at solving         without altering their visible states, enabling the transfer of
              the ARC-AGIchallenge,includingprogramsynthesismeth-             genetic information across the grid. For details on the model
              ods with deep learning techniques, please refer to (Chollet     see (Guichard et al., 2025).
              et al., 2024). Very recently, in April 2025, OpenAI has an-
              nouncedthattheirmostpowerfulmodelsatthattime,named                               CAArchitectureDetails
              o3 and o4 mini (two reasoning models using support to-            CAtype             Augmentations      Channels, Hid-
              kens for planning and summoning internal tokens to run                                                  denSize
              Python code as part of their reasoning, before providing an       NCA                None (standard     50, 64
              answer), achieved promising scores in ARC-AGI (Chollet,                              NCA)
              2025;Kamradt,2025). Specifically, o3-lowscored41%,o3-             EngramNCAv1        None (standard     50, (32,32)
              medium53%,o4-mini-low21%,ando4-mini-medium41%,                                       EngramNCA)
              all on the semi-private evaluation set. Additionally, two o3      EngramNCAv2        Sensing            50, (32,32)
              versions tested with high compute resources (namely using         EngramNCAv3        Sensing        +   50, (32,32)
              6 and 1024 independent inference samples) scored 75.7%                               Toroidal
              and 87.5%, using 33.5 million and 5.7 billion tokens. The         EngramNCAv4        Sensing        +   50, (32,32)
              reported cost for the version with 6 inference samples was                           Toroidal + Lo-
              201USDpersample,whiletheversionwith1024was172x                                       cal vs Global
              more expensive. This staggering cost might be significantly
              reduced by alternative architectures.                           Table 1: Architecture detail for all CA variants. The differ-
                                                                              ent notations for NCA and EngramNCA on Channels, Hid-
                              ModelsandMethods                                den Size are due to the split versus standard architecture be-
              This section details the models used in obtaining develop-      tween the two.
              mental solutions to the Abstraction and Reasoning Corpus.
              Wechiefly explore NCA models and their derivatives in the          Table 1 shows the different CA architectures. The aug-
              form of classic NCA and EngramNCA (and modifications            mentations are detailed in sections Local versus Global So-
              to EngramNCA).                                                  lutions, Toroidal versus Non-Toroidal Problems, and Inap-
              NCAmodels                                                       propriate Sensing.
              WechoosetotesttheGrowingNCAaspresentedby(Mord-                  FromARCtoNCASpace
              vintsev et al., 2020), along with four versions of Engram-      The ARC dataset mainly comprises 2D grids with integer
              NCApresentedin(Guichard et al., 2025): EngramNCA v1,            values. Each grid can range from 1x1 to 30x30 in size, with
