                                  Product of Experts with LLMs: Boosting Performance on ARC Is a Matter of Perspective
               Table 3. Comparison of sampling and selection strategies on the 400 tasks of the ARC-AGI public evaluation set: Under “Candidate
               generation”, we list the percentage of correct solutions sampled with different strategies using 16 augmented versions (reflections,
               rotations, and randomly permuted colors and examples) of each task. We also list the average number of candidates generated per task,
               the runtime of the sampling process on the full dataset and the maximum video memory consumption. Under “Selection”, we compare the
               accuracy of various selections strategies, performed on the scores calculated in a subsequent scoring process on 16 additional random
               augmentations. Total runtime includes the test-time fine-tuning on a task’s examples (see Table 4 in the appendix), as well as the candidate
               generation and selection process. All experiments were performed with the NeMo-Minitron-8B model on a Nvidia RTX 4090 GPU.
                  Sampling                           Candidate generation                      Selection (2-guess accuracy)            Total
                  method                  solutions   avg. cand.    runtime       max.            using 16 augmentations             runtime
                                                                                                 ˆ          ˆ    Pˆ         Qˆ
                                           found       per task     [hh:mm]     VRAM        maxP       minP         P          P     [hh:mm]
                                                                                                  j          j        j         j
                  Greedy                   70.8%          6.7         9:39      7.0GB       63.3%      65.8%     66.1%     67.6%       18:52
                  Stochastic (2x)          74.5%         11.2        19:53      7.0GB       64.5%      67.6%     66.9%     69.9%       34:08
                  Stochastic (4x)          77.3%         17.6        39:47      7.0GB       63.5%      68.8%     67.1%     70.8%       58:55
                  Beamsearch(2x)           75.0%         15.9        29:33      9.6GB       63.1%      65.9%     65.0%     69.9%       47:27
                  Beamsearch(4x)           79.0%         34.7        37:36      14.0GB      61.9%      67.9%     65.0%     71.6%       71:39
                  DFST=20%(ours)           73.5%          4.9         5:58      7.3GB       63.5%      68.1%     66.4%     70.0%       14:12
                  DFST=9%(ours)            76.0%          9.3         9:32      7.3GB       63.5%      68.8%     66.6%     71.6%       20:50
                  DFST=0.5%(ours)          83.5%         84.7        80:56      7.3GB       63.3%      69.1%     66.9%     71.8%      134:43
               found so far as an inital guess to the DFS and process it in a     5.4. Selection Strategies
               single forward pass before starting backtracking, which is         Up to this point, our method generates candidates likely
               muchfaster than token-by-token generation. Note that these         to include the correct solution. However, solving the task
               comparisonsshouldbeinterpretedwithcaution, asthebeam               requires identifying it among the candidates, using at most
               search algorithm is not implemented in the unsloth library         two guesses.
               used for the other experiments, which might provide some
               time savings. However, even when accounting for those              As introduced in Section 4.1, we again use a set of aug-
               savings, beam search still requires far more time overall,         mentations Φ to calculate the results of a product of expert
               as it returns a significant amount of false positives, which       ensemble P. A candidate s ∈ Cp,T is selected for one of
               increase the runtime required in the subsequent selection          the two guesses if it has the (second-)highest probability
               process, where each candidate is evaluated under different         according to P. In Figure 5, we compare the rank of the
               augmentations.                                                     correct solution before and after using this augmentation
               Aswedonotknowthesamplingprobabilityofthecorrect                    procedure. In most cases where the correct solution does
               solution beforehand, we have to treat the probability bound        not start at rank 1, this augmentation leads to a better rank
               T as a hyper-parameter. We found that values between               for the correct solution, increasing our chance to solve a
               T = 5%toT = 20%provided a reasonable compromise                    given task. In Theorem 4.1, we proved that our product of
               between inference time and number of correct solutions,            experts approach is superior to selecting one augmentation
               but the exact parameter depends on the model and training          at random, which can clearly be seen in Table 3. Here, we
               procedure used. Similarly, due to the way probability mass         compare different sampling methods and different aggrega-
               is distributed on the solution tree, DFS is faster when the        tion methods. In all cases, using the product of probabilities
                                                                                  leads to an increase in score, with minP taking second
               model has a higher degree of certainty in its predictions.                                                       i
                                                                                  place for most sampling methods and maxP performing
                                                                                                                                   i
               Wecomparethenumberofcandidatesetsthatcontain the                   the worst. For our T = 9% DFS inference, PoE increases
               correct solution for different values of T in Figure 4. This       the final score by 5% compared to averaging the probabilites
               function is monotonically increasing in T, but so are infer-       (66.6% vs 71.6%).
               ence costs and the size of the set Cp,T, making the selection
               of the correct candidate harder. Our final results are calcu-      5.5. ConceptARC
               lated using T = 9%, as it uses roughly the same amount of          TomakesurewedonotoverfitontheoriginalARCdata,we
               inference time as greedy sampling.                                 further evaluate our method on ConceptARC (Moskvichev
               Weprovidepseudo-code for our DFS sampling algorithm                et al., 2023) - an ARC-like dataset containing tasks sorted
               in Algorithm 1 in the Appendix.                                    into specific conceptual categories. Our method achieves
                                                                               8
