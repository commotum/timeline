                                               REALM:Retrieval-AugmentedLanguageModelPre-Training
               A. Derivation of the gradient with respect to                     zero accuracy (i.e., p(y|z′,x) = 0).         Under this set-
                   the knowledge retriever                                       ting, p(z∗ |y,x) = 1 (provided that p(z∗|x) is non-zero),
                                                                                 which causes the gradient to become
               WecomputethegradientoftheREALMpre-trainingobjec-
               tive (a log-likelihood) with respect to the parameters of the        ∇logp(y|x) = ∇f(x,z∗)−Xp(z|x)∇f(x,z)
               knowledgeretriever, θ:                                                                                 z
                                                                                                   =∇logp(z∗|x).
                                        −1
               ∇logp(y|x) = p(y|x)         ∇p(y|x)
                                        −1X                                      Fromthis, we see that gradient descent on the REALM ob-
                              =p(y|x)           p(y|z,x)∇p(z|x)                                                                          ∗
                                             z                                   jective is equivalent to gradient descent on logp(z |x).
                                        −1X                                      This is none other than the typical maximum likelihood
                              =p(y|x)           p(y|z,x)p(z|x)∇logp(z|x) training objective used in supervised learning, where z∗ is
                                             z                                   the “gold” document.
                              =Xp(z|y,x)∇logp(z|x),
                                  z                                              C. Adapting to new knowledge
               where the last line follows from applying conditional             An explicit retrieval system allows us to adapt to new
               Bayes’ rule. We can then expand ∇logp(z|x) as:                    world knowledge simply by modifying the corpus docu-
                                             expf(x,z)                           ments. To demonstrate this ability, we replace the knowl-
                  ∇logp(z|x) = ∇log Pz′expf(x,z′)                                edge corpus with a more recent version of Wikipedia cor-
                                                                                 pus after pre-training is done. When the input query is
                                      "                X              ′ #        about a fact where the two corpora disagree, REALM can
                                 =∇ f(x,z)−log             expf(x,z )            change the prediction to reﬂect the updated information,
                                                       z′
                                 =∇f(x,z)−Xp(z′|x)∇f(x,z′)                       as exempliﬁed in Table 4.      However, even with an ex-
                                                                                 plicit retrieval mechanism, the knowledge-augmented en-
                                                  z′                             coder will still end up remembering some world knowl-
               Plugging this back into the ﬁrst set of equations yields:         edge, making the prediction of some input sentences not
                                                                                 updated with the new corpus. (For instance, the model pre-
                              X            "           X ′               ′ #     dicts “Thatcher” for “          is the prime minister
                ∇logp(y|x) =      p(z|y,x) ∇f(x,z)−       p(z |x)∇f(x,z )        of United Kingdom.” on both corpora, perhaps due to
                               z                       z′
                            =Xp(z|y,x)∇f(x,z)−Xp(z′|x)∇f(x,z′)                   the frequent mention of her name in Wikipedia articles.)
                               z                      z′
                            =X[p(z|y,x)−p(z|x)]∇f(x,z)                           D. Retrieval Utility
                               z
                            =Xp(y|z,x)p(z|x) −p(z|x)∇f(x,z)                    The null document ∅ described in Section 3.4 provides a
                               z        p(y|x)                                   way to measure the importance of a retrieved document z:
                            =Xp(y|z,x)−1p(z|x)∇f(x,z).                         we deﬁne the retrieval utility (RU) of z for the masked
                                    p(y|x)                                       input x as the difference between the log-likelihood of
                               z
                                                                                 the knowledge-augmented encoder when conditioning on
               In the second line, we used the fact that the overall expres-     z versus on ∅:
               sion is an expectation with respect to p(z |y,x), and the
               terms which depend on z′ but not z can be moved out of                   RU(z|x) = logp(y|z,x)−logp(y|∅,x).                 (2)
               that expectation.
                                                                                 Anegative RU shows that z is less useful for predicting y
               B. Connection between REALMand                                    thanthenulldocument. Thiscouldmeanthatz isirrelevant
                   supervised learning                                           to x, but could also mean that the masked tokens in x do
                                                                                 not require world knowledge to predict, or that the world
               Fromtheequationsin AppendixA, wesaw that                          knowledge is sufﬁciently commonplace it has been baked
                                                                                 into the model’s parameters. In practice, we ﬁnd that RU
                 ∇logp(y|x) =X[p(z|y,x)−p(z|x)]∇f(x,z).                          increases steadily over the course of pre-training, and is
                                     z                                           more predictive of good performance on the downstream
                                                                                 task of Open-QA than even the overall log-likelihood. An
               Suppose that there exists one document z∗ which causes            exampleofhowRUbehavesovertimeandacrossdifferent
               the model to achieve perfect prediction accuracy (i.e.,           settings is in Figure 4.
               p(y|z∗,x) = 1), while all other documents z′ result in
