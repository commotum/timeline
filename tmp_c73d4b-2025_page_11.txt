           References
            [1] Ali Behrouz, Meisam Razaviyayn, Peilin Zhong, and Vahab Mirrokni. Nested learning: The
              illusion of deep learning architectures. arXiv preprint arXiv.
            [2] Walter Pitts. The linear theory of neuron networks: The dynamic problem. The bulletin of
              mathematical biophysics, 5:23–31, 1943.
            [3] Warren S McCulloch. The brain computing machine. Electrical Engineering, 68(6):492–497,
              1949.
            [4] Warren S McCulloch and Walter Pitts. The statistical organization of nervous activity. Biomet-
              rics, 4(2):91–99, 1948.
            [5] Arthur L Samuel. Some studies in machine learning using the game of checkers. IBM Journal
              of research and development, 3(3):210–229, 1959.
            [6] David Silver and Richard S Sutton. Welcome to the era of experience. Google AI, 1, 2025.
            [7] Richard S Sutton, Andrew G Barto, et al. Reinforcement learning: An introduction, volume 1.
              1998.
            [8] Jonathan H. Connell and Sridhar Mahadevan. Robot learning. Robotica, 17(2):229–235, 1999.
              doi: 10.1017/S0263574799271172.
            [9] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436–444,
              2015.
           [10] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ron-
              neberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, et al.
              Highly accurate protein structure prediction with alphafold. nature, 596(7873):583–589, 2021.
           [11] DavidSilver, AjaHuang,ChrisJMaddison,ArthurGuez,LaurentSifre,GeorgeVanDenDriess-
              che, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. Mas-
              tering the game of go with deep neural networks and tree search. nature, 529(7587):484–489,
              2016.
           [12] David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur
              Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, et al. A general
              reinforcement learning algorithm that masters chess, shogi, and go through self-play. Science,
              362(6419):1140–1144, 2018.
           [13] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep
              convolutional neural networks. Advances in neural information processing systems, 25, 2012.
           [14] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,
              Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly,
              Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image
              recognition at scale. In International Conference on Learning Representations, 2021. URL
              https://openreview.net/forum?id=YicbFdNTTy.
           [15] Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit
              Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, et al. Gemini 2.5: Pushing the
              frontier with advanced reasoning, multimodality, long context, and next generation agentic
              capabilities. arXiv preprint arXiv:2507.06261, 2025.
           [16] Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao,
              ChengqiDeng,ChenyuZhang,ChongRuan,etal. Deepseek-v3technicalreport. arXivpreprint
              arXiv:2412.19437, 2024.
           [17] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni
              Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4
              technical report. arXiv preprint arXiv:2303.08774, 2023.
                               11
