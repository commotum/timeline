             444                         14.  ALGORITHMIC  STATISTICS
             complexity is  0 (y /n )  according to  our  assumption,  see  the  discussion  before the 
             statement of the theorem).  The same is true for the final version.  It remains to 
             take X in the intersection of the final As.  (Recall that An is a singleton, so the final 
             An is  {a:}.)  Indeed,  by construction, this x has no bad  (г * j)-descriptions where 
             (i,j) is on the boundary of T.  On the other hand, x has good descriptions that are 
             0 (\/^logn)-close to  this  boundary  and  whose vertical coordinates  are  y/n log n- 
             apart.  (Recall that the slope of the boundary guarantees that horizontal distance 
             is less than the vertical distance.)  Therefore the position of the boundary curve for 
             P'£■  is determined with precision 0 {y/n\ogn), as required.3                       □
                 Remark.  In this proof we may use bad sets not only from A.  Therefore, the 
             set P® is close to T for every family В that contains A, and it is not even needed 
             that В satisfies requirements (l)-(3) itself.
                  360 Provide the missing details in this argument.
                  36Ï (1)  Let  i   be  a string  of length  n  and  let  r  be  a natural  number  not 
             exceeding nj2.  By CT(x) we denote the minimal (plain) complexity of a string у 
             of the same length n that differs from x in at most r positions.  Prove that  (with 
             О (logn) precision) the value of Cr(x) is the minimal i such that x has (i*logF(r))- 
             description that is a Hamming ball.  (Here V(r)  is the cardinality of a Hamming 
             ball of radius r in B71.)
                 (2)  Describe  all  the  possible shapes  of the function  Cr{x)  as a function of r 
             (that appear for different x) with precision 0 (y /n  logn).
                 (Hint:  For every x in Bn we have C q(x)  = C(x) and Cn(x) = O(logn).  Also 
             we have
                               0 ^ Ca(x) -  Cb{x) ^ log{V{b)/V{a)) + O(logn) 
             for every a < b ^ nj2.  On the other hand, for every к ^ n and for every function 
             t:  {0, 1,..., n/2} such that
             t(0) = k, t(n/2) — 0 and 0 ^ t(a) — t(b) ^ log(V(b)/V (a)) for every a < b ^ n/2, 
             there exists a string x of length n and complexity k+0(y/n logn) such that Ca(x) = 
             t(a) + 0 (y/n logn) for all a = 0,1,... n/2.)
                 We can again look at  the error-correcting codes:  If a  (Kolmogorov-)  simple 
             set  of codewords  has  distance d,  then  for  a codeword  x  in  this  set  the  function 
             Cr(x) does not significantly decrease when r increases from 0 to d/2  (indeed, the 
             codeword can be reconstructed from the approximate version of it).
                 Complexity measure  Cr(x)  was  introduced  in  the  paper  [69].  In  [54],  this 
             notion  was  generalized  to  conditional  complexity.  There  are  two  natural  gener­
             alizations,  uniform  and  non-uniform  ones.  The  uniform  conditional  complexity 
             CrS(x I y)  is  defined  as  the  minimal  length of a program that  given  any string y' 
             at Hamming distance at most s from у outputs a string x' at Hamming distance 
             at  most  r  from x.  It  is  important  that  x'  may depend  on  y'.  The  non-uniform 
             conditional complexity Crs(x\y) is defined as maxy/ mkv C(x' \ y') where x',y' are 
             at Hamming distance at most r, s from x, у, respectively.  The difference between 
             the uniform and the non-uniform definitions is the following.  In the non-uniform 
             definition the program to transform y' to x' may depend on y' while in the uniform
                 3Now we see why N was chosen to be  у/n / logn:  the bigger N   is,  the more points on the 
             curve we have,  but then the number of versions of the good sets and their complexity increases, 
            so we have some trade-offs.  The chosen value of N  balances these two sources of errors.
