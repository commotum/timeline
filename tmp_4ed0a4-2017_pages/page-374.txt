                          11.4.  CONDITIONAL INDEPENDENCE AND  COMMON  INFORMATION                      363
              and  then  bound  C(z\u)  and  C(z\v)  using  the  relativized  versions  of the  same 
              inequality:
                                    C(z\u) ^ C(z\x,u) + C(z\y,u) + I(x:y\u),
                                    C(z\v) < C(z \x,v) + C(z\y,v) + I(x:y\v).
              After that it remains to note that we decrease the complexity when adding another 
              condition:  C(z\x, u) ^ C(z \ x).                                                          □
                   This  theorem  can  be  used  to  construct  strings  with  non-extract able  mutual 
              information.  Consider conditionally independent variables that are not independent 
              (Theorem 217, p. 342):  there exist a and ß that are independent given 7 and also 
              independent given <5, where 7 and 5 are independent variables, while a and ß are 
              not independent.
                   Now we may consider N independent trials of this quadruple and collect the 
              outcomes of a into string x, and outcomes of ß into y.  These strings x and y with 
              high probability will have significant mutual information that cannot be extracted. 
              To see this, let us collect the outcomes of 7 and 5 into и and v, and apply the last 
              inequality to these four strings.  (Note that to construct x and y, we need to make 
              N samples of a and ß alone; the variables 7 and 5 are needed only for the proof of 
              non-extract ability.)
                   For technical reasons,  to get a better error term  (our usual logarithmic term 
              instead  of a square  root  that  appears  when  we  compare  the  frequency  and  the 
              probability), one should consider not the independent trials,  but trials with fixed 
              frequencies.  Let us explain what this means.
                   Consider a quadruple of strings x, y, u, v of length N where the frequencies of all 
              quadruples of letters are equal to the probabilities for the outcomes of (a,ß, 7,5). 
              This means that x is a string in the alphabet that is the range of a, у is a string 
              whose alphabet is the range of ß, etc., and the number of positions i — 1,..., N, 
              where strings x, y, u, v have letters a, b, c, d, respectively, is equal to
                                      Pr[o: = a, ß = 6,7 = c, (5 = d\ ■ N + 0(1)
              (we need to add 0(1) for rounding—the product of N and the probability is not 
              always an integer).
                  As we know from Section 7.3 (Theorem 146), for most quadruples of strings with 
              these frequencies the complexities of these strings and their combinations deviate 
              from N x (the corresponding entropies) only by O(logAf).1  In this way we get a 
              quadruple of strings x, y, u, v such that
                      I(x:y I и) — О (log Af),    I(x:y\v) = O(logAf),       I(u:v) — 0(log N), 
              and at the same time
                                           I(x:y) = Nl(or.ß) + О (log AT),
              while  (according to our assumption)  I(a:ß) ф 0.  It remains to use Theorem 228 
              to conclude that for every z the inequality
                                             C(z)^2C(z\x) + 2C(z\y)
                   1To see this we should recall the proof of Theorem 146 where we estimated how many strings 
              with given frequencies exist.
