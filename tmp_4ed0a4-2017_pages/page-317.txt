             304          9.  FREQUENCY AND  GAME APPROACHES TO RANDOMNESS
                 In particular,  this theorem implies that for independent trials where success 
             probabilities Pi  converge to some limit p, the limit frequency p exists with proba­
             bility 1  (since the limit of averages (po + • • • +pn-i)/n is also p).
                 On the other hand, we need more:  We wanted to show that the sequence is 
             random according to a Mises-style definition  (in one of the versions),  so we need 
             to ensure that the limit frequency is p not only for the sequence itself, but for all 
             its  subsequences selected by some admissible rule.  Let  us look at this  question, 
             starting with monotone selection rules (the Church-Daley definition).
                 9.13.3.      The Law of Large Numbers for subsequences.  Let us generalize 
             Theorem  198 by adding selection rules.  This theorem  considered some measure 
             д on fi, and the corresponding function p{x) = p(fix)  and conditional probability 
            p(l I x) = p(xl)/p(x).  For a sequence из and number n we considered two quantities:
                    •  the number m of ones among wo,..., wn_i ;
                    •  the sum of conditional probabilities of 1 at n first positions, i.e.,
                          p(l|A) +p(l|w0)+p(l|w0wi) -I-----hp(l|wo---wn_2).
             Theorem 198 guaranteed that (for every n) these two quantities differ significantly 
             only for a д-small fraction of sequences из (the д-measure of the set of из such that 
             the difference exceeds d is bounded by 2e~d /4n.
                 Now let us add some selection rule Sr to this picture.  Here R is an arbitrary 
            set  of  binary  strings  (the  set  of prefixes  before  the  selected  terms).  For  every 
            sequence из the rule Sr selects some positions го, ii, • • • and outputs a subsequence 
             Sr(u3) = U3i0u3i1 ■ ■ ■  made by the terms at those positions.  Now we compare:
                    •  the number m of ones among the first n selected terms, i.e., the number 
                      of ones among n first bits of S#(w);
                    •  the sum of conditional probabilities of ones for the n first  selected posi­
                      tions, i.e.,
                  P( 1 l^oWl • • • Wio-l) + p( 1 l^oWi • ■ -U3ii_i) -I- • • ■ +p( 1 |Ш0^1 • • ■U3in_1-i).
            When R is the set of all strings,  we get the same quantities as in Theorem  198. 
            The following theorem says that the same bound is valid in the general case:
                 Theorem 200.  The p-measure of the set of из where these two quantities differ 
             by d,  is  at most 2e~d2^4n.
                 Note that for some из the sequence Sr(co) may contain less than n terms.  These 
            из are not elements of the set whose measure is bounded.
                 Example.  Consider an arbitrary measure д and a selection rule R that selects 
            the  terms where  the  conditional  probability  of  1  is  at  most  1/2.  Theorem  200 
            guarantees that the д-probability of the event “there is at least 51% of ones among 
            the first n selected terms”  is exponentially small (as n increases).
                 P r o o f.  This theorem is also a simple consequence of a general Azuma-Hoeff- 
            ding inequality for martingales in the sense of probability theory, but we can easily 
            modify the argument used to prove Theorem 200.
                 First note that this theorem now deals with the entire sequence из instead of its 
            prefix of some length (since the first n selected terms may appear arbitrarily late). 
            But due to the continuity of measure, it is enough to prove the same inequality for
