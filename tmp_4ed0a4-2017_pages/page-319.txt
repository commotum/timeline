             306           9.  FREQUENCY AND  GAME APPROACHES TO RANDOMNESS
                 The first  term of uip  is chosen when no bits are revealed;  it occupies a fixed 
             position in u>.  This position is no  = F(A).  So the probability that  1  appears as 
             the first term in up  is pno•  Now consider the second term of up.  Its position in 
             Q. depends on the value of uino  and can be either F(0) or F( 1).  So the conditional 
             probability for the second term of uip to be one (given the first term as the condition) 
             is either Pf(o)  or Pf{i)-  In general, the probability of 1 after x in uip equals Pf{x)-> 
             since the next revealed bit has number F(x).  Note that the restrictions of F  (no 
             bit  is  revealed  twice)  guarantee  that  conditional  probabilities  along  any  branch 
             form a subsequence of {p*}  (without repetitions), so the number of terms outside 
             of (p — e/2,p + ef 2) for this subsequence is bounded by the number of such terms 
             in the original sequence.
                 This  allows  us  to  apply  the  bound  of Theorem  200  to  sequence cop  and  the 
             selection rule determined by G in the same way as in the proof of Theorem 201.
                 The same bound is true for partial F and G:  Extending them to some total 
             functions, we may only increase the set whose measure is bounded.  (A computable 
             partial function may have no computable extensions, but here we are interested in 
             the bound only, so a non-computable extension can be used.)
                 Having proven the bound for partial F and G, we now observe that for com­
             putable F and  G the set  of u>  such that  Sf,g(w)  starts with x,  is  an effectively 
             open set (uniformly in x).  So now we can finish the argument as in the preceding 
             theorem.                                                                            □
                 Remark.  One can give a more direct proof of Theorem 202.  Here is one of 
             the possible arguments (taken from [177]).
                 Fix some (rational) e > 0 and some Kolmogorov-Loveland admissible selection 
             rule Sf,g-  We need to show that the set  U of sequences u> such that  Sf,g(w)  is 
             infinite and the frequency of ones exceeds p + e infinitely often is an effectively null 
             set.  (The argument for p — e is similar.)
                 By Un we denote the set of all sequences u> such that Sf,g{^>) contains at least 
             n terms and the frequency of ones among the first n terms exceeds p + e.  We need 
             to show that the series    ß(Un) computably converges.  (Here ß is our measure; it 
             corresponds to independent trials with success probabilities pi.)
                 By <2n,fc0r ? • • •, тп) we denote the probability of getting more than к ones on n 
             independent trials with success probabilities r\,... ,rn.  The function an^ is a non­
             decreasing one with respect to each argument r*.  (A side remark:  it is a multilinear 
             function, i.e., a polynomial of degree at most 1 with respect to each argument.)  It 
             is easy to see also that anj. < anj if к ^ I.
                 We claim that ß(Un) ^ &п,к{г1-> • • • ? rn), where к = n(p + e)  and r*  is the ith 
             element of {po,Pi, • • •} in decreasing order, or, more precisely,
                     ri = sup Р»,   r2 = sup min (pi,pj),  r3 =  sup  min (pi,pj,pk), ■■■■
                                         ij£j                    i^jßk
             Let us show that this bound implies the convergence of the series ß{Un).  Obviously, 
            ri  ^ r2  ^  ■ ■ ■  and limn  = p.  Let us replace all n that exceed p + ej2 by 1; let s 
            be the number of these replacements.  We conclude that
                                   KUn) ^ &n—s,k—s{p “b ^/2j ■ • ■, p T ^/2),
            so we have reduced the question to the case of constant probabilities (that we have 
            already discussed several times).  It is important to note that for large n the ratio 
             (k — s)/(n — s) is close to p + e and exceeds p + e/2 significantly.
