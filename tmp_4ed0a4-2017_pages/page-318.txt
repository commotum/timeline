                            9.13.  CHANGE IN  THE  MEASURE AND  RANDOMNESS             305
            first  N bits of u)  (it gives a smaller set, but the union of all these sets for all N is 
            the set in question).
                As in the proof of Theorem 200, we construct a new measure, but now we change 
            conditional probabilities only in the positions where the next term is selected, i.e., 
            the conditional probabilities of p(l\x)  for x  G  R.  Then the ratio of probabilities 
            (for  the  modified  and  original  measures)  will  include  the  length  of the  selected 
            subsequence (instead of the sequence itself) and the sum of conditional probabilities 
            for  the  selected  terms  (instead  of the  sum  of all  conditional  probabilities),  i.e., 
            exactly what we need.                                                       □
                This result gives us a tool (following van Lambalgen [90]) to construct Mises- 
            Church--Daley sequences.  Let Po,Pi, ■ ■ ■  be a computable sequence of computable 
            reals that computably converges to some p G (0,1). This means that for every given 
            £ > 0, one can compute some N such that  \pi — p\  < e for all i ^ N.  (It is easy 
            to see that in this case p is computable.)  Consider a computable measure ß that 
            corresponds to a sequence of independent trials with probabilities pi.
                Theorem 201.  Every ML-random sequence with respect to ß is Mises-Church- 
            Daley random with frequency p.
                PROOF.  Consider some rational e > 0 and some Church-Daley admissible rule 
            Sr  (not  necessarily  total).  We  need  to  show  that  the set  U  of all  sequences uj, 
            where Sr(oj) gives an infinite sequence in which the frequency of ones exceeds p + e 
            infinitely often,  is an effectively null set.  (The argument for frequencies less than 
           p — e is similar.)
               Fix some n, and consider the set Un of sequences uj such that Sr{u)) has length 
            at least n and the frequency of ones among the first n terms exceeds p + £.  This set 
            is effectively open (applying the computable partial selection rule to all branches, 
            we enumerate all strings that guarantee that its every extension is in Un).
               Theorem 200 provides the upper bound for the ß-measure of Un.  If n is large 
            enough, the average of conditional probabilities is less than p + e/2 (and we know 
            how large n should be,  since the sequence pi  converges computably to p).  This 
            bound decreases exponentially as n increases.  So one can cover U by an effectively 
            open set of arbitrarily small measure (taking all the intervals in Un, Un+i, Un+2 , ■ ■ ■ 
            for arbitrarily large N; recall that by definition of U each element of U belongs to 
            infinitely many Un).  Therefore, U is an effectively null set and cannot contain an 
            ML-random sequence.                                                         □
               Now  we  extend  this  statement  to  Mises-Kolmogorov-Loveland  random  se­
            quences.
               Theorem  202.  Every  ML-random  sequence  with  respect  to  ß  is  Mises- 
            Kolmogorov-Loveland random with limit frequency p.
               PROOF.  The application of a Kolmogorov-Loveland admissible selection rule 
            Sp,G   a sequence uj  consists of two phases.  First we use F to select a sequence 
           of revealed bits (both selected and not selected).  Then G is used to select some of 
           the revealed bits, and this operation is a Church-Daley admissible selection rule.
               After this decomposition is done, let us consider the distribution of a sequence 
           up  that  is  obtained  at  the  first  step.  (We  assume  that  the original sequence  is 
           obtained by independent trials with probability pi  in the îth trial.)  Let  us first 
           assume that F and G are total functions.
