                        2.  COMPLEXITY  OF  PAIRS  AND  CONDITIONAL  COMPLEXITY
            44
            strings.  To prove the upper bound, note that strings of length n that have a prefix 
            of к zeros could be described by 2 log к + (n — k) bits.
                (b) Let t be the shortest description of the number of incompressible strings.  If 
            t has n — k bits, then knowing t and log к additional bits, we can reconstruct first n 
            and then the list of all incompressible strings of length n, so the first incompressible 
            string has complexity less than n, a contradiction.
                (c)  If one part of the string is has a short description,  the entire string has a 
            short description that starts with prefix-free encoding of the difference between the 
            length and complexity of the compressible part.
                (d) If a string has a simple substring, then the entire string can be compressed 
            (we need to specify the substring, its position, and the rest of the string).
                (e) Let us count the number of strings of length n that do not contain к zeros in 
            a row; a recurrent relation shows that this number grows like a geometric sequence 
            whose base is the maximal real root of the equation x = 2 — (l/xk), and we can 
            get a bound for complexity of strings that do not have к zeros in a row.)
                 54 Prove that (for some constant c) for every infinite sequence X0X1X2 • • •  of
            zeros and ones there exist infinitely many n such that
                                    C(xqX\ • • • xn-\) ^ n — logn + c.
            Prove that there is a constant c and the sequence xqX\X2 • • •  such that 
                                   C(xqXi • • • £n_i) ^ n — 2logn — c
            for all n.
                (Hint:  The  series  J^l/n  diverges  while  the  series  ^)(l/n2)  converges.  For 
            details see Theorem 95 and 99.)
                This result was published by Martin-Löf [117] for conditional complexity (and 
            a reference to an earlier unpublished work in Russian was given for unconditional 
            complexity; see also [225, Theorem 2.6]).
                55  For a string x of length n let us define d(x) and dc(x) as follows: 
                             d(x) — n — C(x)    and   dc(x) = n — C{x\n). 
            Show that they are rather close to each other:
                            dc(x) — 2logdc(x) — 0(1) ^ d(x) ^ dc(x) + 0(1).
                (Hint:  We need to show that C(x\n) = n—d implies C(x) ^ n—d+21ogd+0(l). 
            Indeed, let us take the conditional description of x of length n — d and put it after 
            the self-delimiting description of d that has size 2 log d + 0(1).  Knowing this string, 
            we can reconstruct d, then n, and finally x.})
                56 Prove that d(xy) = d(x) + d(y\x) + О (log d(xy)) for every two n-bit strings
            x and y.  (Here d(u) = l(u) — C(u).)
                (Hint:  Use Problem 36.)
                The intuitive  meaning of the difference between length and complexity as a 
            kind of “randomness deficiency”  is discussed (for different complexity versions) in 
            Chapter 5 and Chapter 14.
                57 Prove that for sufficiently large values of a constant c the enumerable set
            of pairs (x,y) such that C(x\y) < c is Turing complete (one can solve the halting 
            problem using an oracle for such a set).
                (Hint:  Use Problem  15  and the fact that the output of a program has 0(1) 
            conditional complexity given the program.)
