                                        9.11.  PARTIAL  SELECTION  RULES                        289
             can even hang (and this is the problem, because then it cannot be used as a step 
             in a prediction algorithm for an infinite sequence).
                 To get around this problem, we should recall the proof of the formula for the 
             complexity of pairs  (Theorem 21, p.  37)  and use it as a part of our construction. 
             Let us explain what this means.
                 As before, we make predictions for the left and the right halves  (и and v) of 
             the n-bit prefix separately.  When we read the right half v bit by bit, we enumerate 
             the set  Cn  of possible candidates for the n-bit prefix (^strings of complexity less 
             than 1.5n), waiting until a candidate appears that is consistent with и and already 
             known bits of v.  When such a candidate is found, we use it for predictions until 
             one of the predictions turns out to be false.  Then we look for the next candidate, 
             etc.
                 Will this prediction algorithm be successful?  It depends on u.  More specifically, 
             it  depends on the number of different v such that uv E Cn.  If there are many of 
             them, we can make an error and change the candidate at each step.  But at least 
             our prediction algorithm will not hang as far as uv is indeed in Cn.
                 Now we discuss the left half.  Here we use as candidates the values of и such 
             that there is at least n0,8 different v with uv 6 Cn.  The prediction in the left half 
             is guaranteed to be successful if и is among the candidates  (and this will happen 
             if the predictions in the right half are not successful).  But if not, this prediction 
             algorithm may hang (at some moment we could wait forever for a candidate which 
             is consistent with known bits).
                 What happens when we combine these algorithms for different prefixes?  First 
             we consider the joint algorithm based on the predictions of right halves for each щ. 
             This algorithm never hangs (we assume that щ is large enough, so all prefixes of 
             length щ have complexity less than 1.5пг).  If for infinitely many i the prediction is 
             successful, then we are done (the fraction of successful predictions does not converge 
             to  1/2).  So it is enough to consider the case when the right half prediction works 
                                   i.  Then for all sufficiently large i the left half prediction works, 
             only for finitely many 
             and the finite number of bad prediction algorithms can be replaced by something 
             safe (that never hangs).
                 So we see that in both cases и is not Mises-Church-Daley random.
                 This proves the theorem for c = 1.5 (and the same trick works for every c < 2). 
             But what should be done for bigger values of c?  One can split the sequence not into 
             two halves, but into к pieces of equal size for some к > 2.  One should take к greater 
             than c, and repeat the same argument.  The prediction algorithm for the rightmost 
             piece never hangs, so we can combine these algorithms into a prediction algorithm 
             for the entire sequence.  If it is successful for infinitely many prefixes, we are done. 
             If not,  it  fails starting from some moment,  and then the prediction algorithm for 
             the second (from the right)  piece is total  (but not  necessarily successful).  If it  is 
             successful infinitely often, we are again done.  If not, we should consider the third 
             piece, etc.  (A more formal exposition with all details can be found in [120].)    □
                 So we know the Mises- Church-Daley random sequence cannot have O(logn)- 
             complexity  of prefixes.  However,  it  can  only  slightly  exceed  this  bound  (e.g., 
             O(lognloglogn) complexity is possible), as shown in [120]:
                 Theorem 189.  Let f : N —> N be a total non-decreasing unbounded computable 
            function.  Then there  exists  a Mises-Church-Daley random sequence whose n-bit 
             prefix has complexity at most f(n) logn + 0(1) for all n.
