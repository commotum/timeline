                        8.7.  LIPSCHITZ TRANSFORMATIONS ARE NOT TRANSITIVE          259
               Now we pose the following question:  Does the left shift remain transitive if we 
           change the definition  and  replace  Cantor distance d by the so-called  Besicovitch 
           distance,
                                  p{u)\, U)2 ) = Uni Slip dn (u>i, U)2 )/n
                                                » oo
           (where dn is a number of discrepancies among the first n terms, i.e., the number of 
           i  < n such that ith. terms of uj\  and 0J2 differ)?
               It  turns out that  in this case the left shift  is no more transitive  (is not  Besi- 
           covitch-transitive).  Moreover,  the following statement  is  true  (we reproduce  the 
           proof given in [17]):
               Theorem  165.  No Lipschitz mapping can be Besicovitch-transitive.
               (Speaking about the Lipschitz property, we have in mind the original definition 
           using Cantor distance.)
               The reason is quite simple.  The Lipschitz mapping does not significantly in­
           crease  the  complexity  of the  prefixes  of a  sequence,  since  n  bits  of the  output 
           sequence are determined by n + 0(1) bits of the input sequence.  (We assume that 
           transformation rule is computable; if not, we have to relativize complexity by a suit­
           able oracle.)  On the other hand, if two sequences are Besicovitch-close, then their 
           prefixes have almost the same complexities (a change in a small fraction among the 
           first n bits can be encoded b}' a short string compared to n).
               PROOF.  For a formal proof it is convenient to use the notion of effective Haus- 
           dorff dimension of a sequence (which is equal to liminf C(ujo • • •u)n-\)/n for a sin­
           gleton {ta}; see Theorem 120, p.  174).
               Lemma  1.  A  computable  Lipschitz  mapping  does  not  increase  the  effective 
           Hausdorff dimension of a sequence.
               (Speaking about computability of a Lipschitz mapping / : Q, —y Q, we mean that 
           n first bits of f(uj)  are effectively determined by n + c first bits of uj for some c.)
               P r o o f.  Indeed,  if f(uji)  =   uj2 ,  then  the  complexity of an  n-bit  prefix of uj2 
           does not exceed (up to 0(1)) the complexity of an (n + c)-bit prefix of uq, and for 
           the dimension these constants are not important.
               Lemma 2.  If Besicovitch distance p(uji,uj2)  is less thane,  then effective Haus­
           dorff dimensions ofuj\  and uj2  differ at most by H(e).
               (Here H(e) is the Shannon entropy of a random variable with two values that 
           have probabilities e and 1 — e.)
               P r o o f.  Indeed, if the first n terms of uj\ and uj2 differ in к places, then the com­
           plexities differ at most by the complexity of the bitwise xor of these two sequences 
           (since knowing one sequence and their xor we easily get the other one).  And every 
           sequence of length n that has к ones has complexity at most nH(k/n) + O(logn) 
           (Theorem 146, p. 226).  Lemma 2 is proven.
               So if we take a sequence of a zero dimension (say, a computable sequence), then 
           any sequence that is Besicovitch-close to it has small dimension, and a computable 
           Lipschitz mapping does not increase this dimension, so we can get only sequences 
           of small effective Hausdorff dimension.  On the other hand,  any sequence that is 
           Besicovitch-close to a random sequence (that has dimension 1 ) has dimension close 
           to  1  (Lemma 2 again).
