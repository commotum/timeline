        362             11.  COMMON  INFORMATION
        a two-dimensional space orthogonal to both and two one-dimensional subspaces in 
        it).  Still there are only few one-dimensional subspaces in a two-dimensional space, 
       so we still can apply a similar argument based on the inclusion-exclusion formula. 
        (See the proof of Theorem 5 in [39] for details.)
          There are other similar examples.  One can consider a pair of two affine lines in 
       a three-dimensional space that have a common point.  Another series of examples 
       can be obtained in the following way.  Fix some integer n ^ 3 and some integers 
       k, I  such that  0  <  к < I < n.  Then in the n-dimensional space over a finite field 
       consider  a random pair  (/c-dimensional  subspace,  /-dimensional subspace)  where 
       the first subspace is contained in the second one.  Romashchenko has shown [153], 
       that one cannot extract common information from this pair.  The proof uses the 
       following remark:  making a short random walk in the resulting bipartite graph, we 
       get an almost uniform distribution.
            11.4.  Conditional independence and common information
          In this section we consider one more (quite mysterious) way to obtain strings 
       that have mutual information but no extractable common information [112, 153]. 
       Let us start by recalling the inequality of Problem 296 (p. 341):
                     H(t) ^ H(t\a) + H(t\ß) + I(or.ß),
       or, better to say, the corresponding inequality for complexities
                     C(z) < C(z IX) + C(z I у) + I(x : у)
       (as usual, we omit the logarithmic terms).  If I(x:y) = 0, this inequality implies an 
       upper bound for unconditional complexity in terms of conditional ones,
                        C(z) < C(z \x) + C(z\y).
       There is no surprise here—if there is no mutual information, there is no common 
       information to extract.  It seems that we are not getting anywhere.  But a similar 
       bound can be obtained for the case when x and у are  conditionally independent 
       relative to  two  independent  strings,  i.e.,  if there exist  strings  и  and v  such that 
       I(x:y\u)  —  0,  I(x:y\v) —  0,  and I(u:v)  =  0.  Namely,  the following inequality 
       holds:
          Theorem 228.
              C(z) ^ 2C(z I x) + 2C(z I y) + I(x:y\u) + I(x:y\v) + I(u:v) 
       for arbitrary strings x, y, z, u, v  (with 0(\ogC(x, у, и, z, v))-precision).
          This inequality is a consequence of the previous one and Ingleton’s inequality
                    I(x:y) ^ I(x:y\u) + I(x:y\v) + I(u:v),
       but, of course, Ingleton’s inequality is not always true.  So we need to proceed in a 
       different order.
          PROOF.  Let us consider again the inequality
                     C(z) ^ C(z |w) + C(z I v) + I(u:v)
