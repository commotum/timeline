        104       4.  A  PRIORI  PROBABILITY  AND  PREFIX  COMPLEXITY
        or false depending on whether x is in A or not.)  Almost all known theorems in 
        general computation theory are relativizable,  i.e.,  they remain true if we replace 
        (everywhere) computable functions by А-computable functions.
          By the way, the notion of Kolmogorov complexity can be relativized in a stan­
        dard way, too.  That is, for every set A we can define the plain Kolmogorov complex­
        ity CA{x) and the prefix Kolmogorov complexity KA(x) (see Section 6.4).  However, 
        we do not consider relativized Kolmogorov complexity now.  Instead of algorithms 
        having oracle access to a set of strings, we consider algorithms having access to a 
        finite string z.  In this  way we obtain conditional complexity C(x\z)  or K(x\z) 
        instead of C(x) (resp.  K(x)).  Since z is finite, the access to it does not increase the 
        power of algorithms (any z-computable function is computable without z).  How­
        ever,  the access to z changes Kolmogorov complexity, if z contains non-negligible 
        information.  Here is another example of this kind of relativization:  the quantity 
        I(x : y\z) can be considered as common information in x and y relative to z.
          Up to now the structure (prefix relation) used in the definition of prefix-stable 
        and prefix-free functions was applied to descriptions only.  The described objects, as 
        well as conditions, had no structure at all.  The other approach is also possible:  we 
        could take into consideration the binary relation  “to be a prefix of”  on described 
        objects  as  well.  This  will  lead  us  to  monotone  complexity  (see  Chapter  5)  and 
        decision complexity (Chapter 6).  On the other hand, we could consider the relation 
        “to be a prefix of” on conditions as well (see Section 6.3).  The resulting complexities 
        make sense; however, they are not well studied yet.
          Note that all the requirements in the definitions of prefix-free and prefix-stable 
        decompressors treat different  conditions  separately.  For example,  requiring that 
        a  machine  can  tell  when  the  input  ends,  we  allow  this  decision  depend  on  the 
        condition.  This is an important remark, and we can come to wrong conclusions if 
        we forget about this.  One should be really careful here; for example, the statement 
        of Problem 28 (p. 35) is not true for prefix complexity:
           109 Show that K(y\x) does not exceed the minimal prefix complexity of a 
        program mapping x to y (up to an 0(1) additive term).  The converse statement 
        is  false.  (Both statements hold for every reasonable programming language;  the 
        additive constant depends on the chosen language.)
          (Hint:  It is easy to see that K{y\l{y)) ^ l(y) + 0(1).  Indeed, every string y is 
        its own self-delimiting description when l(y) is known.  If the inequality in question 
        were true, there would be 2n different programs of prefix complexity at most n.)
          4.7.2.  Properties of conditional prefix complexity.  Let us mention sev­
        eral simple results about conditional prefix complexity.
            •  K(x\z) < K(x) + 0(1).
                Indeed,  a  prefix-stable  (or  prefix-free)  unconditional  decompressor 
             y  i—^  D{y)  can  be  considered  as  a prefix-stable  (resp.  prefix-free)  con­
             ditional decompressor  (y, z)  i->  D(y)  that just  ignores the second argu­
             ment z.
                Using semimeasures:  any probabilistic machine without input can be 
             considered  as  a machine that  has  input  but  ignores  it.  And  any  lower 
             semicomputable semimeasure q(x) can be treated as a family q'{x\z)  = 
              q{x) indexed by z.
            •  K(x I x) = 0(1).
