                       348                       10.  INEQUALITIES  FOR  ENTROPY.  COMPLEXITY  AND  SIZE
                       k e e p   t h e ir   s iz e   ( w it h   o (7 r )- p r e c is io n )  e x c e p t   fo r   t h e   o n e :    the conditional entropy
                       H(A'k\Ai,..., A -i) is  now   o{n).
                                304 Prove this statement for the case к = 2.
                              Note that it is important here that we deal with n independent copies and allow 
                       o{n) errors.  It is not possible to get such a result without that.  Indeed, let a and 
                       £ be dependent uniformly distributed binary variables.  Then one cannot construct 
                       a variable e'  that has Н{е'\а)  = 0  (i.e.,  is a function of a)  and has the required 
                       entropy.
                              Now let us explain how the Ahlswede-Körner theorem can be used to prove 
                       Theorem 218.  Let a,/5,7, 5, e be some random variables (on the same probability 
                       space).  First  of all,  let  us  prove  the  inequality  of Theorem  218  with  the  addi­
                       tional term 3H(s | a, ß)  in the right-hand side.  It can be obtained by adding the 
                       inequalities
                                                             H(eb)^H(e\c,) + H(e\ß) + I(a-.ß\1), 
                                                              H(e IÄK H(e I a) + H(e \ 0) + I(a : ß \ S), 
                                                                  Н{е)^Н{еЬ) + Н(е\5) + 1(т.0),
                       and the equality
                                      I {a : ß) + 2 H{e \ a) + 2 H{e | ß) = H{e) + W{a, ß, e) + 3H{e\ a, ß).
                       We have already seen the third inequality  (Problem  296,  p.  341).  The first  two 
                       inequalities  follow  from  its  conditional version.  All  three inequalities  are combi­
                       nations of basic inequalities.  The equality is easy to check using the diagram for 
                       c*,ß,£.
                              Now  the  Ahlswede-Körner  theorem  allows  us  to  get  rid  of the  undesirable 
                      term 3H(£\a, ß).  Consider n independent tuples cq, /?i,7t,£t,£i  (for i =  l,...,n) 
                      of variables with the same distribution,  and random variables A —  (cq,... ,an), 
                       В = {ßi                             С = (7i,...,7n), D = (5Ь...,5П),  E  =  (fi, ..., en).  The
                      entropies of variables А, В, C, D, Е and their combinations are n times bigger than 
                      the entropies of the original variables and their combinations.  Now we can apply the 
                      Ahlswede-Körner theorem to random variables a, 
                                                                                                                      ß, £ and get a random variable 
                      E'  defined  on  the  same  space  as  the  variables  A, B,C, D, E.  For  A,B,C,D,E' 
                      we write the inequality with the additional term 3H(E' \A, B)  in the right-hand 
                      side  (that  we  have just  proven).  This  additional  term  is  o(n)  as  stated  by  the 
                      Ahlswede-Körner theorem.  Then we replace E' by E in all other terms.  We claim 
                      that  all the terms then change only by o(n).  Indeed,  for the terms that contain 
                      C or D, nothing changes as these terms do not contain E'  (here we use the same 
                      property of our inequality as in the other proof of Theorem 218).  And terms that 
                      do not contain C or D can be represented as sums of regions on the diagram for 
                      A,B,E' different  from H(E' \A, B).  Therefore the inequality  remains true with 
                      o(n)-precision after the replacement.  It remains to divide by n and note that we 
                      get the desired inequality as n —> oo.
                              It is instructive to compare these two tricks (making variables artificially inde­
                      pendent and applying the Ahlswede-Körner theorem).  In both cases we have mod­
                      ified the joint distribution of the variables A, B, C, D, E.  (We can apply artificial 
                      independence to the n-times-sampled variables, it does not make any difference.) 
                      In  the  first  case  we  kept  that  joint  distributions  for  А, В, E  and  for  A, B, C, D
