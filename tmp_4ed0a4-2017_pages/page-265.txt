            252                          8.  SOME  APPLICATIONS
                P r o o f.  In  fact.  Theorem  162  is  just  a  complexity  reformulation  of Theo­
            rem 161.  Indeed, consider the set of all restrictions  (F,Z) such that C(F,Z\t) < 
            a\F\ for all t G F.  Then for every index t the number of restrictions (F, Z) of size 
            k, where F contains t, is at most 2ak. and we can apply Theorem 161.           □
                8.5.6.     The  “effective”  proof of the Lovâsz local lemma.  Are the prob­
            abilistic existence proofs  “constructive”?  No, in the sense that they do not provide 
            an  explicit  example  of an  object  with  required  properties.  (One  can  perform  a 
            brute-force search and call the first object with the property an explicit example, 
            but this looks more like cheating, and the search usually takes a very long time.) 
            On the other hand, if the probability of the event  “random object has the required 
            property” is close to 1, we at least have a probabilistic algorithm that generates an 
            object with required properties, with small probability of error (and rather fast).
                What can be said about existence proofs based on the LL? In these proofs the 
            probability is exponentially small (though positive).  Random choice is no more an 
            option:  We cannot just take a random object according to the distribution used 
            in  the  LL.  However,  we  can  use  random  bits  in  a  more  clever  way,  and  in  this 
            section we explain how (and get a new proof for the LL in some special cases as a 
            byproduct).
                Assume that we want to construct a binary string (an assignment)  that sat­
            isfies some restrictions  (^clauses of a CNF, see Section 8.5.4).  Let us first choose 
            independent random values for all the bits.  Most probably some small part of the 
            restrictions will be violated.  Take one of them and try to improve the situation 
            by resampling all the variables that appear in this restriction.  (Resampling means 
            that we assign fresh random bits to these variables.)  Most probably this will solve 
            the problem with this restriction; it is quite unlikely that we will get the same bad 
            values for these variables once more.  Of course, other restrictions may still be vi­
            olated, and new violations may happen (for the restrictions involving the changed 
            variables).  Then we can repeat the process:  Take some restriction that is currently 
            violated, and perform the random resampling for its variables.  And so on.
                More formally,  the  initial  values  of all  variables  are  chosen  at  random,  and 
            then we iterate the following procedure:  While some restrictions are violated,  take 
            one of them (say, the first one in some ordering, or the random one, or use some 
            other rule)  and perform the resampling for all variables that appear in it.  This is 
            repeated until all restrictions are satisfied.  It looks like a miracle, but R. Moser and 
            G. Tardos recently proved [130, 131] that this trivial algorithm indeed achieves the 
            goal rather fast and with high probability.  (Before them, much more complicated 
            algorithms  were  studied  and  much  weaker  results  with  much  more  complicated 
            proofs were obtained.)
                We do not present their proof in full generality; instead we consider a special 
            case when all the clauses have the same number of variables.  Moreover, we assume 
            that the resampling is made in some special order (determined by recursive calls, 
            see below).  In this case a simple argument using Kolmogorov complexity can be 
            used, and we explain this argument, following L. Fortnow.
                So let us assume that a CNF is given with n variables and N clauses, and each 
            clause has some fixed length m (contains m variables).  We say that two clauses are 
            neighbors if they have a common variable.  Assume that every clause has at most t 
            neighbors.  We claim that if t is not very large, the LL guarantees the satisfiability 
            of the CNF in question.
