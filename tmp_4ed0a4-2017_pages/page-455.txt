             446                          14.  ALGORITHMIC STATISTICS
                 For that, it is enough to show that for every fixed x the probability of this bad 
             event is at most  2“^ +1l   The intuitive explanation is simple:  if x belongs to 2k 
             sets, the second player had (at least) 2k chances to mark a set containing x (when 
             these 2k sets were presented by the first player), and the probability of missing all 
             these chances is at most (1 — p)2  ; the choice of p guarantees that this probability 
             is less than l/2 ~(n+x\   Indeed, using the bound (1 — l/x)x < 1/e, it is easy to show 
             that
                                       (1 — p)2k  < e- ln2(n+l) — 2~(n+l).
                 A meticulous reader would say that this argument  is not technically correct 
             since the behavior of the first player (and the moment when the next set containing 
             x is produced) depends on the moves of the second player, so we do not have inde­
             pendent events with probability 1 — p each (as it is assumed in the computation).4 
             The formal argument  considers for each t the event Rt  “after some move of the 
             second player,  the string x belongs to at least t sets provided by the first player, 
             but it does not belong to any selected set”.  Then we prove by induction  (over t) 
             that the probability of Rt does not exceed (1 —p)l.  Indeed, it is easy to see that 
             Rt is a union of several disjoint subsets (depending on the events happening until 
             the first player provides t + 1st set containing x), and Rt+i  is obtained by taking a 
             (1 — p)-fraction in each of them.
                 Constructive proof.  We consider the same game, but now we allow more 
             sets  to  be  selected  (replacing  the  bound  2г~к+1(п +  l)ln2  by  a  bigger  bound 
             2l~ki2n\n2),  and  we  also  allow  the  second  player  to  select  sets  that  were  pro­
             duced earlier  (not  necessarily upon  the preceding move of the first player).  The 
             explicit winning strategy for the second players performs simultaneously i — к + log i 
             substrategies (indexed by the numbers log(2fc/2), log(2fc/2) + 1,..., i).
                 The substrategy number s wakes up once in 2s  moves  (when the number of 
             moves already made by the first player is a multiple of 2s).  It forms a family S that 
             consists of 2s  last sets produced by the first player, and the set T that consists of 
             all strings x covered by at least 2k/i sets from S.  Then it selects some elements in 
             S in such a way that all x G T are covered by one of the selected sets.  It is done 
             by a greedy algorithm:  first take a set from  S that  covers a maximal part of T, 
             then take the set that covers a maximal number of non-covered elements, etc.  How 
             many steps do we need to cover the entire T?  Let us show that
                                                 (i/2k)n2s In 2
             steps are enough.  Indeed, every element of T is covered by at least 2k/i sets from 
             S.  Therefore,  some set  from S covers at least  #T2k/(i2s)  elements,  i.e.,  2k~s/i- 
             fraction of T.  At the next step the non-covered part is multiplied by (1 — 2k~s/г) 
             again, and after m2s-fcln2 steps the number of non-covered elements is bounded 
             by
                                 # I ( l - 2fc-7 f r t l n 2  < 2n(l/e)nln2 -  1,
                 4The same problem appears if we observe a sequence of independent trials.  Each of them is 
             successful with probability p, and then we select some trials (before they are actually performed, 
             based  on the  information  obtained  so  far)  and  ask what  is  the  probability  of the event  “f  first 
             selected trials were all unsuccessful”.  This probability does not exceed (1 — p)4; it can be smaller 
             if the total number of selected trials  is fewer than t with positive probability.  This scheme was 
             considered by von Mises when he defined random sequences using selection rules.
