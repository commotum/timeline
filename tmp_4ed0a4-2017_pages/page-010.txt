                                                            Preface
                     The notion of algorithmic  complexity  (also sometimes  called  algorithmic  en­
                tropy)  appeared in the  1960s in  between the theory of computation,  probability 
               theory, and information theory.
                     The  idea  of A.  N.  Kolmogorov  was  to  measure  the  amount  of information 
               in finite  objects  (and not  in random variables,  as it  is done in classical  Shannon 
               information theory).  His famous paper  [78], published in  1965, explains how this 
               can be done (up to a bounded additive term) using the algorithmic approach.
                     Similar ideas were suggested a few years earlier by R.  Solomonoff (see  [187] 
               and his other papers; the historical account and reference can be found in [103]).1 
               The motivation of Solomonoff was quite different.  He tried to define the notion 
               of  a  priori probability.  Imagine  there  is some  experiment  (random  process)  and 
               we know nothing about its internal structure.  Can we say something about  the 
               probabilities  of different  outcomes  in  this  situation?  One  can  relate  this  to  the 
               complexity measures saying that simple objects have greater a priori probability 
               than complex ones.  (Unfortunately, Solomonoff’s work become popular only after 
               Kolmogorov mentioned it in his paper.)
                    In  1965  G.  Chaitin  (then  an  18-year-old  undergraduate  student)  submitted 
               two papers [28]  and  [29];  they were published in 1966 and  1969,  respectively.  In 
               the  second  paper  he  proposed  the  same  definition  of algorithmic  complexity  as 
               Kolmogorov.
                    The basic properties of Kolmogorov complexity were established in the 1970s. 
               Working independently,  С.  P.  Schnorr and L.  Levin  (who was a student  of Kol­
               mogorov) found a link between complexity and the notion of algorithmic random­
               ness (introduced in 1966 by P. Martin-Löf [115]).  To achieve this, they introduced 
               a slightly different version of complexity, the so-called monotone complexity.  Also 
               Solomonoff’s ideas about a priori probability were formalized in the form of prefix 
               complexity,  introduced by Levin and later by Chaitin.  The notions of complexity 
               turned out to be useful both for theory of computation and probability theory.
                    Kolmogorov complexity became popular (and for a good reason: it is a basic and 
               philosophically important notion of algorithm theory)  after M.  Li and P. Vitânyi 
               published  a book on the subject  [103]  (first  edition  appeared  in  1993).  Almost 
               everything about Kolmogorov complexity that was known at the moment was cov­
               ered in the book or at least mentioned as an exercise.  This book also provided a 
               detailed historical account, references to first publications, etc.  Then the books of
               C. Calude [25] and A. Nies [147] appeared, as well as the book of R. Downey and
               D. Hirschfeldt  [49].  These books cover many interesting results obtained recently
                    1Kolmogorov wrote  in  [79],  “I  came  to  a  similar  notion  not  knowing  about  Solomonoff’s 
               work.”
                                                                  XI
