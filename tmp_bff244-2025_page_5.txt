                                                             Latent Space                                  Footprint                LDM               Syn. Sampling                 (LDM) [21] has proven to be an effective tool for content
                                        I      E            Diffusion Process                                                                                                       generation [26, 30]. As shown in Figure 5, a conditional
                                                        Z                         Z      Footprint                                                                                  LDMis utilized to simulate the sampling locations with a
                                                                                   í µí±‡
                                                         0   Denoising U-Net
                                                                                                                                                                                    given building footprint. We project a point cloud along the
                                         ï¿½
                                        I      D Z                                Z       Ï„                                                                                         gravity axis and mark the corresponding pixel as 0 to obtain
                                                                                   í µí±‡
                                     Pixel Space          0                             Condition           Wireframe             Height map         Syn. Height map                the sampling image.
                                                      (a) Training process                                                (b) Synthesis process                                     Training Process. A latent space is constructed by train-
                                  Figure 5. Illustration of synthetic data generation. The syn-                                                                                     ing an autoencoder with the real LiDAR sampling images
                                  thetic process includes the LiDAR scanning simulation process                                                                                     as input. Given a sampling image I which is a binary image
                                  and the height map synthesis process. The LiDAR scanning sim-                                                                                     in pixel space, the encoder E encodes I into a latent repre-
                                                                                                                                                                                                                                                                                                             e
                                  ulation process is based on a conditional generation process. Tak-                                                                                sentation Z, then, the decoder reconstructs the image I with
                                                                                                                                                                                     e
                                  ing the building footprint as the condition, a latent diffusion model                                                                             S = D(Z) = D(E(I)). With the sampling location latent
                                  generates the LiDAR sampling locations accordingly. The train-                                                                                    space, a latent diffusion model is trained with the building
                                  ing process is shown on the left (a), while the synthesis process is                                                                              footprint (fp) as the condition. With the attention mecha-
                                  shownontheright (b).                                                                                                                              nism [25], the learning objective is represented as:
                                                                                                                                                                                                                                                                                                       2
                                                                                                                                                                                            L=E                                                   [||Ïµ âˆ’ Ïµ (z ,t, Ï„(fp))|| ],                                       (7)
                                  where L                    , L            , L are 2D corner loss, 3D corner loss,                                                                                        E(I),fp,Ïµâˆ¼N(0,1),t                                     Î¸      t                             2
                                                     c2D            c3D            e                                                                                                where Ïµ is the noise added, t is the time step, Ïµ is the pre-
                                  and edge loss respectively. And Î»1, Î»2, and Î»3 are the cor-                                                                                                                                                                                                  Î¸
                                  responding loss weights. The 2D corner loss is defined as:                                                                                        dicted noise, and Ï„ is the condition encoder.
                                                                                                                                                                                    Synthesis Process. Building footprints are obtained from
                                                                                                                                                                                    the 3D wireframe and serve as conditions. With the LDM,
                                                                           L             =L (l ,l ),                                                             (4)
                                                                               c                  ce       pre        gt
                                                                                 2D                                                                                                 thesyntheticsamplinglocationsaregenerated. Finally,with
                                  where l                  and l             are the per-pixel labels for the predicted                                                             the roof height map calculated from the 3D wireframe and
                                                   pre                 gt                                                                                                           the synthetic LiDAR sampling locations, the LiDAR scan-
                                  and ground truth. The 3D corner loss is defined as:                                                                                               ning process is simulated, and synthetic height maps are
                                                                        N
                                                                            gt
                                                                1 X                                                                                                                 generated for data augmentation.
                                         L             =                        (d         (c ,c              ) +L (c ,c                           )).           (5)
                                             c                                       L         i      Ïƒ(i)                 ce       i      Ïƒ(i)
                                               3D            N                          1                                                                                                  Withthe conditional generation method, the synthesized
                                                                  gt i=1                                                                                                            data is rich and diverse, and the sparsity and missing are
                                  Besides, the edge loss is defined as:                                                                                                             well simulated. Mixed with the real data, the data augmen-
                                                                             L =L (e ,e ),                                                                       (6)                tation process boosts the performance of our BWFormer.
                                                                                 e             ce       pre         gt
                                  where e                     and e                are the labels for the predicted and                                                             4. Experiments
                                                     pre                    gt
                                  ground truth edges respectively.                                                                                                                  4.1. Dataset and Evaluation Metrics
                                  3.5. Synthetic Data Augmentation                                                                                                                  Dataset. We evaluate our method on the Building3D [28]
                                  In many domains of computer vision, such as autonomous                                                                                            dataset.               Building3D is an urban-scale dataset collected
                                  driving and point cloud understanding, data augmentation                                                                                          with airborne LiDAR. The open-sourced Tallinn city part
                                  with additional synthetic data has proven to be an effective                                                                                      is divided into a training set (32618) and a test set (3472).
                                  tool to boost the model performance [22, 35]. Limited by                                                                                          Evaluation Metrics. We adopt the same evaluation met-
                                  the number of real-world LiDAR point clouds of buildings,                                                                                         rics as Building3D leaderboard 1, which are briefly intro-
                                  weintroduce a new height map synthesis method to gener-                                                                                           duced in the following. For wireframe-level metrics, Wire-
                                  ate synthetic data for augmenting the real-world dataset.                                                                                         frame Edit Distance (WED) is a modified version of Graph
                                        WhentheairborneLiDARfliesoverabuilding,itemitsa                                                                                             Edit Distance (GED) [1] to measure the number of ele-
                                  laser downward for sampling, and a point cloud is obtained                                                                                        mentary graph edit operators for transforming the predicted
                                  when the laser intersects with the roof of the building. To                                                                                       wireframe to the ground truth [14] while Average Corner
                                  simulate this process, we divide the synthetic process into                                                                                       Offset (ACO) calculates the average distance between pre-
                                  the LiDARscanningsimulationprocesstosamplelocations                                                                                               dicted and ground-truth corners. For corner-level and edge-
                                  on the 2D plane and the height map synthesis process to                                                                                           level metrics, Corner Precision (CP), Corner Recall (CR),
                                  collect the height of the building at that location.                                                                                              Corner F1 (CF1), Edge Precision (EP), Edge Recall (ER)
                                        The LiDAR sampling locations present different data                                                                                         and Edge F1 (EF1) are introduced to evaluate the recon-
                                  distributions due to the different aircraft types and Li-                                                                                         struction quality of the corners and edges.
                                  DAR equipment. Thus, simulating the distribution simi-                                                                                                     1https://huggingface.co/spaces/Building3D/
                                  lar to the real data is important. Latent Diffusion Model                                                                                         USM3D
                                                                                                                                                                        22219
