                                                                Test-Time Learning for Large Language Models
                                                                             Datasets            800                                         Datasets
                                                                               Agriculture                                                    Agriculture
                                 800                                           Medicine          700                                          Medicine
                                                                               Geography         600                                          Geography
                                                                               Finance                                                        Finance
                                 600                                                             500
                                Density                                                         Density400
                                 400
                                                                                                 300
                                 200                                                             200
                                                                                                 100
                                   0 0            50          100         150         200          0  0          100         200          300         400
                                                      Input Sequence Length                                          Output Sequence Length
                                                    Figure 5. Distribution of Sequence Lengths for Samples in DomainBench.
                        linguistic styles, providing a thorough assessment of the model’s capacity to process and respond effectively to diverse
                        instructions in real-world scenarios.
                     • ReasoningBench. This category contains three reasoning-focused datasets: GSM8k, MetaMath, and Logiqa, designed
                        to evaluate the logical reasoning and math problem-solving abilities of LLMs. It evaluates the model’s ability to
                        handle intricate reasoning processes through diverse scenarios, including multi-step mathematical reasoning, complex
                        mathproblemsolving, and logical reading comprehension. ReasoningBench evaluates tasks that require precise and
                        consistent reasoning, offering a thorough test of a model’s ability to tackle complex problems and produce logical,
                        accurate solutions.
                  B.1. DomainBench
                  DomainBench focuses on evaluating the model’s adaptability and performance in four vertical domains: Geography,
                  Agricultural, Medical, and Financial. To ensure the comprehensiveness and scientific rigor of the evaluation, DomainBench
                  integrates four meticulously selected datasets: GeoSignal, Agriculture-QA, GenMedGPT-5k, and Wealth-Alpaca Lora.
                  Each dataset is sourced from a broad range of specialized domains, enabling the measurement of large model performance
                  on complex domain-specific knowledge and task execution. The distribution of sequence lengths for the dataset samples and
                  an example table of dataset entries are provided in Figure 5 and Table 7.
                  Geography: TheGeoSignal1 dataset is a knowledge-intensive instruction-tuning resource tailored for the Earth Sciences
                  domain, aiming to improve model performance in this field. It comprises approximately 39.7k samples, created through a
                  mixofhumancurationandsemi-automaticmethods. Thedatasetisdesignedtoalign with user intent, featuring two sections:
                  a general section for human instruction alignment and a professional section focused on Earth Sciences expertise. It includes
                  tasks such as Named Entity Recognition (NER), relation inference, fact verification, and question answering, enriched with
                  domain-specific terminology like “volcanic neck” and “geomagnetic elements”. Data sources span a multi-modal Earth
                  Sciences knowledge graph (GAKG), academic resources (DDE Scholar), and various databases and QA platforms. From
                  this dataset, we randomly select 5k samples to form the Geography dataset, which evaluates the model’s domain knowledge
                  and task performance in Geography.
                  Agriculture: The Agriculture-QA2 dataset focuses on agricultural QA, containing about 22.6k samples. It covers various
                  aspects of agricultural production, such as crop cultivation, livestock farming, soil management, and farming practices.
                  These QAtasks challenge the model’s ability to transfer knowledge and comprehend natural language, especially within the
                  highly specialized agricultural field. We randomly select 5k samples to create the Agriculture dataset, aiming to evaluate the
                  model’s performance in handling agricultural QA tasks.
                      1https://huggingface.co/datasets/daven3/geosignal
                      2https://huggingface.co/datasets/KisanVaani/agriculture-qa-english-only
                                                                                           18
