                   A "whatpu" is a small, furry animal native to Tanzania.    An example of a sentence that uses
                   the word whatpu is:
                   We were traveling in Africa and we saw these very cute whatpus.
                   To do a "farduddle" means to jump up and down really fast.    An example of a sentence that uses
                   the word farduddle is:
                   One day when I was playing tag with my little sister, she got really excited and she
                   started doing these crazy farduddles.
                   A "yalubalu" is a type of vegetable that looks like a big pumpkin.    An example of a sentence
                   that uses the word yalubalu is:
                   I was on a trip to Africa and I tried this yalubalu vegetable that was grown in a garden
                   there. It was delicious.
                   A "Burringo" is a car with very fast acceleration. An example of a sentence that uses the
                   word Burringo is:
                   In our garage we have a Burringo that my father drives to work every day.
                   A "Gigamuru" is a type of Japanese musical instrument. An example of a sentence that uses the
                   word Gigamuru is:
                   I have a Gigamuru that my uncle gave me as a gift.      I love to play it at home.
                   To "screeg" something is to swing a sword at it. An example of a sentence that uses the word
                   screeg is:
                   We screeghed at each other for several minutes and then we went outside and ate ice cream.
                Figure 3.16: Representative GPT-3 completions for the few-shot task of using a new word in a sentence. Boldface is
                GPT-3’scompletions, plain text is human prompts. In the ﬁrst example both the prompt and the completion are provided
                by a human; this then serves as conditioning for subsequent examples where GPT-3 receives successive additional
                prompts and provides the completions. Nothing task-speciﬁc is provided to GPT-3 other than the conditioning shown
                here.
                nonexistent word being deﬁned and used in a sentence, so the task is few-shot in terms of previous examples of the
                broad task and one-shot in terms of the speciﬁc word. Table 3.16 shows the 6 examples we generated; all deﬁnitions
                were human-generated, and the ﬁrst answer was human-generated as conditioning while the subsequent answers were
                generated by GPT-3. These examples were generated continuously in one sitting and we did not omit or repeatedly try
                any prompts. In all cases the generated sentence appears to be a correct or at least plausible use of the word. In the ﬁnal
                sentence the model generates a plausible conjugation for the word “screeg” (namely “screeghed”), although the use of
                the word is slightly awkward (“screeghed at each other”) despite being plausible in the sense that it could describe a toy
                sword ﬁght. Overall, GPT-3 appears to be at least proﬁcient at the task of using novel words in a sentence.
                3.9.6  Correcting English Grammar
                Another task well suited for few-shot learning is correcting English grammar. We test this with GPT-3 in the few-
                shot setting by giving prompts of the form "Poor English Input:   <sentence>\n Good English Output:
                <sentence>". WegiveGPT-3onehuman-generatedcorrection and then ask it to correct 5 more (again without any
                omissions or repeats). Results are shown in Figure 3.17.
                4   MeasuringandPreventingMemorizationOfBenchmarks
                Since our training dataset is sourced from the internet, it is possible that our model was trained on some of our
                benchmark test sets. Accurately detecting test contamination from internet-scale datasets is a new area of research
                withoutestablishedbestpractices. Whileitiscommonpracticetotrainlargemodelswithoutinvestigatingcontamination,
                given the increasing scale of pretraining datasets, we believe this issue is becoming increasingly important to attend to.
                This concern is not just hypothetical. One of the ﬁrst papers to train a language model on Common Crawl data [TL18]
                detected and removed a training document which overlapped with one of their evaluation datasets. Other work such
                               +
                as GPT-2 [RWC 19]alsoconducted post-hoc overlap analysis. Their study was relatively encouraging, ﬁnding that
                                                                  29
