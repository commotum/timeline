                                          Test-Time Learning for Large Language Models
                            Table 11. Comparison of experimental results on the Agriculture dataset of DomainBench.
                 Method              BERTScore↑    BLEURT↑     BLEU↑     Rouge-1 ↑   Rouge-2 ↑   Rouge-L↑
                 Llama3.2-3B-Instruct  0.6672       -0.7595     0.0104     0.0927     0.0316      0.0684
                   •Tent               0.6350       -0.9975     0.0015     0.0159     0.0034      0.0148
                   •EATA               0.6659       -0.8355     0.0022     0.0263     0.0046      0.0247
                   •TLM(Ours)          0.6787       -0.6668     0.0288     0.1935     0.0655      0.1518
                 Llama3-8B-Instruct    0.6666       -0.7288     0.0106     0.0903     0.0328      0.0665
                   •Tent               0.5746       -1.2577     0.0008     0.0075     0.0011      0.0066
                   •EATA               0.5870       -1.3074     0.0003     0.0019     0.0000      0.0016
                   •TLM(Ours)          0.6526       -0.6703     0.0189     0.1477     0.0496      0.1110
                 Llama2-13B-chat       0.6235       -0.6134     0.0116     0.0910     0.0319      0.0668
                   •Tent               0.5901       -0.9157     0.0015     0.0200     0.0019      0.0193
                   •EATA               0.6065       -0.6084     0.0101     0.0843     0.0257      0.0675
                   •TLM(Ours)          0.6354       -0.5929     0.0144     0.1108      0.0379     0.0826
                 Qwen2.5-7B-Instruct   0.6562       -0.7226     0.0118     0.1068     0.0377      0.0768
                   •Tent               0.6667       -1.1641     0.0118     0.1399     0.0346      0.1145
                   •EATA               0.6562       -1.1517     0.0113     0.1425     0.0357      0.1166
                   •TLM(Ours)          0.6755       -0.6219     0.0291     0.1841     0.0663      0.1394
            outperforms both Tent and the original LLMs across all metrics on the Dolly dataset. Specifically, the proposed method
            achieves a relative improvement of 1.11% in BERTScore compared to Llama3-8B-Instruct. As shown in Table 16, our
            proposed TLM outperforms Tent on the InstructionWild dataset. For instance, our proposed TLM achieves a relative
            improvement 50.15% improvement in the BLEU metric compared to Llama3.2-3B-Instruct.
            E. Discussions and Future Works
            Tothebest of our knowledge, addressing the challenges faced by LLMs in real-world deployments, such as distributional
            shifts in test data, has not been thoroughly explored. In this work, we introduce the Test-Time Learning (TTL) task,
            aiming to dynamically adapt LLMs using only unlabeled test data during testing. Additionally, we propose the AdaptEval
            benchmark, designed to evaluate the effectiveness of TTL in enhancing model performance across a variety of domains.
            Experimental results demonstrate that the proposed Test-Time Learning approach effectively improves LLM performance
            ontarget domains. However, we believe there are several potential research directions worth exploring in the future:
            Cross-Domain Continuous Adaptation: When deploying LLMs across multiple domains, it is essential to achieve
            continuous adaptation without overfitting to a specific domain. This requires balancing the transfer of knowledge across
            domains while mitigating catastrophic forgetting. Future work could explore methods for seamless domain adaptation that
            improves model generalization across dynamic and diverse tasks.
            Only Forward Passes: LLMs have large parameter sizes, and deployed models in practical settings may not support
            backpropagation due to memory or computational limitations. This restricts the ability to perform Test-Time Learning during
            inference, highlighting the need for more efficient methods that enable model adaptation without requiring backpropagation.
                                                            24
