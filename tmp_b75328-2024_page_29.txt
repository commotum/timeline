                • The conference expects that many papers will be foundational research and not tied
                 to particular applications, let alone deployments. However, if there is a direct path to
                 any negative applications, the authors should point it out. For example, it is legitimate
                 to point out that an improvement in the quality of generative models could be used to
                 generate deepfakes for disinformation. On the other hand, it is not needed to point out
                 that a generic algorithm for optimizing neural networks could enable people to train
                 models that generate Deepfakes faster.
                • The authors should consider possible harms that could arise when the technology is
                 being used as intended and functioning correctly, harms that could arise when the
                 technology is being used as intended but gives incorrect results, and harms following
                 from (intentional or unintentional) misuse of the technology.
                • If there are negative societal impacts, the authors could also discuss possible mitigation
                 strategies (e.g., gated release of models, providing defenses in addition to attacks,
                 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
                 feedback over time, improving the efficiency and accessibility of ML).
             11. Safeguards
               Question: Does the paper describe safeguards that have been put in place for responsible
               release of data or models that have a high risk for misuse (e.g., pretrained language models,
               image generators, or scraped datasets)?
               Answer: [NA]
               Justification: We do not release models with potential to misuse.
               Guidelines:
                • The answer NA means that the paper poses no such risks.
                • Released models that have a high risk for misuse or dual-use should be released with
                 necessary safeguards to allow for controlled use of the model, for example by requiring
                 that users adhere to usage guidelines or restrictions to access the model or implementing
                 safety filters.
                • Datasets that have been scraped from the Internet could pose safety risks. The authors
                 should describe how they avoided releasing unsafe images.
                • Werecognize that providing effective safeguards is challenging, and many papers do
                 not require this, but we encourage authors to take this into account and make a best
                 faith effort.
             12. Licenses for existing assets
               Question: Are the creators or original owners of assets (e.g., code, data, models), used in
               the paper, properly credited and are the license and terms of use explicitly mentioned and
               properly respected?
               Answer: [Yes]
               Justification: Please see Section A.8.
               Guidelines:
                • The answer NA means that the paper does not use existing assets.
                • The authors should cite the original paper that produced the code package or dataset.
                • The authors should state which version of the asset is used and, if possible, include a
                 URL.
                • The name of the license (e.g., CC-BY 4.0) should be included for each asset.
                • For scraped data from a particular source (e.g., website), the copyright and terms of
                 service of that source should be provided.
                • If assets are released, the license, copyright information, and terms of use in the
                 package should be provided. For popular datasets, paperswithcode.com/datasets
                 has curated licenses for some datasets. Their licensing guide can help determine the
                 license of a dataset.
                • For existing datasets that are re-packaged, both the original license and the license of
                 the derived asset (if it has changed) should be provided.
                               29
