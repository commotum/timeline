                                                                                    Step 3. Applybackwardchainingtosampleaset
                                                                                              of facts that can prove the target relation
                                                                                              (andoptionally sample a set of “distracting”
                                                                                              or “irrelevant” noise facts).
                                                                                    Step 4. Convertthesampledfactsintoanatural
                                                                                              language story through pre-speciﬁed text
                                                                                              templates and crowd-sourced paraphrasing.
                                                                                     Figure 2 provides a high-level overview of this
                                                                                     idea, and the following subsections describe the
                                                                                     data generation process in detail, as well as the
                    Figure 2: Data generation pipeline. Step 1: generate             diagnostic ﬂexibility afforded by CLUTRR.
                    a kinship graph. Step 2: sample a target fact. Step 3:
                    Usebackwardchainingtosampleasetoffacts. Step 4:                  3.2   Story generation
                    Convert sampled facts to a natural language story.               Theshort stories in CLUTRR are essentially narra-
                    relations by reading short stories. Requiring that               tivized renderings of a set of logical facts. In this
                    the models learn directly from natural language                  section, we describe how we sample the logical
                    makes this task much more challenging than the                   facts that make up a story by generating random
                    purely symbolic ILP setting. However, we lever-                  kinship graphs and using backward chaining to
                    age insights from traditional ILP to generate these              produce logical reasoning chains. The conversion
                    stories in a semi-synthetic manner, providing pre-               from logical facts to natural language narratives is
                    cise control over the complexity of the reasoning                then described in Section 3.3.
                    required to solve the task.                                      Terminology and background.                    Following
                       In its entirety, the CLUTRR benchmark suite al-               standard practice in formal semantics, we use the
                    lows researchers to generate diverse semi-synthetic              term atom to refer to a predicate symbol and a
                    short stories to test different aspects of inductive             list of terms, such as [grandfatherOf,X,Y],
                    reasoning capabilities. We publicly release the en-              where the predicate grandfatherOf denotes
                    tire benchmark suite, including code to generate                 the relation between the two variables, X and Y .
                    the semi-synthetic examples, the speciﬁc datasets                Werestrict the predicates to have an arity of 2, i.e.,
                    that we introduce here, and the different baselines              binary predicates. A logical rule in this setting
                                               1                                     is of the form H ` B, where B is the body of the
                    that we compare with.                                            rule, i.e., a conjunction of two atoms ([α ,α ])
                                                                                                                                         1    2
                    3.1    Overviewofdatagenerationprocess                           and H is the head, i.e., a single atom (α) that
                                                                                     can be viewed as the goal or query. For instance,
                    The core idea behind the CLUTRR benchmark                        given a knowledge base (KB) R that contains
                    suite is the following: Given a natural language                 the single rule [grandfatherOf,X,Y]                       `
                    story describing a set of kinship relations, the goal            [[fatherOf,X,Z],[fatherOf,Z,Y]],
                    is to infer the relationship between two entities,               the    query      [grandfatherOf,X,Y]                 eval-
                    whose relationship is not explicitly stated in the               uates    to   true    if  and only if the body
                    story. To generate these stories, we ﬁrst design a               B = [[fatherOf,X,Z],[fatherOf,Z,Y]]
                    knowledge base (KB) with rules specifying how                    is also true in a given world. A rule is called a
                    kinship relations resolve, and we use the following              groundedruleifallatomsintherulearethemselves
                    steps to create semi-synthetic stories based on this             grounded, i.e., all variables are replaced with con-
                    knowledge base:                                                  stants or entities in a world. A fact is a grounded
                    Step 1. Generate a random kinship graph that sat-                binary predicate. A clause is a conjunction of two
                                                                                     or more atoms (C = (H ` B = ([α ,...,α ])))
                              isﬁes the rules in our KB.                                                          C      C         1       n
                                                                                     which can be built using a set of rules.
                    Step 2. Sample a target fact (i.e., relation) to pre-               In the context of our data generation process,
                              dict from the kinship graph.                           we distinguish between the knowledge base, R,
                        1Benchmark     suite  code   can   be   obtained   from      which contains a ﬁnite number of predicates and
                    https://github.com/facebookresearch/clutrr.       Generated      rules specifying how kinship relations in a family
                    datasets are available to view in this link.                     resolve, and a particular kinship graph G, which
                                                                               4508
