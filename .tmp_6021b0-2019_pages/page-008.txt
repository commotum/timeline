                        Table 2: Testing the robustness of the various models when training and testing on stories containing various types
                        of noise facts. The types of noise facts (supporting, irrelevant, and disconnected) are deﬁned in Section 3.5.
                                        Models                                      Unstructured models (no graph)                                Structured model (with graph)
                          Training      Testing         BiLSTM-Attention      BiLSTM-Mean          RN        MAC       BERT       BERT-LSTM                   GAT
                             Clean          Clean            0.58 ±0.05          0.53 ±0.05     0.49 ±0.06 0.63 ±0.08  0.37 ±0.06   0.67 ±0.03               1.0 ±0.0
                                          Supporting         0.76 ±0.02          0.64 ±0.22     0.58 ±0.06 0.71 ±0.07  0.28 ±0.1    0.66 ±0.06              0.24 ±0.2
                                          Irrelevant          0.7 ±0.15          0.76 ±0.02     0.59 ±0.06 0.69 ±0.05  0.24 ±0.08   0.55 ±0.03              0.51 ±0.15
                                        Disconnected         0.49 ±0.05          0.45 ±0.05      0.5 ±0.06 0.59 ±0.05  0.24 ±0.08    0.5 ±0.06               0.8 ±0.17
                          Supporting      Supporting         0.67 ±0.06          0.66 ±0.07     0.68 ±0.05 0.65 ±0.04  0.32 ±0.09   0.57 ±0.04              0.98 ±0.01
                           Irrelevant     Irrelevant         0.51 ±0.06          0.52 ±0.06      0.5 ±0.04 0.56 ±0.04  0.25 ±0.06   0.53 ±0.06              0.93 ±0.01
                         Disconnected   Disconnected         0.57 ±0.07          0.57 ±0.06     0.45 ±0.11  0.4 ±0.1   0.17 ±0.05   0.47 ±0.06              0.96 ±0.01
                          Average                            0.61 ±0.08          0.59 ±0.08     0.54 ±0.07 0.61 ±0.06  0.30 ±0.07   0.56 ±0.05              0.77 ±0.09
                        with modiﬁed train and test splits for the text-based                              task, it may provide some linguistic cues (e.g.,
                        models, where the same set of natural language                                     about entity genders) that the models exploit. In
                        paraphrases were used to construct the narratives in                               contrast, the BERT-based models do not beneﬁt
                        both the train and test splits (see Appendix 1.3 for                               from the inclusion of this extra content, which
                        details). In this simpliﬁed setting, the text-based                                is perhaps due to the fact that they are already
                        modelsmuststilllearntoreasonaboutheld-outlog-                                      built upon a strong language model (e.g., that
                        ical patterns, but the difﬁculty of parsing the natural                            already adequately captures entity genders.)
                        language is essentially removed, as the same nat-
                        ural language paraphrases are used during testing                              2. The GAT model performs poorly when support-
                        and training. We found that the text-based models                                  ing facts are added but has no performance drop
                        were competitive with the GAT model in this sim-                                   when disconnected facts are added. This sug-
                        pliﬁed setting (Appendix Figure 1), conﬁrming that                                 gests that the GAT model is sensitive to changes
                        the poor performance of the text-based models on                                   that introduce cycles in the underlying graph
                        the main task is driven by the difﬁculty of parsing                                structure but is robust to the addition of noise
                        the unseen natural language narratives.                                            that is disconnected from the target entities.
                        Q3: Robust Reasoning                                                           Moreover, when we trained on noisy examples, we
                        Finally, we use CLUTRR to systematically eval-                                 found that only the GAT model was able to consis-
                        uate how various baseline neural language under-                               tently improve its performance (Table 2). Again,
                        standing systems cope with noise (Q3). In all the                              this highlights the performance gap between the
                        experiments we provide a combination of k = 2                                  unstructured text-based models and the GAT.
                        and k = 3 length clauses in training and testing,
                        with noise facts being added to the train and/or test                          5     Conclusion
                        set depending on the setting (Table 2). We use the
                        different types of noise facts deﬁned in Section 3.5.
                            Overall, we ﬁnd that the GAT baseline outper-                              In this paper we introduced the CLUTRR bench-
                        forms the unstructured text-based models across                                mark suite to test the systematic generalization
                        most testing scenarios (Table 2), which showcases                              and inductive reasoning capababilities of NLU sys-
                        the beneﬁt of a structured feature space for robust                            tems. We demonstrated the diagnostic capabilities
                        reasoning. When training on clean data and testing                             of CLUTRRandfoundthatexisting NLUsystems
                        on noisy data, we observe two interesting trends                               exhibit relatively poor robustness and systematic
                        that highlight the beneﬁts and shortcomings of the                             generalization capabilities—especially when com-
                        various model classes:                                                         pared to a graph neural network that works directly
                        1. All the text-based models excluding BERT ac-                                with symbolic input. These results highlight the
                             tually perform better when testing on examples                            gap that remains between machine reasoning mod-
                             that have supporting or irrelevant facts added.                           els that work with unstructured text and models that
                             This suggests that these models actually beneﬁt                           are given access to more structured input. We hope
                             from having more content related to the enti-                             that by using this benchmark suite, progress can
                             ties in the story. Even though this content is                            be made in building more compositional, modular,
                             not strictly useful or needed for the reasoning                           and robust NLU systems.
                                                                                                4513
