## 2019 — “Solver-in-the-loop” becomes a layer: optimization as computation (not just prediction)

* **Deep Equilibrium Models (DEQ)** (Bai et al., 2019)
  **Missing capability:** effectively infinite-depth / iterative refinement with constant memory (vs fixed feedforward stacks)
  **Mechanism:** define the network by a **fixed point** and compute it via root-finding; train via **implicit differentiation** ([Implicit Layers Tutorial][1])

* **Differentiable Convex Optimization Layers** (Agrawal, Amos, Barratt, Boyd, Diamond, Kolter, NeurIPS 2019)
  **Missing capability:** exact constraint satisfaction / optimization inside neural pipelines
  **Mechanism:** embed a **disciplined convex program solver** as a differentiable layer (forward solves; backward differentiates through the solve) ([arXiv][2])

---

## 2020 — Iterative numerical solvers as part of the learning loop (literal solver-in-the-loop)

* **Solver-in-the-Loop: Learning from Differentiable Physics to Interact with Iterative PDE Solvers** (Um et al., NeurIPS 2020)
  **Missing capability:** correcting / steering **iterative solvers** with learned components rather than replacing them
  **Mechanism:** learn correction functions that plug into and improve **iterative PDE solvers** (“solver-in-the-loop” compute) ([NeurIPS Proceedings][3])

---

## 2021 — Making implicit computation stable and usable at scale (DEQ tooling for real models)

* **Stabilizing Equilibrium Models by Jacobian Regularization** (Bai, Kolter, Koltun, 2021)
  **Missing capability:** stable, reliable fixed-point inference/training (DEQs can be brittle/unstable)
  **Mechanism:** **Jacobian regularization** of the fixed-point update to stabilize convergence in forward + backward passes ([arXiv][4])

---

## 2022 — Test-time “think more” loops and implicit training tricks (self-improvement + implicit differentiation)

### Search/iteration at inference time (reasoning loops)

* **Self-Consistency Improves Chain-of-Thought Reasoning** (Wang et al., 2022; ICLR 2023)
  **Missing capability:** robustness vs a single greedy reasoning path
  **Mechanism:** **sample many reasoning traces** and choose the most consistent answer (inference-time ensembling over thoughts) ([arXiv][5])

* **STaR: Self-Taught Reasoner (Bootstrapping Reasoning With Reasoning)** (Zelikman et al., 2022)
  **Missing capability:** reliable reasoning skill without massive curated rationales
  **Mechanism:** **iterative loop**: generate rationales → repair/regen on failures → finetune → repeat (a train/test compute loop that explicitly iterates) ([arXiv][6])

### Implicit / solver-based training machinery

* **Jacobian-Free Backpropagation for Implicit Networks (JFB)** (Fung et al., 2022)
  **Missing capability:** efficient training of implicit/fixed-point models (implicit differentiation can be heavy)
  **Mechanism:** **Jacobian-free** methods for backprop through implicit layers, reducing memory/compute pain ([Emory Mathematics][7])

* **Training Iterative Refinement Algorithms with Implicit Differentiation** (Chang et al., NeurIPS 2022)
  **Missing capability:** training models whose inference is itself an iterative refinement procedure (fixed-point style)
  **Mechanism:** cast iterative refinement as a fixed-point procedure and train using **implicit differentiation** ([NeurIPS Proceedings][8])

---

## 2023 — Planning/search becomes the default “missing capability” claim (tree search, reflection, and world models)

### Explicit search / planning over intermediate states

* **ReAct: Synergizing Reasoning and Acting in Language Models** (Yao et al., 2022/2023)
  **Missing capability:** pure text-only reasoning that can’t gather info / ground itself; acting and reasoning studied separately
  **Mechanism:** interleave **reasoning traces + actions** (tool/environment calls) as the inference procedure ([arXiv][9])

* **Tree of Thoughts (ToT): Deliberate Problem Solving with Large Language Models** (Yao et al., 2023)
  **Missing capability:** exploration, lookahead, backtracking beyond left-to-right decoding
  **Mechanism:** do **tree search** over “thought” chunks with self-evaluation and backtracking ([arXiv][10])

* **Reasoning with Language Model is Planning with World Model (RAP)** (Hao et al., 2023)
  **Missing capability:** deliberate planning (simulate future states/outcomes; explore alternatives)
  **Mechanism:** repurpose the LLM as **agent + world model** and run **MCTS-style planning** over reasoning trajectories ([arXiv][11])

### Iteration / self-improvement at test time

* **Self-Refine: Iterative Refinement with Self-Feedback** (Madaan et al., 2023)
  **Missing capability:** one-shot generations are often suboptimal (no revision loop)
  **Mechanism:** explicit **FEEDBACK → REFINE → FEEDBACK** loop using the model itself (no extra training required) ([arXiv][12])

* **Reflexion: Language Agents with Verbal Reinforcement Learning** (Shinn et al., 2023)
  **Missing capability:** agents don’t learn from trial-and-error without costly weight updates
  **Mechanism:** store and reuse **episodic “reflections”** as memory to improve future attempts (test-time learning loop without gradient updates) ([arXiv][13])

* **Plan-and-Solve Prompting** (Wang et al., 2023)
  **Missing capability:** zero-shot CoT makes missing-step / semantic errors; no explicit plan phase
  **Mechanism:** two-stage inference: **plan (decompose)** then **solve (execute)** ([arXiv][14])

### Generalizing “search over thoughts” beyond trees

* **Graph of Thoughts (GoT)** (Besta et al., 2023; AAAI 2024)
  **Missing capability:** linear/tree-only reasoning structures limit reuse/merging of partial results
  **Mechanism:** model intermediate “thoughts” as an **arbitrary graph** with dependency edges; run graph-structured inference ([arXiv][15])

### Equilibrium / implicit computation appears in generative modeling

* **One-Step Diffusion Distillation via Deep Equilibrium Models (Generative Equilibrium Transformer, GET)** (Geng et al., NeurIPS 2023)
  **Missing capability:** many-step diffusion inference is expensive; want “solve to equilibrium” behavior
  **Mechanism:** introduce an **equilibrium (fixed-point) transformer layer** inside the generative pipeline ([NeurIPS Papers][16])

* **Language Agent Tree Search (LATS)** (Zhou et al., 2023; ICML 2024)
  **Missing capability:** “act-only” agents are myopic; need principled planning + exploration
  **Mechanism:** integrate **MCTS** with LM reasoning/acting plus LM-powered value/reflection signals ([arXiv][17])

---

## 2024 — Test-time training/adaptation becomes mainstream + new fixed-point/implicit architectures

### Gradient-based test-time adaptation (compute via updating)

* **Test-Time Training on Nearest Neighbors for Large Language Models** (Hardt & Sun, ICLR 2024)
  **Missing capability:** static inference can’t adapt to distribution shift / specialized domains without retraining
  **Mechanism:** retrieve nearest-neighbor text for the test input and do **small gradient updates at test time** (“dynamic evaluation” style) ([arXiv][18])

### Implicit / equilibrium dynamics injected into models

* **Fixed Point Diffusion Models (FPDM)** (2024)
  **Missing capability:** fixed-depth denoisers give fixed compute per step; want variable compute tied to solution accuracy
  **Mechanism:** integrate an **implicit fixed-point solving layer** into diffusion denoising to allow **variable computation** ([arXiv][19])

* **Implicit Factorized Transformer (IFactFormer)** (Yang et al., 2024)
  **Missing capability:** stable very-deep transformer computation for long-horizon dynamics (e.g., PDE/turbulence)
  **Mechanism:** **implicit iteration** over factorized attention (compute is “solve an implicit system,” not “run N layers”) ([ScienceDirect][20])

---

## 2025 — “Test-time compute scaling” as a paradigm + equilibrium-style token refinement

### Allocating compute strategically at inference time

* **Revisiting the Test-Time Scaling of o1-like Models** (Zeng et al., ACL 2025)
  **Missing capability:** one-pass inference caps reasoning quality; need systematic test-time compute scaling
  **Mechanism:** evaluate/organize **parallel vs sequential** test-time compute scaling strategies (sampling/reranking/longer reasoning) ([ACL Anthology][21])

* **Efficiently Allocating Test-Time Compute for LLM Agents** (2025)
  **Missing capability:** always planning is expensive; never planning fails on long-horizon tasks
  **Mechanism:** a framework for **dynamic planning decisions**—decide *when* to plan to spend compute where it matters ([arXiv][22])

* **Test-Time Learning for Large Language Models (TLM / TTL)** (2025)
  **Missing capability:** LLMs struggle under domain shift; static inference can’t adapt
  **Mechanism:** **test-time learning** using unlabeled test data (explicitly making adaptation part of inference) ([OpenReview][23])

### Equilibrium / implicit computation as a deliberate “closed-loop” reasoning mechanism

* **Autoregressive Modeling as Iterative Latent Equilibrium (Equilibrium Transformers, EqT)** (Jafari et al., 2025)
  **Missing capability:** “open-loop” next-token prediction can accumulate inconsistencies; needs iterative self-consistency before committing
  **Mechanism:** per token, solve a **latent energy minimization** via iterative refinement until reaching an equilibrium ([arXiv][24])

### Next-gen differentiable optimization layers (making solver-in-the-loop cheaper)

* **A Fully First-Order Layer for Differentiable Optimization** (Zhao et al., 2025)
  **Missing capability:** implicit differentiation for optimization layers can be compute/memory intensive
  **Mechanism:** compute gradients for optimization layers using **first-order information** to reduce overhead ([arXiv][25])

---

If you want to push this even harder while keeping the exact style: tell me whether to **include “search-only inference procedures”** that are widely used but sometimes published as *frameworks* rather than *papers* (e.g., verifier-guided reranking / best-of-n / rejection sampling families), and I’ll fold in the most “paper-anchored” versions from 2021–2025.

[1]: https://implicit-layers-tutorial.org/deep_equilibrium_models/?utm_source=chatgpt.com "Chapter 4: Deep Equilibrium Models"
[2]: https://arxiv.org/abs/1910.12430?utm_source=chatgpt.com "Differentiable Convex Optimization Layers"
[3]: https://proceedings.neurips.cc/paper_files/paper/2020/hash/43e4e6a6f341e00671e123714de019a8-Abstract.html?utm_source=chatgpt.com "Solver-in-the-Loop: Learning from Differentiable Physics to ..."
[4]: https://arxiv.org/abs/2106.14342?utm_source=chatgpt.com "Stabilizing Equilibrium Models by Jacobian Regularization"
[5]: https://arxiv.org/abs/2203.11171?utm_source=chatgpt.com "Self-Consistency Improves Chain of Thought Reasoning in Language Models"
[6]: https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com "[2203.14465] STaR: Bootstrapping Reasoning With ..."
[7]: https://www.math.emory.edu/site/cmds-reuret/projects/2022-implicit/JFB.pdf?utm_source=chatgpt.com "JFB: Jacobian-Free Backpropagation for Implicit Networks"
[8]: https://proceedings.neurips.cc/paper_files/paper/2022/file/d301e2878a7ebadf1a95029e904fc7d0-Paper-Conference.pdf?utm_source=chatgpt.com "Training Iterative Refinement Algorithms with Implicit ..."
[9]: https://arxiv.org/abs/2210.03629?utm_source=chatgpt.com "ReAct: Synergizing Reasoning and Acting in Language Models"
[10]: https://arxiv.org/abs/2305.10601?utm_source=chatgpt.com "Tree of Thoughts: Deliberate Problem Solving with Large Language Models"
[11]: https://arxiv.org/abs/2305.14992?utm_source=chatgpt.com "Reasoning with Language Model is Planning with World ..."
[12]: https://arxiv.org/abs/2303.17651?utm_source=chatgpt.com "Self-Refine: Iterative Refinement with Self-Feedback"
[13]: https://arxiv.org/abs/2303.11366?utm_source=chatgpt.com "Reflexion: Language Agents with Verbal Reinforcement Learning"
[14]: https://arxiv.org/abs/2305.04091?utm_source=chatgpt.com "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models"
[15]: https://arxiv.org/abs/2308.09687?utm_source=chatgpt.com "Graph of Thoughts: Solving Elaborate Problems with Large ..."
[16]: https://papers.neurips.cc/paper_files/paper/2023/file/82f05a105c928c10706213952bf0c8b7-Paper-Conference.pdf?utm_source=chatgpt.com "One-Step Diffusion Distillation via Deep Equilibrium Models"
[17]: https://arxiv.org/abs/2310.04406?utm_source=chatgpt.com "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models"
[18]: https://arxiv.org/abs/2305.18466?utm_source=chatgpt.com "Test-Time Training on Nearest Neighbors for Large ..."
[19]: https://arxiv.org/html/2401.08741v1?utm_source=chatgpt.com "Fixed Point Diffusion Models"
[20]: https://www.sciencedirect.com/science/article/pii/S2095034924000382?utm_source=chatgpt.com "An implicit factorized transformer with applications to fast ..."
[21]: https://aclanthology.org/2025.acl-long.232.pdf?utm_source=chatgpt.com "Revisiting the Test-Time Scaling of o1-like Models"
[22]: https://arxiv.org/html/2509.03581v1?utm_source=chatgpt.com "Efficiently Allocating Test-Time Compute for LLM Agents"
[23]: https://openreview.net/forum?id=iCYbIaGKSR&noteId=ScPdA3KZCL&utm_source=chatgpt.com "Test-Time Learning for Large Language Models"
[24]: https://arxiv.org/html/2511.21882v1?utm_source=chatgpt.com "Autoregressive Modeling as Iterative Latent Equilibrium"
[25]: https://arxiv.org/pdf/2512.02494?utm_source=chatgpt.com "A Fully First-Order Layer for Differentiable Optimization"
