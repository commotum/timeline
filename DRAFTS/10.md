## 2024 — Aggressive sweep: 3D point segmentation (semantic/instance/panoptic + open-vocab)

* **OneFormer3D: One Transformer for Unified Point Cloud Segmentation** (Kolodiazhnyi et al., CVPR 2024)
  **Improves On:** task-specific 3D segmentation models (semantic vs instance vs panoptic)
  **Adaptation:** a single **query-driven transformer** that unifies 3D segmentation tasks in one architecture (set-style decoding over point clouds) ([CVF Open Access][1])

* **Spherical Mask: Coarse-to-Fine 3D Point Cloud Instance Segmentation with Spherical Representation** (Shin et al., CVPR 2024)
  **Improves On:** coarse-to-fine pipelines whose 3D proposals (e.g., AABB) propagate errors; also compared against stronger transformer-era instance segmentation baselines
  **Adaptation:** a **spherical (radial) 3D instance representation** + pipeline that “lifts” coarse detection into improved 3D mask assembly (representation/decoding is the centerpiece) ([CVF Open Access][2])

* **Open3DIS: Open-Vocabulary 3D Instance Segmentation with 2D Mask Guidance** (Nguyen et al., CVPR 2024)
  **Improves On:** closed-vocabulary 3D instance segmenters; limited ability to use 2D foundation signals in 3D
  **Adaptation:** fuse multi-frame **2D mask guidance into 3D** and perform open-vocabulary 3D instance segmentation (the 2D→3D mapping + 3D transformer reasoning is central) ([CVF Open Access][3])

* **ASGFormer: Point cloud semantic segmentation with adaptive spatial graph transformer** (Han et al., 2024)
  **Improves On:** point segmentation methods that struggle on complex scenes / adherent objects
  **Adaptation:** explicit **graph + transformer** hybrid for point clouds, using graph structure to support global correlation modeling ([ScienceDirect][4])

* **PointRegion: Transformer based 3D tooth segmentation via point cloud processing** (Wu et al., 2024)
  **Improves On:** transformer point methods that only aggregate locally and can’t efficiently model global context due to memory cost
  **Adaptation:** a transformer segmentation design to process **entire dental point clouds** at lower cost (3D medical point-domain adaptation) ([PubMed][5])

* **SegPoint: Segment Any Point Cloud via Large Language …** (He et al., ECCV 2024)
  **Improves On:** “basic” 3D segmentation transformers that don’t naturally handle language-driven 3D segmentation tasks
  **Adaptation:** unify multiple 3D segmentation modes (semantic / referring / instruction / open-vocab) by coupling a point encoder with an LLM-style reasoning + segmentation token path (a 3D+language adaptation) 

---

## 2024 — Aggressive sweep: LiDAR / outdoor 3D detection (attention-first voxel/point backbones)

* **Point Transformer V3: Simpler, Faster, Stronger** (Wu et al., CVPR 2024)
  **Improves On:** earlier point transformers with costly neighbor search / scaling friction
  **Adaptation:** serialize/organize point clouds for efficient attention-driven processing, aiming to make point-transformer backbones truly scalable for large 3D scenes ([CVF Open Access][6])

* **ScatterFormer: Efficient Voxel Transformer with Scattered Linear Attention** (He et al., arXiv v2 Jul 2024)
  **Improves On:** window-based voxel transformers that require heavy sorting/padding for variable-length voxel groups
  **Adaptation:** treat voxels across windows as one sequence via **scattered linear attention** + cross-window interaction—an efficiency-first transformer backbone for large-scale LiDAR detection 

* **DeLiVoTr: Deep and Light-weight Voxel Transformer for 3D Object Detection** (Erabati et al., 2024)
  **Improves On:** voxel pipelines that downsample too aggressively and miss small objects in large-scale driving scenes
  **Adaptation:** a **voxel transformer** backbone designed to keep feature-map scale while expanding effective receptive field for LiDAR detection ([ScienceDirect][7])

* **Voxel self-attention and center-point for 3D object detector** (Fan et al., 2024)
  **Improves On:** LiDAR detectors that don’t model scene context deeply in voxel space
  **Adaptation:** apply **self-attention on voxel features** in an anchor-free LiDAR detection design (voxel-attention as the primary adaptation) ([Cell][8])

---

## 2025 — Aggressive sweep: 3D point segmentation (instance/panoptic + new interfaces)

* **Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation** (Lu et al., CVPR 2025)
  **Improves On:** transformer instance segmenters that mainly model “scene ↔ query” but underuse richer relations
  **Adaptation:** strengthen relation modeling within transformer-style instance segmentation pipelines for 3D scenes ([CVF Open Access][9])

* **CamPoint: Boosting Point Cloud Segmentation with Virtual Camera** (Zhang et al., CVPR 2025)
  **Improves On:** point segmentation that struggles to find semantically relevant neighbors and to inject high-level global information per point
  **Adaptation:** introduce **virtual-camera visibility tokens/features** and global interaction machinery to restructure how point neighborhoods + global context are formed (representation/interface change is central) ([CVPR][10])

* **PMFormer: Point mask transformer for outdoor point cloud semantic segmentation** (Li et al., 2025)
  **Improves On:** outdoor point segmentation pipelines that don’t translate cleanly into mask/query-style transformer formulations
  **Adaptation:** cast outdoor point semantic segmentation into a **mask transformer** style pipeline (query/mask prediction framing in 3D) ([SciOpen][11])

---

## 2025 — Aggressive sweep: LiDAR / outdoor 3D detection (new voxel/cluster transformer backbones)

* **BWFormer: Building Wireframe Reconstruction from Airborne LiDAR Point Cloud with Transformer** (Liu et al., CVPR 2025)
  **Improves On:** non-transformer pipelines for airborne LiDAR building wireframe reconstruction
  **Adaptation:** a transformer pipeline that projects LiDAR to a 2.5D height map for 2D corner detection, then **lifts to 3D** with transformer-based corner/edge reasoning (explicit 2D→3D restructuring) ([CVPR][12])

* **SparseVoxFormer: Sparse Voxel-based Transformer for Multi-modal 3D Object Detection** (arXiv Mar 2025)
  **Improves On:** BEV-centric extraction and dense voxel inefficiency
  **Adaptation:** operate directly on **sparse 3D voxel features** as transformer inputs for detection (voxel-domain transformerization is central) ([arXiv][13])

* **RetentiveBEV: BEV transformer for visual 3D object detection …** (2025)
  **Improves On:** BEV transformer approaches needing better spatiotemporal feature retention/learning
  **Adaptation:** a transformer that learns **spatiotemporal BEV features** for 3D detection (camera→BEV→3D reasoning as the adaptation) ([SAGE Journals][14])

* **PV-DT3D: Point-voxel dual transformer for LiDAR 3D object detection** (Tong et al., 2025)
  **Improves On:** single-representation pipelines that miss complementary point vs voxel cues
  **Adaptation:** a dual **point-wise + channel-wise** transformer encoder–decoder that fuses point and voxel abstractions for proposal refinement ([Springer][15])

* **DCT: Dynamic Clustering Transformer for LiDAR-Based 3D …** (Cui et al., 2025)
  **Improves On:** feature extraction that doesn’t exploit LiDAR’s “non-overlapping object” structure effectively
  **Adaptation:** clustering-driven point cloud backbone that incorporates transformer attention around **dynamic clusters** ([ScienceDirect][16])

---

## 2025 — Aggressive sweep: neural rendering / view synthesis (transformers as the 3D generalization engine)

* **LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias** (Jin et al., ICLR 2025)
  **Improves On:** NeRF / 3DGS-style methods requiring explicit 3D structure or strong geometric inductive bias
  **Adaptation:** a **transformer-based** feed-forward NVS model that replaces explicit 3D structures with learned token-based scene representations (encoder–decoder and decoder-only variants) ([ICLR Proceedings][17])

* **Scaling Transformer-Based Novel View Synthesis with Models Token Disentanglement and Synthetic Data** (Nair et al., ICCV 2025)
  **Improves On:** transformer NVS constrained by limited real scene diversity and entangled token features
  **Adaptation:** scale transformer NVS with synthetic data + **token disentanglement** inside the transformer to improve reconstruction quality/generalization ([CVF Open Access][18])

* **PanSt3R: Multi-view Consistent Panoptic Segmentation** (Züst et al., ICCV 2025)
  **Improves On:** 2D panoptic in multi-view/3D settings and test-time-optimization-heavy pipelines
  **Adaptation:** a unified transformer-style method that jointly predicts **3D geometry + multi-view panoptic segmentation** in a single forward pass (multi-view → 3D adaptation is the core) ([CVF Open Access][19])

* **DT-NVS: Diffusion Transformers for Novel View Synthesis** (2025) — **borderline (diffusion-first, but transformer is the scene-to-radiance-field engine)**
  **Improves On:** diffusion NVS approaches limited to narrow scene assumptions
  **Adaptation:** transformer backbone predicts a radiance field for NVS from minimal inputs ([arXiv][20])

---

If you want the *next* aggressive step (still keeping this exact format): I can do a targeted add-on pass for **2024–2025 3D panoptic/instance segmentation transformer families** (Mask3D/SPFormer/MAFT lines and their 2024–2025 descendants) and **driving-centric BEV transformer variants** that are clearly “domain adaptation first,” not “minor incremental training tweaks.”

[1]: https://openaccess.thecvf.com/content/CVPR2024/papers/Kolodiazhnyi_OneFormer3D_One_Transformer_for_Unified_Point_Cloud_Segmentation_CVPR_2024_paper.pdf "One Transformer for Unified Point Cloud Segmentation"
[2]: https://openaccess.thecvf.com/content/CVPR2024/papers/Shin_Spherical_Mask_Coarse-to-Fine_3D_Point_Cloud_Instance_Segmentation_with_Spherical_CVPR_2024_paper.pdf "Spherical Mask: Coarse-to-Fine 3D Point Cloud Instance ..."
[3]: https://openaccess.thecvf.com/content/CVPR2024/papers/Nguyen_Open3DIS_Open-Vocabulary_3D_Instance_Segmentation_with_2D_Mask_Guidance_CVPR_2024_paper.pdf "Open3DIS: Open-Vocabulary 3D Instance Segmentation with ..."
[4]: https://www.sciencedirect.com/science/article/pii/S156984322400459X "Point cloud semantic segmentation with adaptive spatial ..."
[5]: https://pubmed.ncbi.nlm.nih.gov/39557955/ "Transformer based 3D tooth segmentation via point cloud ..."
[6]: https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_Point_Transformer_V3_Simpler_Faster_Stronger_CVPR_2024_paper.pdf "Point Transformer V3: Simpler Faster Stronger"
[7]: https://www.sciencedirect.com/science/article/pii/S2667305324000371 "DeLiVoTr: Deep and light-weight voxel transformer for 3D ..."
[8]: https://www.cell.com/iscience/fulltext/S2589-0042%2824%2901984-9 "Voxel self-attention and center-point for 3D object detector"
[9]: https://openaccess.thecvf.com/content/CVPR2025/html/Lu_Relation3D__Enhancing_Relation_Modeling_for_Point_Cloud_Instance_Segmentation_CVPR_2025_paper.html "CVPR 2025 Open Access Repository"
[10]: https://cvpr.thecvf.com/virtual/2025/poster/34611 "CVPR Poster CamPoint: Boosting Point Cloud Segmentation with Virtual Camera"
[11]: https://www.sciopen.com/article/10.26599/CVM.2025.9450388 "Point mask transformer for outdoor point cloud semantic ..."
[12]: https://cvpr.thecvf.com/virtual/2025/poster/32868 "CVPR Poster BWFormer: Building Wireframe Reconstruction from Airborne LiDAR Point Cloud with Transformer"
[13]: https://arxiv.org/html/2503.08092v1 "Sparse Voxel-based Transformer for Multi-modal 3D Object ..."
[14]: https://journals.sagepub.com/doi/10.1177/01423312241308367 "BEV transformer for visual 3D object detection applied with ..."
[15]: https://link.springer.com/article/10.1007/s11801-025-3134-9 "Point-voxel dual transformer for LiDAR 3D object detection | Optoelectronics Letters"
[16]: https://www.sciencedirect.com/science/article/abs/pii/S0031320325011069 "Dynamic Clustering Transformer for LiDAR-Based 3D ..."
[17]: https://proceedings.iclr.cc/paper_files/paper/2025/hash/9676c5283df26cabca412ca66b164a7d-Abstract-Conference.html "LVSM: A Large View Synthesis Model with Minimal 3D ..."
[18]: https://openaccess.thecvf.com/content/ICCV2025/papers/Nair_Scaling_Transformer-Based_Novel_View_Synthesis_with_Models_Token_Disentanglement_and_ICCV_2025_paper.pdf "Scaling Transformer-Based Novel View Synthesis with Models Token Disentanglement and Synthetic Data"
[19]: https://openaccess.thecvf.com/content/ICCV2025/papers/Zust_PanSt3R_Multi-view_Consistent_Panoptic_Segmentation_ICCV_2025_paper.pdf "PanSt3R: Multi-view Consistent Panoptic Segmentation"
[20]: https://arxiv.org/html/2511.08823v1 "DT-NVS: Diffusion Transformers for Novel View Synthesis"
