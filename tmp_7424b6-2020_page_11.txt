               Figure 3.1: Smooth scaling of performance with compute. Performance (measured in terms of cross-entropy
               validation loss) follows a power-law trend with the amount of compute used for training. The power-law behavior
                               +
               observed in [KMH 20] continues for an additional two orders of magnitude with only small deviations from the
               predicted curve. For this ﬁgure, we exclude embedding parameters from compute and parameter counts.
                                                    Setting          PTB
                                                    SOTA(Zero-Shot)  35.8a
                                                    GPT-3Zero-Shot   20.5
               Table 3.1: Zero-shot results on PTB language modeling dataset. Many other common language modeling datasets
               are omitted because they are derived from Wikipedia or other sources which are included in GPT-3’s training data.
               a[RWC+19]
               3.1  LanguageModeling,Cloze,andCompletionTasks
               In this section we test GPT-3’s performance on the traditional task of language modeling, as well as related tasks
               that involve predicting a single word of interest, completing a sentence or paragraph, or choosing between possible
               completions of a piece of text.
               3.1.1 LanguageModeling
                                                                        +                         +
               Wecalculate zero-shot perplexity on the Penn Tree Bank (PTB) [MKM 94] dataset measured in [RWC 19]. We omit
               the 4 Wikipedia-related tasks in that work because they are entirely contained in our training data, and we also omit the
               one-billion word benchmark due to a high fraction of the dataset being contained in our training set. PTB escapes these
               issues due to predating the modern internet. Our largest model sets a new SOTA on PTB by a substantial margin of 15
               points, achieving a perplexity of 20.50. Note that since PTB is a traditional language modeling dataset it does not have
               a clear separation of examples to deﬁne one-shot or few-shot evaluation around, so we measure only zero-shot.
               3.1.2 LAMBADA
               The LAMBADAdataset [PKL+16] tests the modeling of long-range dependencies in text – the model is asked to
               predict the last word of sentences which require reading a paragraph of context. It has recently been suggested that the
                                                                                                  +
               continued scaling of language models is yielding diminishing returns on this difﬁcult benchmark. [BHT 20] reﬂect on
                                                                                                          +
               the small 1.5% improvement achieved by a doubling of model size between two recent state of the art results ([SPP 19]
                                                             11
