                           3   Experiments
                           Wenowprovide a summary and discussion of our experiments with the different types of PDE
                           interactions for a selection of physical models. Full details of boundary conditions, parameters, and
                           discretizations of all ﬁve PDE scenarios are given in App. B.
                           3.1  ModelEquationsandDataGeneration
                           Weinvestigate a diverse set of constrained advection-diffusion models of which the general form is
                                             ∂u/∂t = −u·∇u+ν∇·∇u+g subjectto Mu=0,                                      (2)
                           where u is the velocity, ν denotes the diffusion coefﬁcient (i.e., viscosity), and g denotes external
                           forces. The constraint matrix M contains an additional set of equality constraints imposed on u.
                           In total, we target four scenarios: pure non-linear advection-diffusion (Burger’s equation), two-
                           dimensional Navier-Stokes ﬂow, Navier-Stokes coupled with a second advection-diffusion equation
                           for a buoyancy-driven ﬂow, and a 3D Navier-Stokes case. Also, we discuss CG solvers in the context
                           of differentiable operators below.
                           For each of the ﬁve scenarios, we implement the non-interacting evaluation (NON) by pre-computing
                           a large-scale data set that captures a representative and non-trivial space of solutions in S. The
                           reference solutions from R are typically computed with the same numerical method using a ﬁner
                           discretization (4x in our setting, with effective resolutions of 1282 and higher). The PDEs are
                           parametrized such that the change of discretization leads to substantial differences when integrated
                           over time. For several of the 2D scenarios, we additionally train models with data sets of trajectories
                           that have been corrected with other pre-computated correction functions. For these PRE variants, we
                           use a time-regularized, constrained least-squares corrector [21] to obtain corrected phase state points.
                           For the SOL variants, we employ a differentiable PDE-solver that runs mini-batches of simulations
                           and provides gradients for all operations of the solving process within the deep learning framework.
                           This allows gradients to freely propagate through the PDE-solver and coupled neural networks via
                           automatic differentiation. For n > 1, i.e., PDE-based look-ahead at training time, the gradients are
                           back-propagated through the solver n − 1 times, and the difference w.r.t. a pre-computed reference
                           solution is evaluated for all intermediate results.
                           3.2  Training Procedure
                           Theneural network component F(s|θ) of the correction function is realized with a fully convolu-
                           tional architecture. As our focus lies on the methodology for incorporating PDE models into the
                           training, the architectures are intentionally kept simple. However, they were chosen to yield high
                           accuracyacrossallvariants. Ournetworkstypicallyconsistof10convolutionallayerswith16features
                                                                                                   d      d
                           each, interspresed with ReLU activation functions using kernel sizes of 3 and 5 . The networks
                           parameters θ are optimized with a ﬁxed number of steps with an ADAM optimizer [30] and a learning
                           rate of 10−4. For validation, we use data sets generated from the same parameter distribution as the
                           training sets. All results presented in the following use test data sets whose parameter distributions
                           differ from the ones of the training data set.
                           Wequantify the performance of the trained models by computing the mean absolute error between a
                           computed solution and the corresponding projected reference for n consecutive steps of a simulation.
                           Wereport absolute error values for different models in comparison to an unmodiﬁed source trajectory
                           from S. Additionally, relative improvements are given w.r.t. the difference between unmodiﬁed
                           source and reference solutions. An improvement by 100% would mean that the projected reference is
                           reproduced perfectly, while negative values indicate that the modiﬁed solution deviates more from
                           the reference than the original source trajectory.
                           4   Results
                           Our experiments show that learned correction functions can achieve substantial gains in accuracy
                           over a regular simulation. When training the correction functions with differentiable physics, this
                           additionally yields further improvements of more than 70% over supervised and pre-computed
                           approaches from previous work. A visual overview of the different tests is given in Fig. 3, and a
                           summaryofthefull evaluation from the appendix is provided in Fig. 4 and Table 1. In the appendix,
                           wealsoprovide error measurements w.r.t. physical quantities such as kinetic energy and frequency
                           content. The source code of our experiments and analysis will be published upon acceptance.
                                                                          5
