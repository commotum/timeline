          314        10.  INEQUALITIES  FOR ENTROPY,  COMPLEXITY  AND SIZE
             In general, linear inequality for complexities has the form
                                X>C(*7) ^ O(logAZ'), 
                                 i
          where the sum is taken over all non-empty subsets of {1,..., n}.  The coefficients А/ 
          may be positive,  negative,  or zeros;  we assume that all strings X{  have length at 
          most N, and the constant in О-notation does not depend on N (but may depend 
          on n and the inequality chosen).
             Which of these inequalities  are true?  More formally,  we are looking for the 
          tuples of coefficients A/ such that
                                 ^  XIC(xI) ^ clog N
                                  I
          for some c, every N, and all strings aq,..., xn of length at most N.
             This question is still wide open, and only some partial results are known.
             First of all,  this question is not specific to algorithmic information theory,  as 
          shown by A. Romashchenko who proved that such an inequality is true if and only 
          if the  inequality  for  Shannon  entropies  with the  same  coefficients  is  true,  where 
          strings X{ are replaced by random variables £/  (with arbitrary joint distribution),
                                    I
          where £/ is a random variable made from & with i € I (in other words, projection 
          of the random vector (£i,... ,£n) on /-coordinates).
             The implication in one direction is an easy consequence of the result  proven 
          in  Section  7.3:  Theorem  147  (p.  228)  says  that  entropy  is  an  expected value of 
          complexity and any linear inequality that  is true for complexities should be also 
          true for their expectations (with no error term, since the ratio 0(\ogN)/N tends 
          to 0 as N -» oo).
             More precisely, let &  be a random variable with values in some finite set X{. 
          Then the value of a random vector £ = (£i,..., £n) can be represented by a column 
         of height n.  To apply Theorem 147, consider N independent variables distributed 
          as £.  Together they form a random variable that we denote by ÇN.  Its values are 
         matrices having N columns and n rows.  Theorem 147 says that the expected value 
         of the complexity of this matrix is NH(£) + О (log N) (we spoke there about prefix 
         complexity and had A as a condition,  but with 0 (log7V)-precision this does not 
         matter).
             We can consider this matrix as a tuple of rows:  the zth row is a string of length 
         N over the alphabet Xi.  We can apply Theorem 147 not only to the entire matrix, 
         but also to selected rows indexed by i G /, where I is some subset of {1, 2,..., n}. 
         The expected complexity of this part of the matrix is NH(£i) + 0(logA/^).
             If the inequality
                                          s: O(logiV)
                                 I
         is  true  for all tuples x\,... ,xn,  it  can be applied to the rows of our matrix.  So, 
         taking the averages, we get
                               £A,JVtf(6)<0(logiV).
                                I
