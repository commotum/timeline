         352                11.  COMMON  INFORMATION
         theorem on the complexity of the pair implies  that  C{x' \ x)  æ  0 with  accuracy 
         0 (logC(x)).                                           □
            As a corollary we obtain a positive answer to the above question:  Replace the 
         given string by its shortest description x', and let x\  and X2 be two halves of x'.
            305 Verify that all the requirements are fulfilled.
            3Ö6 Assume that C(y\x) = n.  Show that there is an (intermediate) 2 such 
         that C(z |x) æ nj2 and C(y\z) æn/2 with accuracy 0(logC(x, y)).
           In these examples information bits behave as something material.  A similar 
         thing happens when we deal with information in a string and some part  of this 
         information.  Let us explain what we mean by this.
           Assume that some strings x and y are given such that C(y |x)  ~ 0  (“all the 
         information in y is a part of the information from x”).  Then there is an incom­
         pressible string x' that is equivalent to x, and some prefix y' of x' that is equivalent 
         to y.  (This implies that y' is an incompressible string of length about C{y).)  More 
         specifically, the following holds:
           Theorem  222.  For every two  strings x  and y  there  exist  strings x'  and y' 
         that are equivalent to x and y (respectively) with accuracy 0(C(y\x) -flog C(x,y)), 
         such that y'  is a prefix of x'  and both x'  and y'  are incompressible  ( with the same 
         accuracy).
           Proof.  Let y'  be a shortest  description of y.  Then y'  is  an incompressible 
         string of length C(y) and y' is equivalent to y.
           Let z' be a shortest description of x conditional to y.  Then z' is an incompress­
         ible string of length C{x\y).  Knowing y'  and z',  we can find y and then find x. 
         Therefore the complexity of the pair y' ,z' is at least C(x,y).  On the other hand, 
        the total length of strings y'  and z'  equals  C(y) + C(x\y)  « C(x,y).  Hence the 
        string x' = y'z' is incompressible.
           As we have seen,  C'(xlx')  æ 0.  It remains to show that  C{x'\x)  ~ 0.  Since 
         C'(xlx')  «  0,  we have  C(x,x')  «  C{x')  æ  C(x,y).  On the other hand,  we have 
         C(x,y) ~ C(x) with accuracy 0(C(y |x)).  Hence C(x,x') ~ C(x) and the Kolmo- 
        gorov-Levin theorem implies that C{x'\x) ~ 0.           □
           By this theorem we can think of every two strings x,y with C(y\x) « 0 as a 
        string consisting of C(x) almost material bits and its prefix of length C(y).
                 11.2.  Representing mutual information as a string
           Is there an analog of Theorem 222 for arbitrary two strings x, yl  Recall that 
         any two strings x,y can be characterized by their complexities C(x), C{y) and the 
        complexity C(x, y) of the pair.  These values determine both conditional complexi­
        ties (with logarithmic accuracy) and the mutual information
                          C(x\y) = C(x, y) -  C(y),
                          C(y |x) = C{x,y) -  C(x),
                          I(x.y) — C(x) + C(y) - C(x, y)
         (cf.  Figure 3 on p. 46).  We have seen that sometimes Figure 3 can be understood 
        almost literally—this happens when x and y are overlapping substrings of a random 
        string.  One can conjecture that this holds in the general case.
