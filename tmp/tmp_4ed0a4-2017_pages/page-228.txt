                                             7.1.  SHANNON  ENTROPY                              215
                 We have already seen this statement, see the lemmas used to prove Theorems 
             56 (p. 92) and 58 (p. 93).  In one direction, if c* is never a prefix of the other string 
             Cj,  then  the  corresponding  intervals  of lengths  2~Ui  are  disjoint  and  the sum  of 
             their lengths does not exceed 1.  (Using probabilistic language, a random string of 
             zeros and ones has prefix cb with probability 2“"1 ;  these к events are disjoint, so 
             the sum of probabilities does not exceed 1.)
                 Going in the opposite direction, we can use a simpler argument that was used 
             before (in the proof of Theorem 58).  Simplification is possible since we have only 
             a finite number (
                               к) of integers and they are given in advance.  We can simply place 
             the corresponding intervals of lengths 2~Uj  inside [0,1]  from left to right going in 
             decreasing order of length.  Then each interval is properly aligned and corresponds 
             to a binary string of length щ.  The lemma is proven.
                 Let us prove the theorem now.  Without loss of generality we may assume that 
             all Pi  are  strictly positive  (since  null  values  do  not  change  Shannon  entropy and 
             average code length).  Theorem 138(a) says that if щ are non-negative integers and 
             £*2-”'  <  1,  then Т,РгПг  ^  L  It  is true for any non-negative reals щ  (even if 
             they are not integers).  Indeed,  let  qi  be equal to  2“n\  In these coordinates the 
             statement reads as follows:  if qi > 0 and       ^ 1, then
                                       ^2 pi(-log qi) ^ ^2 Pi (“ log Pi)-
             This inequality is sometimes called the  Gibbs inequality.  To prove it,  we rewrite 
             the difference between right-hand side and left-hand side as
             (*)                                  J2Pi l0S
             Then we use the convexity argument:  the weighted sum of logarithms does not 
             exceed the logarithm of the weighted sum ^pilogUi ^ log(52iPiui)  (if all щ are 
             positive).  In our case we see that (*) does not exceed
                                                     log Ç22 qi)  ^ loS1 = 0.
             Item (a) is proven.
                 Let us mention also that the non-negative number
                                                  J2pi log — 
                                                    i       qi
             is called the Kullback-Leibler distance between two probability distributions pi and 
             qi (so we assume that ^2 qi = 1) or the Kullback-Leibler divergence; the latter name 
             is better since this “distance” is not symmetric.  The convexity of the logarithm (its 
             second derivative is negative everywhere)  guarantees that this distance is always 
             non-negative and equals zero only if Pi = qi for all i.
                 To prove item (b), consider the integers щ —  [— \og2 pi]  (where |"u] is a minimal 
             integer greater than or equal to u).  Then
                                                Pi  ^   q—rii  ^
                                                 2  < 2     ^ Pi-
             The  inequality  2~Tli  ^  pi  allows  us  to  use  the  lemma,  so  there  exist  codewords 
             of corresponding  lengths.  The  inequality pij2  <  2~Ui  implies  that  ni  exceeds 
             (—logPi) by less than 1,  and this remains true after averaging:  the average code 
             length {J2Pini) exceeds H = J2Pi(~ l°gP;) by less than 1.                            □
