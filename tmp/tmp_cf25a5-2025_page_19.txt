                                                  Test-Time Learning for Large Language Models
                                                      Table 7. Examples of DomainBench data.
                             Input: I wonder about the fossil of the Odonata. Can you help?
               Geography     Output: Certainly, the Odonata has a fossil of Odonata– Wolfe et al. 2016.
                             Input: Why do cassava propagated through stem cuttings mature faster compared to seed propagation?
               Agriculture   Output: This is because the stem cuttings already have a head start in development and can quickly
                             establish roots and start growing.
                             Instruction: If you are a doctor, please answer the medical questions based on the patient’s description.
               Medicine      Input: Doctor, I’m experiencing some strange symptoms. I’ve been acting hostile towards my family, and
                             I’m having problems with my movement. Also, I’ve noticed that I’ve been slurring my words lately.
                             Output: Based on what you’ve described, it sounds like you may be experiencing delirium, which is a
                             state of mental confusion that can cause changes in behavior, movement problems, and difficulty speaking
                             clearly. We’ll need to run some tests to determine the underlying cause, but it’s important that we act
                             quickly to manage your symptoms and prevent any complications.
                             Input: Assemble an outfit for a Halloween party.
               Finance       Output: For a Halloween party, assemble an outfit that will make you stand out! Start with a base layer
                             of black trousers and a white t-shirt. Then pair it with an eye-catching statement piece, such as a bright
                             orange blazer. For shoes, choose something with a spooky vibe, like a pair of lace-up boots with gothic
                             buckles. Accessorize with a deep red scarf and a black fedora. Finish off the look with a classic cane and a
                             golden pocket watch.
              Medicine: GenMedGPT-5k3 with a total of 5.45k samples is a medical dialogue dataset generated by ChatGPT, and is
              designed to emulate real-life conversations between patients and doctors. It provides rich, scenario-specific content that
              closely mirrors real medical scenarios. The dataset encompasses a wide range of medical queries from patients and responses
              or diagnoses from doctors. We randomly select 5k samples to create the Medicine dataset, aiming to assess the model’s
              performance in medical dialogue, particularly its adaptability to medical contexts and the quality of its responses.
              Finance: The Wealth-Alpaca Lora4 dataset is focused on the financial domain, consisting of 44.3k samples. It integrates
              general task data (Alpaca dataset), financial domain data (FiQA dataset), and custom task data generated using GPT-3.5.
              This dataset is extensively used for sentiment analysis, opinion mining, and QA tasks in financial texts, covering a variety of
              real-world applications in finance. We randomly select 5k samples to create the Finance dataset, designed to evaluate the
              model’s specialized performance in financial QA tasks.
              B.2. InstructionBench
              InstructionBench aims to assess the adaptability and performance of models across a diverse range of general instruction
              tasks, including, but not limited to, question answering (QA), text summarization, and classification. This benchmark
              integrates three carefully curated high-quality datasets: Alpaca-GPT4, Dolly, and InstructionWild, encompassing a variety
              of instruction tasks generated through both human and model-driven approaches. The evaluation is designed to be both
              comprehensive and rigorous. The distribution of dataset samples and an example table of dataset entries are provided in
              Figure 6 and Table 8.
                                   5
              Dolly: The Dolly-15k dataset, created by Databricks, consists of 15k high-quality, human-generated prompt-response
              pairs. It is specifically designed for the instruction fine-tuning of large language models. Unlike datasets generated through
              modeloutputs or copy-pasting, Dolly-15k maintains authenticity and high quality by relying solely on human input. The
              dataset encompasses common instruction fine-tuning tasks, including QA, summarization, and classification. We follow the
              official guide from Databricks6 and concatenate the sample fields into complete training samples. A subset of 5k samples is
              randomly selected to evaluate model performance.
              Alpaca-GPT4: The Alpaca-GPT47 dataset comprises 52k instruction-following samples generated using GPT-4. The
                 3https://huggingface.co/datasets/wangrongsheng/GenMedGPT-5k-en
                 4https://huggingface.co/datasets/gbharti/wealth-alpaca lora
                 5https://huggingface.co/datasets/databricks/databricks-dolly-15k
                 6https://github.com/databrickslabs/dolly/blob/master/training/consts.py
                 7https://huggingface.co/datasets/llamafactory/alpaca gpt4 en
                                                                       19
