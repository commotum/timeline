                                                                                              SegPoint      15
                               References
                                1. Achlioptas, P., Abdelreheem, A., Xia, F., Elhoseiny, M., Guibas, L.: Referit3d:
                                   Neural listeners for fine-grained 3d object identification in real-world scenes. In:
                                   ECCV(2020)
                                2. Alayrac, J.B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K.,
                                   Mensch, A., Millican, K., Reynolds, M., et al.: Flamingo: a visual language model
                                   for few-shot learning. In: NeurIPS (2022)
                                3. Armeni, I., Sener, O., Zamir, A.R., Jiang, H., Brilakis, I., Fischer, M., Savarese,
                                   S.: 3d semantic parsing of large-scale indoor spaces. In: CVPR (2016)
                                4. Chen, D.Z., Chang, A.X., Nießner, M.: Scanrefer: 3d object localization in rgb-d
                                   scans using natural language. In: ECCV (2020)
                                5. Chen, Z., Duan, Y., Wang, W., He, J., Lu, T., Dai, J., Qiao, Y.: Vision transformer
                                   adapter for dense predictions. In: ICLR (2023)
                                6. Choy, C., Gwak, J., Savarese, S.: 4d spatio-temporal convnets: Minkowski convo-
                                   lutional neural networks. In: CVPR (2019)
                                7. Dai, A., Chang, A.X., Savva, M., Halber, M., Funkhouser, T., Nießner, M.: Scannet:
                                   Richly-annotated 3d reconstructions of indoor scenes. In: CVPR (2017)
                                8. Ding, H., Liu, C., He, S., Jiang, X., Loy, C.C.: MeViS: A large-scale benchmark
                                   for video segmentation with motion expressions. In: ICCV (2023)
                                9. Ding, H., Liu, C., He, S., Jiang, X., Torr, P.H., Bai, S.: MOSE: A new dataset for
                                   video object segmentation in complex scenes. In: ICCV (2023)
                               10. Ding, H., Liu, C., Wang, S., Jiang, X.: Vision-language transformer and query
                                   generation for referring segmentation. In: ICCV (2021)
                               11. Ding, H., Liu, C., Wang, S., Jiang, X.: VLT: Vision-language transformer and query
                                   generation for referring segmentation. IEEE TPAMI (2023)
                               12. Ding, R., Yang, J., Xue, C., Zhang, W., Bai, S., Qi, X.: Pla: Language-driven
                                   open-vocabulary 3d scene understanding. In: CVPR (2023)
                               13. Ding, Z., Wang, J., Tu, Z.: Open-vocabulary panoptic segmentation with maskclip.
                                   In: ICLR (2023)
                               14. Girdhar, R., El-Nouby, A., Liu, Z., Singh, M., Alwala, K.V., Joulin, A., Misra, I.:
                                   Imagebind: One embedding space to bind them all. In: CVPR (2023)
                               15. Guo, Z., Zhang, R., Zhu, X., Tang, Y., Ma, X., Han, J., Chen, K., Gao,
                                   P., Li, X., Li, H., et al.: Point-bind & point-llm: Aligning point cloud with
                                   multi-modality for 3d understanding, generation, and instruction following. arXiv
                                   preprint arXiv:2309.00615 (2023)
                               16. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.
                                   In: CVPR (2016)
                               17. He, S., Ding, H.: Decoupling static and hierarchical motion perception for referring
                                   video segmentation. In: CVPR (2024)
                               18. He, S., Ding, H.: RefMask3D: Language-guided transformer for 3d referring seg-
                                   mentation. In: ACM MM (2024)
                               19. He, S., Jiang, X., Jiang, W., Ding, H.: Prototype adaption and projection for few-
                                   and zero-shot 3d point cloud semantic segmentation. IEEE TIP (2023)
                               20. Hong,Y.,Zhen,H.,Chen,P.,Zheng,S.,Du,Y.,Chen,Z.,Gan,C.:3d-llm:Injecting
                                   the 3d world into large language models. In: NeurIPS (2023)
                               21. Hu, E.J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., Chen,
                                   W.: Lora: Low-rank adaptation of large language models. In: ICLR (2022)
                               22. Huang, P.H., Lee, H.H., Chen, H.T., Liu, T.L.: Text-guided graph neural networks
                                   for referring 3d instance segmentation. In: AAAI (2021)
