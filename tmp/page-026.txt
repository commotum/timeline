                • The paper should provide the amount of compute required for each of the individual
                 experimental runs as well as estimate the total compute.
                • The paper should disclose whether the full research project required more compute
                 than the experiments reported in the paper (e.g., preliminary or failed experiments that
                 didn’t make it into the paper).
              9. Code Of Ethics
               Question: Does the research conducted in the paper conform, in every respect, with the
               NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
               Answer: [Yes]
               Justification: The paper respect with the NeurIPS Code of Ethics.
               Guidelines:
                • The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
                • If the authors answer No, they should explain the special circumstances that require a
                 deviation from the Code of Ethics.
                • The authors should make sure to preserve anonymity (e.g., if there is a special consid-
                 eration due to laws or regulations in their jurisdiction).
             10. Broader Impacts
               Question: Does the paper discuss both potential positive societal impacts and negative
               societal impacts of the work performed?
               Answer: [NA]
               Justification: There is no societal impact of the work performed.
               Guidelines:
                • The answer NA means that there is no societal impact of the work performed.
                • If the authors answer NA or No, they should explain why their work has no societal
                 impact or why the paper does not address societal impact.
                • Examples of negative societal impacts include potential malicious or unintended uses
                 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations
                 (e.g., deploymentoftechnologiesthatcouldmakedecisionsthatunfairlyimpactspecific
                 groups), privacy considerations, and security considerations.
                • The conference expects that many papers will be foundational research and not tied
                 to particular applications, let alone deployments. However, if there is a direct path to
                 any negative applications, the authors should point it out. For example, it is legitimate
                 to point out that an improvement in the quality of generative models could be used to
                 generate deepfakes for disinformation. On the other hand, it is not needed to point out
                 that a generic algorithm for optimizing neural networks could enable people to train
                 models that generate Deepfakes faster.
                • The authors should consider possible harms that could arise when the technology is
                 being used as intended and functioning correctly, harms that could arise when the
                 technology is being used as intended but gives incorrect results, and harms following
                 from (intentional or unintentional) misuse of the technology.
                • If there are negative societal impacts, the authors could also discuss possible mitigation
                 strategies (e.g., gated release of models, providing defenses in addition to attacks,
                 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
                 feedback over time, improving the efficiency and accessibility of ML).
             11. Safeguards
               Question: Does the paper describe safeguards that have been put in place for responsible
               release of data or models that have a high risk for misuse (e.g., pretrained language models,
               image generators, or scraped datasets)?
               Answer: [NA]
               Justification: The paper poses no such risks.
               Guidelines:
                • The answer NA means that the paper poses no such risks.
                               26
