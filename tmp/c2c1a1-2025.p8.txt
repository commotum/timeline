                      2. Related Works
                      2.1. Multimodal representation learning
                         Based on a tremendous amount of image-text pair datasets, contrastive
                      pre-trained multimodal models such as CLIP [3], BLIP-2 [16] and Alpha-
                      CLIP[17]recentlyshowimpressiveprogressw.r.tgeneralizability of represen-
                      tation, zero-shot transfer and OOD [18]. A key factor to their great success
                      is the language-guided visual representation learning scheme. Given a set of
                      image-caption pairs (x ,c ),...,(x ,c ), they train an image encoder E   (.)
                                            1  1       N N                                  img
                      and text encoder E    (.) such that the similarity < E   (x ),E   (c ) > be-
                                          txt                               img  i   txt i
                      tween positively aligned pair is maximized relative to negatively unaligned
                      pair through InfoNCE [19] objective function. In addition to image-text
                      learning, video-text learning for segmentation [20] and video-audio-text sen-
                      timent analysis [21] and image-speech-text learning [22] have also studied
                      actively.
                      2.2. General architecture
                         In another line of work, there are attempts that aim to unify the architec-
                      ture or learning objective for training in different modalities. Most of these
                      studies mainly utilize the Transformer [1] architecture which has less data-
                      specific and task-specific inductive bias as the backbone. Instead of relying
                      on modality-specific targets, Data2vec [23] uses the same learning objec-
                      tive for data from different modalities. Based on the combination objective
                      of latent target prediction task [24] and Masked prediction [25], Data2vec
                                                           5
