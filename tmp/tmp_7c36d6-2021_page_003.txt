                                                     Random Input                                    Random Program 
                                                        Generator                                        Generator
                                                   I : [-4, 3, 1, 2, 1]                                                          O : [-4, 3, 3, 3, 3]
                                                    1                                                                              1
                                                   I : [3, 4, 3, 2, 4]                                                           O : [3, 4, 3, 3, 3]
                                                    2                                                                              2                                Neural 
                                                   I : [2, 1, 4, 1, 2]                                                           O : [2, 1, 3, 3, 3]
                                                    3                                                                              3                               Program 
                                                   I : [1, 4, 1, 1, -2]                                                          O : [1, 4, 3, 3, 3]
                                                    4                                                                              4                              Synthesizer
                                                   I : [2, 4, 4, -1, 4]                                                          O : [2, 4, 3, 3, 3]
                                                    5                                                                              5
                                                  Figure 1: Illustration of the C program synthesis pipeline. For dataset construction, we develop a random
                                                  program generator to sample random C programs, then execute the program over randomly generated inputs and
                                                  obtain the outputs. The input-output pairs are fed into the neural program synthesizer to predict the programs.
                                                  Note that the synthesized program can be more concise than the original random program.
                                                  (a) Model Overview                                                                     (b) Program Decoder                                                             	Ì†µ„åµ
                                                                                                                                               Ì†µ„åµ ,	Ì†µ„åµ ,	‚Ä¶,			Ì†µ„åµ             Program	                                       "
                                                   Ì†µ„åµ                                    Ì†µ„åµ                                 Ì†µ„åµ                   /     $           "#$        Context
                                                     "#$                                   "                                  "?$            	‚Ñé                                      Ì†µ„åµÌ†µ„åµÌ†µ„åµÌ†µ„åµ            	‚Ñé            Softmax
                                                   ‚Ñé                Program	             ‚Ñé               Program	           ‚Ñé                   "#$                                           -              "
                                                     "#$            Decoder                "             Decoder              "?$
                                                                     Latent	                              Latent	                             '                     IO	                 1     2         Max 	Ì†µ„åµ           	Ì†µ„åµ
                                                                                                                                             	Ì†µ„åµ       Ì†µ„åµ                            	Ì†µ„åµ   Ì†µ„åµ                      "        "
                                                    '                                     '                                  '                 "#$              Encoder                 "    "          Pool
                                                   	Ì†µ„åµ              Executor             	Ì†µ„åµ             Executor           	Ì†µ„åµ
                                                     "#$                                   "                                  "?$                                                        Ì†µ„åµ4Ì†µ„åµ
                                                                                                                                                                                             "
                                                  (c) Latent Executor                                                                    (d)                                                    Operation Predictor
                                                    ‚Ñé                                                                          Ì†µ„åµ                           Attention
                                                      "                                                                                                                    I    O        Op
                                                                                                                     Training	                       1($)       1(=)
                                                                                                                                                  	Ì†µ„åµ     ‚Ä¶ Ì†µ„åµ            2     4     O=2+I
                                                                                                                      Target                         "          "
                                                                                Ì†µ„åµÌ†µ„åµÌ†µ„åµÌ†µ„åµ                                                                                  2     0     O=2-I Retrieve
                                                    '            Ì†µ„åµÌ†µ„åµÌ†µ„åµÌ†µ„åµ              "   Softmax            '                 '                   2($)       2(=)                                               ($)         (=)
                                                   	Ì†µ„åµ                     7                                	Ì†µ„åµ                	Ì†µ„åµ                 Ì†µ„åµ     ‚Ä¶Ì†µ„åµ                                                 	Ì†µ„åµ4Ì†µ„åµ  ‚Ä¶	Ì†µ„åµ4Ì†µ„åµ
                                                     "#$                                                       "                 >                  "          "          ‚Ä¶ ‚Ä¶                                     "          "
                                                  Figure 2: (a) An overview of LaSynth model architecture. (b), (c), and (d) present the details of the program
                                                  decoder, latent executor, and the operation predictor. Note that the operation predictor is specialized for numerical
                                                  calculation, and thus is not used for the Karel domain.
                                                  decoded programs also becomes more difÔ¨Åcult. In particular, prior neural program synthesizers that
                                                  utilize per-line interpreters for the programming language to guide the synthesis and representation
                                                  learning [12, 44, 37, 18, 38] are not directly applicable to C. Although it is possible to dump some
                                                  intermediate variable states during C code execution [10], since partial C programs are not executable,
                                                 weareable to obtain all the execution states only until a full C code is generated, which is too late to
                                                  include them in the program decoding process. In particular, the intermediate execution state is not
                                                  available when the partial program is syntactically invalid, and this happens more frequently for C
                                                  due to its syntax design.
                                                  3       ProgramSynthesiswithLearnedExecution
                                                  In this section, we present LaSynth which learns to represent the execution of partial programs to
                                                  guide the synthesis process. Fig. 2(a) provides an overview of LaSynth model architecture which
                                                  consists of two components, the program decoder and the latent executor. We present the core design
                                                  below, and defer more details to Appendix B and Appendix C.
                                                  3.1       ModelOverview
                                                 Atahighlevel,theprogramdecoder(Fig.2(b))takesalatentvectorh                                                                       that represents the generated
                                                                                                                                                                            t‚àí1
                                                  partial program, the previous (generated) program token p                                                       , and outputs the latent vector h and
                                                  the next program token p to be generated at time step t:                                                  t‚àí1                                                             t
                                                                                               t
                                                                                               (h ,p ) = ProgramDecoder(h                                     , p        ; IO          )                                        (1)
                                                                                                   t     t                                              t‚àí1       t‚àí1           t‚àí1
                                                  Here the recurrent model is conditioned on the IO pair IOt‚àí1. When IOt = IO := (I,O) for
                                                  every t, i.e., IOt remains constant over the entire recurrent generation process, Eqn. 1 represents the
                                                  standard recurrent architecture used in most autoregressive natural language models [24, 49], and is
                                                  also used in prior works on program synthesis from input-output examples [17, 9].
                                                                                                                                          3
