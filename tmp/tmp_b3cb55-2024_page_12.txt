                          Figure 5: Illustration of the DFS scheme. In this example, only paths with a cumulative
                          probability greater than 5% are kept. Since many paths are cut, we will often end up with
                          far less than 20 possible solutions.
                          the solution tree, as long as the path has a cumulative sampling probabil-
                          ity greater than a specified threshold p. As soon as a branch falls below
                          this probability, the path is discarded. By leveraging inference caches, this
                          algorithm is able to quickly and efÏciently identify all potential candidates
                          that have a sampling probability greater than p. This also means that we
                          are guaranteed to extract the solution with the best possible score, provided
                          that it has a probability greater than p – something we cannot guarantee
                          with greedy or multinomial sampling.
                          We apply this DFS sampling approach across multiple augmented versions
                          of each task. The motivation here is that certain solutions are easier for the
                          model to "see" from alternative perspectives. Since we are using a decoder-
                          only text model, it lacks an intrinsic understanding of the 2D structure of
                          these tasks. This limitation becomes evident when solutions that involve
                          critical vertical lines receive a lower probability, while the same task, once
                          transposed, is much easier for the model to solve. (see Figure 6)
                          Consequently, depending on the specific run, we generate DFS candidates
                          across 8 to 16 augmentations for each task. This results in a set of candidates
                          that is guaranteed to include the correct solution if and only if the model
                          could have sampled that solution with a probability greater than p from at
                          least one augmented perspective.
                          This strategy is highly effective.  Not only do we increase our scores by
                          several points, but the algorithm is also substantially faster then baseline
                          (see Table 5). The algorithm is also very memory efÏcient, as we only need
                          to track a single branch at a time and can avoid duplicating caches – in stark
                          contrast to beam search, which scales linearly with the number of beams
                          considered. We provide pseudocode for DFS sampling in Algorithm 1.
                                                               12
