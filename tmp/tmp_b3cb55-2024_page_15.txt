                         A comparison of this selection procedure can be seen in Table 6. Adding
                         candidate scoring with augmentations improves our score by roughly 25%
                         over baseline, and shows a significant increase compared to our next best
                         solution. Using this technique we are able to select the correct candidate in
                         72.5 of 80 possible cases, thereby solving 72.5 out of the 100 randomly split
                         off tasks from the evaluation set.
                         Even the smaller Llama-rearc model, where preliminary training exclusively
                         used Re-ARC, was able to solve 218 of all 400 evaluation tasks after sec-
                         ondary finetuning on those tasks.
                         4    Discussion
                         Using the above pipeline we were able to score 53.5 points during the Kaggle
                         ARCPrize2024and56.5pointsshortlyafterthesubmissiondeadline(there-
                         fore not being reflected on the leaderboard), securing us the second place
                         in the competition. Our approach demonstrates that LLMs can effectively
                         tackle many of the complex tasks provided by the ARC-AGI benchmark.
                         The pipeline presented is highly interconnected and provides results greater
                         than the sum of its parts. The success of our scoring algorithm relies on the
                         custom DFS algorithmâ€™s ability to provide candidates with arbitrary cutoff
                         values. This in turn is enabled by optimizing model training in both train-
                         ing phases and by simplifying the problem space. Each part of the pipeline
                         requires the augmentations to work as well as it does.
                         Finally, we believe that this approach has not yet completely saturated and
                         might scale further, using additional augmentation strategies, further opti-
                         mizing training hyperparameters or by using larger models.
                         Acknowledgement
                         We would like to express our sincere gratitude to Lambda, for providing
                         computational resources essential for optimizing our preliminary training
                         phase within our overall training pipeline.  Specifically, they supplied us
                         with a server equipped with 8xH100 GPUs, enabling rapid iteration on our
                         ideas. Their support was instrumental for reaching our final score.
                                                             15
