                       Preprint.
                       ARCMEMO: ABSTRACT REASONING
                       COMPOSITION WITH LIFELONG LLM MEMORY
                                   1        1               1          2          1
                        MatthewHo ,ChenSi ,ZhaoxiangFeng ,FangxuYu ,YichiYang
                                  1           1           1
                        Zhijian Liu , Zhiting Hu , Lianhui Qin
                        1University of California, San Diego, 2University of Maryland
                                                          ABSTRACT
                              While inference-time scaling enables LLMs to carry out increasingly long and
                              capablereasoningtraces, the patterns and insights uncovered during these traces are
                              immediately discarded once the context window is reset for a new query. External
                              memoryisanaturalwaytopersist these discoveries, and recent work has shown
                              clear benefits for reasoning-intensive tasks. We see an opportunity to make such
                              memories more broadly reusable and scalable by moving beyond instance-based
                              memoryentries(e.g. exact query/response pairs, or summaries tightly coupled with
                              the original problem context) toward concept-level memory: reusable, modular
                              abstractions distilled from solution traces and stored in natural language. For future
                              queries, relevant concepts are selectively retrieved and integrated into the prompt,
                              enablingtest-timecontinuallearningwithoutweightupdates. Ourdesignintroduces
                              newstrategies for abstracting takeaways from rollouts and retrieving entries for
                              new queries, promoting reuse and allowing memory to expand with additional
                              experiences. We evaluate on ARC-AGI, a benchmark that stresses compositional
                              generalization and abstract reasoning, making it a natural fit for concept memory.
                              Ourmethodyieldsa7.5%relativegainoverastrongno-memorybaseline,with
                              performance continuing to scale with inference compute. We find abstract concepts
                              to be the most consistent memory design, outscoring the baseline at all tested
                              inference compute scales. Moreover, dynamically updating memory during test-
                              time outperforms fixed settings, supporting the hypothesis that accumulating and
                              abstracting patterns enables further solutions in a form of self-improvement. 1.
                       1   INTRODUCTION
                       Large language models (LLMs) have made substantial strides in reasoning-intensive tasks with
                       long-form reasoning. However, a notable opportunity lies in the fact that LLM systems are fixed after
                       deployment: new patterns and strategies uncovered during deep reasoning are not yet carried forward
                       once the context is cleared. This contrasts with human approaches to solving complex, compositional
       arXiv:2509.04439v3  [cs.AI]  4 Oct 2025reasoning problems, which involve building on prior insights, abstracting patterns, and composing
                       them in new contexts. Augmenting LLMs with memory offers a natural solution to retaining and
                       building on their discoveries.
                       While external augmentation was initially designed for factuality in knowledge-intensive tasks (e.g.
                       Lewis et al. (2021) with RAG, Zhang et al. (2019) with Knowledge Graphs, inter alia), recent work
                       has begun developing memory approaches for reasoning-intensive tasks, storing questions, findings,
                       and mistakes in memory instead of simple facts (Yang et al., 2024). These memories tend to be
                       specific to the problem/experience it was originally derived from (we term these “instance-level”
                       concepts, see Figure 1). Although effective for closely related problems, they have diminished
                       utility for problems superficially different from prior experiences. Other approaches, such as Suzgun
                       et al. (2025), begin addressing the “instance-level” issue by maintaining an evolving summary of
                       previous experience to great effect, but the lack of structure and modularity makes scaling with more
                       experiences challenging. Without selective retrieval, the size of memory is limited, and the problem
                       solving model has the additional burden of picking out the relevant ideas from all past experiences.
                         1Codeavailable at https://github.com/matt-seb-ho/arc_memo
                                                               1
