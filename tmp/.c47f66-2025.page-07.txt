                  ferences suggest that strong capable models are            3.5   Qualitative Analysis
                  already proficient at extracting and understanding         Togaindeeperinsights into model performance be-
                  textual information from images, even without ex-          yondquantitativemetrics,weconductedathorough
                  plicit OCR prompts.                                        qualitative analysis of MMMU-Pro results, focus-
                                                                             ing on two key scenarios: 1) Correct answers with
                                                    Vision Setting Acc.      four options but failure with ten options in the stan-
                    Model                   OCR w/OCR w/oOCR                 dard setting; 2) Success in the standard ten-option
                                            Acc.    Prompt     Prompt
                                                                             setting but failure in the vision input setting. Our
                    GPT-4o                   92.3     49.7       49.4        analysis revealed several critical factors affecting
                    Gemini 1.5 Pro(0801)     89.7     44.4       43.6        modelperformance:
                    GPT-4omini               89.6     35.2       35.6
                    InternVL2-Llama3-76B     88.1     38.0       37.9        Challenges with Increased Options. Models of-
                    InternVL2-Llama3-40B     85.5     32.1       28.9        ten select the closest answer rather than arriving at
                    Pixtral-12B              83.1     25.0       24.1
                    LLaVA-OneVision-72B      87.8     24.0       23.8        a definitive choice, leading to increased errors with
                    InternVL2-8B             85.2     25.4       24.6        moreoptions, as shown in Figure 11. Conceptually
                    MiniCPM-V2.6             67.0     24.2       21.1        similar options, particularly in nuanced questions,
                    LLaVA-NEXT-72B           62.0     19.2       20.0
                    Idefics3-8B-Llama3       68.5     15.6       14.1        can cause confusion. For instance, in conceptual
                    LLaVA-NeXT-7B            36.6     14.6       14.3        questions, models struggled to differentiate subtle
                    LLaVA-NeXT-13B           51.1     14.5       12.8        distinctions within a subject area, revealing limita-
                  Table 2: Model performance in the Vision Input setting,    tions in fine-grained understanding.
                  comparing OCRaccuracy with/without OCR prompts.            Increased Cognitive Load in Vision-Text Inte-
                                                                             gration. Processingvisualandtextualinputssimul-
                                                                             taneously increases the cognitive load on models.
                                 Proprietary Models          GPT-4o          An example is shown in Figure 10. The model
                        50       Open-Source Models                          perfectly extracted the text from the image but still
                                                      Gemini 1.5 Pro(0801)   failed to answer the question correctly. Another
                       ision40                       InternVL2-Llama3-76B    case is shown in Figure 21. The graph’s similar
                       o V                                                   lines and overlapping data points may distract the
                                                        GPT-4o mini          model from distinguishing between the two unem-
                        30
                                                      Pixtral-12B            ployment categories, leading to the error.
                                     MiniCPM-V2.6
                       MMMU-Pr                        LLaVA-OneVision-72B    Overemphasis on Visual Cues in Multimodal
                        20      LLaVA-NEXT-72B
                           LLaVA-NeXT-7B          Idefics3-8B                Reasoning. When visual cues dominate over tex-
                        10               VILA-1.5-40B                        tual reasoning, models may incorrectly prioritize
                          30    40   50    60    70    80    90              less relevant information from the images. In the
                                        OCR Accuracy                         Figure 33 example, the Vision Setting incorrectly
                  Figure 6: Correlation between OCR accuracy and             chose the League of Nations by focusing on the
                  MMMU-ProVisionperformance.                                 World War I image, missing the broader context
                                                                             of World War II and the United Nations. A proper
                     Interestingly, Figure 6 shows that high OCR ac-         balance between visual and textual information is
                  curacy doesn’t always translate to strong multi-           essential to avoid such mistakes.
                  modalreasoning. For example, LLaVA-OneVision-              ImpactofContextSwitching. Rapid transitions
                  72BmatchesInternVL2-Llama3-76B and GPT-4o                  between visual and textual information can cause
                  mini in OCR accuracy but lags significantly in             models to lose focus or misinterpret key data. For
                  MMMU-ProVisionperformance, indicating that                 example, in Figure 26, the model initially correctly
                  OCRaccuracyaloneisinsufficient for robust rea-             defined both the objective function and the alge-
                  soning. Conversely, top-performing models like             braic constraints. However, due to context switch-
                  GPT-4o consistently excel in both areas. Despite           ing between the textual description and the geomet-
                  GPT-4o’s high OCR accuracy, its MMMU-Pro                   ric figure, it misinterpreted the feasible region.
                  Vision performance drops notably compared to               3.6   Error Analysis
                  MMMU(Val),revealingthatevenadvancedmod-
                  els struggle to fully integrate and reason over mul-       Following the MMMUerror analysis, we analyze
                  timodal inputs in the vision-only setting.                 60 error cases from GPT-4o in the Vision setting
                                                                        15140
