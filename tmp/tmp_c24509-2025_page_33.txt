           References
            [1] Antonio Alliegro, Yawar Siddiqui, Tatiana Tommasi, and Matthias Nießner. PolyDiff: Generating 3D polygonal
              meshes with diffusion models. arXiv preprint arXiv:2312.11417, 2023.
            [2] Sherwin Bahmani, Xian Liu, Yifan Wang, Ivan Skorokhodov, Victor Rong, Ziwei Liu, Xihui Liu, Jeong Joon Park,
              Sergey Tulyakov, Gordon Wetzstein, Andrea Tagliasacchi, and David B. Lindell. TC4D: Trajectory-conditioned
              text-to-4D generation. arXiv preprint arXiv:2403.17920, 2024.
            [3] Maxim Berman, Amal Rannen Triki, and Matthew B Blaschko. The lovász-softmax loss: A tractable surrogate
              for the optimization of the intersection-over-union measure in neural networks. In IEEE/CVF Conference on
              Computer Vision and Pattern Recognition, pages 4413–4421, 2018.
            [4] Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung Wook Kim, Sanja Fidler, and Karsten
              Kreis. Align your latents: High-resolution video synthesis with latent diffusion models. In IEEE/CVF Conference
              on Computer Vision and Pattern Recognition, pages 22563–22575, 2023.
            [5] Lucas Caccia, Herke van Hoof, Aaron Courville, and Joelle Pineau. Deep generative modeling of LiDAR data. In
              IEEE/RSJ International Conference on Intelligent Robots and Systems, pages 5034–5040, 2019.
            [6] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan,
              Yu Pan, Giancarlo Baldan, and Oscar Beijbom. nuScenes: A multimodal dataset for autonomous driving. In
              IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11621–11631, 2020.
            [7] Ang Cao and Justin Johnson. HexPlane: A fast representation for dynamic scenes. In IEEE/CVF Conference on
              Computer Vision and Pattern Recognition, pages 130–141, 2023.
            [8] Eric R Chan, Connor Z Lin, Matthew A Chan, Koki Nagano, Boxiao Pan, Shalini De Mello, Orazio Gallo,
              Leonidas J Guibas, Jonathan Tremblay, Sameh Khamis, et al. EfÏcient geometry-aware 3D generative adversarial
              networks. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16123–16133, 2022.
            [9] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4D spatio-temporal convnets: Minkowski convolutional
              neural networks. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075–3084, 2019.
           [10] Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. FlashAttention: Fast and memory-efÏcient
              exact attention with io-awareness. In Advances in Neural Information Processing Systems, volume 35, pages
              16344–16359, 2022.
           [11] Sara Fridovich-Keil, Giacomo Meanti, Frederik Rahbæk Warburg, Benjamin Recht, and Angjoo Kanazawa.
              K-Planes: Explicit radiance fields in space, time, and appearance. In IEEE/CVF Conference on Computer Vision
              and Pattern Recognition, pages 12479–12488, 2023.
           [12] Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance. arXiv preprint arXiv:2207.12598, 2022.
           [13] Fangzhou Hong, Lingdong Kong, Hui Zhou, Xinge Zhu, Hongsheng Li, and Ziwei Liu. Unified 3D and 4D panoptic
              segmentation via dynamic shifting networks. IEEE Transactions on Pattern Analysis and Machine Intelligence,
              46(5):3480–3495, 2024.
           [14] Qianjiang Hu, Zhimin Zhang, and Wei Hu. RangeLDM: Fast realistic LiDAR point cloud generation. In European
              Conference on Computer Vision, pages 115–135, 2024.
           [15] Siyuan Huang, Yichen Xie, Song-Chun Zhu, and Yixin Zhu. Spatio-temporal self-supervised representation
              learning for 3D point clouds. In IEEE/CVF International Conference on Computer Vision, pages 6535–6545,
              2021.
           [16] Yanqin Jiang, Li Zhang, Jin Gao, Weimin Hu, and Yao Yao. Consistent4D: Consistent 360° dynamic object
              generation from monocular video. arXiv preprint arXiv:2311.02848, 2023.
           [17] Jumin Lee, Sebin Lee, Changho Jo, Woobin Im, Juhyeong Seon, and Sung-Eui Yoon. SemCity: Semantic scene
              generation with triplane diffusion. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages
              28337–28347, 2024.
           [18] Yuheng Liu, Xinke Li, Xueting Li, Lu Qi, Chongshou Li, and Ming-Hsuan Yang. Pyramid diffusion for fine 3D
              large scene generation. arXiv preprint arXiv:2311.12085, 2023.
           [19] Zhen Liu, Yao Feng, Michael J. Black, Derek Nowrouzezahrai, Liam Paull, and Weiyang Liu. MeshDiffusion:
              Score-based generative 3D mesh modeling. In International Conference on Learning Representations, 2023.
                                             33
