2. Segment Anything Task

We take inspiration from NLP, where the next token pre-
diction task is used for foundation model pre-training and
to solve diverse downstream tasks via prompt engineer-
ing [10]. To build a foundation model for segmentation,
we aim to define a task with analogous capabilities.

Task. We start by translating the idea of a prompt from NLP
to segmentation, where a prompt can be a set of foreground
/ background points, a rough box or mask, free-form text,
or, in general, any information indicating what to segment
in an image. The promptable segmentation task, then, is to
return a valid segmentation mask given any prompt. The re-
quirement of a “valid” mask simply means that even when
a prompt is ambiguous and could refer to multiple objects
(e.g., recall the shirt vs. person example, and see Fig. 3),
the output should be a reasonable mask for at least one of
those objects. This requirement is similar to expecting a lan-
guage model to output a coherent response to an ambiguous
prompt. We choose this task because it leads to a natural
pre-training algorithm and a general method for zero-shot
transfer to downstream segmentation tasks via prompting.

Pre-training. The promptable segmentation task suggests a
natural pre-training algorithm that simulates a sequence of
prompts (e.g., points, boxes, masks) for each training sam-
ple and compares the model’s mask predictions against the
ground truth. We adapt this method from interactive seg-
mentation [1(07, 68], although unlike interactive segmenta-
tion whose aim is to eventually predict a valid mask after
enough user input, our aim is to always predict a valid mask
for any prompt even when the prompt is ambiguous. This
ensures that a pre-trained model is effective in use cases that
involve ambiguity, including automatic annotation as re-
quired by our data engine §4. We note that performing well
at this task is challenging and requires specialized modeling
and training loss choices, which we discuss in §3.

Zero-shot transfer. Intuitively, our pre-training task en-
dows the model with the ability to respond appropriately to
any prompt at inference time, and thus downstream tasks
can be solved by engineering appropriate prompts. For ex-
ample, if one has a bounding box detector for cats, cat in-
stance segmentation can be solved by providing the detec-
tor’s box output as a prompt to our model. In general, a wide
array of practical segmentation tasks can be cast as prompt-
ing. In addition to automatic dataset labeling, we explore
five diverse example tasks in our experiments in §6.

Related tasks. Segmentation is a broad field: there’s in-
teractive segmentation [55, 107], edge detection [3], su-
per pixelization [83], object proposal generation [2], fore-
ground segmentation [92], semantic segmentation [88], in-
stance segmentation [64], panoptic segmentation [57], etc.
The goal of our promptable segmentation task is to produce

Figure 3: Each column shows 3 valid masks generated by
SAM from a single ambiguous point prompt (green circle).

a broadly capable model that can adapt to many (though
not all) existing and new segmentation tasks via prompt
engineering. This capability is a form of task generaliza-
tion [25]. Note that this is different than previous work on
multi-task segmentation systems. In a multi-task system, a
single model performs a fixed set of tasks, e.g., joint seman-
tic, instance, and panoptic segmentation [112, 18, 52], but
the training and test tasks are the same. An important dis-
tinction in our work is that a model trained for promptable
segmentation can perform a new, different task at inference
time by acting as a component in a larger system, e.g., to
perform instance segmentation, a promptable segmentation
model is combined with an existing object detector.

Discussion. Prompting and composition are powerful tools
that enable a single model to be used in extensible ways, po-
tentially to accomplish tasks unknown at the time of model
design. This approach is analogous to how other founda-
tion models are used, e.g., how CLIP [80] is the text-image
alignment component of the DALL-E [81] image generation
system. We anticipate that composable system design, pow-
ered by techniques such as prompt engineering, will enable
a wider variety of applications than systems trained specif-
ically for a fixed set of tasks. It’s also interesting to com-
pare promptable and interactive segmentation through the
lens of composition: while interactive segmentation mod-
els are designed with human users in mind, a model trained
for promptable segmentation can also be composed into a
larger algorithmic system as we will demonstrate.

4018
