                                      Table 4: Results on C dataset.
                                Approach                     Accuracy
                                LaSynth                        55.2%
                                NoAttentionInDecoding          53.5%
                                NoOpPredictor                  53.7%
                                NoPartialExecutor              42.9%
                                NoExecutor                     38.6%
                                RobustFill [17]                37.6%
                                Property Signatures [39]       34.5%        Figure 6: Accuracies of different program types
                                                                            on C dataset.
                                                    (a)                                         (b)
                           Figure 7: Results of iterative retraining on the C dataset. (a) Accuracies with different training data sizes. With
                           the full training set, the accuracies are 55.2%, 56.0% and 56.5% for training on random programs, retraining
                           for 1 and 2 iterations, respectively. (b) The program distributions after each retraining iteration.
                           ﬂowconstructs, For-only includes programs with For loops but no If statements, and Mixture includes
                           programswithbothForloopsandIfstatements. Thenwedemonstratetheresultsondifferentprogram
                           lengths in Fig. 8b. We show that LaSynth achieves decent performance on long and complicated
                           programs, while the accuracies of baseline models drop dramatically.
                           5.3  Discussion of Iterative Retraining
                           In Fig. 3, we show the effectiveness of retraining on decoded Karel programs (Sec. 3.4). We observe
                           that retraining for one iteration is sufﬁcient, and it signiﬁcantly improves the generalization accuracy
                           by over 3%. To understand the differences between predicted programs and randomly generated
                           programs, we demonstrate the changes of dataset distributions after each retraining iteration in Fig. 4a
                           and 4b. We observe that the model learns to predict more concise programs than the ground truth for
                           a large proportion of input-output examples, and considerably alters the dataset distribution so that it
                           becomesmoreconcentrated on short programs with simpliﬁed control ﬂow structures. Speciﬁcally,
                           from Fig. 4a, although the initial Karel dataset seems to include a large proportion of complicated
                           programs with different control ﬂow constructs, our model synthesizes straight-line programs for
                           nearly half of the samples, which means that many loops and branches in the annotated ground
                           truth programs are unnecessary. This distribution shift also explains the gap between the exact
                           match and generalization accuracies. The program distribution after the second retraining iteration is
                           largely similar to the ﬁrst iteration, thus retraining for more iterations does not considerably improve
                           the performance. Note that in the second iteration, the synthesizer tends to generate slightly more
                           complicated programs than the ﬁrst iteration, in order to deal with the cases when the input-output
                           examples oversimplify the intended program functionality. For example, sometimes the input-output
                           examplesdonotcovertheedgecasesthattherobotmayencounter,thusaddingadditionalIfbranches
                           could avoid the crashes when testing on held-out cases.
                           Fig. 7a presents the results of retraining on decoded C programs. Similarly, retraining improves the
                           prediction accuracy, especially when the training set is small. From Fig. 7b and 8a, we again observe
                           that the model tends to predict shorter programs than the random code, and it eliminates unnecessary
                           control ﬂows to simplify the programs. We present more examples in Appendix D.
                                                                           9
