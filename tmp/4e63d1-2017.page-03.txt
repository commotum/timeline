                                in OR for translating a goal like [grandfatherOf,Q,BART] into subgoals [fatherOf,Q,Z] and
                                                                                                    1
                                [parentOf,Z,BART]that are subsequently proven by AND.
                                3    Differentiable Prover
                                In the following, we describe the recursive construction of NTPs – neural networks for end-to-end
                                differentiable proving that allow us to calculate the gradient of proof successes with respect to vector
                                representations of symbols. We deﬁne the construction of NTPs in terms of modules similar to
                                dynamicneuralmodulenetworks[29]. Eachmoduletakesasinputsdiscreteobjects(atomsandrules)
                                and a proof state, and returns a list of new proof states (see Figure 1 for a graphical representation).
                                Aproofstate S = (ψ,ρ) is a tuple consisting of
                                the substitution set ψ constructed in the proof
                                so far and a neural network ρ that outputs a
                                real-valued success score of a (partial) proof.              X/Q                              X/Q
                                                                                            Y/BART                          Y/BART
                               While discrete objects and the substitution set                                              Z/HOMER
                                are only used during construction of the neu-
                                                                                              S          S                    S0         S0
                                ral network, once the network is constructed a                 ψ          ρ                     ψ         ρ
                                continuous proof success score can be calcu- Figure 1: A module is mapping an upstream proof
                                lated for many different goals at training and           state (left) to a list of new proof states (right),
                                test time. To summarize, modules are instanti-           thereby extending the substitution set S            and
                                ated by discrete objects and the substitution set.                                                        ψ
                               They construct a neural network representing              adding nodes to the computation graph of the neu-
                                the (partial) proof success score and recursively        ral network Sρ representing the proof success.
                                instantiate submodules to continue the proof.
                               ThesharedsignatureofmodulesisD×S → SN whereDisadomainthatcontrolstheconstructionof
                                the network, S is the domain of proof states, and N is the number of output proof states. Furthermore,
                                let Sψ denote the substitution set of the proof state S and let Sρ denote the neural network for
                                calculating the proof success.
                               Weusepseudocodeinstyle of a functional programming language to deﬁne the behavior of modules
                                and auxiliary functions. Particularly, we are making use of pattern matching to check for properties
                                of arguments passed to a module. We denote sets by Euler script letters (e.g. E), lists by small capital
                                letters (e.g. E), lists of lists by blackboard bold letters (e.g. E) and we use : to refer to prepending an
                                element to a list (e.g. e : E or E : E). While an atom is a list of a predicate symbol and terms, a rule
                                                                                                                                          2
                                can be seen as a list of atoms and thus a list of lists where the head of the list is the rule head.
                                3.1   Uniﬁcation Module
                                Uniﬁcation of two atoms, e.g., a goal that we want to prove and a rule head, is a central operation
                                in backward chaining. Two non-variable symbols (predicates or constants) are checked for equality
                                and the proof can be aborted if this check fails. However, we want to be able to apply rules even
                                if symbols in the goal and head are not equal but similar in meaning (e.g. grandfatherOf and
                                grandpaOf)andthusreplace symbolic comparison with a computation that measures the similarity
                                of both symbols in a vector space.
                               Themoduleunifyupdatesasubstitution set and creates a neural network for comparing the vector
                                representations of non-variable symbols in two sequences of terms. The signature of this module
                                is L ×L × S → S where L is the domain of lists of terms. unify takes two atoms represented
                                as lists of terms and an upstream proof state, and maps these to a new proof state (substitution set
                                and proof success). To this end, unify iterates through the list of terms of two atoms and compares
                                their symbols. If one of the symbols is a variable, a substitution is added to the substitution set.
                                Otherwise, the vector representations of the two non-variable symbols are compared using a Radial
                                                                                                                         1
                                Basis Function (RBF) kernel [30] where µ is a hyperparameter that we set to √2 in our experiments.
                               Thefollowing pseudocode implements unify. Note that "_" matches every argument and that the
                                   1For    clarity,   we will      sometimes     omit    lists  when     writing    rules   and    atoms,    e.g.,
                                grandfatherOf(X,Y):–fatherOf(X,Z),parentOf(Z,Y).
                                   2For example, [[grandfatherOf,X,Y],[fatherOf,X,Z],[parentOf,Z,Y]].
                                                                                        3
