                  Learning program synthesis with self-improving language models: A case study on ARC-AGI
         C. Model ensembling
                                      All models
                       Mistral+Q-72B+QC-32B+14B
                            Mistral+Q-72B+QC-32B
                                   Mistral+Q-72B
                           Q-72B+QC-32B+14B+7B
                                 QC-32B+14B+7B
                                        Mistral
                                         Q-72B
                                     QC-14B+7B
                                        QC-32B
                                        QC-14B
                                         QC-7B
                                              0     20     40
                                                 ARC-test score (%)
                             Figure 10. ARC-test score for different model combinations
         D. Implementation details
         D.1. Weighted Majority Voting Algorithm
         Thealgorithm processes the ensemble of model responses, each containing output predictions for a set of input grids. It
         groups responses by their test output grids and applies weighted voting to select the most reliable predictions (see Alg. 1).
         WeightedMajorityVotingAlgorithm:
          1. Pattern Extraction: Each response’s complete set of test outputs is serialized into a pattern key.
          2. Weighted Voting: Patterns are weighted using the formula: weight = count + c × train_accuracy, where count is
            the frequency of the pattern, train_accuracy is the mean accuracy of the generated program on the training examples,
            and c is a scaling parameter, as we want to penalize low pattern with a low train_accuracy we set it to a high values
            (c = 1000).
          3. Selection: The top n_output patterns with highest weights are selected as final outputs.
         Algorithm 1 Weighted Majority Voting algorithm
         Require: Set of responses with test outputs and training accuracies, scaling parameter c, number of outputs n_output
         Ensure: Top n_output patterns with highest weights (n_output = 2 when testing)
         1: Pattern Extraction:
         2: for each response do
         3:  Serialize the complete set of test outputs into a pattern key
         4: end for
         5: Weighted Voting:
         6: for each unique pattern do
         7:  Computecount ←frequencyofthepattern
         8:  Computetrain_accuracy ←meanaccuracyofthegeneratedprogramontrainingexamples
         9:  Computeweight ← count+c×train_accuracy
         10: end for
         11: Selection:
         12: Select the top n_output patterns with the highest weight values as final outputs
                                            17
