100 = Unified Theories of Cognition

character. Problem search constructs its space. The only states that
exist as declarative data structures are the current one plus, possi-
bly, some that were generated in the search up to the current mo-
ment and have been saved to be accessed by memory operations.
Each new operator application generates a new state, which has
never been seen before by the agent. The problem space is neces-
sarily combinatorial (with greater or less branching factor). Its to-
pology could be reduced in dimension only if new states converged
back on one another, as indicated in Figure 2-17, Convergence can
happen only by comparison and identification of the states, since a
Priori it cannot be known what other states a newly constructed
state might equal. Thus, the states have to be generated and then
processed for duplication.

On the other hand, knowledge search occurs in a fixed, preexist-
ing structure. The items being sought (the analog of the states in the
problem space) preexist as data structures. The structure of the
space (its connectivity and how paths through it are described) is
preconstructed. Indeed, it is preconstructed to facilitate the search.
The same place can be accessed through different paths and dupli-
cation can be immediately detectedâ€”just by marking the place
when it is first encountered, something impossible in the problem
space. Of course, it is possible to treat the knowledge search as if it
were occurring in a problem space and to search it by the same
combinatorial search methods. This is not the usual option, how-
ever, which is to exploit a specialized structure (indexes, hash
tables, binary trees, balanced trees). In sum, the two spaces and the
two searches are different.

There is much more to be said about problem spaces, which can
only be touched on here. A problem space is a form of generate and
test, with the operators comprising the generator and the Tecogni-
tion of a desired state being the test. Thus, the generator is realized
by a sequence of operators; it is not a black-box process. Knowl-
edge can terminate generation at many different points in the gener-
ation process (namely, after the application of any operator), thus
opening the way for the generation to be intelligent. A major lesson
from AI about generate-test situations is that it always pays to
transfer knowledge from the test to the generator, so that candidate
solutions need never be created at all. This is why multiple problem
spaces should exist, rather than just a single large space with all
conceivable operators. Packaging sequences of the operators of the

