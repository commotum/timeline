                           While pre-trained models may solve some problems either in one shot or with minimal sampling,
                           certain solutions are highly unlikely to be generated by the model, and no amount of search or
                           sampling will uncover them within a reasonable time. Fine-tuning [Hottung et al., 2021b, Hübotter
                           et al., 2024, Li et al., 2024a] for a new problem is one way to break out of this, but it is very expensive
                           and inefficient to perform on large models. A branch of work that has the potential to overcome
                           someofthesechallenges is conditioning models on a latent space, where moving through the latent
                           space impacts the distribution of outputs predicted by the decoder. Most of the existing work in this
                           field with the strongest similarities to our work does not investigate the task of program synthesis.
                           Gómez-Bombarelli et al. [2018] investigate latent space optimization for molecule generation, and on
                           the Traveling Salesman Problem Hottung et al. [2021a] show that learning a latent space can be more
                           sample-efficient than simply sampling from a standard transformer model. Compass [Chalumeau
                           et al., 2023] leverage a latent space in online Reinforcement Learning applied to combinatorial
                           optimization, using the Poppy objective [Grinsztajn et al., 2022] to encourage diversity of the latent
                           space. This idea has also been explored in black-box optimization [Yu et al., 2024] to increase
                           the diversity of input design modes, levering an energy-based model to search the latent space. In
                           symbolic mathematics, latent space optimization has been used to find an equation that best explains
                           the data, balancing a trade-off between low complexity and high accuracy [Meidani et al., 2023].
                           In program synthesis, similar concepts have been explored, such as in Hong et al. [2021], which
                           focuses on discrete representations of programs for string transformation tasks, by training an auto-
                           encoder [Hinton and Salakhutdinov, 2006] on the full specification. However, they do not leverage
                           gradient search in the latent space at test time but instead use beam search [Furcy and Koenig, 2005]
                           and simply train the model to find a program in the DSL that can explain the specification instead
                           of generalizing to a new input. Policy sketches [Murali et al., 2017, Nye et al., 2019] can also be
                           seen as learning a discrete latent space which is then more compressed and therefore potentially
                           more efficient to search. However, while discrete spaces can be useful for interpretability and
                           potentially compositional generalization [Shi et al., 2023], they still suffer from the drawback that
                           they are harder to search relative to smooth continuous latent spaces that can leverage a gradient
                           signal [Bartunov et al., 2020]. LEAPS [Trivedi et al., 2021] learn a latent space over programs for
                           the Karel domain [Pattis, 1994], and then use gradient-free optimization to search this space for
                           high-performing programs, however, Carvalho et al. [2024] show this method is outperformed by hill
                           climbing in the programmatic space.
                           3    Background
                           ProgramSynthesis      aims to generate deterministic programs in a target language, such that outputs
                           generated from inputs are consistent with the given specification. Typically, the problem space Y
                           consists of programs formulated within a domain-specific language (DSL). Each task is defined by a
                           specification set X, where each specification, X   ∈X,isdescribedbyasetofinput/output (I/O)
                                                                           m
                           examples:
                                                           X ={(xm,ym),...,(xm,ym)}                                       (1)
                                                             m        1   1          n   n
                           Aprogramf ∈Y isconsideredtosolvethetask associated with X            if it satisfies:
                                                                                             m
                                                                                m       m
                                                              ∀j ∈ [1,n],    f(x ) = y                                    (2)
                                                                                j       j
                           Thisdefinition requires that the program exactly replicates the output for each input in its specification.
                           WedenoteF torepresentthetruefunction that generates the input-output pairs.
                                        m
                           ProgramSynthesisGeneralization.        In this work, we consider the problem where we are given a
                           specification set of input-output examples generated by a program F (not necessarily constrained to
                                                                                             m
                                                                   m
                           a DSL), along with an additional input x    :
                                                                   n+1
                                                                  m m            m m m
                                                        P ={(x ,y ),...,(x ,y ),x             }.                          (3)
                                                         m        1   1          n   n     n+1
                           Thegoalis not to be able to explain the specification, but to apply the program shown in the specifi-
                           cation to a new input example xm , demonstrating generalization. This can be done via induction
                                                           n+1
                                                                           4
