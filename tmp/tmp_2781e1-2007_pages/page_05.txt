                                         Downloaded from http://rstb.royalsocietypublishing.org/ on March 30, 2015
                                                                Towards an executive without a homunculus      T. E. Hazy et al.   1605
                  (vi) Learning what and when to gate (for both mainten-      architectural and/or parametric constraints discovered
                       anceandoutput)isaccomplishedbyadopamine-               by evolution). That is, without such a learning
                       based reinforcement-learning mechanism that is         mechanism, our model would have to resort to some
                       capable of providing temporally appropriate            kind of intelligent homunculus to control gating.
                       learning signals to train gating update activity in       Our approach for simulating how the BG learn to
                       the striatal Go and NoGosynapses(Frank2005;            update task-relevant versus irrelevant working memory
                       O’Reilly & Frank 2006); this learning occurs in        information builds on prior work showing how the same
                       parallel for maintenance and for output. Thus,         basic mechanism can bring about the learning of the
                       each striatal medium spiny neuron (MSN)                appropriate selection of motor responses. Speciﬁcally,
                       develops its own unique pattern of connection          the BG are thought to learn to facilitate the selection of
                       weights enabling separate Go versus NoGo               the most appropriate response while suppressing all
                       decisions in each stripe.                              othercompetingresponses(Mink1996).Inourmodels,
                                                                              the BG learn the distinction between good and bad
                  Figure5showshowtheBG-mediatedselectivegating                responses via changes in dopamine ﬁring in response to
               mechanismcanenablebasicperformanceofthe1-2-AX                  reward signals during positive and negative reinforce-
               task. Whenataskdemandstimulusispresented(e.g.1),               ment (Frank 2005). The net effect is that increases in
               aBGgatingsignal(i.e.aGosignal)mustbeactivatedto                DA enhance BG Go ﬁring and learning via simulated
               enable a particular PFC stripe to gate in and retain this      D1 receptors, whereas decreases in dopamine during
               information (panel a), and no stripe (or NoGo ﬁring)           negative reinforcement have the opposite effect enhan-
               should be activated for a distractor such as C (panel b).      cing NoGo ﬁring and learning via simulated D2
               Adifferent stripe must be gated for the subsequent cue         receptors. This functionality enables the BG system to
               stimulus A (panel c). When the X stimulus is presented,        learn to discriminate between subtly different reinforce-
               the combination of this stimulus representation plus the       mentvaluesofalternativeresponses(Frank2005)andis
               maintained PFC working memory representations is               consistent with several lines of biological and beha-
               sufﬁcient to trigger a target response R (panel d).            vioural evidence (for review see Frank & O’Reilly 2006).
                  The need for an output-gating mechanism can be              This direct modulation of Go versus NoGo actions in
               motivated by considering a situation where a motor             BG can train the output-gating mechanism in our
               plan is being formulated. For example, you might be            model,whichisfunctionallythesameasamotorcontrol
               planning a sequence of steps (e.g. picking up a set of         gating mechanism.
               plates, condiments and other items sitting on the table           A similar logic applies to training maintenance
               after dinner) and need to ﬁgure out the best order to          gating: increases in dopamine reinforce BG Go ﬁring
               execute these steps. As you are juggling the possible          to gate information into working memory that contrib-
               orderings in your mind, you do not want to actually            utes to better performance at later time-steps, while
               execute those actions. Thus, the maintenance-gating            decreases in dopamine allow the model to learn that a
               function is enabling the updating of different action plan     current working memory state is contributing to poor
               representations, while the output gates remain closed to       performance (ﬁgure 5). In this manner, the BG
               prevent actual actions from being executed based on            eventually come to gate in information that is task-
               these plans. Then, once the plan is ready to execute, the      relevant, because maintenance of this information over
               output-gating mechanism ﬁre Go signals for each step           time leads to adaptive behaviour and reinforced
               of the plan in order. This coordination between                responses. Conversely, the system learns to ignore
               maintenance and output gating can apply to more                distracting information, because its maintenance will
               abstract cognitive operations in addition to concrete          interfere with that of task-relevant information and
               motor actions.                                                 thereforeleadtopoorperformance.TheoverallPBWM
                  In addition, even situations that may appear to only        modeloftheroleofthePFCandBGinworkingmemory
               require output-gating often require a maintenance-             makesanumberoffurtherpredictions,severalofwhich
               gating step as well. For example, in the motor domain          have been validated empirically (Frank et al. 2007).
               (where output gating is synonymous with motor action              From a computational perspective, maintenance
               gating), there are many cases where a motor plan must          gating also requires very speciﬁc mechanisms to deal
               ﬁrst be selected and maintained even for a few hundreds        with the temporal credit assignment problem. The beneﬁts
               of milliseconds, and this could beneﬁt from mainten-           of having encoded a given piece of information into
               ance gating. Thus, the clear implication of this overall       prefrontal working memory are typically only available
               formulation is that both output gating and maintenance         later in time (e.g. encoding the 1 task demand stimulus
               gating apply equally well to the action selection and          can only really help later (in terms of getting an actual
               working memory domains.                                        reward)whenconfrontedwithanA–Xsequence).Thus,
                                                                              the problem is to know which prior events were critical
               (c) Learning when to gate in the basal ganglia                 for subsequent good (or bad) performance.
               Of all the aspects of our model that purport to                   The ﬁring patterns of midbrain dopamine (DA)
               deconstruct the homunculus, learning when to gate is           neurons (ventral tegmental area, VTA; substantia nigra
               clearly the most critical. For any model, either the           pars compacta, SNc; both strongly innervated by the
               explicit knowledge of when to update working memory            BG) exhibit the properties necessary to solve the
               must be programmed in by the model’s designer or,              temporal credit assignment problem, because they
               somehow,amodelmustlearnitonitsown,relyingonly                  learn to ﬁre for stimuli that predict subsequent rewards
               on its training experience as it interacts with any            (e.g. Schultz et al.1993; Schultz 1998). This property is
               primitive built in biases and constraints (much like the       illustrated in schematic form in ﬁgure 6a for a simple
               Phil. Trans. R. Soc. B (2007)
