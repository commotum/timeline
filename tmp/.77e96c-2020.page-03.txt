                            interact with a PDE-solver that provides a coarse approximation to the problem. Hence, our models
                            always alternate between inference via an artiﬁcial neural network (ANN) and a solver step. This
                            distinguishes our work from studies of recurrent ANN architectures [11, 54, 62] as the PDE-solver
                            can introduce signiﬁcant non-linearities in-between evaluations of the ANN.
                            Wefocusonchaotic systems for which ﬂuid ﬂow represents an exciting and challenging problem
                            domain that is highly relevant for industrial applications. Deep learning methods have received
                            signiﬁcant amounts of attention in this area [31]. For example, both steady [19] and unsteady [40], as
                            well as multi-phase ﬂows [16] have been investigated with deep learning based approaches. Turbu-
                            lence closure modeling has been an area of particular focus [59, 38, 6]. Additionally, convolutional
                            neural networks (CNNs) were studied for stochastic sub-grid modeling [60], airfoil ﬂow problems
                            [56, 67], and as part of generative networks to leverage the fast inference of pre-trained models
                            [10, 66, 29]. Other studies have targeted the unsupervised learning of divergence-free corrections [57]
                            or incorporated PDE-based loss functions to represent individual ﬂow solutions via ANNs [43, 52].
                            In addition to temporal predictions of turbulent ﬂows [39], similar algorithms were more recently
                            also employed for classiﬁcation problems [20]. However, to the best of our knowledge, the existing
                            methods do not let ANNs interact with solver in a recurrent manner. As we will demonstrate below,
                            this combination yields signiﬁcant improvements in terms of inference accuracy.
                            While we focus on Eulerian, i.e., grid-based discretizations, the Lagrangian viewpoint is a popular
                            alternative. While a variety of studies has investigated graph-based simulators, e.g., for rigid-body
                            physics in the context of human reasoning [5, 64, 3] or weather predictions [51], particles are also a
                            popular basis for ﬂuid ﬂow problems [33, 61, 48]. Despite our Eulerian focus, Lagrangian methods
                            could likewise beneﬁt from incorporating differentiable solvers into the training process.
                            Ourworksharesthemotivation of previous work to use differentiable components at training time
                            [1, 14, 58, 9] and frameworks for differentiable programming [50, 25, 26, 23]. Differentiable physics
                            solvers were proposed for inverse problems in the context of liquids [49], cloth [34], soft robots
                            [25], and molecular dynamics [63]. While these studies typically focus on optimization problems or
                            replace solvers with learned components, we focus on the interaction between the two. Hence, in
                            contrast to previous work, we always rely on a PDE-solver to yield a coarse approximate solution
                            and improve its performance via a trained ANN.
                            2   Learning to Reduce Numerical Errors
                            Numerical methods yield approximations of a smooth function u in a discrete setting and invariably
                            introduce errors. These errors can be measured in terms of the deviation from the exact analytical
                            solution. For discrete simulations of PDEs, they are typically expressed as a function of the truncation,
                                  k
                            O(∆t ). Higher-order methods, with large k, are preferable but difﬁcult to arrive at in practice. For
                            practical schemes, no closed-form expression exists for truncation errors, and the errors often grow
                            exponentially as solutions are integrated over time. We investigate methods that solve a discretized
                            PDEPbyperformingdiscretetimesteps∆t. Eachsubsequentstep can depend on any number of
                            previous steps, u(x,t + ∆t) = P(u(x,t),u(x,t−∆t),...), where x ∈ Ω ⊆ Rd for the domain Ω
                            in d dimensions, and t ∈ R+.
                            Problem Statement:      Weconsider two different discrete versions of the same PDE P, with P
                                                                                                                              R
                            denoting a more accurate discretization with solutions r ∈ R from the reference manifold, and an
                            approximate version P with solutions s ∈ S from the source manifold. We consider r and s to be
                                                   s
                            states at a certain instance in time, i.e., they represent phase space points, and evolutions over time
                            are given by a trajectory in each solution manifold. As we focus on the discrete setting, a solution
                            over time consists of a reference sequence {r ,r     , · · · , r  } in the solution manifold R, and
                                                                         t  t+∆t        t+k∆t
                            correspondingly, a more coarsely approximated source sequence {s ,s         , · · · , s  }exists in
                                                                                                t  t+∆t        t+k∆t
                            the solution manifold S. We also employ a mapping operator T that transforms a phase space point
                            from one solution manifold to a suitable point in the other manifold, e.g., for the initial conditions of
                            the sequences above, we typically choose s = T r . We discuss the choice of T in more detail in the
                                                                      t       t
                            appendix, but in the simplest case, it can be obtained via ﬁltering and re-sampling operations.
                            Byevaluating P for R, we can compute the points of the phase space sequences, e.g., r            =
                                            R                                                                           t+∆t
                            P (r ) for an update scheme that only depends on time t. Without loss of generality, we assume
                             R t
                            a ﬁxed ∆t and denote a state rt+k∆t after k steps of size ∆t with rt+k. Due to the inherently
                            different numerical approximations, P (T r ) 6= T r      for the vast majority of states. In chaotic
                                                                   s    t        t+1
                            systems, such differences typically grow exponentially over time until they saturate at the level
                                                                             3
