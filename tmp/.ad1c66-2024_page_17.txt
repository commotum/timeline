             T. Han et al.                                                                               International Journal of Applied Earth Observation and Geoinformation 133 (2024) 104105 
                               Table 9
                               Comparison of computation costs with performance.
                                Method                                          Param. (M) ↓            FLOPs (G) ↓            Throughput (ins./s) ↑          mIoU (%) ↑
                                PointNet (Qi et al., 2017a)                     3.6                     35.5                   162                            41.1
                                PointNet++ (Qi et al., 2017b)                   1.0                     7.2                    237                            53.5
                                PointCNN (Li et al., 2018)                      0.6                     –                      –                              57.3
                                DGCNN (Wang et al., 2019b)                      1.3                     –                      8                              47.9
                                DeepGCN (Li et al., 2019a)                      3.6                     –                      3                              52.5
                                3D-GCN (Lin et al., 2020)                       0.6                     –                      –                              51.9
                                KPConv (Thomas et al., 2019)                    15.0                    –                      30                             67.1
                                AGConv (Wei et al., 2023)                       1.9                     3.6                    –                              67.9
                                Point Transformer (Zhao et al., 2021)           7.8                     5.6                    34                             70.4
                                ASSANet (Qian et al., 2021)                     2.4                     2.5                    300                            68.0
                                PointNeXt (Qian et al., 2022)                   41.6                    84.8                   43                             70.5
                                PointTransformerV2 (Wu et al., 2022)            12.8                    18.2                   –                              71.6
                                PointTransformerV3 (Wu et al., 2023)            46.2                    5.2                    –                              73.4
                                ASGFormer (Ours)                                19.0                    7.3                    155                            72.3
             Table 10
             Class-level evaluation on the Area 5 of S3DIS dataset. We compared against unsupervised (Unsup.) and weakly supervised (*% labeling efforts) approaches (%).
               Method                           Setting      Avg.     Ceiling    Floor    Wall    Column      Window      Door     Table    Chair     Sofa    Bookcase     Board     Clutter
               K-means                          Unsup.       38.4     59.8       63.3     34.9    24.6        34.2        29.3     35.7     33.1      45.0    45.6         41.7      30.4
               Ncut                             Unsup.       40.0     63.5       63.8     37.2    24.6        35.5        29.9     38.9     34.3      47.1    46.3         44.1      31.5
               Xia et al. (2023)                Unsup.       25.7     79.1       86.6     51.8    0.3         0.5         7.6      30.6     26.4      5.6     45.5         0.0       0.7
                    3
               U3DS (Liu et al., 2024)          Unsup.       42.8     –          –        –       –           –           –        –        –         –       –            –         –
               GrowSP (Zhang et al., 2023b)     Unsup.       44.5     –          –        –       –           –           –        –        –         –       –            –         –
               Xu and Lee (2020)                10%          48.0     90.9       97.3     74.8    8.4         49.3        27.3     69.0     71.7      16.5    53.2         23.3      42.8
               PSD (Zhang et al., 2021)         1%           63.5     92.3       97.7     80.7    27.8        56.2        62.5     78.7     84.1      63.1    70.4         58.9      53.2
               HybridCR (Li et al., 2022)       1%           51.5     85.4       91.9     65.9    18.0        51.4        34.2     63.8     78.3      52.4    59.6         29.9      39.0
               GaIA (Lee et al., 2023)          1%           53.7     –          –        –       –           –           –        –        –         –       –            –         –
               Li et al. (2024)                 1%           68.2     91.7       95.5     82.5    46.6        63.3        65.4     77.0     89.0      64.7    74.5         69.2      67.2
               SQN (Hu et al., 2022)            1%           63.6     92.0       96.4     81.3    21.4        53.7        73.1     77.8     85.9      56.7    69.9         66.5      52.4
               MSC (Su et al., 2023a)           1%           65.3     93.3       97.5     82.0    29.0        56.2        64.2     75.9     87.2      70.7    71.5         66.8      54.6
               DR-Net (Zhang and Bi, 2024)      1%           64.2     93.2       98.0     81.4    34.1        53.7        60.9     79.4     86.3      61.4    70.0         62.4      52.5
               UCL (Yao et al., 2024)           1%           68.2     93.4       97.3     82.6    25.7        59.9        66.3     81.9     89.7      75.9    75.4         78.5      60.0
               SQN (Hu et al., 2022)            0.1%         61.4     91.7       95.6     78.7    24.2        55.8        63.1     70.5     83.1      60.6    67.8         56.1      50.6
               DR-Net (Zhang and Bi, 2024)      0.1%         58.7     92.1       96.6     78.0    15.6        52.3        58.4     69.2     77.1      52.8    65.2         57.8      48.5
               UCL (Yao et al., 2024)           0.1%         65.4     93.3       97.2     82.0    26.5        60.3        62.1     79.2     85.6      68.4    73.7         65.7      55.6
               VIBUS (Tian et al., 2022)        0.02%        52.0     –          –        –       –           –           –        –        –         –       –            –         –
               Xu et al. (2023c)                0.02%        55.9     –          –        –       –           –           –        –        –         –       –            –         –
               ASGFormer (Ours)                 Ful. Sup.    72.3     93.4       98.5     84.9    41.1        61.1        82.7     83.6     92.0      80.8    77.8         78.6      63.2
             Table 11
             Class-level evaluation on the Toronto 3D dataset. We compared against weakly supervised (*% labeling efforts) approaches (%).
               Method                              Setting          Avg.         Road         Rd mrk.         Natural       Building        Uti. line       Pole         Car          Fence
               MSC (Su et al., 2023a)              1%               81.20        96.60        63.60           95.70         93.50           85.40           72.20        89.30        53.30
               PSD (Zhang et al., 2021)            0.1%             73.30        95.29        60.81           94.68         82.73           84.13           72.18        82.44        14.13
               SQN (Hu et al., 2022)               0.1%             77.75        96.69        65.67           94.58         91.34           83.36           70.59        88.87        30.91
               WSPointNet (Lei et al., 2022)        0.1%            78.96        96.70        66.99           94.89         90.79           83.68           75.71        88.37        34.54
               Liu et al. (2023a)                  0.1%             67.42        70.23        9.60            94.03         91.64           83.66           62.98        84.96        42.26
               DR-Net (Zhang and Bi, 2024)         0.1%             78.10        97.00        65.80           94.70         92.20           82.10           69.60        88.80        34.50
               DAAL-WS (Lei et al., 2024)          0.01%            81.91        97.67        73.42           96.27         92.35           83.57           78.03        91.82        42.16
               ASGFormer (Ours)                    Ful. Sup.        81.60        97.26        65.41           97.76         94.13           81.28           79.07        91.11        46.57
             Declaration of competing interest                                                          Guangdong Province, China with Grant No. 2024A1515010986. We
                                                                                                        also appreciate the valuable comments and constructive suggestions
                 No conflict of interest exists in the submission of this manuscript,                   from the anonymous reviewers that helped improve the manuscript.
             and all authors approve the manuscript for publication. All the authors
             listed have approved the manuscript that is enclosed. We sincerely                         References
             appreciate your consideration of our manuscript and look forward to
             receiving comments from the reviewers.                                                     Armeni, I., Sener, O., Zamir, A.R., Jiang, H., Brilakis, I., Fischer, M., Savarese, S.,
                                                                                                            2016. 3D semantic parsing of large-scale indoor spaces. In: Proceedings of the
             Data availability                                                                              IEEE Conference on Computer Vision and Pattern Recognition. pp. 1534–1543.
                                                                                                        Behley, J., Garbade, M., Milioto, A., Quenzel, J., Behnke, S., Stachniss, C., Gall, J.,
                 No data was used for the research described in the article.                                2019. Semantickitti: A dataset for semantic scene understanding of lidar sequences.
                                                                                                            In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp.
                                                                                                            9297–9307.
             Acknowledgments                                                                            Cho, H., Choi, I.S., 2018. Three-dimensionally embedded graph convolutional network
                                                                                                            (3dgcn) for molecule interpretation. arXiv preprint arXiv:1811.09794.
                 The authors would like to thank the National Natural Science Foun-                     Choromanski, K., Likhosherstov, V., Dohan, D., Song, X., Gane, A., Sarlos, T.,
                                                                                                            Hawkins, P., Davis, J., Mohiuddin, A., Kaiser, L., et al., 2020. Rethinking attention
             dation of China, and Basic and Applied Basic Research Foundation of                            with performers. arXiv preprint arXiv:2009.14794.
                                                                                                    17 
