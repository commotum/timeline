174 Â« Unified Theories of Cognition

havior to any particular sequence of choices, say, to move along the
state-operator-state path just described. For instance, in Figure 4-6
if the preference rejecting state s13 had not appeared, then the
decision procedure would have chosen to change the state s2 in the
supergoal rather than to install operator 07. Thus, at any point, any
choice can be made.

All the knowledge that guides the problem solving resides in the
productions. The decision procedure adds no knowledge of itself; it
just implements the fixed semantics of the concepts, accept, reject,
better, best, worse, worst, and indifferent. Behavior, of course,
needs to be directed. The goals and the goal stack provide the
context that lets that happen. Each level of the stack specifies a
subgoal of the level above, so the goal stack produces a goal-
subgoal hierarchy. In this respect, Soar is like most complex AI
problem-solving systems. In fact, one of the main things that has
been learned in AI is the effectiveness, and apparent necessity, of a
goal hierarchy, with goals, subgoals, and alternative subgoals, for
controlling behavior to achieve intelligent performance.

4.1.5, Impasses and Subgoals for Resolving Difficulties

So far, we have taken the conteat stack (the goal-subgoal hierarchy)
as given. The Soar architecture creates the goals dynamically as it
goes along. This is an important feature of Soar that contrasts sub-
stantially with the current state of the art. In essentially all AT
systems, subgoals are created dynamically, but oaly as predeter-
mined and stored in memory. Cast in terms of productions, the
situation is like that shown in Figure 4-7. The production reads: if
you are attempting to attain goal gO and if other conditions, C,, C2,
and so on, are satisfied, then set up g1, g2, and g3 as subgoals to be
attained. The subgoals are created deliberately in terms of the
methods the system has available to it.

Soar creates subgoals dynamically when it runs into impasses. It
might have occurred to the reader that there was something odd
about the decision cycle, as described above. Given an arbitrary
collection of preferences, what guarantees that the decision proce-
dure will yield a clear choice to be taken next? All kinds of things
could happen to prevent that. Suppose, just to be extreme, no
production proposed any new preference! What then? The extreme
simplicity of the decision cycle would seem illusory, because sub-
stantial complexities still need to be taken into account.

