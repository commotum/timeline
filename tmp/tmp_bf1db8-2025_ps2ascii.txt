                                                                     BIG-BenchExtraHard
                                                               1                          2                       1, 3                          1
                                      MehranKazemi ,BahareFatemi ,HritikBansal ,JohnPalowitch ,
                                                                                1                                      1                      2
                                       Chrysovalantis Anastasiou , Sanket Vaibhav Mehta , Lalit K. Jain ,
                                                                  1                      1                   1                              2
                                         Virginia Aglietti , Disha Jindal , Peter Chen , Nishanth Dikkala ,
                                                        1              2                  1                         1                           1
                                     GladysTyen , Xin Liu , Uri Shalit , Silvia Chiappa , Kate Olszewska ,
                                                               1                       1                   1                     1
                                                    Yi Tay , Vinh Q. Tran , Quoc V. Le , Orhan Firat
                                                        1Google DeepMind, 2Google Research, 3UCLA
                                                 Correspondence: mehrankazemi@google.comandbaharef@google.com
                                                 Abstract                                                                      Performance on BBEH
                                                                                                            Random
                           Current benchmarks for large language model                          Llama-3.1-8B-Instruct
                           (LLM)reasoningpredominantlyfocusonmath-                                   Gemma2-27B-IT               general-purpose models
                           ematical and coding abilities, leaving a gap                                Gemma3 27B
                                                                                                Gemini-2.0-Flash-Lite
                           in evaluating broader reasoning proficiencies.                           Gemini-2.0-Flash
                           One particular exception is the BIG-Bench                                         GPT-4o
                                                                                                 Distill-R1-Qwen-32B                reasoning models
                           dataset, which has served as a crucial bench-                               Deepseek R1
                           mark for evaluating the general reasoning ca-                               o3-mini(high)
                           pabilities of LLMs, thanks to its diverse set                                            0   5   10 15 20 25 30 35 40 45 50
                           of challenging tasks that allowed for a com-                                                     Harmonic Mean Accuracy (%)
                           prehensive assessment of general reasoning                         Figure 1: Model performances on BBEH (harmonic
                           across various skills within a unified frame-                      meanoverindividual task performances).
                           work. However, recent advances in LLMs
                           have led to saturation on BIG-Bench, and its
                           harder version BIG-Bench Hard (BBH). State-                        benchmarks in these domains and the relative ease
                           of-the-art models achieve near-perfect scores                      of evaluating quantitative solutions. However, rea-
                           on many tasks in BBH, thus diminishing its                         soning encompasses a far broader spectrum of cog-
                           utility.   To address this limitation, we intro-                   nitive skills, including logical deduction, temporal
                           duce BIG-Bench Extra Hard (BBEH), a new
                           benchmark designed to push the boundaries                          and spatial understanding, commonsense reason-
                           of LLMreasoning evaluation. BBEH replaces                          ing, and even the ability to comprehend humor.
                           each task in BBH with a novel task that probes                        Toassessthesediversereasoningfacets,thecom-
                           a similar reasoning capability but exhibits sig-                   munity has relied on the BIG-Bench benchmark
                           nificantly increased difficulty. We evaluate vari-                 (Srivastava et al., 2022), specifically its more chal-
                           ous general-purpose and reasoning-specialized                      lenging subset, BIG-Bench Hard (BBH) (Suzgun
                           models on BBEH and observe an accuracy                             et al., 2022). BBH has served as the de facto stan-
                           of 23.9% for the best general-purpose model
                           and 54.2% for the best reasoning-specialized                       dard for evaluating general reasoning in LLMs due
                           model, indicating substantial room for im-                         to its versatility and the wide array of reasoning
                           provement and highlighting the ongoing chal-                       skills it probes. However, the rapid progress in
                           lenge of achieving robust general reasoning in                     LLMdevelopmenthasledtoasaturationofBBH,
                           LLMs. Werelease BBEHpublicly at: https:                            with frontier models achieving over 90% accuracy
                           //github.com/google-deepmind/bbeh.                                 (e.g., Claude 3.5 reported an accuracy of 93.1% on
                      1 Introduction                                                          BBHinJune2024usinga3-shotprompt1). This
                      Reasoning, the ability to draw inferences and con-                      performance ceiling renders BBH less effective in
                      clusions from given information, is a cornerstone                       discriminating between the reasoning abilities of
                      of human intelligence and a critical frontier in the                    the latest generation of LLMs.
                      development of large language models (LLMs).                               To address this challenge, we introduce BIG-
                      While recent research has made significant strides                      BenchExtra Hard (BBEH), a benchmark designed
                      in evaluating the reasoning capabilities of LLMs,                       to assess advanced reasoning capabilities. BBEH
                      the focus has been disproportionately skewed to-                        builds upon BBH by replacing each of its 23 tasks
                      wards math/science and coding. This emphasis                            with a novel counterpart that probes similar reason-
                      is likely driven by the availability of challenging                         1www.anthropic.com/news/claude-3-5-sonnet
                                                                                        26473
                Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 26473–26501
                                                  July 27 - August 1, 2025 ©2025 Association for Computational Linguistics
                  ing capabilities, but exhibits significantly increased     the problems in BBH can be solved using shortcuts
                  difficulty. Solving the tasks in BBEH requires fur-        without solving the problem (for example, in the
                  ther reasoning skills than the problems in BBH.            geometric shapes task, whenever there are three L
                  These skills include, but are not limited to, many-        commandstheansweristriangle). Thirdly, while
                  hop reasoning, learning on the fly, finding errors         real-world reasoning problems typically require
                  in reasoning traces, processing long-context inputs        processing large amounts of input texts, the input
                  and finding (multi-)needles in a haystack, going           lengths of the problems in BBH are often quite
                  against strong prior, dealing with long-range de-          short with a macro average of 700 characters across
                  pendencies, dealing with distractors and inducing          tasks. Fourthly, since the problems were made to
                  patterns from examples. By presenting LLMs with            be challenging for the LLMs of the time, they typ-
                  problems that demand a wider array of reasoning            ically require only few hops of reasoning. And
                  capabilities, BBEHaimstoprovideamoreaccurate               finally, while BBH tests for a quite large and di-
                  measure of their general reasoning abilities.              verse set of skills, the set can be greatly expanded
                     Weprovideacomprehensiveevaluation of sev-               to include even more reasoning skills. The fast
                  eral state-of-the-art LLMs on BBEH. Our results            pace of improvement in the reasoning ability of
                  demonstrate that BBEH presents a significant chal-         the latest LLMs coupled with the limitations of the
                  lenge even for the most advanced models. Specifi-          BBHdatasetoutlinedabovehasledtoBBHgetting
                  cally, we observe a ceiling accuracy of 23.9% for          saturated with latest models achieving accuracies in
                  the best general-purpose model and 54.2% for the           the range of 90+ percent on it, thus causing BBH to
                  model reasoning-specialized model, highlighting            disappear from the latest model evaluation reports.
                  the substantial headroom for improvement in ro-              Wecreate a challenging benchmark for measur-
                  bust general reasoning for LLM. Furthermore, we            ing the general reasoning capability of LLMs by
                  conduct a detailed failure analysis, revealing in-         using BBH as a guide: we preserve the positive
                  triguing failure modes for both general-purpose            aspects of BBH and lift the limitations as much
                  LLMs and models specifically designed for rea-             as possible. Specifically, we create a benchmark
                  soning and thinking. These findings offer valuable         that is challenging for the frontier models, the cor-
                  insights into the current limitations of LLMs and          rectness of the model responses can be verified
                  provide guidance for future research aimed at en-          automatically despite being composed of several
                  hancing their reasoning capabilities.                      sub-tasks, the random chance baseline has a much
                  2 BeyondBIG-BenchHard(BBH)                                 lower success rate and the shortcuts are removed
                                                                             from the problems as much as possible, problems
                  Webelieve three key factors in the success of BBH          require processing longer inputs and require sig-
                  were the following: 1- it was challenging for the          nificantly more hops of reasoning to be solved,
                  frontier models at the time, thus helping reveal           and, perhaps most importantly, covers a wide array
                  areas for improvement, 2- despite being composed           of reasoning skills including those in the original
                  of various tasks, all the questions in BBH were in a       BBHdataset and beyond. Through studying the 23
                  waythatallowedforsimplecorrectnessverification             tasks in BIG-Bench Hard (BBH), we identify that
                  of model responses with a few simple rules, and            for a reasoner to perform well on BBH it needs to
                  3- perhaps most importantly, it tested for a vast          have at least the following broad reasoning skills:
                  array of reasoning skills making it a good proxy for      1- temporal understanding, 2- spatial and geomet-
                  measuring general reasoning. The latter factor is          ric understanding, 3- commonsense understanding,
                  in contrast to many existing reasoning benchmarks          4- humour understanding, 5- causal understanding,
                  that test only for a few of these skills as explained      6- reasoning about world entities and events, 7-
                  in the related work section.                               deductive logical reasoning, 8- reasoning through
                     Despite the great success of BBH and its                linguistic knowledge, 9- counting and filtering, 10-
                  widespread use, it also exhibited some key limi-           data structures and algorithms, and 11- performing
                  tations. Firstly, a random chance baseline already         arithmetic operations.
                  has a high performance on BBH due to the high                Forourbenchmark,wewishtopreservethehigh
                  numberoftasks with limited options (8/23 of the            diversity of the reasoning skills and capabilities
                  tasks have binary labels, and another 5/23 have at         from BBH and also expand upon it by including
                  most 5 options to choose from). Secondly, some of          moreofthefollowing skills.
                                                                       26474
                                                    Spatial Reasoning                                                              Buggy Tables
                             You have been given a diamond tile map consisting of N rows [...]           I have a table with 30 rows (including the header) and 18 columns.
                            There is a unique object placed at each vertex. [...] You are initially        The table was converted to Markdown format as follows: <TA-
                             at the top corner where you see a football. Then you move down-               BLEINMARKDOWNFORMAT>. However,the code used
                              right for one step and see a shampoo. Then you move down-left                to convert the table into Markdown format was buggy and mis-
                             for one step and you see a cat. [...] Then, you jump to a random               takenly replaced some values with "ERROR". The correct val-
                              vertex V where you see a bear. Then you move [...] Then you                    ues for those cells in row-order are respectively as follows:
                             move up-left and you see a shampoo. Then you jump back to the               [9,10,null,12,...,29]. Compute the absolute difference between
                              random vertex V and do the following moves: down-left, down-               the mean of coding_minutes and exercise_minutes, considering
                              left, down-right, up-left, down-left, up-left. What will you find?        only the days where: 1- The number of meetings was greater than 2.
                                                  Causal Understanding                                                             Word Sorting
                            Reagent X is being added to a tank. At each time interval, a drop of              Consider a new alphabet whose letters have the same or-
                           Reagent X is being added. At one point the tank overflows. Is adding             der as the English alphabet, except that r and p are swapped.
                           the last drop of Reagent X a necessary cause for the tank to overflow?           Sort the following words with the new alphabet and separate
                                                                                                            them with comma: syndrome, therefrom, [...], specifications.
                                                  Multistep Arithmetic                                                            BoardgameQA
                                          Consider the following new operations:                       Afew players are playing a boardgame. The current state of the game
                                                            a[]b     = [...]                            is as follows. The bee has a football with a radius of 15 inches. The
                                                                                                      chihuahua has a smoothie. [...]
                                                   ((a−b)∗b, ifa[]b<2                                 And the rules of the game are as follows.
                                          a@b=                                                        Rule1: Anyone who [...] has to pay $$$ to the beaver.
                                                     (b −a)∗a, otherwise                              Rule2: If the stork [...], then it does not pay $$$ to beaver.
                                                                                                        Rule 2 is preferred over Rule 1. If a rule is preferred over the other,
                              For brevity, we use a⟨op1⟩⟨op2⟩b to denote (aop1b)op2b.                    it means whenever both of them can be applied to derive new con-
                             Let A = ((((1 @*+ 4) <>+[] (-4 *<>* -1)) @; ((-1 <> six) ; (2 ;*               clusions and those conclusions contradict with each other, we
                              one))) @@@ (((five ;- five) []@@ (-8 - one)) ; ((two +; -5) +[]-           should go with the conclusion from the rule with higher preference.
                              (three - -8)))). Let B = [...]. Let C = [...]. Compute: A + B - C.                      What is the truth value of the statement:
                                                                                                                       "Does the finch shout at the mermaid?"
                                                     Dyck Language                                                               Time Arithmetic
                                   You are given an initial Dyck language sequence and                         Let the answer to Q1 be X and the answer to Q2 be Y.
                                  the steps, provided as thoughts, that were used to arrive           Q1: Clara and William were born on 2015-Aug-24 and 2016-May-20 re-
                                   at the closing bracket sequence in the Dyck language.              spectively. When William was 326 days old, how old was Clara in days?
                                  Your job is to identify the first step that was a mistake.                            Q2: <TEXT OF THE QUESTION>
                                      Task: Complete the rest of the sequence, mak-                   Define: X’ = X + 3,    Y’ = Y - 568
                                      ing sure that the parentheses are closed properly.                        Q3: Alan and Mary tried a new restaurant on Aug Y’,
                                                  Input: ( < < > [ (                                          1997 and really liked it. They decided to go to the same
                                   Thoughts: Thought 1: We should process each input                            restaurant every X′ days. If today is Oct 11, 1997,
                                   one by one and keep track of the stack configuration.                        when is the next time they will go to that restaurant?
                                  Thought 2: stack: empty Thought 3: (; stack: ( [...]
                                       Figure 2: Sample Questions from 8 tasks. The text has been shortened due to lack of space.
                             • Many-hopreasoning: The ability to solve a                                   • Needleinahaystack: theabilitytofindsmall
                               problem that require many steps/hops                                           pieces of relevant information from a large
                             • Very long-range dependency: the ability to                                     input (e.g., finding one value from a large
                               remember and use information provided or                                       table)
                               concluded much earlier in the context                                       • Finding errors in reasoning traces: the abil-
                             • Going against strong prior: the ability to                                     ity to identify the errors in a chain of reasoning
                               reason through a problem even when it does                                     not produced by the model itself
                               not match the prior beliefs (it has been shown                              • Inductive reasoning: the ability to induce
                               that models often fail and even exhibit inverse                                patterns from a number of examples and be-
                               scaling in such cases (McKenzie et al., 2023))                                 ing able to apply the same pattern to a new
                             • Learning on the fly: the able to learn some-                                   instance of a problem
                               thing new on the fly (i.e. from the information                             • Contraint satisfaction: the ability to under-
                               in the context) and apply it to solve a problem                                stand constraints and find a solution that satis-
                             • Dealing with distractors: The ability to iden-                                 fies them
                               tify the parts of the context necessary for solv-                           • Compositional understanding: the ability to
                               ing the problem, and not getting distracted by                                 solve multiple independent problems that are
                               the redundant information                                                      fusedintooneproblem(recentwork(Hosseini
                             • Long-context: the ability to reason through                                    et al., 2024; Miner et al., 2024) shows that
                               a long input context and stitching different                                   models may fail more often in solving two
                               pieces of input together                                                       problems composed into one, compared to
                                                                                                26475
                                     BBEHtask             SummaryofchangesmadeandthetaskitreplacesfromBBH                                                                                                     Mainreasoningskills
                                     Boardgame            Based on (Kazemi et al., 2023b) but with larger reasoning depth. Requires many hops of deductive reasoning as well as learning a specific           Deductive reasoning, learning on the fly,
                                     QA                   type of conflict resolution on the fly. Replaces Logical Deduction from BBH which needed only a few simple steps of deductive logic.                many-hopreasoning.
                                     Boolean      Ex-     Requires determining the truth value of an expression whose operands could themselves be textual/mathematical sub-expressions that                  Logical reasoning, many-hop reasoning.
                                     pressions            evaluate to True or False. Replaces the Boolean Expressions task from BBH which can be easily solved through one line of python code.
                                     BuggyTables          Requires understanding and reconstructing a large buggy table given the description of the bug, and then computing some conditional                 Datastructures, learningonthefly, needle
                                                          queries on it. Replaces Penguins in a table from BBH which required simple operations over small, clean tables.                                     in haystack
                                     Causal Under-        Asubsetofthecausalstories in (Nie et al., 2023) and improved examples from (Kıcıman et al., 2023). One subtask focuses on testing causal            Causal judgement/reasoning, logical rea-
                                     standing             judgment and the other on the ability to reason about necessary and sufficient causes. Replaces the Causal Judgement task from BBH.                 soning, counterfactual reasoning
                                     Disambiguation       A task created by the authors, requiring pronoun disambiguation over longer and more challenging text compared to the original                      Commonsenseunderstanding, linguistics
                                     QA                   Disambiguation QA task in BBH.                                                                                                                      knowledge.
                                     Dyck        Lan-     Involves finding errors in (potentially) faulty solutions to closing a sequence of brackets. It comes from (Tyen et al., 2023) and replaces the     Data structures, finding errors in reason-
                                     guage                Dycklanguages task from BBH which requires properly closing brackets as opposed to finding errors.                                                  ing traces.
                                     Geometric            Requires identifying the set of shapes drawn by a series of SVG commands while also dealing with distracting commands that do not                   Spatial reasoning, geometric understand-
                                     Shapes               participate in any shape. Replaces the Geometric Shapes from BBH which involved identifying a single shape.                                         ing, dealing with distractors.
                                     Hyperbaton           Requires inducing correct adjective order given examples on a new variant of English, and properly apply it to new examples. Replaces               Inductive reasoning, going against strong
                                                          Hyperbaton from BBH which required simply knowing the correct adjective order in English.                                                           prior, linguistic knowledge.
                                     Linguini             Comesfrom(Sánchezetal.,2024)andrequires linguistic reasoning and inductive reasoning to learn about a new language given some                       Inductive reasoning, linguistic knowl-
                                                          examples and then apply those learnings. Replaces Salient Translation Errors from BBH which involved simpler linguistic understanding.              edge.
                                     Movie Recom-         Given a number of sets of movies, the task is to determine which set has movies that are all likely to be liked by a specific group of people.      Reasoning through knowledge
                                     mendation            Replaces Movie Recommendation from BBH which required simple next movie recommendation.
                                     Multi-step           Requires learning new arithmetic operations and their compositions on the fly, and apply them to evaluate long expressions. Replaces the            Learning on the fly, many-hop reasoning.
                                     Arithmetic           Multi-step Arithmetic task from BBH which involved simple arithmetic over basic operations.
                                     New      Yorker      Comesfrom(Hesseletal., 2022; Zhang et al., 2024) and requires selecting the funniest caption for an image. We adopt the variant that                Humour understanding, commonsense
                                     Cartoon    Cap-      predicts the best caption only given the textual description of the image. This replaces the Ruin Names task from BBH which involved                understanding.
                                     tion (NYCC)          simpler humour understanding.
                                     Object Count-        Requires counting the number of objects of a certain type given a very long list of various objects and in presence of many types of                Long-context,     (multi-)needle    in   a
                                     ing                  distractors. Replaces the Object Counting from BBH which required simple counting in a short context.                                               haystack, dealing with distractors.
                                     Object Proper-       Requires keeping track of a large collection of objects with various properties while they go through multiple rounds of modification.              Temporal track keeping, long-range de-
                                     ties                 Replaces Colored Objects from BBH which required only recognizing the color of some objects.                                                        pendency.
                                     SARCTriples          Requires understanding sarcasm in Reddit posts and replies. Each problem requires determining the sarcastic-ness of three post/reply pairs.         Commonsense and sarcasm understand-
                                                          Replaces the Snark task in BBH which required simpler sarcasm understanding.                                                                        ing, compositional reasoning.
                                     Shuffled    Ob-      Along-context variant of the original Shuffled Objects from BBH which may also require remembering very long-range information.                     Temporal track keeping, long-context,
                                     jects                                                                                                                                                                    long-range dependency.
                                     Spatial Reason-      Adopts the SpatialLLMEval (Yamada et al., 2023) dataset requiring spatial reasoning over complex patterns and expands it to require                 Spatial understanding, many-hop reason-
                                     ing                  many-hops of reasoning. Replaces the navigation task from BBH which requires much simpler spatial understanding of navigation signals.              ing, long-range dependency.
                                     SportQA              Comes from (Xia et al., 2024) and requires reasoning combined with a high amount of sports knowledge. We use the hardest subset                     Knowledge-intensive reasoning, compo-
                                                          containing compositional questions. Replaces Sport Understanding from BBH which needed much simpler reasoning over sport knowledge.                 sitional reasoning.
                                     Temporal             Requires finding proper meeting times given multiple calendars (each corresponding to a temporal sequence) and various constraints.                 Temporal understanding, constraints sat-
                                     Sequences            Replaces the Temporal Sequence task from BBH which involves understanding only a single sequence.                                                   isfaction.
                                     Time      Arith-     ComesfromtheTestofTimebenchmark(Fatemietal.,2024)andinvolvesvariousoperations over various representations of date/time. We                         Temporal reasoning, compositional un-
                                     metic                created a compositional version of this task following (Hosseini et al., 2024). Replaces the Date Understanding task from BBH which                 derstanding.
                                                          involved significantly simpler operations over dates.
                                     WebofLies            Requires many-hop reasoning to predict the truthfulness of a set of people, and contains two subsets: one coming from the variant used in           Logical reasoning, many-hop reasoning.
                                                          LiveBench (White et al., 2024) and one novel variant that involves cases where the truthfulness of some individuals remains unknown but
                                                          newconclusions can be drawn from it nevertheless. Replaces the Web of Lies from BBH which involved simpler cases of this problem.
                                     WordSorting          Contains two subtasks: 1- sorting over a modified alphabet order, which goes against the strong prior of the model, and 2- finding errors in        Apply algorithms, Going against strong
                                                          sorting traces. Replaces the original Word Sorting task which required simple sorting.                                                              prior, Finding errors in reasoning traces.
                                     Zebra Puzzles        This is based on puzzles from (Shah et al., 2024) and requires applying various logical deduction rules to be solved. We add distracting            Constraint satisfaction, many-hop reason-
                                                          clues for extra challenge. Replaces Formal Fallacies from BBH which requires understanding formal fallacies in much simpler setups.                 ing, distractors, long-range dependency.
                                  Table 1: The tasks in BBEH in alphabetical order of the names, a high-level description of what they test for, the
                                  reasoning capabilities that they probe, and the task from BBH that they replace.
                                             solving the two problems in isolation)                                                                high diversity of original BBH dataset. In Table 1,
                                         • Knowledge-intense reasoning: the ability to                                                            weoutline a high-level description of the new tasks
                                             reason in domains where a great amount of                                                             in BBEH, how they have been constructed and
                                             domain knowledge is needed                                                                           whichtaskfromBBHthereplace,andwhatreason-
                                                                                                                                                   ing skills they target. The benchmark contains 200
                                  3 BIG-BenchExtraHard                                                                                             questions per task, except for the Disambiguation
                                                                                                                                                  QAtask where we have 120 questions. For more
                                  We create BIG-Bench Extra Hard (BBEH), a                                                                         details about the tasks and some intuitions from the
                                  dataset that tests the general reasoning capability                                                              experimental results and model failure modes, see
                                  of models on a wide array of reasoning skills. To                                                               AppendixA.Samplesfromafewofourtasksare
                                  this end, we build on the success of BBH and re-                                                                 provided in Figure 2.
                                  place each of the 23 tasks in BBH with another task
                                  that is in a similar reasoning domain and tests for                                                                   Akey challenge in creating model evaluation
                                  similar (or more) skills, but is more challenging                                                                benchmarks is ensuring they remain difficult for
                                  compared to the original one. Replacing each task                                                                frontier models. This is particularly true for rea-
                                  with another one in the same domain that tests for                                                               soning benchmarks, given the rapid progress in the
                                  similar capabilities ensures that we preserve the                                                                field over the past year, and especially for BBEH,
                                                                                                                                         26476
                 which comprises 23 distinct tasks, each requir-      following sections. However, this approach also
                 ing careful design. To ensure our tasks challenge    has some notable limitations. Firstly, the choice
                 frontier models, we adopted a semi-adversarial ap-   of the reference model will unavoidably bias the
                 proach. We selected two strong reference models:     benchmark towards certain types of failure modes.
                 one general-purpose and one specialized in reason-   For instance, had our reference model not used
                 ing. We iteratively increased task difficulty while  code to solve the multi-hop Boolean expressions,
                 keeping in mind the extra skills that we wanted      we might have stopped there, resulting in a task
                 our benchmark to test for, evaluating the reference  too easy for models that appropriately trigger code.
                 models on each new iteration. If a task proved       Wetried to mitigate this as much as possible by
                 insufficiently challenging, we either replaced it    using strong reference models, and by avoiding
                 with another task or added extra types of difficulty over-engineering to the reference model failures.
                 and re-evaluated until the difficulty level was sat- Secondly, since the benchmark is created adver-
                 isfactory. We used Gemini 1.5 Flash (Team et al.,    sarially with respect to the reference models, a
                 2024a)asourgeneral-purposereferencemodeland          fair comparison of the reference and non-reference
                 the Gemini Thinking Experimental model as our        models may not be possible. We expect this limita-
                 reasoning-specialized reference model (initially the tion to be temporary and be resolved when newer
                 December 2024 version but later changed to the       versions of the reference models become available.
                 January 2025 version, known as Gemini-2.0-Flash-        BBEH Mini: Besides reporting results on
                 Thinking-Exp-01-21). These models were chosen        BBEH,wealsoreportresults on a smaller subset
                 for their performance and the speed of generating    called BBEH Mini which contains 460 examples
                 outputs, whichfacilitatedrapiditerationduringtask    overall (20 examples randomly selected from each
                 construction. We iterated on each task until both    task). This subset can be used for faster and cheaper
                 reference models achieved an accuracy below 70%.     experimentations.
                   In most cases, we tried to use the reference mod-
                 els only as a black box that provided feedback on    4 ResultsandAnalyses
                 the difficulty of our tasks. In some cases, how-     Westart by analyzing the BBEH dataset and com-
                 ever, making tasks more difficult required looking   paring it against its counterpart, BBH. We then
                 into the approach adopted by the model. As an        report results on BBEH for various models and
                 example, the original "Boolean Expression" task in   compare their performances. Then, we provide
                 BBHrequired models to evaluate the truth value       someextraanalysis of the results revealing interest-
                 of expressions such as (not True) or False. Our      ing insights about where reasoning-specialized and
                 initial attempt to increase difficulty involved cre- larger models gain more and where they gain less
                 ating longer expressions with significantly more     compared to general-purpose and smaller models
                 clauses. However, our reference model achieved       respectively. We also provide a large body of ob-
                 high accuracy regardless of the number of clauses.   servations and insights from task-specific results in
                 Whileinitially this seemed surprising, upon investi- Appendix A.
                 gating the model’s approach, we discovered it clev-
                 erly used Python to solve the problem by directly    4.1   BBEHAnalysis
                 evaluating the expression: result = <expression>;
                 print(result). Thus, adding more clauses did not     RequiredAmountofThinking: Manyoftheprob-
                 have much effect in increasing difficulty. Our next  lems in BBH only require few hops of reasoning,
                 step was to prevent the model from using Python.     sometimesnotrequiringagreatamountofthinking.
                 We achieved this by replacing some "True" and        Asaproxyformeasuringthe amount of thinking
                 "False" clauses with sentences that evaluated to the required by BBEH and compare it to BBH, we
                 sametruth value (e.g., replacing "True" with "The    compare the average length of the outputs gener-
                 capital of Canada is Ottawa.").                      ated by a fixed model (Gemini 2.0 Flash) for the
                   Given the similarity of the high-level approach    two datasets. The results are presented in Figure 3.
                 in creating LLM reasoners (architecture, train-      From the figure, we can observe that the average
                 ing phases, etc.), we believe our semi-adversarial   length of the output has significantly increased for
                 benchmark construction can lead to a benchmark       every single one of the tasks in BBEH compared to
                 that is also challenging for non-reference models.   their counterpart in BBH, thus providing evidence
                 This is confirmed by the experimental results in the that the problems in BBEHmayrequiremuchmore
                                                                  26477
                                                                                                                                      Average output length
                                         104                                                                                                                                                                                                     Benchmark
                                                                                                                                                                                                                                                       BBEH
                                                                                                                                                                                                                                                       BBH
                                         103
                                        ength in characters
                                        L
                                                                 ables                                                                              CC
                                                      essions                                                       Linguini                      NY             operties    riples                  SportQA                                        uzzles
                                          dgameQA                                                                                                               r         C T              easoning                            eb of liesd Sorting
                                                                                                       Hyperbaton                                                     SAR                                                    W        or
                                      Boar               Buggy T                                                                                                                                                ime Arithmetic      W       Zebra P
                                                                                 Dyck Languages                      ecommendation              Object Counting            Shuffled Objects                    T
                                                                                        Geometric Shapes                                                Object P                  Spatial R
                                                                      DisambiguationQA                                                                                                              emporal Sequence
                                         Boolean Expr    Causal Understanding                                             Multistep Arithmetic                                                     T
                                                                                                             Movie R
                                   Figure 3: A comparison of the average output lengths of the Gemini 2.0 Flash responses for each of the tasks in
                                   BBEHandtheircounterparts in BBH, as a proxy for the required amount of thinking.
                                   thinking. The macro average output length of the                                                                   are susceptible to distortion by outlier performance,
                                   responses for tasks in BBEH is about seven times                                                                   potentially presenting a misleadingly optimistic
                                   bigger than that of BBH.                                                                                           assessment when a model excels in a limited sub-
                                        Input/Context Length: As mentioned in Sec-                                                                    set of tasks while faltering in others. To address
                                                                                                                                                                                                                                                              3
                                   tion 2, the problems in the original BBH dataset                                                                   this, we employ the (adjusted) harmonic mean
                                   are mostly short. On the contrary, the problems                                                                    as our primary evaluation metric for BBEH. The
                                   in BBEHtendtobequitelongandrequire a great                                                                         harmonic mean provides a more conservative and
                                   amountofinputprocessingbythemodels. Figure6                                                                        balanced representation of overall performance, ef-
                                   (in Appendix) compares the average input lengths                                                                   fectively penalizing models with significant per-
                                   of each of the tasks in BBEH with their counterpart                                                                formance disparities across different tasks, thereby
                                   from BBH.Fromthefigure, one can observe how                                                                        aligning more closely with the requirement for con-
                                   input lengths have increased for almost all the tasks                                                              sistent, general reasoning capabilities. We also
                                   (except two), sometimes quite significantly. The                                                                   report micro average accuracies for completeness.
                                   macroaveragecontext length of the tasks in BBEH                                                                    For BBEHMini,duetothesmallnumberofexam-
                                   is about six times bigger than that of BBH.                                                                        ples per task, harmonic mean may be too noisy, so
                                                                                                                                                      weonlyreport micro average.
                                   4.2         ModelEvaluations                                                                                            Theresultsforeachtaskandontheentiredataset
                                   Models: We evaluate various models on BBEH                                                                         for each model is presented in Table 2 and in Ta-
                                   and compare their performance across individual                                                                    ble 3 for BBEH Mini. According to the results,
                                   tasks and on the entire dataset. Specifically, we                                                                  wemakeseveral interesting observations. Firstly,
                                   experiment with models from the following fam-                                                                     weobserve a large headroom not only for the in-
                                   ilies: Llama 3.1 (Dubey et al., 2024), Qwen 2.5                                                                    dividual tasks, but also for BBEH overall. The
                                   (Yang et al., 2024a), Gemma2 (Team et al., 2024b),                                                                 best performance for the general-purpose models
                                   Gemma3(Teametal.,2025),Gemini2.0,GPT4o                                                                             is at 23.9% micro average accuracy. The reasoning-
                                   (the latest version, 2024-11-20, at the time of the                                                                specialized models are expectedly performing bet-
                                   experiments) (Achiam et al., 2023), DeepSeek R1                                                                    ter than the general-purpose models on the bench-
                                   and the Distilled model in Qwen 32b (Guo et al.,                                                                   mark, but the best performance for these models
                                   2025), and o3-mini (high)2.                                                                                        is still at 54.2% on BBEH. Note that while we
                                        Metric: Given the highly versatile use-cases of                                                               calibrated the difficulty with respect to two refer-
                                   the current LLM reasoners, they should be capable                                                                  encemodelssotheiraccuraciesfallbelow70%,the
                                   across the board to excel at real-world problems                                                                   difficulty mostly carries to other models too with
                                   and be robust general reasoners. However, we find                                                                  o3-mini (high) exceeding 70% accuracy only on 4
                                   that micro and macro averages (which are often                                                                     out of 23 tasks, DeepSeek R1 exceeding it only on
                                   used for benchmarks composed of multiple tasks),                                                                   3outof23tasks,andothermodelsneverexceeding
                                   fail to capture this crucial aspect. These metrics                                                                 it. Despite the adversarial construction, the refer-
                                                                                                                                                            3To deal with zero values, we add a value of 1 to all accu-
                                         2https://openai.com/index/openai-o3-mini/                                                                    racy numbers.
                                                                                                                                           26478
                                                                                                             32b
                                                          InstructIT
                                                          8b    27b   4b     12b   27b    Flash-LiteFlash    Qwen  R1
                                                          3.1                             2.0   2.0          R1           (high)
                       Tasks/Models          RandomQwen-2.5-7B-InstructLlamaGemma2Gemma3Gemma3Gemma3GeminiGeminiGPT4oDistillDeepSeeko3-mini
                       BoardgameQA        33.3   31.0  31.5  39.5   34.5  33.0   37.0  29.5   42.5  41.0  36.0   75.5  53.0
                    Boolean Expressions   20.0   22.0  18.0  25.0   23.0  25.5   22.0  24.0   27.0  22.5  17.5   55.5  67.0
                       BuggyTables         0.0   1.5    0.0   0.5   0.5    0.0   0.0    1.5   3.5   0.5    0.5   4.5   59.5
                    Causal Understanding  38.0   40.0  37.0  45.5   46.0  49.0   51.5  52.5   52.0  54.0  54.5   54.5  54.0
                     DisambiguationQA     21.0   34.2  36.7  45.0   33.3  41.7   49.2  50.0   48.3  51.7  52.5   50.0  58.3
                      DyckLanguages        1.4   1.0    4.5   2.0   3.5    8.5   4.5    6.5   14.0  8.0   18.0   56.0  55.0
                     Geometric Shapes      6.2   41.5  25.5  31.0   18.0  32.5   26.5  30.0   35.0  22.5   4.5   1.5   52.5
                        Hyperbaton         0.0   0.5    2.0   4.0   2.0    2.5   3.5    6.5   4.5   7.5    3.0   6.0   32.0
                         Linguini          0.0   2.5    3.0   7.0   1.0    6.0   9.0   12.5   15.5  15.5   6.0   19.5  17.0
                   MovieRecommendation    10.0   24.5  30.0  40.0   35.0  44.5   55.0  51.5   59.5  61.0  46.0   59.5  84.0
                    Multistep Arithmetic   0.0   0.0    0.5   0.0   0.0    0.5   1.5    7.5   9.5   5.5   36.0   46.5  73.0
                          NYCC            10.0   13.0  13.0  13.5   7.0   11.5   15.0  13.5   11.0  23.0  10.5   20.0  16.0
                      Object Counting      0.0   0.0    0.0   0.0   0.0    0.5   0.0    4.0   11.0  6.5    4.0   76.5  90.0
                      Object Properties    1.6   0.0    0.5   0.0   0.5    1.5   0.5    0.5   1.5   0.0    0.0   0.0   56.5
                       SARCTriples        12.5   17.5  16.5  21.0   14.0  26.0   24.0  27.0   37.5  38.5  22.0   28.5  24.0
                      Shuffled Objects    14.3   8.0    9.5  12.0   1.0    7.0   5.0   15.0   9.0   14.0   2.0   6.0   49.5
                     Spatial Reasoning     5.2   0.0    1.0   7.0   4.0   10.5   13.0  10.5   18.5  14.0  14.5   37.0  48.5
                         SportQA           0.0   5.0    1.5  10.0   2.5   12.5   20.0  18.5   23.0  25.0  19.5   29.0  26.5
                    Temporal Sequences     0.0   0.5    9.5   1.5   1.0    0.0   1.5    1.0   0.5   0.0    0.5   0.0   68.5
                      TimeArithmetic       0.5   18.5   4.0  15.5   9.5   23.5   46.5  45.0   48.0  45.5  56.5   77.0  76.5
                        WebofLies          5.5   2.5    5.5   6.5   12.0  22.0   21.0  14.0   18.5  14.5  13.0   29.5  43.0
                       WordSorting         4.3   4.0    2.5   3.5   4.5    6.0   7.5   12.5   26.0  22.0  36.0   68.0  77.5
                       Zebra Puzzles      15.4   19.0   2.5  23.0   10.0  19.5   30.0  32.0   44.5  32.0   1.5   8.0   67.5
                   BBEH(MicroAverage)      8.4   12.5  10.6  14.8   11.0  16.3   18.8  19.7   23.9  22.3  19.2   34.9  54.2
                  BBEH(HarmonicMean)       2.4   3.0    3.6   4.0   3.4    4.5   4.9    8.0   9.8   6.0    5.2   6.8   44.8
                            Table 2: The performance of various models on the individual tasks and overall on BBEH.
                 ence Thinking model achieves a (micro) average         baseline to have a high performance. In Table 2, we
                 accuracy of 32.8% and a harmonic average accu-         provide the results of a random baseline for each
                 racy of 20.2% on BBEH. Note that some model            of the tasks in BBEH and the entire dataset. As can
                 accuracies are even below random performance.          be viewed, the random baseline has a performance
                 Uponchecking, we observe that these are mostly         of 8.4% for BBEH which leaves substantial room
                 cases where models could not solve the problem         for comparing models of various size.
                 in their effective output token lengths and started      Finally, looking at the accuracies of the models
                 degenerating after a point, so no final answer could   onvarioustasks,wecanseethatvariousmodelsare
                 be extracted from their solution.                      goodatdifferent types of reasoning. For example,
                   Secondly, the harmonic mean accuracies reveal        DeepSeekR1significantly outperforms other mod-
                 an even larger headroom: the best general-purpose      els on BoardgameQA, o3-mini (high) significantly
                 modelhavingaharmonicmeanaccuracyof9.8%                 outperforms other models on Temporal Sequences
                 andthebestreasoning-specialized model having an        and Object Properties, GPT4o significantly outper-
                 accuracy of 44.8%. Interestingly, while DeepSeek       forms other models on NYCC, and GPT4o and
                 R1performsbetter than all general-purpose mod-         Gemini 2.0 Flash significantly outperform other
                 els in terms of micro average accuracy, given its      models on SARCTriples.
                 low performance on some of our tasks it performs       4.3  Further Analyses of the Results
                 worse than two of the general-purpose models in        General-Purpose vs Reasoning Models: With
                 terms of harmonic mean accuracy.                       the introduction of reasoning models that leverage
                   Thirdly, as mentioned in Section 2, the problems     test-time compute for thinking, a tremendous jump
                 in the original BBH dataset suffered from having       in performance was observed on reasoning tasks
                 a small output space, thus allowing for a random       involving math and coding. For example, on the
                                                                   26479
                                                                                                         32b
                                             InstructIT
                                             8b      27b    4b      12b    27b     Flash-LiteFlash       Qwen   R1
                                             3.1                                   2.0    2.0            R1            (high)
                        Tasks/Models         Llama   Gemma2 Gemma3  Gemma3 Gemma3  Gemini Gemini GPT4o   DistillDeepSeeko3-mini
                        BBEHMini          11.5    15.0   13.3    14.3   17.4   22.2    27.0   23.5    15.4   37.2   56.7
                      (Micro Average)
                                   Table 3: The performance of various models on BBEH Mini (micro average).
                     riplesCC                                                easoning uzzlesessions     opertiesables
                     C T  NY       LinguiniSportQAdgameQAecommendationeb of Lies                    d Sortingr
                     AR                                   HyperbatonW                               or
                     S                           Boar                   ime ArithmeticZebra P       W        Buggy T
                                            DisambiguationQA       Geometric ShapesTSpatial RShuffled ObjectsBoolean ExprDyck LanguagesObject PMultistep Arithmeticemporal SequencesObject Counting
                              Causal Understanding   Movie R                                                          T
                 Figure 4: Performance gains (absolute) of o3-mini (high) over GPT-4o on BBEH tasks. Tasks are ordered
                 bythe magnitude of improvement, with green signifying substantial gains and yellow/red signifying minimal or
                 negative gains.
                 AIME2024dataset,theperformanceofGPT4owas                 as the case where we compared general models
                 13.4%, but the o1 model increased it to 83.3% and        against reasoning models, we still observe that the
                 o3-mini (high) increased it further to 87.3%. Here,      tasks related to humour, commonsense, and causal
                 weexamine whether the same is true for various           reasoning are the ones with the least gains, and
                 types of general reasoning. In Figure 4, we com-         tasks requiring many-hop reasoning or applying
                 pare o3-mini (high) and GPT4o, as examples of            algorithms are the ones with the largest gains. A
                 reasoning and general models respectively, on each       particular exceptionistheSARCTriplestaskwhich
                 of the tasks from BBEH and sort the tasks ascend-        is a sarcasm understanding and where the gains are
                 ing based on how much o3-mini (high) gains over          large. This could in part be due to the fact that each
                 GPT4o. We observe that the tasks that gain the           example in SARC Triples is a composition of three
                 most are those involving counting, planning, arith-      sub-questions, and larger models may be better at
                 metic, and data structures and algorithms. Whereas       dealing with such composite questions.
                 the tasks that gain the least (or sometimes nega-          TheEffect of Context Length and Required
                 tively) are mostly those involving commensense,         Thinking: The tasks in BBEH come at different
                 humour, sarcasm, and causation. Our results indi-        average context lengths (see Figure 6) and may re-
                 cate that reasoning models achieve the most sig-         quire different amount of thinking (as shown using
                 nificant gains when applied to formal problems           the output length proxy in Figure 3). We use this
                 and demonstrate limited progress in handling the         property to understand the effect of context length
                 softer reasoning skills which are typically needed       andrequired thinking on reasoning vs general mod-
                 for complex, real-world scenarios.                       els, and on larger vs smaller models. To this end, in
                    ModelSizeEffect: In Figure 7 (in Appendix),           Figure 5 we compare the performance of o3-mini
                 wecompareGemini2.0FlashagainstGemini2.0                 (high) vs GPT4o and Gemini 2.0 Flash vs Gem-
                 Flash-Lite on different tasks from BBEH and sort         ini 2.0 Flash-Lite as a function of average context
                 the tasks ascending based on how much Flash gains        chance due to not generating an extractable final answer. To
                 over Flash-Lite4. While the signal is not as clear       reduce noise for this analysis, in such cases we assumed the
                                                                          performance of the model is the same as the random chance
                    4In some cases, these models perform below random     performance for the task.
                                                                     26480
                                                                                                 25                                                                                25
                               l80        General vs Reasoner                 Larger vs Smaller                 l 80        General vs Reasoner                 Larger vs Smaller
                                                                                                 20             a                                                                  20   r
                               a                                                                       r        r                                                                       e
                               r                                                                                e                                                                       l
                               e                                                                       e        n 60                                                                    l
                                                                                                       l
                               n60                                                                     l        e                                                                  15   a
                               e                                                                 15    a        G                                                                       m
                               G                                                                       m                                                                                S
                                                                                                       S        s                                                                        
                               s                                                                                v                                                                       s
                               v                                                                       s          40                                                               10   v
                                40                                                               10    v        r                                                                        
                               r                                                                                e                                                                       r
                               e                                                                       r        n                                                                       e
                               n                                                                       e        o                                                                       g
                               o                                                                       g        s 20                                                               5    r
                               s20                                                               5     r        a                                                                       a
                               a                                                                       a        e                                                                       L
                               e                                                                       L        R                                                                        
                               R                                                                                                                                                   0
                                                                                                 0                 0
                                 0                                                                                                                                                  5
                                                                                                   5                     1000   2000   3000   4000    5000   6000   7000   8000
                                           2000      4000      6000       8000     10000                                    Average Output Length for the Task 
                                          Average Context Length for the Task                                       (Proxy for how much thinking the task may need)
                          Figure 5: Performance gains as a function of (left) context length and (right) output length (proxy for required
                          thinking). A scatter plot and line fit for the gains obtained by a reasoning-specialized model (o3-mini high) vs a
                          general-purpose model (GPT4o) and a larger model (Gemini 2.0 Flash) vs a smaller model (Gemini 2.0 Flash-Lite),
                          as a function of (left) the average context lengths and (right) the average output lengths, for the tasks in BBEH.
                          lengths of the tasks and average output length as                                   LLMsincomplex,real-world applications.
                                                                         5
                          a proxy for required thinking .. We observe that                                    Limitations
                          the gains of o3-mini tend to increase compared
                          to GPT4o both when context length increases and                                     As explained in the main text, BBEH has been
                          whentherequired thinking increases, showing how                                     constructed semi-adversarially with respect to two
                          reasoning models may have improved across both                                      reference models. This leads to two limitations: 1-
                          directions compared to general models. For Gem-                                     it will unavoidably bias the benchmark towards cer-
                          ini 2.0 Flash vs Gemini 2.0 Flash-Lite, we see a                                    tain types of failure modes, 2- since the benchmark
                          similar increase in gains when the context length                                   is created adversarially with respect to the refer-
                          increases, but the curve for the case of increased                                  ence models, a fair comparison of the reference
                          thinking remains mostly flat.                                                       and non-reference models may not be possible.
                          5 Conclusion                                                                        Acknowledgements
                          Recent advances in LLM reasoning has made these                                     We acknowledge the help from Vahab Mirrokni,
                          models reach near ceiling performance on exist-                                     Tania Bedrax-Weiss, Don Metzler, Javad Hosseini,
                          ing general reasoning benchmarks such as BIG-                                       Phoebe Kirk, and Katherine Tong.
                          Benchanditsharder variant BBH, and shifted fo-
                          cus toward other types of more focused reasoning.
                          However, substantial distance remains before we                                     References
                          can claim these models posses true mastery of di-                                   Josh Achiam, Steven Adler, Sandhini Agarwal, Lama
                          verse reasoning skills. To rekindle the pursuit of                                      Ahmad, Ilge Akkaya, Florencia Leoni Aleman,
                          truly robust and versatile LLM reasoners, we pre-                                       Diogo Almeida, Janko Altenschmidt, Sam Altman,
                          sented BIG-Bench Extra Hard (BBEH), a signifi-                                          ShyamalAnadkat,etal.2023. Gpt-4technicalreport.
                          cantly more challenging successor to BBH. This                                          arXiv preprint arXiv:2303.08774.
                          new benchmark, meticulously crafted to amplify                                      RohanAnil, Andrew M. Dai, Orhan Firat, Melvin John-
                          the difficulty of existing tasks while preserving                                       son, Dmitry Lepikhin, Alexandre Passos, Siamak
                          their core diversity, reveals a stark reality: even the                                 Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng
                          most advanced LLMs still grapple with fundamen-                                         Chen, Eric Chu, Jonathan H. Clark, Laurent El
                          tal aspects of general reasoning. BBEH provides                                         Shafey, Yanping Huang, Kathy Meier-Hellstern, Gau-
                          a crucial stepping stone, reigniting the challenge                                      rav Mishra, Erica Moreira, Mark Omernick, Kevin
                                                                                                                  Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao,
                          and offering a more rigorous platform for future                                        Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez
                          research aimed at unlocking the full potential of                                       Abrego, Junwhan Ahn, Jacob Austin, Paul Barham,
                                                                                                                  Jan Botha, James Bradbury, Siddhartha Brahma,
                              5for the latter case, we removed the Shuffled Objects task                          Kevin Brooks, Michele Catasta, Yong Cheng, Colin
                          as models ran out of effective tokens and started degenerating,                         Cherry, Christopher A. Choquette-Choo, Aakanksha
                          and this was adding noise to the analysis                                               Chowdhery, Clément Crepy, Shachi Dave, Mostafa
                                                                                                       26481
                     Dehghani, Sunipa Dev, Jacob Devlin, Mark Díaz,              Sungyong Seo, Jonathan Halcrow, and Bryan Per-
                     Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu               ozzi. 2024. Test of time: A benchmark for evalu-
                     Feng, Vlad Fienber, Markus Freitag, Xavier Gar-             ating llms on temporal reasoning. arXiv preprint
                     cia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-           arXiv:2406.09170.
                     Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua
                     Howland, Andrea Hu, Jeffrey Hui, Jeremy Hur-             Elliot Glazer, Ege Erdil, Tamay Besiroglu, Diego
                     witz, Michael Isard, Abe Ittycheriah, Matthew Jagiel-       Chicharro, Evan Chen, Alex Gunning, Caroline Falk-
                     ski, Wenhao Jia, Kathleen Kenealy, Maxim Krikun,            man Olsson, Jean-Stanislas Denain, Anson Ho,
                     Sneha Kudugunta, Chang Lan, Katherine Lee, Ben-             Emily de Oliveira Santos, Olli Järviniemi, Matthew
                     jamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li,           Barnett, Robert Sandler, Matej Vrzala, Jaime Sevilla,
                     Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu,          Qiuyu Ren, Elizabeth Pratt, Lionel Levine, Grant
                     FrederickLiu,MarcelloMaggioni,AromaMahendru,                Barkley, Natalie Stewart, Bogdan Grechuk, Tetiana
                     Joshua Maynez, Vedant Misra, Maysam Moussalem,              Grechuk, Shreepranav Varma Enugandla, and Mark
                     Zachary Nado, John Nham, Eric Ni, Andrew Nys-               Wildon. 2024.     Frontiermath: A benchmark for
                     trom, Alicia Parrish, Marie Pellat, Martin Polacek,         evaluating advanced mathematical reasoning in ai.
                     Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif,         Preprint, arXiv:2411.04872.
                     Bryan Richter, Parker Riley, Alex Castro Ros, Au-
                     rko Roy, Brennan Saeta, Rajkumar Samuel, Renee           DayaGuo,DejianYang,HaoweiZhang,JunxiaoSong,
                     Shelby, Ambrose Slone, Daniel Smilkov, David R.             RuoyuZhang,RunxinXu,QihaoZhu,ShirongMa,
                     So, Daniel Sohn, Simon Tokumine, Dasha Valter,              Peiyi Wang, Xiao Bi, et al. 2025. Deepseek-r1: In-
                     Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang,             centivizing reasoning capability in llms via reinforce-
                     Pidong Wang, Zirui Wang, Tao Wang, John Wiet-               ment learning. arXiv preprint arXiv:2501.12948.
                     ing, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting
                     Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven        Joseph Y Halpern. 2008. Defaults and normality in
                     Zheng, Ce Zheng, Weikang Zhou, Denny Zhou, Slav             causal structures. In KR, pages 198–208.
                     Petrov, and Yonghui Wu. 2023. Palm 2 technical
                     report. Preprint, arXiv:2305.10403.                      Joseph Y Halpern. 2016. Actual Causality. The MIT
                                                                                 Press.
                  Hritik Bansal and Pratyush Maini. 2024. Peeking be-
                     hind closed doors: Risks of llm evaluation by private    Joseph Y Halpern and Christopher Hitchcock. 2015.
                     data curators.                                              Graded causation and defaults. The British Journal
                                                                                 for the Philosophy of Science.
                  Himanshu Beniwal, Mayank Singh, et al. 2024. Re-
                     member this event that year? assessing temporal          DanHendrycks,CollinBurns,StevenBasart,AndyZou,
                     information and reasoning in large language models.         Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
                     arXiv preprint arXiv:2402.11997.                            2020. Measuring massive multitask language under-
                                                                                 standing. arXiv preprint arXiv:2009.03300.
                  BerndBohnet,AzadeNova,AaronTParisi,KevinSwer-
                     sky, Katayoon Goshvadi, Hanjun Dai, Dale Schuur-                                      ´
                                                                              Jack Hessel, Ana Marasovic, Jena D Hwang, Lillian
                     mans, Noah Fiedel, and Hanie Sedghi. 2024. Explor-          Lee, Jeff Da, Rowan Zellers, Robert Mankoff, and
                     ing and benchmarking the planning capabilities of           Yejin Choi. 2022.    Do androids laugh at electric
                     large language models. Preprint, arXiv:2406.13094.          sheep? humor" understanding" benchmarks from
                                                                                 the new yorker caption contest.      arXiv preprint
                  Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,                arXiv:2209.06293.
                     Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias
                     Plappert, Jerry Tworek, Jacob Hilton, Reiichiro          Arian Hosseini, Alessandro Sordoni, Daniel Toyama,
                     Nakano, et al. 2021. Training verifiers to solve math       Aaron Courville, and Rishabh Agarwal. 2024. Not
                     wordproblems. arXiv preprint arXiv:2110.14168.              all llm reasoners are created equal. arXiv preprint
                                                                                 arXiv:2410.01748.
                  Bhuwan Dhingra, Jeremy R Cole, Julian Martin
                     Eisenschlos, Daniel Gillick, Jacob Eisenstein, and       Thomas F Icard, Jonathan F Kominsky, and Joshua
                     William W Cohen. 2022. Time-aware language mod-             Knobe. 2017. Normality and actual causal strength.
                     els as temporal knowledge bases. Transactions of the        Cognition, 161:80–93.
                     Association for Computational Linguistics, 10:257–
                     273.                                                     MehranKazemi,HamidrezaAlvari,AnkitAnand,Jialin
                                                                                 Wu,XiChen,andRaduSoricut.2023a. Geomverse:
                  Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,               Asystematic evaluation of large models for geomet-
                     Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,             ric reasoning. arXiv preprint arXiv:2312.12241.
                     Akhil Mathur, Alan Schelten, Amy Yang, Angela
                     Fan, et al. 2024. The llama 3 herd of models. arXiv      MehranKazemi,Nishanth Dikkala, Ankit Anand, Petar
                     preprint arXiv:2407.21783.                                  Devic, Ishita Dasgupta, Fangyu Liu, Bahare Fatemi,
                                                                                 Pranjal Awasthi, Dee Guo, Sreenivas Gollapudi, et al.
                  Bahare Fatemi, Mehran Kazemi, Anton Tsitsulin,                 2024. Remi: A dataset for reasoning with multiple
                     Karishma Malkan, Jinyeong Yim, John Palowitch,              images. arXiv preprint arXiv:2406.09175.
                                                                         26482
                  MehranKazemi, Quan Yuan, Deepti Bhatia, Najoung            Mihir Parmar, Nisarg Patel, Neeraj Varshney, Mutsumi
                     Kim, Xin Xu, Vaiva Imbrasaite, and Deepak Ra-              Nakamura, Man Luo, Santosh Mashetty, Arindam
                     machandran. 2023b. Boardgameqa: A dataset for              Mitra, and Chitta Baral. 2024. Logicbench: Towards
                     natural language reasoning with contradictory infor-       systematic evaluation of logical reasoning ability of
                     mation. Advances in Neural Information Processing          large language models. In Proceedings of the 62nd
                     Systems, 36.                                               AnnualMeetingoftheAssociationforComputational
                                                                                Linguistics (Volume 1: Long Papers), pages 13679–
                  Mikhail Khodak, Nikunj Saunshi, and Kiran Vodrahalli.         13707.
                     2017. A large self-annotated corpus for sarcasm.        LongPhan,AliceGatti, Ziwen Han, and Nathaniel Li
                     arXiv preprint arXiv:1704.05579.                           et. al. 2025.   Humanity’s last exam.      Preprint,
                  EmreKıcıman,RobertNess,AmitSharma,andChen-                    arXiv:2501.14249.
                     hao Tan. 2023. Causal reasoning and large language      Jonathan Phillips, Jamie B Luguri, and Joshua Knobe.
                     models: Opening a new frontier for causality. arXiv        2015. Unifying morality’s influence on non-moral
                     preprint arXiv:2305.00050.                                 judgments: The relevance of alternative possibilities.
                  Jonathan F Kominsky, Jonathan Phillips, Tobias Ger-           Cognition, 145:30–42.
                     stenberg, David Lagnado, and Joshua Knobe. 2015.        Angelika Romanou, Syrielle Montariol, Debjit Paul,
                     Causal superseding. Cognition, 137:196–209.                Leo Laugier, Karl Aberer, and Antoine Bosselut.
                  Konstantin Raphael Kueffner. 2021. A comprehensive            2023. CRAB:Assessingthe strength of causal rela-
                     survey of the actual causality literature.                 tionships between real-world events. arXiv preprint
                                                                                arXiv:2311.04284.
                  lmarena.   Chatbot Arena Leaderboard - a Hugging           Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavat-
                     Face Space by lmarena-ai — huggingface.co.                 ula, and Yejin Choi. 2021. Winogrande: An adver-
                     https://huggingface.co/spaces/lmarena-ai/                  sarial winograd schema challenge at scale. Commu-
                     chatbot-arena-leaderboard.                                 nications of the ACM, 64(9):99–106.
                  Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chun-       Eduardo Sánchez, Belen Alastruey, Christophe Rop-
                     yuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-              ers, Pontus Stenetorp, Mikel Artetxe, and Marta R
                     WeiChang,MichelGalley, and Jianfeng Gao. 2023.             Costa-jussà. 2024.    Linguini: A benchmark for
                     Mathvista: Evaluating mathematical reasoning of            language-agnostic linguistic reasoning.       arXiv
                     foundation models in visual contexts. arXiv preprint       preprint arXiv:2409.12126.
                     arXiv:2310.02255.
                                                                             Abulhair Saparov and He He. 2022. Language models
                  Ian R McKenzie, Alexander Lyzhov, Michael Pieler,             are greedy reasoners: A systematic formal analysis of
                     Alicia Parrish, Aaron Mueller, Ameya Prabhu, Euan          chain-of-thought. arXiv preprint arXiv:2210.01240.
                     McLean, Aaron Kirtland, Alexis Ross, Alisa Liu,         Abulhair Saparov, Richard Yuanzhe Pang, Vishakh Pad-
                     et al. 2023. Inverse scaling: When bigger isn’t better.    makumar, Nitish Joshi, Mehran Kazemi, Najoung
                     arXiv preprint arXiv:2306.09479.                           Kim,andHeHe.2023. Testingthegeneraldeductive
                  Stephen Miner, Yoshiki Takashima, Simeng Han, Fer-            reasoning capacity of large language models using
                     hat Erata, Timos Antonopoulos, Ruzica Piskac, and          ood examples. Advances in Neural Information Pro-
                     Scott J Shapiro. 2024. Scheherazade: Evaluating            cessing Systems, 36:3083–3105.
                     chain-of-thought math reasoning in llms with chain-     Abulhair Saparov, Srushti Pawar, Shreyas Pimpal-
                     of-problems. arXiv preprint arXiv:2410.00151.              gaonkar, Nitish Joshi, Richard Yuanzhe Pang,
                  ImanMirzadeh, Keivan Alizadeh, Hooman Shahrokhi,              Vishakh Padmakumar, Seyed Mehran Kazemi, Na-
                     Oncel Tuzel, Samy Bengio, and Mehrdad Farajtabar.          joung Kim, and He He. 2024. Transformers struggle
                     2024. Gsm-symbolic: Understanding the limitations          to learn to search. arXiv preprint arXiv:2412.04703.
                     of mathematical reasoning in large language models.     ScaleAI. SEAL LLM Leaderboards: Expert-Driven
                     arXiv preprint arXiv:2410.05229.                           Private Evaluations — scale.com. https://scale.
                  Roshanak Mirzaee, Hossein Rajaby Faghihi, Qiang               com/leaderboard.
                     Ning, and Parisa Kordjmashidi. 2021. Spartqa:: A        KulinShah,NishanthDikkala,XinWang,andRinaPan-
                     textual question answering benchmark for spatial rea-      igrahy. 2024. Causal language modeling can elicit
                     soning. arXiv preprint arXiv:2104.05832.                   search and reasoning capabilities on logic puzzles.
                                                                                arXiv preprint arXiv:2409.10502.
                  Allen Nie, Yuhui Zhang, Atharva Shailesh Amdekar,
                     Chris Piech, Tatsunori B Hashimoto, and Tobias Ger-     Zhengxiang Shi, Qiang Zhang, and Aldo Lipani. 2022.
                     stenberg. 2023. MoCa: Measuring human-language             Stepgame: A new benchmark for robust multi-hop
                     modelalignmentoncausalandmoraljudgmenttasks.               spatial reasoning in texts.  In Proceedings of the
                     In Advances in Neural Information Processing Sys-          AAAIconferenceonartificialintelligence, volume 36,
                     tems, pages 78360–78393.                                   pages 11321–11329.
                                                                        26483
                   Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,            Alex Wang. 2018. Glue: A multi-task benchmark and
                      AbuAwalMdShoeb,AbubakarAbid,AdamFisch,                       analysis platform for natural language understanding.
                      Adam R Brown, Adam Santoro, Aditya Gupta,                    arXiv preprint arXiv:1804.07461.
                      Adrià Garriga-Alonso, et al. 2022.       Beyond the
                      imitation game: Quantifying and extrapolating the         Alex Wang, Yada Pruksachatkun, Nikita Nangia, Aman-
                      capabilities of language models.      arXiv preprint         preet Singh, Julian Michael, Felix Hill, Omer Levy,
                      arXiv:2206.04615.                                            and Samuel Bowman. 2019. Superglue: A stick-
                                                                                   ier benchmark for general-purpose language under-
                   Mirac Suzgun, Nathan Scales, Nathanael Schärli, Se-             standing systems. Advances in neural information
                      bastian Gehrmann, Yi Tay, Hyung Won Chung,                   processing systems, 32.
                      AakankshaChowdhery,QuocVLe,EdHChi,Denny
                      Zhou, et al. 2022. Challenging big-bench tasks and        YuboWang,XueguangMa,GeZhang,YuanshengNi,
                      whether chain-of-thought can solve them.       arXiv        Abhranil Chandra, Shiguang Guo, Weiming Ren,
                      preprint arXiv:2210.09261.                                  Aaran Arulraj, Xuan He, Ziyan Jiang, et al. 2024.
                   Oyvind Tafjord, Bhavana Dalvi Mishra, and Peter                 Mmlu-pro: Amorerobustandchallengingmulti-task
                      Clark. 2020. Proofwriter: Generating implications,           language understanding benchmark. arXiv preprint
                      proofs, and abductive statements over natural lan-           arXiv:2406.01574.
                      guage. arXiv preprint arXiv:2012.13048.                   Jason Weston, Antoine Bordes, Sumit Chopra, Alexan-
                   Alon Talmor, Jonathan Herzig, Nicholas Lourie, and              der M Rush, Bart Van Merriënboer, Armand Joulin,
                      JonathanBerant.2018. Commonsenseqa: Aquestion                and Tomas Mikolov. 2015. Towards ai-complete
                      answering challenge targeting commonsense knowl-             question answering: A set of prerequisite toy tasks.
                      edge. arXiv preprint arXiv:1811.00937.                       arXiv preprint arXiv:1502.05698.
                   Gemini Team, Petko Georgiev, Ving Ian Lei, Ryan              Colin White, Samuel Dooley, Manley Roberts, Arka
                      Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer,            Pal, Ben Feuer, Siddhartha Jain, Ravid Shwartz-Ziv,
                      Damien Vincent, Zhufeng Pan, Shibo Wang, et al.              Neel Jain, Khalid Saifullah, Siddartha Naidu, et al.
                      2024a. Gemini 1.5: Unlocking multimodal under-               2024. Livebench: A challenging, contamination-free
                      standing across millions of tokens of context. arXiv         llm benchmark. arXiv preprint arXiv:2406.19314.
                      preprint arXiv:2403.05530.                                Haotian Xia, Zhengbang Yang, Yuqing Wang, Rhys
                   GemmaTeam,AishwaryaKamath,JohanFerret,Shreya                   Tracy, Yun Zhao, Dongdong Huang, Zezhi Chen,
                      Pathak,NinoVieillard,RamonaMerhej,SarahPerrin,              Yan Zhu, Yuan-fang Wang, and Weining Shen.
                      Tatiana Matejovicova, Alexandre Ramé, Morgane                2024.   Sportqa: A benchmark for sports under-
                      Rivière, et al. 2025. Gemma3technicalreport. arXiv           standing in large language models. arXiv preprint
                      preprint arXiv:2503.19786.                                   arXiv:2402.15862.
                   Gemma Team, Morgane Riviere, Shreya Pathak,                  Siheng Xiong, Ali Payani, Ramana Kompella, and
                      Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupati-          Faramarz Fekri. 2024.      Large language models
                      raju, Léonard Hussenot, Thomas Mesnard, Bobak                can learn temporal reasoning.        arXiv preprint
                      Shahriari, Alexandre Ramé, et al. 2024b. Gemma 2:            arXiv:2401.06853.
                      Improving open language models at a practical size.       Yutaro Yamada, Yihan Bao, Andrew K Lampinen,
                      arXiv preprint arXiv:2408.00118.                             Jungo Kasai, and Ilker Yildirim. 2023.       Evaluat-
                   Gladys Tyen, Hassan Mansoor, Victor Carbune, Peter              ing spatial understanding of large language models.
                      Chen, and Tony Mak. 2024. LLMs cannot find rea-              arXiv preprint arXiv:2310.14540.
                      soning errors, but can correct them given the error       AnYang,BaosongYang,BeichenZhang,BinyuanHui,
                      location. In Findings of the Association for Compu-          BoZheng,BowenYu,ChengyuanLi,DayihengLiu,
                      tational Linguistics: ACL 2024, pages 13894–13908,           Fei Huang, Haoran Wei, et al. 2024a. Qwen2. 5
                      Bangkok, Thailand. Association for Computational             technical report. arXiv preprint arXiv:2412.15115.
                      Linguistics.
                   Gladys Tyen, Hassan Mansoor, Peter Chen, Tony Mak,           ZhengbangYang,HaotianXia,Jingxi Li, Zezhi Chen,
                                    ˘                                              Zhuangdi Zhu, and Weining Shen. 2024b. Sports
                      and Victor Carbune. 2023. LLMs cannot find rea-
                      soning errors, but can correct them! arXiv preprint          intelligence:  Assessing the sports understanding
                      arXiv:2311.08516.                                            capabilities of language models through question
                                                                                   answering from text to video.        arXiv preprint
                   KiranVodrahalli, SantiagoOntanon, NileshTripuraneni,            arXiv:2406.14877.
                      Kelvin Xu, Sanil Jain, Rakesh Shivanna, Jeffrey Hui,
                      Nishanth Dikkala, Mehran Kazemi, Bahare Fatemi,           Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali
                      et al. 2024. Michelangelo: Long context evaluations          Farhadi, and Yejin Choi. 2019. Hellaswag: Can
                      beyond haystacks via latent structure queries. arXiv         a machine really finish your sentence?      Preprint,
                      preprint arXiv:2409.12640.                                   arXiv:1905.07830.
                                                                          26484
                  Jifan Zhang, Lalit Jain, Yang Guo, Jiayi Chen, KuanLok        • Movie Recommendation: We programmati-
                     Zhou, Siddharth Suresh, Andrew Wagenmaker,                   cally updated the options for each question
                     Scott Sievert, Timothy Rogers, Kevin Jamieson,               to turn the problem from a “recommendation”
                     Robert Mankoff, and Robert Nowak. 2024. Hu-                  task to a “best subset selection” task.
                     morinai: Massive scale crowd-sourced preferences
                     and benchmarks for cartoon captioning. Preprint,           • Spatial Reasoning (the SpatialLLMEval sub-
                     arXiv:2406.10522.
                                                                                  set): We programmatically sampled from the
                  A DetailedDescription of the Tasks and                          harder subtasks of the dataset.
                       Task-Specific Insights from                             Category 2: Re-running the code that gener-
                       Experiments                                           ates an existing dataset, but changing the origi-
                  weclassifythe23tasksinBBEHintothefollowing                 nal parameters: These are the tasks that already
                  four categories.                                           existed in the literature and they were generated
                     Category1: Apost-processedversionofanal-                using code. The code contained parameters that
                  ready existing dataset: These are the tasks where          could be modified to create more difficult versions
                  wetookanalreadyexisting dataset from the liter-            of them. The tasks in this category include:
                  ature and did some post-processing to make them               • BoardgameQA:Weonlyincreasedthedepth
                  conform to the format of the tasks in BBEH. The                 parameter. Zebra Puzzles: We only increased
                  tasks in this category include:                                 the puzzle size and
                     • SARCTriples: We did some length filtering                • distractor parameters.
                        andcombinedthreeproblemsintoone. Every-                Category 3: Creating new tasks through
                        thing was done programmatically.                     writing code that generates the tasks: These
                     • SportQA: We took a subset of examples from            are the tasks that did not previously exist. We
                        the most difficult subset. Everything was done       wrote code that could be executed and created in-
                        programmatically.                                    stances of them. The tasks in this category include:
                     • Linguini: The original questions asked about          Boolean Expressions, Buggy Tables, Geometric
                        multiple things; we slightly modified them           Shapes, Hyperbaton, Multi-Step Arithmetic, Ob-
                        so each question asks about a single thing.          ject Counting, Object Properties, Shuffled Objects,
                        Everything was done programmatically.                Spatial Reasoning(excepttheSpatialLLMEvalsub-
                                                                             set), Temporal Sequences, Web of lies (except the
                     • Causal Understanding: We did some manual              LiveBench subset), and Word Sorting (except the
                        cleaning for all the examples in this task as        error finding subset).
                        described in detail in the Appendix.                   Category 4: Creating new tasks manually:
                                                                             This subset only includes the DisambiguationQA
                     • NYCC:Wetookanexistingbinaryclassifica-                task, which was created manually by the authors.
                        tion dataset and turned it into multiple-choice        In what follows, we describe in detail how each
                        questions. Everything was done programmati-          of the 23 new tasks in BBEH have been created.
                        cally.                                               Moreover, we provide interesting task-specific in-
                     • Time Arithmetic: We took an existing dataset          sights from our experiments.
                        and combined multiple questions into one to          A.1   BoardgameQA
                        create a compositional version of it. Every-         BoardgameQA(Kazemietal.,2023b)isabench-
                        thing was done programmatically.                     markwheregivenadefeasibletheory(asetofinput
                     • DyckLanguagesWordSorting(theerror de-                 facts, possibly contradictory rules, and preferences
                        tection subset): We took a subset of the exist-      overtherules), and a question about that theory, the
                        ing dataset that involved more reasoning steps.      task is to do multi-hop reasoning and conflict reso-
                        Everything was done programmatically.                lution over the input theory to answer the question.
                                                                             Thefinal answer to the question is either ‘proved‘
                     • Web of lies (the LiveBench subset): Part of           (if the statement in the question derives from the
                        the data comes from LiveBench with minimal           theory), ‘disproved‘ (if the negation of the state-
                        programmatic post-processing.                        ment in the question derives from the theory), or
                                                                       26485
                                                                                                                                       Average input length
                                         104                                                                                                                                                                                                     Benchmark
                                                                                                                                                                                                                                                       BBEH
                                                                                                                                                                                                                                                       BBH
                                         103
                                        ength in characters
                                        L
                                                                 ables                                                                              CC
                                                      essions                                                       Linguini                      NY             operties    riples                  SportQA                                        uzzles
                                          dgameQA                                                                                                               r         C T              easoning                            eb of liesd Sorting
                                                                                                       Hyperbaton                                                     SAR                                                    W        or
                                      Boar               Buggy T                                                                                                                                                ime Arithmetic      W       Zebra P
                                                                                 Dyck Languages                      ecommendation              Object Counting            Shuffled Objects                    T
                                                                                        Geometric Shapes                                                Object P                  Spatial R
                                                                      DisambiguationQA                                                                                                              emporal Sequence
                                         Boolean Expr    Causal Understanding                                             Multistep Arithmetic                                                     T
                                                                                                             Movie R
                                            Figure 6: A comparison of the average input lengths of the tasks in BBEH to their counterparts in BBH.
                                           CC                                                      operties           ables     essions                                                                             easoning           riples    uzzles
                                           NY                                                      r                                     Linguini           SportQA  eb of Lies                            ecommendation      dgameQA  C T                d Sorting
                                                    Hyperbaton                                                                                                       W                                                                 AR                 or
                                                                                                                      Buggy T                     ime Arithmetic                                                              Boar     S         Zebra P  W
                                                              DisambiguationQAShuffled Objectsemporal SequencesObject PMultistep ArithmeticBoolean ExprT                       Geometric ShapesObject CountingDyck LanguagesSpatial R
                                                                                Causal UnderstandingT                                                                                                      Movie R
                                   Figure 7: Performance gains (absolute) of Gemini 2.0 Flash over Gemini 2.0 Flash-Lite on BBEH tasks. Tasks
                                   are ordered by the magnitude of improvement, with green signifying substantial gains and yellow/red signifying
                                   minimal or negative gains.
                                  ‘unknown‘(if neither the statement in the questions                                                                      Through analyzing the model outputs, we ob-
                                   nor its negation derives from the theory). With                                                                    serve that for this task, models tend to over-predict
                                   three labels per question, a random baseline has an                                                                that the truth value of a statement is unknown. The
                                   accuracy of 33.3%. Conflicts may arise when two                                                                    percentage of unknown predictions for our models
                                   rules such as R1 : a → c and R2 : b → ¬c are                                                                       (whenatleastoneofthethreelabelswaspredicted)
                                   both activated leading to different beliefs about the                                                              is presented in Table 4. Note that only one-third of
                                   truth value of the variable c. However, preferences                                                                the problems have an unknown label. An unknown
                                   over the rules is provided in the input question and                                                               label is typically predicted when the model cannot
                                   in the case of conflicts, the derivation from the rule                                                             find a way to either prove or disprove the statement
                                   with the higher preference must be concluded (e.g.,                                                                from the facts and rules. Therefore, we observe a
                                   if R1 is preferred over R2 and they both apply,                                                                    failure mode for the state-of-the-art models: they
                                   then we conclude c is true).                                                                                       struggle to search the space of facts and rules and
                                        Oneoftheparameters controlling the difficulty                                                                 find a proof, despite there being one. While simi-
                                   of the problems in this benchmark is the depth,                                                                    lar observations have been previously made about
                                   corresponding to the number of hops of reasoning                                                                   models without chain-of-thought (Saparov et al.,
                                   that must be done to compute the truth value of the                                                                2024), our results apply to the case with chain-of-
                                   statement in the question. We use the code from the                                                                thought.
                                   paperandgeneratetaskswithdepths6,7and8. We                                                                         A.2          Boolean Expressions
                                   madesomechangesintheprompttoclarifythetask
                                   for the model so that it works in zero-shot setting.                                                               This task requires determining the truth value of
                                   That includes: Answer ’proved’ if it can be proved,                                                                a statement that is composed of logical operands
                                  ’disproved’ if it can be disproved, and ’unknown’ if                                                                such as True and False as well as other textual
                                   it can neither be proved nor disproved as well as A                                                                or mathematical statements that evaluate to True
                                   rule is only applicable if all of its antecedents can                                                              or False. To create this task, we first randomly
                                   be proved.. We then uniformly sampled prompts                                                                      create expressions containing only True and False
                                   across depths and labels to created the final set.                                                                 operands and three logical operators: and, or, and
                                                                                                                                           26486
                     Models       Gemma227bIT      Gemini2.0Flash-Lite   Gemini2.0Flash   GPT4o     DeepSeekR1    o3-mini (high)
                   Unknown%            77.6               67.4                73.3          82.4        39.7           65.5
                 Table 4: Percentage of unknown predictions on BoardgameQA for different models (only one third of the labels are
                  unknown).
                  not. We create this in a bottom-up fashion where        one so that the original table can be reconstructed
                 wegenerate smaller sub-expressions and then com-         basedonthatinformation. Examplesofconditional
                  bine them with logical operators. Once a large          queries include computing some statistics (count,
                  enough expression is created, we replace some of        sum, mean, stdev, median) of some columns while
                  the True and False operands with statements that        only considering rows where some columns have
                  evaluate to True or False. These could be mathe-        somespecific values.
                  matical expressions such as 24 - 2 is greater           A.4    Causal Understanding
                  than 48 / 2 (which evaluates to False) or textual
                  statements such as The capital of Canada is             In BBEHwereplacetheoriginal causal judgement
                  Ottawa (which evaluates to True). In both cases,        task in BBH with a set of questions that assess
                 we select these statements from a predefined set.        both (i) causal judgement (142 queries) and (ii) the
                 While determining the truth value of each of these       ability to determine necessary and sufficient causes
                  statements in isolation may be easy for many mod-       (58 queries). In this section we describe how these
                  els, including these statements makes it more diffi-    different sets of questions are obtained.
                  cult for models; otherwise, they can simply solve       CausalJudgement Thesequeriesarebasedon
                  the problem by generating a single line of python       the 144 causal stories included in the MoCa bench-
                  code.                                                   mark (Nie et al., 2023), which partially overlap
                    Wegenerate five expressions using the approach        with the sets of questions originally included in
                  outlined above, four of which evaluate to False         BBH.InMoCa,shortstoriesobtained from cogni-
                  and one of which evaluate to True. The job of the       tive science papers were given to 25 human annota-
                  modelisthentofindtheexpressionthatevaluatesto           tors who had to judge whether, based on the given
                 True. Since this is a five-way question, the random      story, a certain person or event caused a certain
                  chance accuracy is 20%.                                 outcome. The task was phrased as a binary task
                  A.3   BuggyTables                                       with Yes/No answers, and the ground truth label
                                                                          wasassigned according to the label chosen by the
                 The objective in this task is to be able to respond      majority of humans.
                  to conditional queries over tabular data, where the        However, the stories included complex norma-
                  information in the table are presented in a buggy       tive and logical factors, and for many of them there
                 waybutthedescriptionforthebugisalsopresented             wasalargedegree of disagreement among the hu-
                  so that the model can reconstruct the original ta-      manannotators. In cases where the human raters
                  ble based on that. As an example, we provide a          strongly disagreed on the answer (defined as hav-
                  row-major/column-major format of the table where        ing a difference of at most 20% between the “Yes”
                  the null values have been mistakenly removed, but       and “No” answers among the annotators), ques-
                 wealsoprovide the positions of the null values in        tions were additionally tagged as “Ambiguous”.
                  the original table so one can reconstruct the table     Based on this, we constructed the renewed task to
                  given the two pieces of information. As another         have 3 possible labels: Yes, No and Ambiguous.
                  example, we provide a buggy version of the table        Thelabel ambiguous was assigned to the 46 ques-
                 wheresomerandomvaluesareappendedattheend                 tions originally tagged as “Ambiguous” in MoCa.
                  of each row or each column, but we also specify         For instance, the label for example 36 in Table 5
                  howtheyhavebeenaddedsoonecanusethisinfor-               waschangedfromYestoAmbiguous,as15human
                  mation to remove them and reconstruct the original      annotators replied Yes while 10 replied No. In this
                  table. As yet another example, we provide a mark-       example we have that, on the one hand Billy was
                  downformatofthetable that mixes each two rows           asked to be in the room at 9am and cannot be given
                  of the table into one row, but also provide an expla-   the fault of entering the room and triggering the
                  nationofhoweachtworowshavebeenmergedinto                alarm. On the other hand, the alarm was set to
                                                                     26487
                 be triggered if at least one person appeared in the     ambiguities, typos, and incorrect outputs. The main
                 room, thus both Billy and Suzy could be assigned        ambiguities that were identified relates to the use of
                 the responsibility for the detector going off. Both    {Actor}, which was substituted with the associated
                 explanation could be considered valid. For the re-      action. Each example was discussed to reach an
                 maining questions, the label was kept unchanged         agreementonthechanges,thisresultedinchanging
                 to Yes/No.                                              the outputs of six examples (see Table 6).
                    With the above re-definition of ground truth la-
                 bels, models were then asked to correctly identify      ModelOutputsAnalysis Analysingtheperfor-
                 the way humans, as a group, would answer the            mancethatGemini2.0Flashachievesonthecausal
                 question, thus testing alignment with human causal      understanding task reveals that this model answers
                 intuitions. To reflect this, we added the following     correctly to 45% of the causal judgment queries
                 instructions to each query:                            (random performance is 33%) and 71% of the
                                                                         queries about necessary and sufficient causes (ran-
                     Prompt Instructions                                 domperformanceis 50%).
                     Reply Yes or No based on the answer the               Focusing on the causal judgment queries, most
                     majority of people would give.                      of the errors are in questions for which the ground
                     If you think people would be split roughly          truth label is Ambiguous (44 mistakes out of 45
                     50-50 between Yes and No then reply Am-             examples) or No (24 mistakes out of 49 examples),
                     biguous.                                           with only 10 mistakes out of 48 examples for the
                                                                        Yes label. This reveals the difficulty the model has
                    Finally, to ensure consistency in terms of           in determining an absence of causal relationships,
                 number of queries included for the other tasks,         andindealingwithambiguitiesandtheexistenceof
                 we removed 2 stories included in the origi-             different possible answers. Thisbehaviourhasbeen
                 nal set (these correspond to question 17 and            previously observed across other causal reason-
                 19 at https://moca-llm.github.io/causal_                ing benchmarks (see e.g. (Romanou et al., 2023))
                 stories/1/). The final set includes 45 Ambigu-         where models have been found to infer stronger
                 ous questions and 48 and 49 questions with Yes          causal relationships than those that humans per-
                 and No labels respectively.                             ceive. Another interesting failure mode is that the
                                                                         model sometimes exhibits a lack of understanding
                 Necessary and Sufficient Causes        Wecomple-        of the normative aspect of causal judgements as
                 mented the causal judgement stories with 58 ex-         madebyhumans: humanstendtoascribe causality
                 amples testing reasoning about necessary and suffi-     moreeasily when the causal factor is unusual in a
                 cient causes given a description of a set of events     statistical sense, or when it violates an established
                 (example scenario). These examples were obtained        rule or behavioral norm (Halpern, 2008; Phillips
                 by modifying those in (Kıcıman et al., 2023) to         et al., 2015; Kominsky et al., 2015; Halpern and
                 correct ambiguities and incorrect outputs.              Hitchcock, 2015; Icard et al., 2017). For instance,
                    Thefirst 30 examples in (Kıcıman et al., 2023)       in example 136 of Table 5, the event can only oc-
                 were constructed from 15 scenarios introduced in        cur if both Alice and Zoe log on simultaneously
                 different studies over the years to critique actual     to a computer – which is indeed what happened.
                 causality (Halpern, 2016) definitions from the liter-   However, Alice was allowed to log on while Zoe
                 ature (Kueffner, 2021). Each scenario is associated    violated an established rule when she logged in. In
                 with a question about necessary cause and a ques-       such situations, humans tend to say that Alice did
                 tion about sufficient cause, specifically “Is {Actor}   not cause the event, while Zoe did. The model fails
                 a necessary cause of {Event}?” and “Is {Actor} a        to capture this nuance and instead it applies straight-
                 sufficient cause of {Event}?”. To test LLM memo-        forward causal reasoning and concludes that Alice
                 rization issues, (Kıcıman et al., 2023) constructed     is a cause.
                 28 additional examples from 14 new scenarios ob-          Looking at the reasoning traces for Gemini 2.0
                 tained by adapting the original ones to a chemistry     Flash responses to questions on sufficient and nec-
                 lab setting involving reagents, mixtures and crys-      essarycausesrevealsthat,whilethemodelachieves
                 tals.                                                  very close performances in terms of precision and
                    Three experts of causal reasoning analysed each      recall, it fails on identifying sufficient causes (11
                 exampleandsuggestedminimalchangestoresolve              errors out of 28 examples) more often than identify-
                                                                    26488
                             ExampleID        Input                                                                              Output          Gemini2.0FlashResponse
                             36               Question: Suzy and Billy are working on a project that is very important for our   Ambiguous       Thequestion asks whether Billy caused the mo-
                                              nation’s security. The boss tells them both: “Be sure that you are here at exactly                 tion detector to go off. The motion detector was
                                              9 am. It is absolutely essential that you arrive at that time.” Both Billy and Suzy                triggered if at least one person was present. Both
                                              arrive at 9 am. As it happens, there was a motion detector installed in the room                   BillyandSuzywerepresentat9am. Suzy’spres-
                                              where they arrived. The motion detector was set up to be triggered if at least one                 ence also triggered the motion detector. Since
                                              person appeared in the room at the same time. So the motion detector went off.                     the motion detector would have gone off regard-
                                              Did Billy cause the motion detector to go off? Reply Yes or No based on the                        less of whether Billy was there, it cannot be
                                              answer the majority of people would give. If you think people would be split                       definitively said that Billy caused the motion de-
                                              roughly 50-50 between Yes and No then reply Ambiguous.                                             tector to go off. The answer is: Ambiguous.
                             123              Question: A group of students who lived on the same floor of a dormitory           No              Here’s a step-by-step analysis: 1. John’s Score:
                                              obtained a copy of the final exam for their biology class. The students cheated                    John earned the 20th highest score, placing him
                                              onthe test. One student, John Granger, did not go along with the group. Granger                    at the very top of the “A" grade range. 2. The
                                              deviates from the norm and refuses to cheat on the test. The biology class                         Pre-MedStudent’s Score: The pre-med student
                                              comprises 80 students and is graded on a curve such that 20 people will receive                    scored the 21st highest score, placing her at the
                                              a grade of A, 20 a grade of B, 20 a grade of C, and 20 students will receive a D.                  top of the “B" grade range. 3. Impact on the
                                                      ´
                                              Grangers score was the 20th-highest score in the class, which means he was the                     Curve: If John had cheated and scored higher,
                                              last student to receive a grade of A. The 21st student was a pre-med student who                   he could have potentially been in the “A" range
                                              received a B and, as a result, missed the GPA cutoff she needed to get into the                    with a higher score. This would have potentially
                                              medical school she was hoping for by .07 GPA points. Did Granger cause the                         shifted the scores on the curve down. 4. The Stu-
                                              student to fail to meet the medical school cutoff? Reply Yes or No based on the                    dent’s Failure: It is possible, though not guaran-
                                              answer the majority of people would give. If you think people would be split                       teed, that if John had cheated and scored higher,
                                              roughly 50-50 between Yes and No then reply Ambiguous.                                             the curve could have shifted down. 5. Conclu-
                                                                                                                                                 sion: The pre-med student failing the cutoff is
                                                                                                                                                 related to the grading curve. If a number of stu-
                                                                                                                                                 dents cheated, it changed the overall distribution.
                                                                                                                                                 It is highly probable that, without cheating, the
                                                                                                                                                 pre-med student would have gotten the higher
                                                                                                                                                 grade. The answer is: Yes.
                             136              Question: Alice and Zoe work for the same company. They work in different          Yes             The question asks if Alice caused the deletion
                                              roomsandbothofthemsometimesneedtoaccessthecentralcomputerofthe                                     of spam emails. The scenario states that if Alice
                                              company. Unbeknownst to everybody, if two people are logged in to the central                      and Zoe are logged in simultaneously, the spam
                                              computer at the same time, some spam emails containing dangerous viruses                           emailsaredeleted. BothAliceandZoeloggedin
                                              are immediately deleted from the central computer. In order to make sure that                      at the same time. Thus, Alice’s action, combined
                                              one person is always available to answer incoming phone calls, the company                         with Zoe’s, resulted in the deletion of the spam
                                              issued the following official policy: Alice is the only one permitted to log in to                 emails. The answer is: Yes"
                                              the central computer in the mornings, whereas Zoe is the only one permitted to
                                              log in to the central computer in the afternoons. One day, violating the official
                                              policy, Zoe logs in to the central computer at 9 am. The same day, Alice also logs
                                              in at 9 am. Immediately, some spam emails containing dangerous viruses are
                                              deleted from the central computer. Did Alice cause some spam emails containing
                                              dangerous viruses to be removed from the central computer? Reply Yes or No
                                              based on the answer the majority of people would give. If you think people
                                              would be split roughly 50-50 between Yes and No then reply Ambiguous.
                           Table 5: Causal understanding: examples of causal judgment queries and correct or incorrect reasoning traces.
                           ExampleIDcorresponds to the index of the question in the causal understanding sub-benchmark.
                           ing necessary causes (6 errors out of 30 examples).                                    than those in BBH, require more referent disam-
                           Interestingly, the model correctly recalls the defi-                                   biguation, and each question contains more op-
                           nition of necessary and sufficient causes in most                                      tions so the random chance performance is lower.
                           of the responses and uses counterfactual reason-                                       These examples were constructed either by creat-
                           ing to consider alternative scenarios. Despite this,                                   ing entirely new sentences or combining existing
                           the model often fails at interpreting some of the                                      BBHinstances. Ten annotators (all of them the au-
                           causal links described in the scenarios (in exam-                                      thors of the paper) were tasked with creating these
                           ple 155 of Table 6 the model interprets the input                                      examples, each comprising a potentially ambigu-
                           as implying that “flowers would likely die in hot                                      ous sentence, a single correct resolution statement,
                           weather whether the neighbor waters or not”) or                                        and several distractor options for a multiple-choice
                           draws incorrect conclusions despite correct reason-                                    format. To ensure data quality, each example un-
                           ing traces.                                                                            derwent a two-stage verification process. First, a
                           A.5       Disambiguation QA                                                            separate annotator independently evaluated the cor-
                                                                                                                  rectness of the resolution. Discrepancies were then
                           This task introduces a more challenging adaptation                                     resolved through a third-party adjudicator or collab-
                           of the original DisambiguationQA task in BBH.                                          orative refinement by all three annotators. In cases
                           Theobjective is to accurately determine the refer-                                     where consensus could not be reached, the annota-
                           ents of ambiguous pronouns in complex sentences,                                       tors jointly revised the example to achieve clarity
                           or to explicitly identify instances of unresolvable                                    and accuracy. This rigorous process resulted in 25
                           ambiguity by responding ’ambiguous’. To enhance                                        examples requiring modification. An example of
                           the task’s difficulty and complexity, we constructed                                   an ambiguous sentence is provided below.
                           a dataset of 120 novel examples that are longer
                                                                                                          26489
                                  ExampleID        Original Input                                                                        Original Output       Modified Input                                      Modified Output
                                  149              Twotwo-state switches are wired to an electrode. The switches are controlled by       No                   Twotwo-stateswitchesarewiredtoanelectrode.           Yes
                                                   AandBrespectively, and the electrode is attached to C. A has the first option                              Theswitches are controlled by A and B respec-
                                                   to flip her switch. B has the second option to flip her switch. The electrode is                           tively, and the electrode is attached to C. A has
                                                   activated and shocks C if both switches are in the same position. B wants to                               the first option to flip her switch. B has the
                                                   shock C, and so flips her switch iff A does. C gets an electric shock. Is A’s action                       second option to flip her switch. The electrode
                                                   to flip the switch a necessary cause for C getting shocked?                                                is activated and shocks C if both switches are
                                                                                                                                                              flipped. B wants to shock C, and so flips her
                                                                                                                                                              switch if and only if A does. C gets an electric
                                                                                                                                                              shock. Is A’s action to flip the switch a necessary
                                                                                                                                                              cause for C getting shocked?
                                  154              There are a left and a right window. Alice and Bob both order Carol to fire           Yes                  There are a left and a right window. Alice and       No
                                                   at the left window. Carol fires at the left window, shattering it. Commands                                BobbothorderCaroltofire at the left window.
                                                   from Alice always trump commands form Bob (e.g. if Bob would have ordered                                  Carol fires at the left window, shattering it. Com-
                                                   to fire at right window, Carol would still have fired at the left one.). Without                           mandsfromAlicealwaystrumpcommandsfrom
                                                   a command Carol would not have fired at all. Is Alice a necessary cause for                                Bob (e.g. if Bob would have ordered to fire at
                                                   windowshattering?                                                                                          the right window, Carol would still have fired at
                                                                                                                                                              the left one). Without a command Carol would
                                                                                                                                                              not have fired at all. Is Alice ordering Carol to
                                                                                                                                                              fire a necessary cause for the window shattering?
                                  155              If there is hot weather, flowers will die. Watering prevents the flowers to die in    No                   If there is hot weather, flowers will die. Watering  Yes
                                                   hot weather. The neighbor does not water the flowers in her yard. The flowers                              prevents the flowers from dying in hot weather.
                                                   die. Is neighbor’s inaction a necessary cause for flowers’ death?                                          Theneighbor does not water the flowers in her
                                                                                                                                                              yard, the weather is hot and the flowers die. Is
                                                                                                                                                              the neighbor’s inaction a necessary cause for the
                                                                                                                                                              flowers’ death?
                                  170              If there is hot weather, flowers will die. Watering prevents the flowers to die in    Yes                  If there is hot weather, flowers will die. Watering  No
                                                   hot weather. The neighbor does not water the flowers in her yard. The flowers                              prevents the flowers from dying in hot weather.
                                                   die. Is neighbor’s inaction a sufficient cause for flowers’ death?                                         Theneighbor does not water the flowers in her
                                                                                                                                                              yard, the weather is hot and the flowers die. Is
                                                                                                                                                              the neighbor’s inaction a sufficient cause for the
                                                                                                                                                              flowers’ death?
                                  177              Reagent X is added to a beaker containing a crystal. If Reagent X touches the         No                   Reagent X is added to a beaker containing a          Yes
                                                   crystal, the crystal dissolves. If Reagent X does not touch the crystal, Sam adds                          crystal. If Reagent X touches the crystal, the
                                                   Reagent Y which leads to the crystal dissolving. Is Reagent X a necessary cause                            crystal dissolves. If, when added, Reagent X
                                                   for crystal dissolving?                                                                                    does not touch the crystal, Sam adds Reagent
                                                                                                                                                              Y, which leads the crystal to dissolve. Is adding
                                                                                                                                                              Reagent X to the beaker a necessary cause for
                                                                                                                                                              the crystal to dissolve?
                                  183              There is a test tube on the left and a test tube on the right. Sam and Riya both      Yes                  There is a test tube on the left and a test tube     No
                                                   order Frank to break the left test tube. Carol throws the left test tube, breaking it.                     onthe right. Sam and Riya both order Frank to
                                                   CommandsfromSamalwaystrumpcommandsformRiya(e.g. ifRiyawould                                                break the left test tube. Frank throws the left test
                                                   have ordered to break the right test tube, Frank would still have thrown the left                          tube, breaking it. Commands from Sam always
                                                   one.). Without a command Frank would not have acted at all. Is Sam a necessary                             trump commands from Riya (e.g. if Riya would
                                                   cause for test tube breaking?                                                                              have ordered to break the right test tube, Frank
                                                                                                                                                              would still have thrown the left one). Without a
                                                                                                                                                              commandFrankwouldnothaveactedatall. Is
                                                                                                                                                              Sam’s order a necessary cause for the test tube
                                                                                                                                                              to break?
                                Table 6: Causal understanding: queries for which the output was changed with respect to the original dataset in
                                (Kıcıman et al., 2023). Example ID corresponds to the index of the question in the causal understanding sub-
                                benchmark.
                                       AmbiguousExample                                                                                 question in the original BBH dataset. In each
                                       Here is a sentence with pronoun(s) whose                                                         example, the target answer is either the number
                                       antecedent(s) can either be derived from the                                                     where the first mistake occurred, or that there are
                                       context or is ambiguous.                                                                         no mistakes in the CoT sequence. These CoT
                                       Sentence: While walking through the forest,                                                      sequences are generated by prompting PaLM 2
                                       John saw a deer and its fawn. It was beauti-                                                     Unicorn (Anil et al., 2023) on the original BBH
                                       ful.                                                                                             dataset at temperature = 0. The prompts can be
                                      Whichofthefollowingoptionscorrectlyex-                                                            found at https://github.com/suzgunmirac/
                                                                                                                                        BIG-Bench-Hard/blob/main/cot-prompts/
                                       plains the antecedent(s) of the pronoun(s)?                                                      dyck_languages.txt. The newline is used as
                                       (A) The deer was beautiful.                                                                      a stop token so that each intermediate step can
                                       (B) The fawn was beautiful.                                                                      be prepended with ‘Thought 1: ’, ‘Thought 2: ’,
                                       (C) The walk through the forest was beauti-                                                      etc.      Further information on the prompting and
                                       ful.                                                                                             generation process can be found in Tyen et al.
                                       (D) Ambiguous.                                                                                   (2024).
                                A.6         DyckLanguages                                                                                    In the cases where there is an error in the trace
                                                                                                                                        and the model makes a mistake in identifying the
                                This task comes from the BIG-Bench Mistake                                                              first error, the mistake can occur due to two differ-
                                dataset (Tyen et al., 2024). It involves finding                                                        ent reasons: 1- mis-classifying a correct reasoning
                                the first mistake in an existing chain-of-thought                                                       step as erroneous before any error has occurred,
                                sequence, used to answer a Dyck Languages                                                               and 2- missing the first error and identifying some
                                                                                                                               26490
                 later erroneous step. We looked into the breakdown    dering task designed to evaluate a model’s linguis-
                 of what percentage of the errors belong to each cat-  tic knowledge—specifically, its understanding of
                 egory when there is an error to be found and the      adjective categories and adherence to the correct
                 model also identifies one of the steps as erroneous.  adjective ordering in English. In this task, models
                   Wefind that the majority of the errors belong       mustchoosethesentencewiththecorrect adjective
                 to the second category. Specifically, for o3-mini     sequence from a pair of English sentences. Current
                 (high) 98.7% of the errors belong to the second       general-purpose models excel at this task, reaching
                 class, for Gemini 2.0 Flash all the errors belong to  nearly 95% accuracy (see Table 9 for Gemini 2.0
                 the second class, for Gemini 2.0 Flash-Lite 94.9%     Flash performance on Hyperbaton task from BBH).
                 and for GPT4o 96.8% of the errors belong to the
                 second class. This highlights a failure mode for the
                 frontier models in that they can identify the correct
                 reasoning steps, but fail to identify the ones that
                 have errors.
                 A.7   Geometric Shapes
                 SVG is a language for drawing shapes. We use             WereplaceHyperbatonwithanoveltaskthatas-
                 two basic commands: 1- M(x,y) corresponding           sesses inductive reasoning in addition to linguistic
                 to moving to the (x,y) coordinate, and 2- L(x,y)      knowledge. This new task involves inducing the
                 corresponding to drawing a line from the current      correct adjective order in a new variant of English,
                 location to (x,y). We use the shape outlines from     given a set of example sentences. Specifically, for
                 GeomVerse (Kazemi et al., 2023a), a dataset of        eachtestsample,wecreateauniqueEnglishvariant
                 geometry questions involving multiple shapes that     by randomly shuffling the standard adjective order
                 share some elements, which are specified as TikZ      and generating 50-250 sentences. Each sentence
                 commandsandconvertthemtoSVG.Wethenask                 contains 1 to 3 adjectives preceding a noun. Mod-
                 the model to identify what shapes will be drawn if    els must then infer the correct adjective order for
                 wevisualize the SVG.                                  this variant and identify all correct sentences from
                   Weconsider two extra axes for difficulty: 1- we     10provided options. A “None of the above” option
                 randomly break some lines segments into multi-        is included as a distractor. We observe that this
                 ple colinear line segments, and 2- we add some        variant already poses a challenge for latest general-
                 extra lines such that they intersect at some points   purpose models. To further increase the difficulty,
                 and those intersections form some shapes (in other    weensurethat the provided sentences only reveal
                 cases, shapes are created using the full line seg-    partial adjective orderings, such as opinion, size,
                 ments and not at their intersection points). We then  shape, color, purpose, age, and material, origin,
                 create four subsets for the task corresponding to     without specifying the relative order of all cate-
                 the cross product of few vs many line breaks and      gories (e.g., whether material precedes or follows
                 intersect vs no intersect.                            age, or whether origin precedes or follows opin-
                   For o3-mini (high), which is the best performing    ion). This requires models to reason with partial
                 model on this task, we observe that the accuracy      information and avoid relying on prior knowledge.
                 for the few breaks subset is 58% while the accuracy
                 for the many breaks subset is 47%; we also observe
                 that the accuracy for the no intersect subset is 72%
                 while for the intersect subset is 33%. This shows
                 that both axes are adding to the difficulty of the
                 task.
                 A.8   Hyperbaton
                 In English, a prescribed order governs the sequence      Weobserve an interesting failure mode in this
                 of multiple adjectives preceding a noun. This or-     task: some models correctly induce partial adjec-
                 der, generally, is: opinion → size → age → shape      tive orderings but rely on prior knowledge of stan-
                 →color → origin → material → purpose. The             dard English order when selecting answers. Con-
                 BBHsuite includes Hyperbaton, an adjective or-        sider the example below.
                                                                  26491
                      Prompt                                                    ModelResponse
                      In a variant of English, we are given that the            Theansweris: ACDEHI
                      following sentences have correct adjective                In every correct sentence the adjectives
                      order: (1) medium-size aqua wrench (2)                    from chain A (if present) appear in the
                      normal-size spherical repulsive scissors ···              order: size → color → purpose → shape
                      (90) big chair (91) midsize bicycle                       →opinion → origin; and if any chain-B
                                                                                adjectives are used they come afterward in
                      In this variant of English, which of                      the order: material → age.
                      the following sentences use the correct
                      adjective order? ··· Select all that apply.               Looking at the options:
                      (A) big yellow drinking prismlike mysteri-                (A) “big (size) yellow (color) drinking
                      ous bangladeshi fiberglass brand-new ball                 (purpose) prismlike (shape) mysterious
                      (B) old leather drinking pyramidal lovely                 (opinion) bangladeshi (origin) fiberglass
                      congolese teal key                                        (material) brand-new (age) ball” fits exactly.
                      · · ·                                                     (C) “large (size) gray (color) whittling
                      (J) ancient paper smoking circular repulsive              (purpose) spherical (shape) silly (opinion)
                      turkish bottle                                            turkish (origin) brand-new (age) banana”
                      (K) None of the above                                     fits (chain-A adjectives then the single
                                                                                chain-B adjective).
                                                                                (D) “medium-size (size) brown (color)
                                                                                walking     (purpose)    triangular   (shape)
                                                                                ridiculous (opinion) russian (origin) dog”
                                                                                fits chain A perfectly.
                                                                                (E) “little (size) crimson (color) driving
                                                                                (purpose) circular (shape) ridiculous (opin-
                                                                                ion) congolese (origin) rubber (material)
                                                                                bowl” fits (chain-A then chain-B).
                                                                                (H) “red (color) typing (purpose) circular
                                                                                (shape) good (opinion) vietnamese (origin)
                                                                                paper (material) archaic (age) candle” fits.
                                                                                (I) “typing (purpose) pyramidal (shape)
                                                                                obnoxious (opinion) mexican (origin)
                                                                                cardboard (material) brand-new (age) bag”
                                                                                fits as well.
                                                                               Although the model correctly infers the partial
                                                                            adjective orderings: (i) size → color → purpose →
                                                                            shape→opinion→origin,and(ii)material→age,
                                                                            it incorrectly assumes that material follows origin.
                                                                            Thisassumptionlikelystemsfrompriorknowledge
                                                                            of standard English ordering (opinion → size →
                                                                            age →shape→color→origin→material→pur-
                                                                            pose). While the model correctly identifies option
                                                                            D,theonlycorrectanswer,itsincorrectassumption
                                                                            leads it to also select options A, C, E, H, and I.
                                                                            A.9    Linguini
                                                                            This task comes from Sánchez et al. (2024) and its
                                                                            problems are extracted from the International Lin-
                                                                            guistic Olympiad (IOL). According to the original
                     o3-mini (high) provides the following response:        workthat introduced this dataset, the problems are
                                                                       26492
                  "linguistic problems which require meta-linguistic           Another Sample New Operator
                  awareness and deductive reasoning capabilities to            a ; b equals (a >< b) if a + b > 0; otherwise,
                  be solved instead of pre-existing language profi-            it equals a - b
                  ciency".
                    Wecreated a subset of the Linguini problems
                  by sampling from four categories of the Linguini            We also define a form of composing multiple
                  problems, namely translation, fill blanks, num to        operations as follows: a <op1><op2> b denotes (a
                  text and text to num. The original dataset contains      op1b)op2b;forexample,4+*-5means(4+ 5)*
                  questions that require multiple answers. For exam-       -5 and 4 ∗ + + 5 means (4 * 5) ++ 5.
                  ple, the fill blanks questions have multiple blanks         Thenwesamplerandomarithmeticexpressions
                  that need to be filled. We create questions that have    involvingtheaboveoperations. Anexampleexpres-
                  a single answer by randomly selecting one of those       sion is: (1 @*+ 4) <>+[] (-4 *<>* -1) (although
                  blanks and only asking the model to fill that one.       our expressions are longer), with @, <>, and []
                                                                           being new operations. The job of the model is to
                  A.10    MovieRecommendation                              compute the value of the expression. Being able to
                  Theoriginal Movie Recommendation task in BBH             compute these expressions requires expanding the
                  has been created as follows. For each question,          expressions and making a long list of computations
                  a set of eight movies from MovieLens have been           correctly.
                  selected such that a rather large number of people          Upon looking at the outputs generated by the
                  have all liked five of them and disliked three of        models, we find a common failure mode is that
                  them. Then, a question has been generated by giv-        when multiple operations are composed, models
                  ing four of the five liked movies and asking models      sometimes forget to apply all of them despite un-
                  to recommend one of the remaining four movies,           derstanding how the operator composition works.
                  where the correct answer is the one left out of the      For instance, in one of our examples, while o3-
                  5 liked movies.                                          mini correctly explains how the operator composi-
                                                                           tion works in its reasoning trace, it still computes
                    Weupdatedthis task as follows. We create mul-          (1   ∗ ><− −6)as(1∗−6) >< −6and
                  tiple sets of movies where one of them contains          forgets the final subtraction operator in the com-
                  the five liked movies and the other ones contain         posed operator ∗ >< −.
                  someoftheliked movies and some of the disliked
                  movies. Then, we ask the model to select the set         A.12    NYCC
                  that contains movies that are more likely to all be      This task builds on the existing benchmarks for the
                  liked by a large group of people. In the new vari-       NewYorkerCaptionContest(NYCC)dataset(Hes-
                  ant we created, instead of recommending a single         sel et al., 2022; Zhang et al., 2024). The NYCC
                  movie given four movies, models have to examine          caption dataset consists of a) several hundred con-
                  each set separately and predict their overall likabil-   tests, each of which is a cartoon published in the
                  ity, and then decide the option that is more likely to   NewYorker magazine and several thousand sub-
                  have a likability score with our specific definition     mitted humorous captions, b) crowdsourced ratings
                  of likeability.                                          for each caption. The ratings are on a scale of
                  A.11    Multi-step Arithmetic                            “Unfunny”, “Somewhat Funny”, and “Funny”, and
                                                                           each caption has anywhere from a few dozen to a
                  This task introduces new arithmetic operators. An        few thousand ratings. Past works have focused on
                  example of such an operator is as follows:               pairwise comparison tasks, where two captions and
                                                                           a textual description of the cartoon are presented
                      Sample NewOperator                                   to the model, and the model has to pick the funnier
                      a >< b equals (a - b) if a * b > 0; otherwise,       of the two. As discussed in these works, the model
                      it equals a + b                                      tends to be fairly successful at these tasks, with
                                                                           GPT-4Turbogetting to ≈ 70% accuracy.
                                                                              Tomakethetasksignificantly more difficult, for
                    Someoftheoperations can be defined based on            each contest we sample one query from the top ten
                  the other new operations. For example we may             rated, and then take captions ranked 1000-1009 and
                  have:                                                    ask the model to choose the funniest. We use the
                                                                      26493
                   textual descriptions of the cartoons generated by               Sample Update to the Collection
                   GPT-4o that are provided in Zhang et al. (2024).                Mydadthrewawayallobjectsofacertain
                   Anexamplequeryisbelow.                                          color from my collection.
                                                                                   After this, my collection only had 5 blue
                       Sample Problem                                              objects and 3 white objects.
                      The following is a description of a funny                  Fortheaboveupdate,onehastofindwhichcolor
                       cartoon for the New Yorker Caption Contest              has been removed by comparing the new colors
                       Description: Two people are sitting at a ta-            with the object colors in the previous collection,
                       ble in a restaurant, having a conversation              and then update the collection accordingly. The
                       over glasses of wine. One of them is wear-              set of updates that the collection goes through in
                       ing a suit of armor.                                    each of the examples are randomly selected from a
                      Whichofthefollowing captions is the fun-                 large set of possible changes. At the end, a question
                       niest?                                                  is asked about the final collection. The question
                      1) Yes, I wrote that in my profile but I didn’t          is either an either question in which we ask how
                       meanit literally.                                       manyitemsinthefinal collection have property 1
                       2) That’s not what I meant by a nice night              or property 2, ... (e.g., how many items are either
                       out and you know it.                                    blue or small), or a neither question in which we
                       3) Sorry. It’s laundry day.                             ask how many items neither have property 1 nor
                      4) So, do you like horses?                               property 2, ... (e.g., how many items are not blue
                       5) In vino veritas? Surely you joust.                   and are not small).
                       6) So that’s your best suit?                              Oneoftheupdates,inparticular,isatrickupdate.
                       7) “Cougar seeks millennial” didn’t mean                It says one of the objects of property X has been
                       the year 1000                                           lost, but does not say which one. For example
                       8) Oh, really? You think men are under at-              it says: I lost one of the blue objects
                       tack?                                                   without specifying which blue object. This update
                       9) This is not what I expected when you                 is made in a way that the final number is the same
                       said you were middle aged.                              regardless of which object was lost. However, we
                      10) Frankly, you look much older than your               observe that many of the models get confused with
                       profile photo                                           this update and assume that the final count cannot
                                                                               becomputedsincewedonotknowwhichitemwas
                     In the above the correct caption is caption num-          lost. Specifically, o3-mini (high) says the problem
                   ber 9. Adding multiple possible options makes the           cannot be solved in 8% of such cases, Gemini 2.0
                   task significantly more challenging compared to             Flash in 93.5% of the cases, and GPT4o in 96.5%
                   the pairwise task.                                          of the cases.
                                                                               A.14    Object Counting
                   A.13    Object Properties                                   Given a long list of objects that a person has, the
                                                                               modelhastocountthenumberofitemsofacertain
                                                                               type. For examples, the items might belong to
                   In this task, an initial collection of objects with dif-    classes (fruits, cell phones, cars) and the goal may
                   ferent properties (color, size, origin, smell, and ma-      be to count the total number of cell phones that the
                   terial) are provided (e.g., a extra-small blue Cana-        person has. We consider two types of questions: 1-
                   dian jar made of glass and with a smell of rose).           counting the sum of the number of items belonging
                   Then, the collection goes through several updates           to two different classes, and 2- finding the absolute
                   corresponding to adding, removing or editing some           difference of the number of items belonging to two
                   of the objects. The updates are explained in the            different classes. To add to the difficulty of the task,
                   prompt and the models require a full grasp of the           someirrelevant information, including the number
                   object properties to identify what changes to the           of the same items that other people have, are added
                   collection must be made for each update. A simple           to the input context so the problem becomes one of
                   example of an update is as follows:                         finding multiple needles in a haystack.
                                                                         26494
                             Models        Gemini2.0Flash-Lite   Gemini2.0Flash   GPT4o    DeepSeekR1     o3-mini (high)
                          Over-count %            53.0                50.5          17.5        6.0            1.5
                         Under-count %            43.0                38.5          66.5       15.5            8.5
                  Table 7: Percentage of problems from the Object Counting task where the models over-counted or under-counted.
                    In Table 7, we report the percentage of cases             Prompt Template
                 whereeachofthemodelseitherover-counted the                   Here are three (post, reply) pairs from Red-
                  numberofobjects or under-counted, for the subset            dit. Your task is to decide whether
                 where the sum of two sets must be reported. Inter-           each reply is sarcastic. Specifically, label
                  estingly, we observe a that different models have           each pair with a "0" or "1", where
                  different failure modes on this task. The Gemini            a "1" indicates that the reply is sarcastic,
                  models tend to mostly over-count when they are              and a "0" indicates that the reply
                 wrong, whereas GPT4o, DeepSeekR1ando3-mini                   does not contain sarcasm, and provide your
                  tend to under-count when they are wrong.                    final answer as a comma-separated set of
                                                                              labels (e.g., "1,0,0" or "0,0,0").
                                                                              POST1: post1_text
                                                                              REPLY1: reply1_text
                  A.15   SARCTriples                                          POST2: post2_text
                                                                              REPLY2: reply2_text
                                                                              POST3: post3_text
                                                                              REPLY3: reply3_text
                  SARC(Self-Annotated Corpus for Sarcasm) (Kho-
                  dak et al., 2017) is a large dataset of sarcasm re-     A.16    Shuffled Objects
                  sponses mined from the Reddit social media / fo-
                  rum platform. Many Reddit users end a post or           The original task in BBH is as follows: there are
                  reply with the token “/s” when they have intended       Npeopleeachassigned to an object/person (e.g., a
                  the preceding text to be interpreted sarcastically      dance partner, a book, a color, etc.). For example,
                  or satirically. This allowed positive examples of       Alice has a green book, Bob has a red book, etc.
                  user-intended sarcasm to be mined.                      Then, there are multiple switch operations where
                                                                          pairs of people switch together what they are as-
                    Forking off the SARC dataset, we construct a          signed to (e.g., Alice and Bob switch their books).
                  challenging task for LLMs that requires reading         Attheend, one needs to predict the object/person
                  three independent examples from SARC, and clas-         assigned to one of the N people (e.g., at the end,
                  sifying each into binary label, where a positive        what color is the book that Bob has?).
                  label indicates sarcasm. The SARC authors created          Wecreated two variants of this problem. In the
                  a balanced test set with 64,666 examples. Many          first variant, we keep everything the same except
                  of these examples can only be understood with           that we add switch actions that have no effect. For
                  an image or an article link that accompanied the        example, we add Then, Person1 and Person2
                  original post or reply. On the other hand, some         switch their books.          Then, Person2 and
                  examples, usually with longer textual content, can      Person1 switch their books. We add many
                  be understood on their own. We design our de-           of these no-effect operations so that the problem
                  rived benchmark to consist mainly of the latter         becomes a long-context reasoning problem similar
                  type. To achieve this, we filter out examples with      to the approach in Vodrahalli et al. (2024).
                  either (1) less than 100 characters or (2) without a       The second variant extends the first variant, in
                  reply, resulting in 679 examples from the original      which we assign names to some of the switch ac-
                  test set, with 48.4% positive label rate. We sam-       tions as they occur and use those names later. For
                  ple (uniformly-at-random) 600 examples from this        example, the first time Person1 switches with
                  set, group them (uniformly-at-random) into groups       Person2occurs, we replace the text with Person1
                  of three, and pass the text of each 3-tuple of post,    switches with Person2 (let’s call this
                  reply pair to the following prompt:                     Action K), and the next time the same switch hap-
                                                                     26495
                     pens, with some probability we replace the text                       angular and diamond shapes and increased the
                     with action K repeats. Given the long-context                         difficulty compared to the problems in Spacial-
                     nature of the problem, the model requires to have                     LLMEval by increasing the number of hops of
                     the ability to remember information from many                         reasoning (corresponding to the number of moves
                     steps ago to be able to identify what that action                     of the agent). Moreover, while the original prob-
                     corresponded to.                                                      lems and the aforementioned problems we created
                         Anaiveapproachtotheprobleminthesetasks                            mainly require keeping track of the state after each
                     is to look at the switch operations one by one and                    move, we also create some variants of the problem
                     keep updating the object/person assigned to each                     where we provide multiple paths that intersect at
                     of the N people. This, however, will require track                    some vertex, thus requiring backward reasoning
                     keeping over a very large number of operations.                       from the intersection point to identify the position
                     While reasoning-specialized models might still be                     of the previous objects. As an example, consider
                     able to do this thanks to their long outputs, this may                the problem below:
                     be less feasible for the general-purpose models,
                     and it is not the optimal solution to the problem.                        SampleProblemRequiring Backward Rea-
                     Amoreclever approach to the problem is to first                           soning
                     identify all the operations that cancel each other
                     out, and then do the track keeping only over the                          You have been given a diamond tile map
                     few operations that do not cancel.                                        consisting of N rows [...] There is a unique
                         Looking at some model traces, we observe that                         object placed at each vertex. [...] You are
                     the models typically adopt the non-optimal ap-                            initially at the top corner where you see a
                     proach of updating the state after each switch, thus                      football. Then you movedown-rightforone
                     running out of output tokens in some cases. For ex-                       step and see a shampoo. Then you move
                     ample, Gemini 2.0 Flash runs out of output tokens                         down-leftforonestepandyouseeacat. [...]
                     for 25% of the problems. We also observe a sec-                           Then,youjumptoarandomvertexVwhere
                     ondfailure case where, if the question asks about                         you see a bear. Then you move [...] Then
                     the person/object assigned to Person P at the end,                        you move up-left and you see a shampoo.
                     the model assumes only switches involving Person                          Then you jump back to the random vertex
                     Pare important and other switches are irrelevant.                         Vanddothefollowing moves: down-left,
                     This is, however, not True. To understand why,                            down-left, down-right, up-left, down-left,
                     suppose "A" is assigned to "a", "B" is assigned to                        up-left. What will you find?
                     "b", and "C" is assigned to "c". Then "A" and "B"
                     switch and then "B" and "C" switch, and then we                          Forthefirst path (up until the first random jump),
                     want to know what "C" is assigned to. If we only                     weknowwherethepathstartsandwecanusethat
                     consider the switches involving "C", then we may                      alongwiththefollowingmovestodeterminewhich
                     predict the correct answer to be "b" whereas the                      object is where. Then, a random jump is made
                     correct answer in this case is "a".                                   to a vertex V but it is not specified which vertex
                     A.17      Spatial Reasoning                                           it is.  However, we observe that after a number
                     This task is mainly based on the problems in Spa-                     of moves, the agent sees the shampoo again so it
                     cialLLMEval (Yamada et al., 2023). The problems                       can reason backward from this point to figure out
                     describe a geometric construct composed of verte-                    which vertex it has been at in the previous steps.
                     cies and edges. At each vertex, there is a unique                    These information can also be used to determine
                     object. An agent starts from one of the vertecies,                    the vertex V which must then be used to solve the
                     movesalongtheedgesandobserves the objects at                          problem when the second jump to V is made.
                     several vertices, and then after moving for several                      Wefind that the problems involving backward
                     steps along the edges, the job of the model is to                     reasoning are more challenging for the models.
                     determine what object is at the final vertex where                    Specifically, we find that o3-mini (high) gives an ac-
                     the agent stops.                                                      curacy of 58.8% on the forward-only problems and
                         Wesampled from the hexagonal, circular, and                      19.2% on the backward problems and DeepSeek
                     rhombusconstructs of SpacialLLMEval. We also                          R1givesanaccuracyof48.6%ontheforward-only
                     created similar constructs with tree structure, tri-                  problems and 3.8% on the backward problems.
                                                                                    26496
                 A.18    SportQA                                          A.19   TemporalSequences
                                                                          In this task, the calendar schedules of a few peo-
                 SportQA(Xiaetal., 2024) is a challenging sports          ple is provided for an entire week. The blocked
                 understanding dataset designed to test rule-based        times for the calendar of each person is sampled
                 and strategic reasoning capabilities in LLMs be-         randomly, and is provided as text either by giving
                 yond surface-level sports knowledge. It consists         the times of the day when it is blocked or giving the
                 of three levels (Level 1 to Level 3) with increasing     times of the day when it is free. The goal is to find:
                 difficulty. In this work, we focus on Level 3 ques-     1- the longest meeting that can be scheduled for
                 tions, which are curated by coaches and student          them, and 2- the number of possibilities for such
                 athletes across six sports: soccer, basketball, vol-     a meeting. These people may also have some con-
                 leyball, tennis, table tennis, and American football.    straints or we might have some information about
                 Wesub-sample200multi-hop reasoning questions             themthat has to be taken into account for meeting
                 and discard single-hop questions from the Level 3        scheduling. Examples include: being in a different
                 set. Overall, these questions challenge LLMs to          timezone than the other participants, needing some
                 reason about fine-grained sports rules (e.g., penalty    free time before/after the meeting, being flexible to
                 assessment and tactical choices), which expert stu-      miss a portion of the meeting, requiring some free
                 dent athletes can answer with near-perfect accuracy      time for lunch, only being able to attend meetings
                 (Yang et al., 2024b).                                    of up to a certain length, being willing to free up
                    Thequestions we selected from SportQA have a          somespecific parts of the day if needed, etc.
                 compositional nature, in that a main question and          The model predictions are considered correct
                 somesub-questionsareprovidedandthemodelhas               if they predict both values (i.e. the longest time
                 to answer all of them correctly for its answer to be     and the number of possibilities for a meeting of
                 considered correct. We add some instructions at          that length) correctly. We observe that both of
                 the end of the questions so the models can answer        these add to the difficulty of the problem. For
                 them zero-shot in the format that we want. The           example, o3-mini (high) has an overall accuracy of
                 questions are in the following format:                   68.5%onthisproblem,butifweonlyaskedforthe
                                                                          longest meeting time, then the accuracy will jump
                                                                          to 78%. The same is true for Gemini 2.0 Flash
                     Prompt Template                                      and Flash-Lite where their accuracy for the overall
                                                                          task is respectively 0.5% and 1.0%, but if we had
                     Youwill be given a main question and two             asked only for the longest meeting time then their
                     sub-questions. Each question comes with              accuracy will jump to 5% and 7% respectively.
                     multiple choices you can select from. For
                     each question, select all the correct choices.       A.20   TimeArithmetic
                     Main Question: <TEXT OF THE QUES-                   This task is based on the time arithmetic subset of
                     TION>                                                the Test of Time (ToT) benchmark (Fatemi et al.,
                     <OPTIONSAtoD>                                        2024). The original subset contains various ques-
                     Sub-Question 1: <TEXT OF THE SUB-                    tions about understanding, computations over, com-
                     QUESTION>                                            parisons, and conversions of dates and times. There
                     <OPTIONSAtoD>                                        are also trick questions which may require extra
                     Sub-Question 2: <TEXT OF THE SUB-                    thinking. The dataset also contains some schedul-
                     QUESTION>                                            ing problems, but we removed that subset given
                     <OPTIONSAtoD>                                        that we have an entire task (Temporal Sequence)
                     For each question, provide the answer as a           dedicated to it.
                     concatenation of the correct choices. Sepa-            Following Hosseini et al. (2024), we created a
                     rate the answersforthequestionsbycomma.              compositional version of the ToT Time Arithmetic
                     For example, if the correct choices for the          dataset as follows. Let Q1 and Q2 be two ques-
                     main question are A and C, for the first             tions from the original dataset, where the answer
                     sub-question is D and for the second sub-            to the Q1 is A1 (A1 being a number) and let A2
                     question are B and D, your final answer              be a number that is used in Q2. Then, we create a
                     must be "AC, D, BD".                                 compositional question as follows:
                                                                     26497
                     Sample Prompt Template                              77.5%, whereas on the second subset the two mod-
                     Let the answer to Q1 be X.                           els give an accuracy of 28.8% and 3.8%. We still
                     Q1: <Text of the question>.                          keep the first subset despite the high performance
                     Let X’ = X + (A2 - A1). Use this value to            of the o3-mini model so it can be used to distin-
                     solve Q2.                                            guish among smaller, general-purpose models.
                     Q2: <Text of the question with A2 replaced             For the new set we created, we always ask about
                     with "X’">.                                          the truthfulness of one of the people at the end of
                                                                          the chain, and another person at an earlier position
                                                                          in the chain (but still far off in the chain). Concep-
                    In some cases, the answer to a question might         tually, one would expect that if a model has made
                 contain multiple numbers, e.g. a date with three         a mistake for the person at an earlier position in
                 numbers. In those cases, we assign these values          the chain, then the chances of making a mistake for
                 to variables X, Y, and Z and use them in the later       the person at the end of the chain must be higher.
                 questions.                                              Weverified whether this is the case for our models.
                 A.21    WebofLies                                        For o3-mini, we observe that the accuracy for both
                                                                          cases is 41.2%, for Gemini 2.0 Flash it is 30% for
                 In this task, whether a specific person P1 tells the     the earlier person and 27.5% for the last person,
                 truth of lies is provided as input. Then, for other      and for Gemini 2.0 Flash-Lite it is 25.6% for the
                 people, it is specified what they say about the truth    earlier person and 21.2% for the last person, all
                 value of some other person. This forms a chain-like      showing this effect. GPT4o, however, is surpris-
                 structure that can be started from P1 and continued      ingly behaving the opposite, having an accuracy of
                 to find whether each of the people tells the truth or   19.4% for the earlier person and 25% for the last
                 lies.                                                    person.
                    Weusedtwodifferent variants for this task. The        A.22   WordSorting
                 first variant comes from the web of lies V2 from
                 LiveBench (White et al., 2024). In this variant,        TheWordSortingtaskis split into 2 sub-tasks.
                 complexity has been added to the task by specify-          The first sub-task is from the BIG-Bench Mis-
                 ingwhereeachpersonis,andthenhavingsentences              take dataset (Tyen et al., 2024). This task involves
                 such as The person at the cafe says the person at        finding the first mistake in an existing chain-of-
                 the zoo lies. The second version is created by us. In    thought sequence, used to answer a Word Sorting
                 this version, we add cyclic cases whose truth value      question in the original BBH dataset. In each exam-
                 remains unknown, but one can still infer something       ple, the target answer is either the number where
                 about them and continue the chain. For example,          the first mistake occurred, or that there are no mis-
                 consideracycliccasesuchasPerson1saysPerson2              takes in the CoT sequence. These CoT sequences
                 tells the truth. Person2 says Person1 tells the truth.   are generated by prompting PaLM 2 Unicorn (Anil
                 In this case, we cannot determine whether Person1        et al., 2023) on the original BBH dataset at temper-
                 or Person2 tell the truth or lie (so their truthfulness  ature = 0. The newline is used as a stop token so
                 remains unknown). However, if we have another            that each intermediate step can be prepended with
                 sentence Person3 says either both Person1 and Per-      ‘Thought 1: ’, ‘Thought 2: ’, etc. Further informa-
                 son2 lie or both tell the truth, we can determine        tion on the prompting and generation process can
                 that Person3 tells the truth. In both variants of the    be found in Tyen et al. (2024).
                 problems, we ask about the truthfulness of three           The second sub-task is sorting a list of words
                 of the people in the chain, so the random chance         given a new alphabet order (examples include: an
                 performance for the LiveBench subset is 1/8 since        alphabet order that is the same as English but two
                 the truthfulness of each of the three people can be      letters are swapped in the order, an alphabet order
                 either yes or no, and 1/27 for our new set given         that is the same as English but one/two letters are
                 that the values can also be unknown.                     movedtothebeginning/end of the order, or a com-
                    Weobservethat the first subset is easier than the     pletely new order). This task requires going against
                 second subset, so we included only 40 examples           a strong prior and sorting words in a non-typical
                 of subset one and 160 of subset 2. Specifically,        way. We observe an interesting failure mode for
                 o3-mini (high) gives an accuracy of 100% on sub-         this task where some models understand the new
                 set one and Gemini 2.0 Flash gives an accuracy of        alphabet order correctly but keep sorting the words
                                                                     26498
                     basedontheoriginalEnglishorder. Asanexample,                           Looking at the performance for the top perform-
                     consider the following question:                                   ing models in Table 8, we notice two interesting
                         Prompt                                                         patterns. Firstly, while the random chance per-
                                                                                        formance is lower for larger puzzles, we see that
                         Consider a new alphabet whose letters have                     increasing the puzzle sizes does not significantly
                         the same order as the English alphabet, ex-                    lower the model performances in some cases. This
                         cept that s and i are the last two letters.                    is especially true when going from puzzles of size
                         Sort the following words with the new al-                      6 to 7. Secondly, we observe that the top-2 mod-
                         phabet and separate them with comma: va,                       els (Gemini 2.0 Flash and o3-mini high) perform
                         sprue, subject, immemorial, anaheim, in-                       significantly better on the 8x8 puzzles that have no
                         terpretations, clinic, trafficked, communica-                  distracting clues compared to the smaller puzzles
                         tions, marx, demonstrations, micro, offprint,                  of size 7x7 or 6x6 that do have distracting clues.
                         characterizations, personifications, eaten,                    This hints at a possible failure mode for frontier
                         madeira                                                        models: they seem to get confused in presence of
                                                                                        distractors and underperform. This might be in
                        Gemini 2.0 Flash provides the following re-                     part due to the fact that models might have already
                     sponse:                                                            seen clean zebra puzzles and their solutions, but
                                                                                        they may not have seen the variant with distracting
                         ModelResponse                                                  clues, makingthelatteracaseofout-of-distribution
                                                                                        generalization.
                         Here’s how to sort the words according to
                         the modified alphabet: 1. **Modified Al-                       B Reproducibility
                         phabet:** a, b, c, d, e, f, g, h, j, k, l, m, n, o,
                         p, q, r, t, u, v, w, x, y, z, s, i [...] The final an-         For most of the models we tested in this work, we
                         swer is: anaheim, characterizations, clinic,                   obtained the results through API calls. Specifically,
                         communications, demonstrations, eaten, im-                     for Gemini 2.0 and Gemma2 models, we used AI
                         memorial, interpretations, madeira, marx,                      Studio, for GPT4o and o3-mini (high) we used the
                         micro, offprint, personifications, sprue, sub-                 OpenAIAPI,andforDeepSeekR1resultsweused
                         ject, trafficked, va                                           the API from Together AI. For the LLama and Dis-
                                                                                        till R1 Qwen results, whose parameters are avail-
                        While the model provides the correct new alpha-                 able publicly, we obtained results by loading them
                     bet, we see that the final answer is sorted based on               on GPUs. This ensures reproducibility as other
                     theoriginalorder(whichagreesbetterwithmodel’s                      researchers can also follow the same approach and
                     prior), and not based on the new order.                            obtain our results.
                                                                                            For all of our problems, we added the following
                     A.23     ZebraPuzzles                                              suffix to the text of the question to encourage the
                     Zebra puzzles, also known as Einstein puzzles, are                 model to produce the final answer in a format that
                     verbal descriptions of entities and properties that                wecaneasily extract it:
                     partially populate a grid linking entities to their                     Suffix
                     properties (Shah et al., 2024). The description may
                     also include constraints on these properties, such                      Think step by step, and when you provide
                     that it is possible to deduce the other entity-property                 the final answer, please use the prefix "The
                     links. Following the approach in Shah et al. (2024),                    answer is:" without any modification, and
                     wegenerate square-grid Zebra puzzles of size 5x5,                       provide the answer directly, with no format-
                     6x6, 7x7, and 8x8. We add distracting clues to                          ting, no bolding, and no markup. For in-
                     puzzles of size 5, 6, and 7 to make them more                           stance: "The answer is: 42" or "The answer
                     challenging, but do not add them to puzzles of                          is: yes". If the question is multiple choice
                     size 8 to avoid keeping the context size too large.                     with a single correct answer, the final an-
                     To simplify evaluation, the questions ask for the                       swer must only be the letter corresponding
                     position of one of the n people in the n x n puzzles,                   to the correct answer. For example, "The
                     so the random chance performance for a n x n                            answer is: (a)".
                     puzzle is 1/n.
                                                                                  26499
                                 Puzzle Size / Models     Gemini2.0Flash-Lite     Gemini2.0Flash     GPT4o     o3-mini (high)
                                5 x 5 (with distractors)          37.5                  60.0          37.5         90.0
                                6 x 6 (with distractors)          38.9                  33.3          30.6         58.3
                                7 x 7 (with distractors)          36.5                  36.5          37.8         55.4
                               8 x 8 (without distractors)        16.0                  52.0          20.0         74.0
                          Table 8: Accuracy break-down of the model performances on the Zebra Puzzles task by puzzle size.
                      Wethenextract the answer by splitting with the            is the DisambiguationQA task. Checking the re-
                   prefix and finding what comes next. We find that             sponsesfromGemini2.0FlashontheBBHversion
                   sometimes the models slightly deviate from the               of the dataset, we observe that the model overly
                   exact prefix we gave them, so we look for four               selects the ambiguous option, sometimes for poten-
                   prefixes in the answer until one of them is found:           tially legit reasons. For example, for disambiguat-
                   "The answer is: ", "The answer is ", "The                    ing the pronoun they in the sentence "Alex told
                   final answer is: ", "The final answer is                     us that they could not meet", the model responds
                   ". Once weextract the final answer, we apply some            that "They could refer to Alex or to some other
                   minimal cleaning as follows: 1- if the final answer          group of people not explicitly mentioned. There-
                   is wrapped within the boxed, text, texttt or **, we          fore, the antecedent is ambiguous". We also find
                   removethat and extract what is inside it. We notice          that in several of the cases, simply changing the
                   that after producing the final answer, some models           task description from "explain the antecedent of
                   producea"\n"andthensomeextratext. Therefore,                 the pronoun [...] or state that it is ambiguous" to
                   wesplit the extracted final answer using "\n" and            "try to disambiguate the antecedent of the pronoun
                   take the first element as the final answer. Then             given the context or state that it is ambiguous if it
                   welowercase both the final answer and the label              cannot be disambiguated" makes the model pick
                   determine correctness using a few simple rules: 1-           the right choice.
                   if the two are identical, then we consider the final         D RelatedWork
                   answer correct, 2- if the final answer is identical to
                   the label up to removing single or double quotes             There has been significant emphasis on using
                   or brackets from the beginning and end of it, we             LLMsfor mathematical and scientific reasoning.
                   consider it to be correct, 3- the label for multi-           This has led to the popularity and proliferation
                   choice questions is in (<LETTER>) format and                 of math- and STEM-based evaluations, such as
                   we expect a similar final answer but if the final            (Hendrycks et al., 2020; Cobbe et al., 2021), and
                   answer is only the letter without the parentheses,           more recently, (Glazer et al., 2024; Phan et al.,
                   weconsider it correct, and finally 4- for questions          2025). However, the generalizability of mathe-
                   whoselabels contain multiple elements separated              matical reasoning skills to broader domains re-
                   by comma, if the label and final answer are the              mains unclear. Indeed, attempts to make existing
                   sameuptoreplacing the spaces after the commas                benchmarks more robust—for example, (Mirzadeh
                   with blanks, then we consider the final answer to            et al., 2024)—have highlighted an overall lack of
                   be correct.                                                  robustness and logical reasoning capabilities. Sev-
                   C BBEHvsBBHPerformance                                       eral benchmarks have also been developed to ad-
                                                                                dress specific areas of reasoning, including tempo-
                   To understand how much each task in BBEH has                 ral reasoning (Xiong et al., 2024; Beniwal et al.,
                   becomehardercomparedtoitscounterpartinBBH,                   2024; Dhingra et al., 2022), spatial understand-
                   we evaluated Gemini 2.0 Flash on BBH and re-                 ing (Bohnet et al., 2024; Yamada et al., 2023;
                   ported the results in Table 9. For the fairness of the       Mirzaee et al., 2021; Shi et al., 2022), common-
                   comparison,weranthemodelinazero-shotsetting.                 sense reasoning (Zellers et al., 2019; Talmor et al.,
                   However, we note that some of the tasks in BBH               2018; Sakaguchi et al., 2021), and logical reason-
                   maybecomeslightly ambiguous in a zero-shot set-              ing (Saparov and He, 2022; Tafjord et al., 2020;
                   ting given that it has been mostly developed for a           Saparov et al., 2023; Parmar et al., 2024). How-
                   few-shot evaluation. Nevertheless, we observe that           ever, these benchmarks tend to focus narrowly on
                   onalmost all the tasks, the difficulty level has sig-        specific domains, leading to potential evaluation
                   nificantly increased in BBEH. A notable exception            biases if a more holistic view of model capabilities
                                                                          26500
                             TaskinBBEH↓/Accuracyon→ OldtaskfromBBH NewtaskinBBEH
                                       BoardgameQA                          88.0                  42.5
                                    Boolean Expressions                     97.6                  27.0
                                   Causal Understanding                     65.2                  52.0
                                    DisambiguationQA                        42.0                  48.3
                                      DyckLanguages                         65.2                  14.0
                                     Geometric Shapes                       73.6                  35.0
                                        Hyperbaton                          94.8                   4.5
                                       SARCTriples                          86.0                  37.5
                                          Linguini                          62.8                  15.5
                                  MovieRecommendation                       66.4                  59.5
                                   Multistep Arithmetic                     99.6                   9.5
                                           NYCC                             81.2                  11.0
                                     Object Properties                      96.8                   1.5
                                      Object Counting                       97.6                  11.0
                                      Shuffled Objects                     100.0                   9.0
                                     Spatial Reasoning                      97.6                  18.5
                                          SportQA                           89.6                  23.0
                                        BuggyTables                         98.6                   3.5
                                    TemporalSequences                       98.8                   0.5
                                      TimeArithmetic                        92.0                  48.0
                                        WebofLies                           94.8                  18.5
                                       WordSorting                          84.8                  26.0
                                       ZebraPuzzles                         87.6                  44.5
                                           BBEH                             85.2                  23.90
                             Table 9: Performance of Gemini 2.0 Flash on BBEH and its counterpart task from BBH.
                 is not considered. To address this limitation, sev-    E Potential Risks
                 eral benchmarks have been developed to integrate       Our benchmark contains questions that contain
                 multiple tasks into a single evaluation framework,     long contexts and require a great amount of think-
                 including (Wang, 2018; Wang et al., 2019; Weston       ing, reflected in the number of output tokens that
                 et al., 2015; Lu et al., 2023; Kazemi et al., 2024;    the models have to generate to solve them. As
                 Hendrycks et al., 2020; Wang et al., 2024; Parmar      such, evaluating models on our benchmark may
                 et al., 2024; Srivastava et al., 2022). Our work       require a higher amount of computation and energy
                 builds on this line of research, introducing a new     compared to some other benchmarks.
                 set of challenging tasks for future model evaluation
                 and performance improvement. The multi-task na-
                 ture of our benchmark with fine-grained tasks each
                 focused on some reasoning skills enables model
                 developers to discover and analyze failure modes
                 in further depth. Note that while private initiatives
                 such as ChatBot Arena (lmarena) and the SEAL
                 leaderboard (ScaleAI) conduct model evaluations
                 acrossvariousaspects,theymaysufferfromseveral
                 potential issues as pointed out in (Bansal and Maini,
                 2024). Our benchmark provides an open evalua-
                 tion frameworkwithanautomaticanddeterministic
                 scoring mechanism, ensuring full transparency and
                 reproducibility for the broader research commu-
                 nity.
                                                                   26501
