                                                           Generative Pretraining from Pixels
               Ioffe, S. and Szegedy, C. Batch normalization: Accelerating    Menick,J.andKalchbrenner,N. Generatinghighﬁdelityim-
                 deep network training by reducing internal covariate shift.     ages with subscale pixel networks and multidimensional
                 arXiv preprint arXiv:1502.03167, 2015.                          upscaling. arXiv preprint arXiv:1812.01608, 2018.
               Ke, N. R., GOYAL, A. G. A. P., Bilaniuk, O., Binas, J.,        Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., and
                 Mozer, M. C., Pal, C., and Bengio, Y. Sparse attentive          Dean,J. Distributed representations of words and phrases
                 backtracking: Temporal credit assignment through re-            and their compositionality. In Advances in neural infor-
                 minding. In Advances in neural information processing           mation processing systems, pp. 3111–3119, 2013.
                 systems, pp. 7640–7651, 2018.                                Misra, I. and van der Maaten, L. Self-supervised learn-
               Kingma, D. P. and Dhariwal, P. Glow: Generative ﬂow               ing of pretext-invariant representations. arXiv preprint
                 with invertible 1x1 convolutions. In Advances in Neural         arXiv:1912.01991, 2019.
                 Information Processing Systems, pp. 10215–10224, 2018.       Mohamed, A.-r., Dahl, G., and Hinton, G. Deep belief
               Kingma,D.P.andWelling,M. Auto-encoding variational                networks for phone recognition. 2009.
                 bayes. arXiv preprint arXiv:1312.6114, 2013.                 Nair, V. and Hinton, G. E. Rectiﬁed linear units improve
               Kingma,D.P., Mohamed,S., Rezende, D. J., and Welling,             restricted boltzmannmachines. InProceedingsofthe27th
                 M. Semi-supervised learning with deep generative mod-           international conference on machine learning (ICML-10),
                 els. In Advances in neural information processing sys-          pp. 807–814, 2010.
                 tems, pp. 3581–3589, 2014.                                   Noroozi, M. and Favaro, P. Unsupervised learning of visual
               Kitaev, N., Kaiser, Ł., and Levskaya, A. Reformer: The            representations by solving jigsaw puzzles. In European
                 efﬁcient transformer. arXiv preprint arXiv:2001.04451,          Conference on Computer Vision, pp. 69–84. Springer,
                 2020.                                                           2016.
                                                                              Oord, A. v. d., Kalchbrenner, N., and Kavukcuoglu,
               Kolesnikov, A., Zhai, X., and Beyer, L. Revisiting self-          K. Pixel recurrent neural networks.      arXiv preprint
                 supervised visual representation learning. In Proceedings       arXiv:1601.06759, 2016.
                 of the IEEE conference on Computer Vision and Pattern        Oord, A. v. d., Li, Y., and Vinyals, O. Representation learn-
                 Recognition, pp. 1920–1929, 2019.                               ing with contrastive predictive coding. arXiv preprint
               Krizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet         arXiv:1807.03748, 2018.
                 classiﬁcation with deep convolutional neural networks.       Paine, T. L., Khorrami, P., Han, W., and Huang, T. S. An
                 In Advances in neural information processing systems,           analysis of unsupervised pre-training in light of recent
                 pp. 1097–1105, 2012.                                            advances. arXiv preprint arXiv:1412.6597, 2014.
               Larochelle, H. and Murray, I. The neural autoregressive        Parmar, N., Vaswani, A., Uszkoreit, J., Kaiser, Ł., Shazeer,
                 distribution estimator. In Proceedings of the Fourteenth        N., Ku, A., and Tran, D. Image transformer. arXiv
                 International Conference on Artiﬁcial Intelligence and          preprint arXiv:1802.05751, 2018.
                 Statistics, pp. 29–37, 2011.
               Lasserre, J. A., Bishop, C. M., and Minka, T. P. Principled    Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., and
                 hybrids of generative and discriminative models. In 2006        Efros, A. A. Context encoders: Feature learning by
                 IEEEComputerSociety Conference on Computer Vision               inpainting. In Proceedings of the IEEE conference on
                 andPattern Recognition (CVPR’06), volume 1, pp. 87–             computer vision and pattern recognition, pp. 2536–2544,
                 94. IEEE, 2006.                                                 2016.
                                                                              Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V.,
               Lee, H., Grosse, R., Ranganath, R., and Ng, A. Y. Convo-          Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P.,
                 lutional deep belief networks for scalable unsupervised         Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cour-
                 learning of hierarchical representations. In Proceedings        napeau, D., Brucher, M., Perrot, M., and Duchesnay, E.
                 of the 26th annual international conference on machine          Scikit-learn: Machine learning in Python. Journal of
                 learning, pp. 609–616, 2009.                                    Machine Learning Research, 12:2825–2830, 2011.
               May,A.,Garakani, A. B., Lu, Z., Guo, D., Liu, K., Bellet,      Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark,
                 A., Fan, L., Collins, M., Hsu, D., Kingsbury, B., et al.        C., Lee, K., and Zettlemoyer, L. Deep contextualized
                 Kernel approximation methods for speech recognition.            wordrepresentations. arXiv preprint arXiv:1802.05365,
                 arXiv preprint arXiv:1701.03577, 2017.                          2018.
