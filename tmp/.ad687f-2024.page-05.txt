                 Algorithm 1 Pseudocode of RESONANCE ROPE.                  Because    of   its  simplicity,   RESONANCE
                 Require: θ ,θ ,··· ,θd       ∈Θ                         ROPE can be applied on top of RoPE and all
                              0  1         −1
                                          2                              RoPE-based scaling methods to reduce their
                    for i ∈ {0,1,··· , d − 1} do
                                       2                                 feature gap in TSTL and further improve their
                        λ =2π/θ
                         i         i                                     performance.      Meanwhile, this method only
                        ˜
                        λ =round(λ )       ▷ Roundtointeger wavelength
                         i            i                                  involves an offline computation of the scaled θ,
                        ˜        ˜
                        θ =2π/λ
                         i         i                                     thus introducing no online computation overhead.
                    endfor
                    ˜      ˜ ˜         ˜
                    Θ={θ0,θ1,··· ,θd−1}                                  5 EvaluatingPosition Embeddings
                                        2
                    ComputeRd byEquation2                                    with POSGEN
                                 ˜
                                Θ
                    Computeq,kbyEquation4,5                              In this section, we propose our new position em-
                                                                         bedding evaluation suite: POSGEN, based on an
                    Wetackle this issue by developing a synergistic      analysis of common failure patterns on existing
                 modification to the conventional RoPE embedding,        position embedding evaluation methods.
                 referred to as RESONANCE ROPE. It aims to iden-            Weconsider a next token prediction task, where
                 tify the optimal angular frequency that minimizes       weexpect the model to generate the token xl given
                                                                         the input sequence {x0,··· ,x      }. In TSTL sce-
                 the interpolation gap, which ensures the corre-                                         l−1
                 sponding wavelength closely matches the original        narios, when a model succeeds in correctly generat-
                 one while imposing alignment of the wavelength          ing a token up to position L but fails systematically
                 to an integer. More specifically, for a given angular   afterwards, we observe two failure patterns:
                                                              	
                 frequencysetofRoPEΘ = θ ,θ ,...,θ               , we
                                                 1  2       d/2             • Failure due to harder algorithmic difficulty
                 round their wavelengths to their nearest integer to          ongenerating later tokens. The rule of gen-
                 eliminate new rotary angles on each feature. We              erating a new token x may vary with the se-
                 provide a pseudocode for RESONANCE ROPE in                                          l
                                                                              quence length l. Generally, tokens placed
                 Algorithm 1.                                                 later in the sequence depend on more con-
                    Afterapplyingthistechnique,eachRoPEfeature                text tokens, which incurs a more complex de-
                               ˜
                 repeats after λ tokens, and therefore “resonates”
                                 i                                            pendency pattern. During training on shorter
                 with a specific span length and eliminates the in-           sequences, the model only learns the token
                 terpolation gap between pre-trained and OOD po-              dependency rules involving up to L tokens,
                 sitions on pre-critical dimensions. We illustrate            and might fail on longer sequences because it
                 the effect of RESONANCE ROPE on RoPE’s fea-                  has never been exposed to the more complex
                 ture gap on one of the pre-critical dimensions in            dependency rules.
                 Figure 1. Moreover, we can prove the feature gap
                 reducing ability of our method. As for above, we           • Failure due to unrecognized new token po-
                 formalize RESONANCE ROPE’s computation rule                  sitions. The difference between training and
                     ˜            d                                           testing lengths in the TSTL setting creates
                 as f(x,m) = R˜       Wx.
                                  Θ,m                                         a feature gap between the position indices
                 Theorem1. ForaRoPE-equippedmodelwithcon-                     or position embeddings in training and infer-
                                                        ˜
                 text window L, RESONANCE ROPE f reduces the                  ence. Thisfeaturegapmakesitdifficultforthe
                 feature gap on pre-critical dimensions to 0. Specifi-        model to generalize to new positions due to
                 cally, ∀x ∈ X, ∀n ∈ N\{0,··· ,L −1}, we have:                unrecognized features. RoPE scaling methods
                                     ˜            ˜                           mainly focus on reducing this type of length
                           min      |f(x,m) −f(x,n) | = 0
                       m∈{0,···,L−1}          i          i                    extrapolation failure.
                 for all i = 0,...,2c − 1.                                  Currently,   neither perplexity-based evalua-
                                                                         tions (Rae et al., 2020; Huang et al., 2021; Wu et al.,
                    See the proof in Appendix A. Note that although      2022) nor synthetic TSTL evaluations (Kazemne-
                 each pre-critical RoPE feature R˜       repeats, the    jad et al., 2023; Liu et al., 2023) can effectively
                                                    θ ,m
                                                     j
                 combination of all {R˜       }     only repeats af-     distinguish these two failure patterns, since the
                                          θ ,m j<c
                                           j
                 ter the least common multiple (LCM) of all pre-         token generation difficulty tends to increase with
                 critical dimensions’s wavelengths. For LLaMA2,          respect to the sequence length in these tasks. To fa-
                                                        51
                 this LCM value is greater than 7 × 10     .             cilitate research on better position representations,
                                                                     590
