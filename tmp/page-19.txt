                                   Learning program synthesis with self-improving language models: A case study on ARC-AGI
                cost, generation for a task was halted once at least 100 solutions achieved perfect accuracy on ARC input-output examples.
                This criterion was applied independently during both the sampling and refinement phases.
                Algorithm 3 SOAR
                Require: pretrained LLM, ARC dataset
                Ensure: Best performing program solution
                  1: loop
                  2:    Generate 3k program candidates
                  3:    Apply program refinement to obtain 6k programs
                  4:    Perform majority voting on refined programs
                  5:    Update search traces
                  6:    Perform data selection
                  7:    Apply generation & refinement fine-tuning
                  8: end loop
                  9: return Top performing program solutions
                E. Learning to generate and refine programs jointly
                Given that both generation and refinement can be improved independently, should we train separate specialized models
                or can a single model learn both capabilities? Table 7 explores several combinations of using base/finetuned models for
                generation and refinement steps. The results reveal several key insights:
                1. Negative transfer from generation to refinement: Models finetuned for generation (fine-gen) decrease refinement
                    performance compared to base models (exp 2 < exp 1),
                2. Positive transfer from refinement to generation: Models finetuned for refinement only (fine-ref) strongly improve program
                    generation compared to base models (exp 7 > exp 1), even more so than models finetuned for generation (exp 7 > exp 5),
                3. Positive interaction effects between refinement and generation: Models finetuned for refinement and generation jointly
                    (fine-both) lead to better generation (exp 8 > exp 7 > exp 1) and better refinements (exp 8 > exp 6 > exp 1) than leveraging
                    two models trained on each of the tasks.
                Theseresults demonstrate the importance of learning both to better generate and to better refine programs, and highlighting a
                useful synergy between the two capabilities. This suggests these tasks share underlying knowledge about program structure
                and transformation patterns.
                                                         Exp    Genmodel       Ref model     Genacc      Search acc
                                                          1         base          base        29.67         34.83
                                                          2                     fine-gen                    32.92
                                                          3                      fine-ref                   42.88
                                                          4                     fine-both                   44.04
                                                          5       fine-gen        base        36.46         40.63
                                                          6                      fine-ref                   43.88
                                                          7       fine-ref        base        39.17         39.93
                                                          8                     fine-both     39.79         44.42
                Table 7. ARC-train performance using different combinations of models for generation (col 2) and refinement (col 3). fine-gen/ref/both
                indicate a base model finetuned for generation, refinement or both. Gen acc and search acc indicate the ARC-train accuracy after
                generations (3k solutions) and after search (3k generations + 3k refinements).
                F. Program synthesis using a mix of induction and transduction
                During our analysis of data collected in the self-improving phase on ARC-train tasks, we identified some solutions that
                employed a hybrid approach combining transduction and induction (see Code F). These solutions used Python to compute
                                                                                     19
