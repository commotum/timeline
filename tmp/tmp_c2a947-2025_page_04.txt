                 Enhancing Modern SAT Solver With Machine Learning Method                                                GLSVLSI’25, June 30–July 02, 2025, New Orleans, LA, USA
                 3 RelatedWorks
                 In recent years, several techniques have emerged that employ ma-
                 chine learning methods to improve the efÏciency and effectiveness
                 of SAT solving. Kurin and Godil have tried to improve the SAT
                 solver heuristics with graph neural networks and reinforcement
                 learning [12], and later demonstrated in Graph-Q-SAT [13] that
                 Q-learning can be used to learn the branching heuristic of a SAT
                 solver. NeuroSAT, introduced by Selsam et al. [18], was the pio-
                 neering framework that integrated a neural network model into
                 an end-to-end SAT solver. Notably, it was not designed to function
                 as a complete SAT solver by itself. NLocalSAT [23] builds upon
                 NeuroSAT’sarchitecture,usingtheoutputfromtheneuralnetwork
                 to improve initial variable assignments for SLS solvers ofÒine. Han
                 [11] introduced a network within NeuroGlue designed to forecast                                       Figure 1: Model Overviews
                 variables that are prone to be part of the glue clauses. These glue
                 clauses, recognized as conflict clauses by the Glucose family of
                 solvers [7], are essential for conflict analysis. Although this method            4.2    CDCLSolverIntegration
                 reducestherequirednumberofsolvingiterations,itdoesnotleadto                       TheCDCLalgorithm,commonlyusedinmodernSATsolvers,com-
                 substantial improvementsinthesolver’seffectiveness. Nonetheless,                  bines decision-making, unit propagation, conflict analysis, and non-
                 manyimprovements fail to deliver noticeable improvements for                      chronological backtracking. In modern CDCL SAT solvers, includ-
                 large-scale problems.NeuroCore,introducedbySelsamandBjørner                       ing ones like MiniSAT, Glucose, and Kissat, two closely related
                 [19], focuses on enhancing solving effectiveness, particularly for                concepts, decision queue and decision scores, are essential to vari-
                 large-scale problems as seen in SAT competitions. It improves the                 able selection during branching. Decision Scores are numerical
                 branching heuristic for CDCL solvers by employing supervised                      scores (usually floats or doubles) assigned to each variable that
                 learning to map UNSAT instances to their corresponding UNSAT                      indicate how “promising” or “active” a variable is. The decision
                 core variables – that is, the variables involved in the UNSAT-core.               queue is a heap or priority queue that stores unassigned variables,
                 Leveraging clauses dynamically learned during the solving process,                sorted by their decision scores. Fig.2 provides a detailed overview
                 NeuroCore conducts frequent online model inferences to refine its                 of the CDCL process. The algorithm starts with decision-making,
                 predictions. Moreover, NeuroBack introduced by Wen et al. [20],                   assigning Boolean values to variables according to a decision queue.
                 uses a GNN-based method to improve CDCL SAT solvers by per-                       This is followed by unit propagation, where necessary assignments
                 forming ofÒine predictions of variable phases before solving, espe-               for other variables are inferred based on the current partial assign-
                 cially backbone variables, enabling more effective phase selection                ment. Conflicts may occur if a clause becomes unsatisfiable with
                 in Kissat without runtime GPU usage, and achieving up to 7.4%                     these assignments. In response, the CDCL process conducts conflict
                 moresolved problems in SAT competitions.                                          analysis, learning from the conflict by adding a new clause that ex-
                                                                                                   plainsitscause,thusavoidingsimilarissuesinfutureiterations.The
                 4 OurMachineLearningBasedMethod                                                   algorithm concludes with non-chronological backtracking (back-
                 4.1     Overview                                                                  jumping),whichrevertsnotonlythemostrecentdecisionbutjumps
                                                                                                   back to a point before the conflict, adjusting the decision queue or
                 TosupportCDCLsolversinaddressingbothSATandUNSATin-                                loweringthedecisionscoreforconflictingvariables.Thisallowsfor
                 stances,weproposetheframeworkasshowninFig.1thatintegrates                         a more rapid exploration of different solution spaces and prevents
                 a neural network with a SAT solver. An input Boolean formula is                   repeating past mistakes.
                 initially converted into a Weighted Literal-Incidence Graph (WLIG)                   Twopivotal stages in this process are conflict analysis (clause
                 and fed into a Graph Neural Network (GNN) for updating node                       learning) and variable decision-making, which work together to
                 features. The GNN generates probabilities indicating the likelihood               construct the decision queue for branching. To optimize the per-
                 of variables being part of the backbone or the UNSAT-core. These                  formance, it is important to guide the decision queue and decision
                 probabilities are then assigned to the CDCL solver to initialize the              scores. Specifically, we aim to refine the decision queue and de-
                 variable decision queue and decision scores, guiding the solving                  cision scores, which are internal variables used in both variable
                 process more effectively.                                                         decision-making and conflict analysis.
                    ThetwoGNNmodelsdesignedforclassificationtasksaretrained                           Given this context, our methodology for interacting with the
                 ondistinct datasets to ensure specialized performance in different                CDCLsolverisasfollows. Before tackling a problem, our trained
                 problem domains. Specifically, one model is trained on the SAT                    network performs an inference to determine two probabilities per
                 dataset, which consists of satisfiable instances of SAT problems,                 variable, one for it be part of the backbone and the other for it be
                 while the other model is trained on the UNSAT dataset, comprising                 part of the UNSAT-core. The two probabilities are added to guide
                 unsatisfiable instances. This approach allows each model to develop               the solver in setting up a decision queue and decision scores. To
                 expertise in recognizing patterns and features unique to either SAT               be more specific, the summation of the inferred probabilities are
                 or UNSATinstances.                                                                first used to initialize the decision scores. Then, they are employed
                                                                                            888
