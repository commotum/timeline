                             Algorithm 1 Minibatch stochastic gradient descent training of generative adversarial nets. The number of
                             steps to apply to the discriminator, k, is a hyperparameter. We used k = 1, the least expensive option, in our
                             experiments.
                                for number of training iterations do
                                   for k steps do
                                     • Sample minibatch of m noise samples {z(1),...,z(m)} from noise prior p (z).
                                                                                                                       g
                                     • Sample minibatch of m examples {x(1),...,x(m)} from data generating distribution
                                     p    (x).
                                       data
                                     • Update the discriminator by ascending its stochastic gradient:
                                                                 m h                                    i
                                                        ∇ 1 X logD x(i) +log 1−D G z(i)                            .
                                                          θ
                                                           d m
                                                                i=1
                                   endfor
                                   • Sample minibatch of m noise samples {z(1),...,z(m)} from noise prior p (z).
                                                                                                                    g
                                   • Update the generator by descending its stochastic gradient:
                                                                         m                      
                                                                ∇ 1 Xlog 1−D G z(i)                     .
                                                                   θg m
                                                                        i=1
                                endfor
                                The gradient-based updates can use any standard gradient-based learning rule. We used momen-
                                tuminourexperiments.
                             4.1   Global Optimality of p = p
                                                             g     data
                             Weﬁrstconsider the optimal discriminator D for any given generator G.
                             Proposition 1. For G ﬁxed, the optimal discriminator D is
                                                                   D∗(x)=          pdata(x)                                         (2)
                                                                     G         p   (x)+p (x)
                                                                                data        g
                             Proof. The training criterion for the discriminator D, given any generator G, is to maximize the
                             quantity V (G,D)
                                            V(G,D)=Z p (x)log(D(x))dx+Z p (z)log(1−D(g(z)))dz
                                                              data                          z
                                                           x                             z
                                                       =Z p (x)log(D(x))+p (x)log(1−D(x))dx                                         (3)
                                                              data                    g
                                                           x
                             For any (a,b) ∈ R2 \ {0,0}, the function y → alog(y) + blog(1 − y) achieves its maximum in
                             [0,1] at   a . The discriminator does not need to be deﬁned outside of Supp(p             ) ∪ Supp(p ),
                                       a+b                                                                          data            g
                             concluding the proof.
                             Note that the training objective for D can be interpreted as maximizing the log-likelihood for es-
                             timating the conditional probability P(Y = y|x), where Y indicates whether x comes from p
                                                                                                                                    data
                             (with y = 1) or from p (with y = 0). The minimax game in Eq. 1 can now be reformulated as:
                                                     g
                                          C(G)=maxV(G,D)
                                                     D
                                                 =E         [logD∗(x)]+E           [log(1 − D∗ (G(z)))]                             (4)
                                                     x∼p          G           z∼p              G
                                                         data                     z
                                                 =E         [logD∗(x)]+E           [log(1 − D∗ (x))]
                                                     x∼p          G           x∼p              G
                                                         data                    g                                   
                                                                       p   (x)                              p (x)
                                                 =E          log        data          +E          log        g
                                                     x∼p                                   x∼p
                                                         data     P (x)+p (x)                  g      p    (x)+p (x)
                                                                   data        g                       data        g
                                                                                 4
