               www.nature.com/scientificdata/                                                                                                     www.nature.com/scientificdata
                                                         Fig. 3  Predicted task success rate af㘶er three attempts. We report model-based estimates, inferred using a 
                                                         Bayesian IRT model which accounts for missing data. Tasks are ordered from lowest success rate to highest, 
                                                         showing the distribution of model-based estimates of task di㘠陦culty for the 400 tasks in the training and 
                                                         evaluation sets, respectively. Dotted lines show average accuracy across all tasks in either the training (blue) or 
                                                         evaluation (orange) set.
                                                             – test_output_grid: State of the output grid in string format.
                                                             – action_x: X-coordinate of the action.
                                                             – action_y: Y-coordinate of the action
                                                         •	   summary_data.csv: A summary f㘶le where each row represents a single attempt by a participant at a task. 
                                                              Important columns include:
                                                             – hashed_id, task_name, attempt_number.
                                                             – num_actions: Total actions taken for the current attempt.
                                                             – test_output_grid: Final submitted output grid in string format.
                                                             –  f㘶rst_written_solution and last_written_solution: Natural-language solutions provided 
                                                               by participants.
                                                         •	   incorrect_submissions.csv: Contains data on incorrect grid submissions. Columns include:
                                                             – task_name, test_output_grid, count.
                                                         Survey directory.  T㔴is directory includes three CSV f㘶les capturing participant feedback and demographics: 
                                                         •	   demographics.csv: Includes age, gender, race and education_level.
                                                         •	   feedback.csv: Contains a feedback column with textual feedback from participants.
                                                         •	   withdraw.csv: Documents participant withdrawals, including withdraw_reason and withdraw_
                                                              comment columns when given by the participant.
                                                         technical Validation
                                                         We present four checks to support the validity of the dataset we are releasing. Firstly, we conducted model-based 
                                                         analyses of performance that incorporate uncertainty about our measurements by accounting for the missing 
                                                         data. Additionally, because this data was collected to showcase the diverse patterns of behavior that could explain 
                                                         aspects of people’s thinking and creativity, we present checks on the errors that people make, attempt-by-attempt 
                                                         improvement and the hypotheses that people generate when thinking about ARC problems.
                                                         performance.  Here, we check the ability of participants to perform the ARC tasks and check the possible 
                                                         inf㘶uence of incomplete data.
                                                         Incomplete data.  Participant data collected online can be incomplete for many reasons: participants may f㘶nd 
                                                         the task too hard, have technical di㘠陦culties, f㘶nd the experiment uninteresting, misunderstand the instructions 
                                                         or even run out of time. In our experiments, a number of participants withdrew from the experiment af㘶er 
                                                         completing between 0 and 4 tasks, although most did not provide any particular reason for withdrawing. All 
                                                         withdrawal reasons, when provided by participants, are available in the released dataset. We found that 94 out 
                                                         of 783 participants’ data from the training set experiment are incomplete, while 242 out of 946 participants’ data 
                                                         from the evaluation set experiment are incomplete. Our results indicate that 7.5% and 13.3% of the training and 
                                                         evaluation set task data are missing, for a total of 10.3% missing task data. We obtained these values by comput-
                                                         ing the proportion of expected task data (number of participants  × number of tasks assigned) that was missing 
                                                         from our dataset.
               Scientific Data | (2025) 12:1380 | https://doi.org/10.1038/s41597-025-05687-1                                                                                                           5
