           Published as a conference paper at ICLR 2022
           Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago
            Ontañón, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, and Amr Ahmed. Big bird:
            Transformers for longer sequences. In NeurIPS, 2020.
           Yury Zemlyanskiy, Joshua Ainslie, Michiel de Jong, Philip Pham, Ilya Eckstein, and Fei Sha.
            Readtwice: Readingverylargedocumentswithmemories. InACL:HumanLanguageTechnologies,
            2021.
           Zhenhai Zhu and Radu Soricut. H-transformer-1d: Fast one-dimensional hierarchical attention for
            sequences. In ACL, 2021.
                               13
