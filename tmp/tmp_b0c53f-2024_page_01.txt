                                ScatterFormer: EfÏcient Voxel Transformer with
                                                 Scattered Linear Attention
                                                  1              1,2               1               1,2
                                     Chenhang He , Ruihuang Li     , Guowen Zhang , and Lei Zhang
                                       1 The Hong Kong Polytechnic University, Hong Kong SAR, China
                                                     2 OPPO Research, Shenzhen, China
                                                         chenhang.he@polyu.edu.hk
                                                         csrhli@comp.polyu.edu.hk
                                                    guowen.zhang@connect.polyu.edu.hk
                                                        cslzhang@comp.polyu.edu.hk
                                     Abstract. Window-based transformers excel in large-scale point cloud
                                     understanding by capturing context-aware representations with afford-
                                     able attention computation in a more localized manner. However, the
                                     sparse nature of point clouds leads to a significant variance in the number
                                     of voxels per window. Existing methods group the voxels in each win-
                                     dow into fixed-length sequences through extensive sorting and padding
                                     operations, resulting in a non-negligible computational and memory over-
                                     head. In this paper, we introduce ScatterFormer, which to the best of our
                                     knowledge,isthefirsttodirectlyapplyattentiontovoxelsacrossdifferent
                                     windows as a single sequence. The key of ScatterFormer is a Scattered
                                     Linear Attention (SLA) module, which leverages the pre-computation
                                     of key-value pairs in linear attention to enable parallel computation on
                                     the variable-length voxel sequences divided by windows. Leveraging the
                                     hierarchical structure of GPUs and shared memory, we propose a chunk-
                                     wise algorithm that reduces the SLA module’s latency to less than 1
                                     millisecond on moderate GPUs. Furthermore, we develop a cross-window
                                     interaction module that improves the locality and connectivity of voxel
                                     features across different windows, eliminating the need for extensive win-
                                     dow shifting. Our proposed ScatterFormer demonstrates 73.8 mAP (L2)
                                     on the Waymo Open Dataset and 72.4 NDS on the NuScenes dataset,
                                     running at an outstanding detection rate of 23 FPS. The code is available
                                     at https://github.com/skyhehe123/ScatterFormer.
        arXiv:2401.00912v2  [cs.CV]  18 Jul 2024Keywords: 3D Object Detection · Voxel Transformer
                               1   Introduction
                               In the field of 3D object detection, the use of point clouds has become increas-
                               ingly popular, especially for providing accurate and reliable perception results in
                               autonomous systems. Unlike image data, point clouds obtained from LiDAR are
                               often sparse and nonuniformly distributed, with varying density depending on
                               their distances from the sensor. Earlier approaches utilize point-cloud operators
