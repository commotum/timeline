                multi-modal features through a deep fusion module and                 [15] Youngwan Lee, Joong-won Hwang, Sangrok Lee, Yuseok
                an additional feature elimination scheme. Consequently,                    Bae, and Jongyoul Park. An energy and gpu-computation
                our approach achieves state-of-the-art performance on the                  efficient backbone network for real-time object detection. In
                nuScenes dataset with a faster inference speed.                            Proc. CVPRW, 2019. 6, 7, 8
                                                                                      [16] Feng Li, Hao Zhang, Shilong Liu, Jian Guo, Lionel M Ni,
                                                                                           and Lei Zhang. Dn-detr: Accelerate detr training by intro-
                References                                                                 ducing query denoising. In Proc. CVPR, 2022. 3, 6, 11
                                                                                      [17] Yanwei Li, Yilun Chen, Xiaojuan Qi, Zeming Li, Jian Sun,
                 [1] Xuyang Bai, Zeyu Hu, Xinge Zhu, Qingqiu Huang, Yilun                  and Jiaya Jia.   Unifying voxel-based representation with
                      Chen, HongboFu,andChiew-LanTai. TransFusion:Robust                   transformer for 3d object detection. In Proc. NeurIPS, 2022.
                      lidar-camera fusion for 3d object detection with transform-          2, 3, 6, 7, 8
                      ers. In Proc. CVPR, 2022. 1, 3, 7, 8                            [18] Yinhao Li, Zheng Ge, Guanyi Yu, Jinrong Yang, Zengran
                 [2] Garrick Brazil and Xiaoming Liu. M3D-RPN:monocular3d                  Wang,YukangShi,JianjianSun,andZemingLi.BEVDepth:
                      region proposal network for object detection. In Proc. ICCV,         Acquisition of reliable depth for multi-view 3d object detec-
                      2019. 2                                                              tion. In Proc. AAAI, 2023. 2
                 [3] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora,         [19] Zhichao Li, Feng Wang, and Naiyan Wang. Lidar r-cnn: An
                      Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi-             efficient and universal 3d object detector. In Proc. CVPR,
                      ancarlo Baldan, and Oscar Beijbom. NuScenes: A multi-                2021. 1, 2
                      modaldatasetforautonomousdriving. InProc.CVPR,2020.             [20] Zhiqi Li, Wenhai Wang, Hongyang Li, Enze Xie, Chong-
                      2, 6, 8, 12                                                          hao Sima, Tong Lu, Yu Qiao, and Jifeng Dai. BEVFormer:
                 [4] NicolasCarion,FranciscoMassa,GabrielSynnaeve,Nicolas                  Learning bird’s-eye-view representation from multi-camera
                      Usunier, Alexander Kirillov, and Sergey Zagoruyko. End-              images via spatiotemporal transformers.    In Proc. ECCV,
                      to-end object detection with transformers. In Proc. ECCV,            2022. 2
                      2020. 1, 3, 4, 6                                                [21] MingLiang,BinYang,ShenlongWang,andRaquelUrtasun.
                 [5] Xuanyao Chen, Tianyuan Zhang, Yue Wang, Yilun Wang,                   Deepcontinuousfusionformulti-sensor3dobjectdetection.
                      and Hang Zhao. FUTR3D: A unified sensor fusion frame-                In Proc. ECCV, 2018. 5
                      workfor 3d detection. In Proc. CVPR, 2023. 3, 7, 8              [22] Tingting Liang, Hongwei Xie, Kaicheng Yu, Zhongyu Xia,
                 [6] YukangChen,JianhuiLiu,XiangyuZhang,XiaojuanQi,and                     Zhiwei Lin, Yongtao Wang, Tao Tang, Bing Wang, and Zhi
                      Jiaya Jia. Voxelnext: Fully sparse voxelnet for 3d object de-        Tang. BEVFusion: A simple and robust lidar-camera fusion
                      tection and tracking. In Proc. CVPR, 2023. 2, 8, 12                  framework. In Proc. NeurIPS, 2022. 1, 3, 7, 8
                 [7] Zehui Chen, Zhenyu Li, Shiquan Zhang, Liangji Fang, Qin-         [23] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and
                      hong Jiang, and Feng Zhao. Autoalignv2: Deformable fea-                        ´
                                                                                           Piotr Dollar. Focal loss for dense object detection. IEEE
                      ture aggregation for dynamic multi-modal 3d object detec-            Transactions on Pattern Analysis and Machine Intelligence,
                      tion. arXiv preprint arXiv:2207.10316, 2022. 7, 8                    42(2):318–327, 2020. 6
                 [8] Jiahui Fu, Chen Gao, Zitian Wang, Lirong Yang, Xiaofei           [24] Zhijian Liu, Haotian Tang, Alexander Amini, Xinyu Yang,
                      Wang, Beipeng Mu, and Si Liu. Eliminating cross-modal                Huizi Mao, Daniela L Rus, and Song Han. BEVFusion:
                      conflicts in bev space for lidar-camera 3d object detection.         Multi-task multi-sensor fusion with unified bird’s-eye view
                      In Proc. ICRA, 2024. 1, 3, 7, 8                                      representation. In Proc. ICRA, 2023. 1, 2, 3, 7, 8
                 [9] Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are we          [25] Charles Ruizhongtai Qi, Wei Liu, Chenxia Wu, Hao Su, and
                      ready for autonomous driving? the kitti vision benchmark             Leonidas J. Guibas. Frustum pointnets for 3d object detec-
                      suite. In Proc. CVPR, 2012. 2                                        tion from RGB-D data. In Proc. CVPR, 2018. 2
                [10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.           [26] Byungseok Roh, JaeWoong Shin, Wuhyun Shin, and Sae-
                      Deep residual learning for image recognition.     In Proc.           hoon Kim. Sparse DETR: Efficient end-to-end object detec-
                      CVPR,2016. 8                                                         tion with learnable sparsity. In Proc. ICLR, 2022. 3, 6
                [11] Junjie Huang, Guan Huang, Zheng Zhu, Ye Yun, and Dalong          [27] Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping
                      Du. BEVDet:High-performancemulti-camera3dobjectde-                   Shi, Xiaogang Wang, and Hongsheng Li. PV-RCNN: point-
                      tection in bird-eye-view. arXiv preprint arXiv:2112.11790,           voxel feature set abstraction for 3d object detection. In Proc.
                      2021. 2                                                              CVPR,2020. 1, 2
                [12] Junjie Huang, Yun Ye, Zhujin Liang, Yi Shan, and Dalong          [28] Shaoshuai Shi, Xiaogang Wang, and Hongsheng Li. Pointr-
                      Du. Detecting as labeling: Rethinking lidar-camera fusion in         cnn: 3d object proposal generation and detection from point
                      3dobject detection. arXiv preprint arXiv:2311.07152, 2023.           cloud. In Proc. CVPR, 2019. 1, 2
                      11                                                                                                           `
                                                                                      [29] Andrea Simonelli, Samuel Rota Bulo, Lorenzo Porzi,
                [13] QiJiang, HaoSun,andXiZhang. SemanticBEVFusion:Re-                               ´
                                                                                           Manuel Lopez-Antequera, and Peter Kontschieder. Disen-
                      think lidar-camera fusion in unified bird’s-eye view repre-          tangling monocular 3d object detection.    In Proc. ICCV,
                      sentation for 3d object detection. In Proc. IROS, 2023. 1,           2019. 2
                      8                                                               [30] Ziying Song, Lei Yang, Shaoqing Xu, Lin Liu, Dongyang
                [14] Alex H. Lang, Sourabh Vora, Holger Caesar, Lubing Zhou,               Xu, Caiyan Jia, Feiyang Jia, and Li Wang. GraphBEV: To-
                      Jiong Yang, and Oscar Beijbom. PointPillars: Fast encoders           wards robust bev feature alignment for multi-modal 3d ob-
                      for object detection from point clouds. In Proc. CVPR, 2019.         ject detection. In Proc. ECCV, 2024. 1, 3, 8
                      1, 2
