                                 Puzzle Size / Models     Gemini2.0Flash-Lite     Gemini2.0Flash     GPT4o     o3-mini (high)
                                5 x 5 (with distractors)          37.5                  60.0          37.5         90.0
                                6 x 6 (with distractors)          38.9                  33.3          30.6         58.3
                                7 x 7 (with distractors)          36.5                  36.5          37.8         55.4
                               8 x 8 (without distractors)        16.0                  52.0          20.0         74.0
                          Table 8: Accuracy break-down of the model performances on the Zebra Puzzles task by puzzle size.
                      Wethenextract the answer by splitting with the            is the DisambiguationQA task. Checking the re-
                   prefix and finding what comes next. We find that             sponsesfromGemini2.0FlashontheBBHversion
                   sometimes the models slightly deviate from the               of the dataset, we observe that the model overly
                   exact prefix we gave them, so we look for four               selects the ambiguous option, sometimes for poten-
                   prefixes in the answer until one of them is found:           tially legit reasons. For example, for disambiguat-
                   "The answer is: ", "The answer is ", "The                    ing the pronoun they in the sentence "Alex told
                   final answer is: ", "The final answer is                     us that they could not meet", the model responds
                   ". Once weextract the final answer, we apply some            that "They could refer to Alex or to some other
                   minimal cleaning as follows: 1- if the final answer          group of people not explicitly mentioned. There-
                   is wrapped within the boxed, text, texttt or **, we          fore, the antecedent is ambiguous". We also find
                   removethat and extract what is inside it. We notice          that in several of the cases, simply changing the
                   that after producing the final answer, some models           task description from "explain the antecedent of
                   producea"\n"andthensomeextratext. Therefore,                 the pronoun [...] or state that it is ambiguous" to
                   wesplit the extracted final answer using "\n" and            "try to disambiguate the antecedent of the pronoun
                   take the first element as the final answer. Then             given the context or state that it is ambiguous if it
                   welowercase both the final answer and the label              cannot be disambiguated" makes the model pick
                   determine correctness using a few simple rules: 1-           the right choice.
                   if the two are identical, then we consider the final         D RelatedWork
                   answer correct, 2- if the final answer is identical to
                   the label up to removing single or double quotes             There has been significant emphasis on using
                   or brackets from the beginning and end of it, we             LLMsfor mathematical and scientific reasoning.
                   consider it to be correct, 3- the label for multi-           This has led to the popularity and proliferation
                   choice questions is in (<LETTER>) format and                 of math- and STEM-based evaluations, such as
                   we expect a similar final answer but if the final            (Hendrycks et al., 2020; Cobbe et al., 2021), and
                   answer is only the letter without the parentheses,           more recently, (Glazer et al., 2024; Phan et al.,
                   weconsider it correct, and finally 4- for questions          2025). However, the generalizability of mathe-
                   whoselabels contain multiple elements separated              matical reasoning skills to broader domains re-
                   by comma, if the label and final answer are the              mains unclear. Indeed, attempts to make existing
                   sameuptoreplacing the spaces after the commas                benchmarks more robust—for example, (Mirzadeh
                   with blanks, then we consider the final answer to            et al., 2024)—have highlighted an overall lack of
                   be correct.                                                  robustness and logical reasoning capabilities. Sev-
                   C BBEHvsBBHPerformance                                       eral benchmarks have also been developed to ad-
                                                                                dress specific areas of reasoning, including tempo-
                   To understand how much each task in BBEH has                 ral reasoning (Xiong et al., 2024; Beniwal et al.,
                   becomehardercomparedtoitscounterpartinBBH,                   2024; Dhingra et al., 2022), spatial understand-
                   we evaluated Gemini 2.0 Flash on BBH and re-                 ing (Bohnet et al., 2024; Yamada et al., 2023;
                   ported the results in Table 9. For the fairness of the       Mirzaee et al., 2021; Shi et al., 2022), common-
                   comparison,weranthemodelinazero-shotsetting.                 sense reasoning (Zellers et al., 2019; Talmor et al.,
                   However, we note that some of the tasks in BBH               2018; Sakaguchi et al., 2021), and logical reason-
                   maybecomeslightly ambiguous in a zero-shot set-              ing (Saparov and He, 2022; Tafjord et al., 2020;
                   ting given that it has been mostly developed for a           Saparov et al., 2023; Parmar et al., 2024). How-
                   few-shot evaluation. Nevertheless, we observe that           ever, these benchmarks tend to focus narrowly on
                   onalmost all the tasks, the difficulty level has sig-        specific domains, leading to potential evaluation
                   nificantly increased in BBEH. A notable exception            biases if a more holistic view of model capabilities
                                                                          26500
