                                             Recurrent Relational Networks
                                  RasmusBergPalm                 Ulrich Paquet                OleWinther
                            Technical University of Denmark        DeepMind          Technical University of Denmark
                                       Tradeshift              upaq@google.com                olwi@dtu.dk
                                    rapal@dtu.dk
                                                                   Abstract
                                  This paper is concerned with learning to solve tasks that require a chain of interde-
                                  pendent steps of relational inference, like answering complex questions about the
                                  relationships between objects, or solving puzzles where the smaller elements of a
                                  solution mutually constrain each other. We introduce the recurrent relational net-
                                  work, a general purpose module that operates on a graph representation of objects.
                                  Asageneralization of Santoro et al. [2017]’s relational network, it can augment
                                  any neural network model with the capacity to do many-step relational reasoning.
                                  Weachievestate of the art results on the bAbI textual question-answering dataset
                                  with the recurrent relational network, consistently solving 20/20 tasks. As bAbI is
                                  not particularly challenging from a relational reasoning point of view, we introduce
                                  Pretty-CLEVR, a new diagnostic dataset for relational reasoning. In the Pretty-
                                  CLEVRset-up, we can vary the question to control for the number of relational
                                  reasoning steps that are required to obtain the answer. Using Pretty-CLEVR, we
                                  probe the limitations of multi-layer perceptrons, relational and recurrent relational
                                  networks. Finally, we show how recurrent relational networks can learn to solve
                                  Sudokupuzzlesfromsupervisedtrainingdata,achallengingtaskrequiringupwards
                                  of 64 steps of relational reasoning. We achieve state-of-the-art results amongst
                                  comparable methods by solving 96.6% of the hardest Sudoku puzzles.
                          1   Introduction
                          Acentral component of human intelligence is the ability to abstractly reason about objects and their
                          interactions [Spelke et al., 1995, Spelke and Kinzler, 2007]. As an illustrative example, consider
                          solving a Sudoku. A Sudoku consists of 81 cells that are arranged in a 9-by-9 grid, which must
                          be ﬁlled with digits 1 to 9 so that each digit appears exactly once in each row, column and 3-by-3
                          non-overlapping box, with a number of digits given 1. To solve a Sudoku, one methodically reasons
                          about the puzzle in terms of its cells and their interactions over many steps. One tries placing digits
                          in cells and see how that affects other cells, iteratively working toward a solution.
                          Contrast this with the canonical deep learning approach to solving problems, the multilayer perceptron
                          (MLP), or multilayer convolutional neural net (CNN). These architectures take the entire Sudoku
                          as an input and output the entire solution in a single forward pass, ignoring the inductive bias that
                          objects exists in the world, and that they affect each other in a consistent manner. Not surprisingly
                          these models fall short when faced with problems that require even basic relational reasoning [Lake
                          et al., 2016, Santoro et al., 2017].
                          The relational network of Santoro et al. [2017] is an important ﬁrst step towards a simple module
                          for reasoning about objects and their interactions but it is limited to performing a single relational
                          operation, and was evaluated on datasets that require a maximum of three steps of reasoning (which,
                             1Weinvite the reader to solve the Sudoku in the supplementary material to appreciate the difﬁculty of solving
                          a Sudoku in which 17 cells are initially ﬁlled.
                          32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Montréal, Canada.
