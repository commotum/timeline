                    VECTOR SYMBOLIC ALGEBRAS FOR THE ABSTRACTION AND
                                                        REASONING CORPUS
                                                                    APREPRINT
                                           Isaac Joffe                                        Chris Eliasmith
                               Centre for Theoretical Neuroscience                   Centre for Theoretical Neuroscience
                          David R. Cheriton School of Computer Science                   Department of Philosophy
                                      University of Waterloo                     Department of Systems Design Engineering
                                          Waterloo, ON                                     University of Waterloo
                                     ijoffe@uwaterloo.ca                                       Waterloo, ON
                                                                                        celiasmith@uwaterloo.ca
                                                                    ABSTRACT
                           The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) is a gen-
                           erative, few-shot fluid intelligence benchmark. Although humans effortlessly solve ARC-AGI, it
                           remains extremely difficult for even the most advanced artificial intelligence systems. Inspired
                           by methods for modelling human intelligence spanning neuroscience to psychology, we propose
                           a cognitively plausible ARC-AGI solver. Our solver integrates System 1 intuitions with System
                           2 reasoning in an efficient and interpretable process using neurosymbolic methods based on Vec-
                           tor Symbolic Algebras (VSAs). Our solver works by object-centric program synthesis, leveraging
                           VSAstorepresent abstract objects, guide solution search, and enable sample-efficient neural learn-
                           ing. Preliminary results indicate success, with our solver scoring 10.8% on ARC-AGI-1-Train and
                           3.0%onARC-AGI-1-Eval. Additionally, our solver performs well on simpler benchmarks, scoring
                           94.5% on Sort-of-ARC and 83.1% on 1D-ARC—the latter outperforming GPT-4 at a tiny fraction
                           of the computational cost. Importantly, our approach is unique; we believe we are the first to apply
                           VSAs to ARC-AGI and have developed the most cognitively plausible ARC-AGI solver yet. Our
                           code is available at: https://github.com/ijoffe/ARC-VSA-2025.
                  1   Introduction
                  The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI; Chollet, 2019; Chollet et al.,
                  2025b) challenges the tremendous progress deep learning has made in artificial intelligence (AI). ARC-AGI is a fluid
                  intelligence benchmark comprising a collection of grid prediction tasks (see Figs. 1 and 2). The goal of the test-
                  taker, human or AI, is simple: given a few pairs of input and output grids containing abstract symbols, determine
                  the rules underlying the symbol transformations and use this understanding to predict the output grids corresponding
                  to lone test input grids. ARC-AGI is easy for humans. Human performance is estimated to be 85.0% and all tasks
                  were solved by at least one of two experts (Chollet et al., 2025a), indicating human intelligence can completely solve
                  the benchmark. Conversely, ARC-AGI is hard for AI. Despite ample focus and investment over multiple $1,000,000
                  competitions (Chollet et al., 2024, 2025c), the benchmark remains unbeaten. ARC-AGI has proved resistant to old and
                  new deep learning techniques, including the large language model (LLM)—OpenAI’s original GPT-3 (Brown et al.,
                  2020)scored0.0%(Cholletetal.,2025a)notwithstandingclaimsofemergentreasoning(Weietal.,2022). Thechasm
                  between human and AI performance on ARC-AGI suggests fundamental problems with leading approaches to AI.
                  Twosuchproblemsoftenidentified in the literature are sample-efficient learning and explicit reasoning (Bengio et al.,
                  2021; Greff et al., 2020; LeCun et al., 2015). Deep learning’s success requires vast amounts of often-labelled high-
                  quality training data, making it ineffective in the sample-few regime. Additionally, deep learning systems struggle
                  with representing explicit rules, sometimes manifesting in poor out-of-distribution generalization. Vector Symbolic
                  Algebras (VSAs), a neurosymbolic AI method introducing syntactic structure into high-dimensional distributed rep-
                  resentations, hold promise to overcome these two limitations that ARC-AGI targets. VSAs specify high-dimensional
