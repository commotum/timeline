                  TheSurprising Effectiveness of Test-Time Training for Few-Shot Learning
       D. LMDataGeneration
       Wedescribed three approaches in Appendix B to use LM, we generated 6426 task generators by few-shot prompting GPT-4
       and GPT-4o models (OpenAI, 2024; Hurst et al., 2024).
       D.1. Getting Descriptions for Tasks
       This procedure is shown in Figure 15. We initially described 10 training tasks with the hierarchical-style shown in Figure 11.
       Then, for other training tasks tasks, we obtained less quality crowd-worker annotations from LARC (Acquaviva et al., 2022)
       project. By using our high-quality seed annotations and their LARC version, we 10-shot prompt and LM to produce high
       quality annotations for the other training tasks.
         Youare an intelligent agent that can induce task descriptions from examples. For Category, please *do not* use
         generic terms like Transformation, Pattern Recognition.
        —————-
         Task: {stringified task inputs and outputs}
         LARCDescription: {description of the task-1 from LARC dataset}
         GoodDescription: {hierarchical description}
        —————-
         [truncated]
        —————-
         Task: {stringified task inputs and outputs for task-K}
         LARCDescription: {description of the task-K from LARC dataset}
         GoodDescription: {hierarchical description}
        —————-
         Task: {stringified task inputs and outputs for query task}
         LARCDescription: {description of the query task from LARC dataset}
       D.2. Few-shot Prompting Details
       Weusethefollowing simple prompting template with k-shot prompting for all data generation procedures, where numbers
       filled with examples sampled from seed set. In simple few-shot generation, we exclude examples. We use GPT-4 and
       GPT-4otogenerate the new scripts.
         Youareaproblemgenerator on 2D grids of colors. Here are some examples of such transformations, please follow
         the format:
        —————-
         Example: {description of the generator function-1}
         Script: {generator function-1}
        —————-
         [truncated]
        —————-
         Example: {description of the generator function-K}
         Script: {generator function-K}
         Please generate more and make sure they are different:
                                  18
