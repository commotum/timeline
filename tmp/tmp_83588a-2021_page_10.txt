                                               Stabilizing Equilibrium Models by Jacobian Regularization
               Avron, H. and Toledo, S. Randomized algorithms for esti-          M., Heigold, G., Gelly, S., et al. An image is worth
                 mating the trace of an implicit symmetric positive semi-        16x16words: Transformersforimagerecognitionatscale.
                 deﬁnite matrix. Journal of the ACM (JACM), 58(2):1–34,          arXiv:2010.11929, 2020.
                 2011.                                                        Drucker, H. and Le Cun, Y. Improving generalization perfor-
               Ba, L. J., Kiros, R., and Hinton, G. E. Layer normalization.      manceusingdoublebackpropagation. IEEETransactions
                 arXiv:1607.06450, 2016.                                         onNeuralNetworks, 3(6):991–997, 1992.
               Baevski, A. and Auli, M. Adaptive input representations for    Dupont, E., Doucet, A., and Teh, Y. W. Augmented neural
                 neural language modeling. In International Conference           ODEs. In Neural Information Processing Systems, 2019.
                 onLearning Representations (ICLR), 2019.                     Duvenaud, D., Kolter, J. Z., and Johnson, M. Deep implicit
               Bai, S., Kolter, J. Z., and Koltun, V. Deep equilibrium           layers tutorial - neural ODEs, deep equilibirum models,
                 models. In Neural Information Processing Systems, 2019.         and beyond. Neural Information Processing Systems
                                                                                 Tutorial, 2020.
               Bai, S., Koltun, V., and Kolter, J. Z. Multiscale deep equilib-
                 rium models. In Neural Information Processing Systems,       El Ghaoui, L., Gu, F., Travacca, B., and Askari, A. Implicit
                 2020.                                                           deep learning. arXiv:1908.06315, 2019.
               Bradbury, J., Merity, S., Xiong, C., and Socher, R. Quasi-     Finlay, C., Jacobsen, J.-H., Nurbekyan, L., and Oberman,
                 recurrent neural networks. In International Conference          A. M. Howtotrain your neural ODE. arXiv:2002.02798,
                 onLearning Representations (ICLR), 2017.                        2020.
               Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan,        Gal, Y. and Ghahramani, Z. A theoretically grounded appli-
                 J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,       cation of dropout in recurrent neural networks. In Neural
                 Askell, A., et al. Language models are few-shot learners.       Information Processing Systems, 2016.
                 arXiv:2005.14165, 2020.                                      Gould, S., Hartley, R., and Campbell, D. Deep declarative
               Broyden, C. G. A class of methods for solving nonlinear           networks: A new hope. arXiv:1909.04866, 2019.
                 simultaneous equations. Mathematics of Computation,          Grathwohl, W., Chen, R. T., Betterncourt, J., Sutskever,
                 1965.                                                           I., and Duvenaud, D. FFJORD: Free-form continuous
               Chang, B., Meng, L., Haber, E., Tung, F., and Begert, D.          dynamics for scalable reversible generative models. In
                 Multi-level residual networks from dynamical systems            International Conference on Learning Representations
                 view. In International Conference on Learning Represen-         (ICLR), 2019.
                 tations (ICLR), 2018.                                        He, K., Zhang, X., Ren, S., and Sun, J. Deep residual
               Chen, T. Q., Rubanova, Y., Bettencourt, J., and Duvenaud,         learning for image recognition. In Computer Vision and
                 D. K. Neural ordinary differential equations. In Neural         Pattern Recognition (CVPR), 2016.
                 Information Processing Systems, 2018.                        Hoffman, J., Roberts, D. A., and Yaida, S. Robust learning
               Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler,         with Jacobian regularization. arXiv:1908.02729, 2019.
                 M., Benenson, R., Franke, U., Roth, S., and Schiele, B.      Huang, G., Liu, Z., Van Der Maaten, L., and Weinberger,
                 TheCityscapes dataset for semantic urban scene under-           K. Q. Densely connected convolutional networks. In
                 standing. In Computer Vision and Pattern Recognition            Computer Vision and Pattern Recognition (CVPR), 2017.
                 (CVPR), 2016.
                                                                              Hutchinson, M. F. A stochastic estimator of the trace of the
               Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., and        inﬂuence matrix for laplacian smoothing splines. Com-
                 Salakhutdinov, R. Transformer-XL: Attentive language            munications in Statistics-Simulation and Computation,
                 modelsbeyondaﬁxed-lengthcontext. InAnnualMeeting                18(3):1059–1076, 1989.
                 of the Association for Computational Linguistics (ACL),
                 2019.                                                        Ioffe, S. and Szegedy, C. Batch normalization: Accelerat-
                                                                                 ing deep network training by reducing internal covariate
               Deng, J., Dong, W., Socher, R., Li, L., Li, K., and Li, F.        shift. In International Conference on Machine Learning
                 ImageNet: A large-scale hierarchical image database. In         (ICML), 2015.
                 Computer Vision and Pattern Recognition (CVPR), 2009.        Kawaguchi,K. Dynamicsofdeepequilibriumlinearmodels.
               Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,          In International Conference on Learning Representations
                 D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer,          (ICLR), 2021.
