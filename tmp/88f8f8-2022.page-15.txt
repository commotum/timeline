                                                                               Point Primitive Transformer      15
                                  3. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Nee-
                                    lakantan, A., Shyam, P., Sastry, G., Askell, A., et al.: Language models are few-shot
                                    learners. Advances in neural information processing systems 33, 1877–1901 (2020)
                                  4. Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., Zagoruyko, S.: End-
                                    to-end object detection with transformers. In: European conference on computer
                                    vision. pp. 213–229. Springer (2020)
                                  5. Chen, J., Chen, B.: Architectural modeling from sparsely scanned range data.
                                    International Journal of Computer Vision 78(2), 223–236 (2008)
                                  6. Choy, C.B., Gwak, J., Savarese, S.: 4d spatio-temporal convnets: Minkowski con-
                                    volutional neural networks. CoRR abs/1904.08755 (2019)
                                  7. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert: Pre-training of deep bidirec-
                                    tional transformers for language understanding. arXiv preprint arXiv:1810.04805
                                    (2018)
                                  8. Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner,
                                    T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et al.: An image is
                                    worth 16x16 words: Transformers for image recognition at scale. arXiv preprint
                                    arXiv:2010.11929 (2020)
                                  9. Du, H., Yu, X., Zheng, L.: Vtnet: Visual transformer network for object goal nav-
                                    igation. arXiv preprint arXiv:2105.09447 (2021)
                                10. Fan, H., Yang, Y., Kankanhalli, M.S.: Point 4d transformer networks for spatio-
                                    temporal modeling in point cloud videos. In: IEEE Conference on Computer Vision
                                    and Pattern Recognition, CVPR. pp. 14204–14213 (2021)
                                11. Fan, H., Yu, X., Ding, Y., Yang, Y., Kankanhalli, M.: Pstnet: Point spatio-temporal
                                    convolution on point cloud sequences. In: International conference on learning rep-
                                    resentations (2020)
                                12. Fernando, B., Gavves, E., Oramas, J., Ghodrati, A., Tuytelaars, T.: Rank pooling
                                    for action recognition. IEEE transactions on pattern analysis and machine intelli-
                                    gence 39(4), 773–787 (2016)
                                13. Fischler, M.A., Bolles, R.C.: Random sample consensus: a paradigm for model
                                    fitting with applications to image analysis and automated cartography. Communi-
                                    cations of the ACM 24(6), 381–395 (1981)
                                14. Ganapathi-Subramanian, V., Diamanti, O., Pirk, S., Tang, C., Niessner, M.,
                                    Guibas, L.: Parsing geometry using structure-aware shape templates. In: 2018 In-
                                    ternational Conference on 3D Vision (3DV). pp. 672–681. IEEE (2018)
                                15. Graham, B., van der Maaten, L.: Submanifold sparse convolutional networks.
                                    CoRRabs/1706.01307 (2017)
                                16. Guo, M.H., Cai, J.X., Liu, Z.N., Mu, T.J., Martin, R.R., Hu, S.M.: Pct: Point
                                    cloud transformer. Computational Visual Media 7(2), 187–199 (2021)
                                17. He,K.,Zhang,X.,Ren,S.,Sun,J.:Deepresiduallearningforimagerecognition.In:
                                    Proceedings of the IEEE conference on computer vision and pattern recognition.
                                    pp. 770–778 (2016)
                                18. Hendrycks, D., Gimpel, K.: Gaussian error linear units (gelus). arXiv preprint
                                    arXiv:1606.08415 (2016)
                                19. Hinton, G.: How to represent part-whole hierarchies in a neural network. arXiv
                                    preprint arXiv:2102.12627 (2021)
                                20. Huang, J., Zhang, Y., Sun, M.: Primitivenet: Primitive instance segmentation
                                    with local primitive embedding under adversarial metric. In: Proceedings of the
                                    IEEE/CVFInternationalConferenceonComputerVision.pp.15343–15353(2021)
                                21. Kolesnikov, A., Beyer, L., Zhai, X., Puigcerver, J., Yung, J., Gelly, S., Houlsby, N.:
                                    Big transfer (bit): General visual representation learning. In: European conference
                                    on computer vision. pp. 491–507. Springer (2020)
