                                                                                                              ´
                References                                                                      [28] G. Montufar, R. Pascanu, K. Cho, and Y. Bengio. On the number of
                 [1] Y.Bengio,P.Simard,andP.Frasconi. Learninglong-termdependen-                      linear regions of deep neural networks. In NIPS, 2014.
                      cies with gradient descent is difﬁcult. IEEE Transactions on Neural       [29] V. Nair and G. E. Hinton. Rectiﬁed linear units improve restricted
                      Networks, 5(2):157–166, 1994.                                                   boltzmann machines. In ICML, 2010.
                 [2] C. M. Bishop. Neural networks for pattern recognition. Oxford              [30] F. Perronnin and C. Dance. Fisher kernels on visual vocabularies for
                      university press, 1995.                                                         image categorization. In CVPR, 2007.
                 [3] W. L. Briggs, S. F. McCormick, et al. A Multigrid Tutorial. Siam,          [31] T. Raiko, H. Valpola, and Y. LeCun. Deep learning made easier by
                      2000.                                                                           linear transformations in perceptrons. In AISTATS, 2012.
                 [4] K. Chatﬁeld, V. Lempitsky, A. Vedaldi, and A. Zisserman. The devil         [32] S. Ren, K. He, R. Girshick, and J. Sun. Faster R-CNN: Towards
                      is in the details: an evaluation of recent feature encoding methods.            real-time object detection with region proposal networks. In NIPS,
                      In BMVC,2011.                                                                   2015.
                 [5] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zis-           [33] S. Ren, K. He, R. Girshick, X. Zhang, and J. Sun. Object detection
                      serman. The Pascal Visual Object Classes (VOC) Challenge. IJCV,                 networks on convolutional feature maps. arXiv:1504.06066, 2015.
                      pages 303–338, 2010.                                                      [34] B. D. Ripley. Pattern recognition and neural networks. Cambridge
                 [6] S. Gidaris and N. Komodakis. Object detection via a multi-region &               university press, 1996.
                      semantic segmentation-aware cnn model. In ICCV, 2015.                     [35] A. Romero, N. Ballas, S. E. Kahou, A. Chassang, C. Gatta, and
                 [7] R. Girshick. Fast R-CNN. In ICCV, 2015.                                          Y. Bengio. Fitnets: Hints for thin deep nets. In ICLR, 2015.
                 [8] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hier-      [36] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma,
                      archies for accurate object detection and semantic segmentation. In             Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al. Imagenet
                      CVPR,2014.                                                                      large scale visual recognition challenge. arXiv:1409.0575, 2014.
                 [9] X. Glorot and Y. Bengio. Understanding the difﬁculty of training           [37] A. M. Saxe, J. L. McClelland, and S. Ganguli. Exact solutions to
                      deep feedforward neural networks. In AISTATS, 2010.                             the nonlinear dynamics of learning in deep linear neural networks.
                [10] I. J. Goodfellow, D. Warde-Farley, M. Mirza, A. Courville, and                   arXiv:1312.6120, 2013.
                      Y. Bengio. Maxout networks. arXiv:1302.4389, 2013.                        [38] N.N.Schraudolph. Accelerated gradient descent by factor-centering
                [11] K.HeandJ.Sun. Convolutionalneuralnetworksatconstrainedtime                       decomposition. Technical report, 1998.
                      cost. In CVPR, 2015.                                                      [39] N. N. Schraudolph. Centering neural network gradient factors. In
                [12] K.He,X.Zhang,S.Ren,andJ.Sun. Spatialpyramidpoolingindeep                         Neural Networks: Tricks of the Trade, pages 207–226. Springer,
                      convolutional networks for visual recognition. In ECCV, 2014.                   1998.
                [13] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectiﬁers:          [40] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, and Y. Le-
                      Surpassing human-level performance on imagenet classiﬁcation. In                Cun. Overfeat: Integrated recognition, localization and detection
                      ICCV,2015.                                                                      using convolutional networks. In ICLR, 2014.
                [14] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and              [41] K. Simonyan and A. Zisserman. Very deep convolutional networks
                      R. R. Salakhutdinov. Improving neural networks by preventing co-                for large-scale image recognition. In ICLR, 2015.
                      adaptation of feature detectors. arXiv:1207.0580, 2012.                   [42] R. K. Srivastava, K. Greff, and J. Schmidhuber. Highway networks.
                [15] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural                 arXiv:1505.00387, 2015.
                      computation, 9(8):1735–1780, 1997.                                        [43] R. K. Srivastava, K. Greff, and J. Schmidhuber. Training very deep
                [16] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep                  networks. 1507.06228, 2015.
                      networktrainingbyreducinginternalcovariateshift. In ICML, 2015.           [44] C.Szegedy,W.Liu,Y.Jia,P.Sermanet,S.Reed,D.Anguelov,D.Er-
                [17] H.Jegou,M.Douze,andC.Schmid. Productquantizationfornearest                       han, V. Vanhoucke, and A. Rabinovich. Going deeper with convolu-
                      neighbor search. TPAMI, 33, 2011.                                               tions. In CVPR, 2015.
                [18] H. Jegou, F. Perronnin, M. Douze, J. Sanchez, P. Perez, and                [45] R. Szeliski. Fast surface interpolation using hierarchical basis func-
                      C.Schmid. Aggregatinglocalimagedescriptorsintocompactcodes.                     tions. TPAMI, 1990.
                      TPAMI,2012.                                                               [46] R. Szeliski. Locally adapted hierarchical basis preconditioning. In
                [19] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick,              SIGGRAPH,2006.
                      S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for      [47] T. Vatanen, T. Raiko, H. Valpola, and Y. LeCun. Pushing stochas-
                      fast feature embedding. arXiv:1408.5093, 2014.                                  tic gradient towards second-order methods–backpropagation learn-
                [20] A. Krizhevsky. Learning multiple layers of features from tiny im-                ing with transformations in nonlinearities. In Neural Information
                      ages. Tech Report, 2009.                                                        Processing, 2013.
                [21] A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classiﬁcation         [48] A. Vedaldi and B. Fulkerson. VLFeat: An open and portable library
                      with deep convolutional neural networks. In NIPS, 2012.                         of computer vision algorithms, 2008.
                [22] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard,              [49] W. Venables and B. Ripley. Modern applied statistics with s-plus.
                      W. Hubbard, and L. D. Jackel. Backpropagation applied to hand-                  1999.
                      written zip code recognition. Neural computation, 1989.                   [50] M. D. Zeiler and R. Fergus. Visualizing and understanding convolu-
                                                                 ¨                                    tional neural networks. In ECCV, 2014.
                [23] Y.LeCun,L.Bottou,G.B.Orr,andK.-R.Muller. Efﬁcientbackprop.
                      In Neural Networks: Tricks of the Trade, pages 9–50. Springer, 1998.
                [24] C.-Y. Lee, S. Xie, P. Gallagher, Z. Zhang, and Z. Tu.       Deeply-
                      supervised nets. arXiv:1409.5185, 2014.
                [25] M.Lin,Q.Chen,andS.Yan. Networkinnetwork. arXiv:1312.4400,
                      2013.
                [26] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,
                             ´
                      P. Dollar, and C. L. Zitnick. Microsoft COCO: Common objects in
                      context. In ECCV. 2014.
                [27] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks
                      for semantic segmentation. In CVPR, 2015.
                                                                                            9
