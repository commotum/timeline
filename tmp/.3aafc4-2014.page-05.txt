               information in a string—while using Kolmogorov complexity itself to deﬁne what is meant by “non-
                                                                                    n
               random.” Givenann-bitstringx, let a model for x be a set S ⊆ {0,1} such that x ∈ S. Let K (S)
               be the length of the shortest program that enumerates the elements of S, in any order (crucially,
               the program must halt when it is done enumerating the elements). Also, let K (x|S) be the length
               of the shortest program that outputs x given as input a description of x.   Then we can consider
               x to be a “generic” element of S if K (x|S) ≥ log2|S| − c for some small constant c. This means
               intuitively that S is a “maximal” model for x: one can summarize all the interesting, non-random
               properties of x by simply saying that x ∈ S.
                   Nowthec-sophistication of x or sophc(x), deﬁned by Koppel [8], is the minimum of K (S) over
               all models S for x such that K (S)+log2|S| ≤ K (x)+c. (The optimal such S is said to “witness”
               soph (x).) In words, soph (x) is the smallest possible amount of “non-random” information in a
                    c                     c
               program for x that consists of two parts—a “non-random” part (specifying S) and a “random” part
               (specifying x within S)—assuming the program is also near-minimal. We observe the following:
                  (i) soph (x) ≤ K(x)+O(1), since we can always just take S = {x} as our model for x.
                          c
                                                                                          n
                 (ii) Most strings x satisfy soph (x) = O(1), since we can take S = {0,1} as our model for x.
                                                c
                (iii) If S witnesses soph (x), then log |S| ≤ K (x) − K (S) + c ≤ K (x|S) + c, meaning that x
                                        c              2
                     must be a “generic” element of S.
                   It can be shown (see G´acs, Tromp, and Vit´anyi [6] or Antunes and Fortnow [1]) that there do
               exist highly “sophisticated” strings x, which satisfy sophc(x) ≥ n − c − O(logn).    Interestingly,
               the proof of that result makes essential use of the assumption that the program for S halts, after
               it has ﬁnished listing S’s elements. If we dropped that assumption, then we could always achieve
                                                                                  n
               K(S)=O(logn), by simply taking S to be the set of all y ∈ {0,1} such that K (y) ≤ K (x), and
               enumerating those y’s in a dovetailing fashion.
                   Recently, Mota et al. [10] studied a natural variant of sophistication, in which one only demands
               that S be a maximal model for x (i.e., that K (x|S) ≥ log2|S| − c), and not that S also lead to a
               near-optimal two-part program for x (i.e., that K (S)+log2|S| ≤ K (x)+c). More formally, Mota et
               al. deﬁne the na¨ıve c-sophistication of x, or nsophc (x), to be the minimum of K (S) over all models
               S for x such that K (x|S) ≥ log |S|−c. By point (iii) above, it is clear that nsoph (x) ≤ soph (x).
                                              2                                                 c           c
               Apriori, nsophc(x) could be much smaller sophc(x), thereby leading to two diﬀerent sophistication
               notions. However, it follows from an important 2004 result of Vereshchagin and Vit´anyi [13] that
               soph          (x) ≤ nsoph (x) for all x, and hence the two notions are basically equivalent.
                    c+O(logn)            c
                   Sophistication is sometimes criticized for being “brittle”: it is known that increasing the pa-
               rameter c only slightly can cause soph (x) and nsoph (x) to fall drastically, say from n−O(logn)
                                                     c              c
               to O(1). However, a simple ﬁx to that problem is to consider the quantities min {c+soph (x)}
                                                                                                c          c
               and minc{c+nsophc(x)}. Those are known, respectively, as the coarse sophistication csoph(x)
               and na¨ıve coarse sophistication ncsoph(x), and they satisfy ncsoph(x) ≤ csoph(x) ≤ ncsoph(x)+
               O(logn).
                   The advantage of sophistication is that it captures, more cleanly than any other measure, what
               exactly we mean by “interesting” versus “random” information. Unlike with apparent complexity,
               with sophistication there’s no need to specify a smoothing function f, with the arbitrariness that
               seems to entail. Instead, if one likes, the deﬁnition of sophistication picks out a smoothing function
               for us: namely, whatever function maps x to its corresponding model S.
                                                               5
