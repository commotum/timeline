                                                                                                                                                                                             Point Transformer
                                                                                                                                                        1,2                                                3                                              3                                                       1                                                                        4
                                                                                    Hengshuang Zhao                                                                          Li Jiang                                     Jiaya Jia                                       Philip Torr                                             Vladlen Koltun
                                                                                                                                 1University of Oxford                                                                         2The University of Hong Kong
                                                                                                                                     3The Chinese University of Hong Kong                                                                                                                            4Intel Labs
                                                                                                                   Abstract
                                                                                                                                                                                                                                                                                                                                  ation                                                      lamp
                                                 Self-attention networks have revolutionized natural lan-                                                                                                                                                                                                                       ic                airplane                                                                    bed
                                                                                                                                                                                                                                                                                                                              if
                                                                                                                                                                                                                                                                                                                             s
                                        guage processing and are making impressive strides in im-                                                                                                                                                                                                                       clas
                                        age analysis tasks such as image classification and object                                                                                                                                                                                                                    part 
                                        detection. Inspired by this success, we investigate the ap-                                                                                                                                                                                                                   segmentation
                                                                                                                                                                                                                                                                                                                          s
                                        plication of self-attention networks to 3D point cloud pro-                                                                                                                                                                                                                  s     em
                                                                                                                                                                                                                                                                                                                      egm an
                                                                                                                                                                                                                                                                                                                           e     t
                                        cessing. Wedesignself-attentionlayersforpointcloudsand                                                                                                                                                                                                                              n    ic 
                                                                                                                                                                                                                                                                                                                             t
                                                                                                                                                                                                                                                                                                                              at
                                        use these to construct self-attention networks for tasks such                                                                                                                                                                                                                           ion
                                        as semantic scene segmentation, object part segmentation,                                                                                                                                                                     Point Transformer
                                        andobjectclassification. Our Point Transformer design im-
                                        proves upon prior work across domains and tasks. For ex-
                                        ample, on the challenging S3DIS dataset for large-scale se-                                                                                                                                               Figure1.ThePointTransformercanserveasthebackboneforvar-
                                        mantic scene segmentation, the Point Transformer attains                                                                                                                                                  ious 3D point cloud understanding tasks such as object classifica-
                                        an mIoU of 70.4% on Area 5, outperforming the strongest                                                                                                                                                   tion, object part segmentation, and semantic scene segmentation.
                                        prior model by 3.3 absolute percentage points and crossing
                                        the 70% mIoU threshold for the first time.
                                                                                                                                                                                                                                                  in natural language processing [39, 45, 5, 4, 51] and image
                                        1. Introduction                                                                                                                                                                                           analysis [10, 28, 54]. The transformer family of models is
                                                                                                                                                                                                                                                  particularly appropriate for point cloud processing because
                                                 3D data arises in many application areas such as au-                                                                                                                                             the self-attention operator, which is at the core of trans-
                                        tonomous driving, augmented reality, and robotics. Unlike                                                                                                                                                 former networks, is in essence a set operator: it is invariant
                                        images, which are arranged on regular pixel grids, 3D point                                                                                                                                               to permutation and cardinality of the input elements. The
                                        clouds are sets embedded in continuous space. This makes                                                                                                                                                  application of self-attention to 3D point clouds is therefore
                                        3Dpointclouds structurally different from images and pre-                                                                                                                                                 quite natural, since point clouds are essentially sets embed-
                                        cludes immediate application of deep network designs that                                                                                                                                                 ded in 3D space.
                                        havebecomestandardincomputervision,suchasnetworks                                                                                                                                                                   We flesh out this intuition and develop a self-attention
                                        based on the discrete convolution operator.                                                                                                                                                               layer for 3D point cloud processing. Based on this layer,
                                                 A variety of approaches to deep learning on 3D point                                                                                                                                             we construct Point Transformer networks for a variety of
                                        clouds have arisen in response to this challenge. Some vox-                                                                                                                                               3Dunderstandingtasks. Weinvestigatetheformoftheself-
                                        elize the 3D space to enable the application of 3D discrete                                                                                                                                               attention operator, the application of self-attention to local
                                        convolutions [23, 32]. This induces massive computational                                                                                                                                                 neighborhoods around each point, and the encoding of po-
                                        and memory costs and underutilizes the sparsity of point                                                                                                                                                  sitional information in the network. The resulting networks
                                        sets in 3D. Sparseconvolutionalnetworksrelievetheselimi-                                                                                                                                                  are based purely on self-attention and pointwise operations.
                                        tations by operating only on voxels that are not empty [9, 3].                                                                                                                                                      Weshowthat Point Transformers are remarkably effec-
                                        Other designs operate directly on points and propagate in-                                                                                                                                                tive in 3D deep learning tasks, both at the level of detailed
                                        formation via pooling operators [25, 27] or continuous con-                                                                                                                                               object analysis and large-scale parsing of massive scenes.
                                        volutions [42, 37]. Another family of approaches connect                                                                                                                                                  In particular, Point Transformers set the new state of the art
                                        the point set into a graph for message passing [44, 19].                                                                                                                                                  on large-scale semantic segmentation on the S3DIS dataset
                                                 In this work, we develop an approach to deep learning on                                                                                                                                         (70.4% mIoU on Area 5), shape classification on Model-
                                        point clouds that is inspired by the success of transformers                                                                                                                                              Net40 (93.7% overall accuracy), and object part segmenta-
                                                                                                                                                                                                                                       16259
