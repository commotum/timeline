           Fali Wang, Hui Liu, Zhenwei Dai, Jingying Zeng, Zhiwei Zhang, Zongyu Wu, Chen Luo,
            Zhen Li, Xianfeng Tang, Qi He, and Suhang Wang. Agenttts: Large language model
            agent for test-time compute-optimal scaling strategy in complex tasks. arXiv preprint
            arXiv:2508.00890, 2025a.
           Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha
            Chowdhery,andDennyZhou. Self-consistencyimproveschainofthoughtreasoningin
            languagemodels,2023. URLhttps://arxiv.org/abs/2203.11171.
           Yue Wang, Qiuzhi Liu, Jiahao Xu, Tian Liang, Xingyu Chen, Zhiwei He, Linfeng Song,
            Dian Yu, Juntao Li, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, and Dong
            Yu. Thoughts are all over the place: On the underthinking of o1-like llms, 2025b. URL
            https://arxiv.org/abs/2501.18585.
           Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi,
            Quoc Le, and Denny Zhou. Chain-of-thought prompting elicits reasoning in large lan-
            guagemodels,2023. URLhttps://arxiv.org/abs/2201.11903.
           Yige Xu, Xu Guo, Zhiwei Zeng, and Chunyan Miao. Softcot++: Test-time scaling with soft
            chain-of-thought reasoning, 2025. URL https://arxiv.org/abs/2505.11484.
           AnYang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu,
            Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei
            Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong
            Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jing Zhou, Jingren Zhou, Junyang Lin, Kai
            Dang,KeqinBao,KexinYang,LeYu,LianghaoDeng,MeiLi,MingfengXue,MingzeLi,
            PeiZhang,PengWang,QinZhu,RuiMen,RuizeGao,ShixuanLiu,ShuangLuo,Tianhao
            Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng
            Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun
            Wang,ZeyuCui,ZhenruZhang,ZhipengZhou,andZihanQiu.Qwen3technicalreport,
            2025. URLhttps://arxiv.org/abs/2505.09388.
           Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, and Thomas Lee. Tree of thoughts:
            Deliberate problem solving with large language models. In NeurIPS 2023, 2023.
           Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu Yue, Weinan Dai,
            TiantianFan,GaohongLiu,LingjunLiu,XinLiu,HaibinLin,ZhiqiLin,BoleMa,Guang-
            ming Sheng, Yuxuan Tong, Chi Zhang, Mofan Zhang, Wang Zhang, Hang Zhu, Jinhua
            Zhu, Jiaze Chen, Jiangjie Chen, Chengyi Wang, Hongli Yu, Yuxuan Song, Xiangpeng
            Wei, Hao Zhou, Jingjing Liu, Wei-Ying Ma, Ya-Qin Zhang, Lin Yan, Mu Qiao, Yonghui
            Wu,andMingxuanWang. Dapo: Anopen-sourcellmreinforcementlearningsystemat
            scale, 2025. URL https://arxiv.org/abs/2503.14476.
           Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D. Goodman. Star: Bootstrapping reason-
            ing with reasoning. arXiv preprint arXiv:2203.14465, 2022.
           Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Wenyue Hua, Haolun
            Wu,ZhihanGuo,YufeiWang,NiklasMuennighoff,IrwinKing,XueLiu,andChenMa.
            Asurvey on test-time scaling in large language models: What, how, where, and how
            well? arXiv preprint arXiv:2503.24235, 2025.
           ChujieZheng,ShixuanLiu,MingzeLi,Xiong-HuiChen,BowenYu,ChangGao,KaiDang,
            YuqiongLiu,RuiMen,AnYang,JingrenZhou,andJunyangLin. Groupsequencepolicy
            optimization, 2025. URL https://arxiv.org/abs/2507.18071.
                               11
