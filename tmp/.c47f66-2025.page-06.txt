                                                                 Standard                                                                           Vision Input
                                                                Direct      CoT                                                                     Direct      CoT
                                                                                                                          GPT-4o (0513)
                                      GPT-4o (0513)
                                                                                                                       Claude 3.5 Sonnet
                                  Claude 3.5 Sonnet
                                                                                                                   Gemini 1.5 Pro (0801)
                               Gemini 1.5 Pro (0801)
                                                                                                                             GPT-4o mini
                                         GPT-4o mini
                                                                                                                   InternVL2-Llama3-76B
                              InternVL2-Llama3-76B
                                                                                                                   LLaVA-OneVision-72B
                              LLaVA-OneVision-72B
                                                                                                                             VILA1.5-40B
                                         VILA1.5-40B
                                                                                                                            InternVL2-8B
                                        InternVL2-8B
                                                                                                                      Idefics3-8B-Llama3
                                  Idefics3-8B-Llama3
                                                                                                                                          0.0              20.0              40.0              60.0
                                            Figure 5: Impact of CoT prompting of different models in the two settings of MMMU-Pro.
                           moredrastic drops were seen in models like VILA-                                        provements in reasoning-intensive fields like Tech
                           1.5-40B with a 26.9% decrease.                                                          and Engineering (e.g., a 14.49% gain for GPT-
                               This significant reduction in accuracy across the                                   4o) and Science (8.22% gain). Smaller yet consis-
                           board suggests that MMMU-Pro successfully mit-                                          tent gains are observed for LLaVA-OneVision 72B,
                           igates the shortcuts and guessing strategies that                                       such as 2.33% in Tech and Engineering. However,
                           models could exploit in the original benchmark.                                         CoT’s benefits are limited or negative in fields like
                           3.3      ImpactofCoTPrompting                                                           Art and Design, where GPT-4o gains only 1.58%,
                                                                                                                   and LLaVA-OneVision 72B sees a 17.12% decline.
                           Figure 5 examines the effectiveness of Chain of                                         These results underscore CoT’s strengths in struc-
                           Thought (CoT) prompting on the MMMU-Pro                                                 tured reasoning tasks but its reduced effectiveness
                           benchmark, in both Standard and Vision Input set-                                       in domains requiring subjective interpretation.
                           tings. Across both settings, CoT prompts generally
                           improved performance, though the extent varied                                          3.4      DoesOCRHelpintheVisionSetting?
                           significantly. For instance, Claude 3.5 Sonnet saw                                      In the Vision Input setting, one natural question
                           a substantial increase in the Standard setting, rising                                  is whether Optical Character Recognition (OCR)
                           from 42.7% to 55.0%, while models like LLaVA-                                           helps improve model performance on MMMU-Pro.
                           OneVision-72B showed only minimal gains.                                                We answer this question by first calculating the
                               Interestingly, we observed a significant perfor-                                    OCRaccuracyofdifferentmodels. Specifically,we
                           mance drop for some models, such as VILA1.5-                                            ask the model to extract the full text of the question
                           40B. This decline might be attributed to challenges                                     and answer choices. Then the OCR accuracy is
                           in instruction-following abilities. When a model                                        calculated by comparing the text extracted with
                           struggles to follow instructions accurately, gener-                                     the original text using Levenshtein distance, which
                           ating CoT explanations becomes more difficult.                                          measures the difference between the two strings.
                           Additionally, these models may face issues with                                         Thesimilarity between the extracted and original
                           maintaining the correct response format, leading to                                     text is computed as:
                           what is known as “boiled response format” prob-                                                                            Levenshtein.distance(text1,text2)
                           lems. These findings highlight the potential of CoT                                         OCRAccuracy=1−                     max(len(text1),len(text2))
                           to enhance model performance in complex, real-                                              Table 2 shows that although most of the models
                           world tasks that require nuanced reasoning and                                          demonstrate strong OCR capabilities, as indicated
                           integration of multiple information sources. How-                                       byhighsimilarity scores. Based on the result, we
                           ever, they also underscore the importance of robust                                     then explore whether explicitly asking the model
                           instruction-following capabilities as a prerequisite                                    to first extract the question and then solve it (with
                           for effective CoT implementation.                                                       an OCRpromptshowninAppendixA)couldhelp
                               Theeffectiveness of CoT prompting across disci-                                     in improving performance within the Vision In-
                           plines is summarized in Table 6 and Figure 9, com-                                      put setting of MMMU-Pro. Across the models
                           paring CoT and direct accuracy for GPT-4o and                                           evaluated, the inclusion of OCR prompts did not
                           LLaVA-OneVision 72B. CoT shows significant im-                                          significantly alter performance. These minimal dif-
                                                                                                           15139
