                             3.4        Dynamic physical systems
                             Wedeveloped a dataset of simulated physical mass-spring systems using the MuJoCo physics engine
                             [40]. Each scene contained 10 colored balls moving on a table-top surface. Some of the balls moved
                             independently, free to collide with other balls and the barrier walls. Other randomly selected ball
                             pairs were connected by invisible springs or a rigid constraint. These connections prevented the
                             balls from moving independently, due to the force imposed through the connections. Input data
                             consisted of state descriptions matrices, where each ball was represented as a row in a matrix with
                             features representing the RGB color values of each object and their spatial coordinates (x,y) across
                             16 sequential time steps.
                                   The introduction of random links between balls created an evolving physical system with a
                             variable number “systems” of connected balls (where “systems” refers to connected graphs with
                             balls as nodes and connections between balls as edges). We deﬁned two separate tasks: 1) infer the
                             existence or absence of connections between balls when only observing their color and coordinate
                             positions across multiple sequential frames, and 2) count the number of systems on the table-top,
                             again when only observing each ball’s color and coordinate position across multiple sequential frames.
                                   Both of these tasks involve reasoning about the relative positions and velocities of the balls to
                             infer whether they are moving independently, or whether their movement is somehow dependent on
                             the movement of other balls through invisible connections. For example, if the distance between two
                             balls remains similar across frames, then it can be inferred that there is a connection between them.
                             The ﬁrst task makes these inferences explicit, while the second task demands that this reasoning
                             occur implicitly, which is much more diﬃcult. For further information on all tasks, including videos
                             of the dynamic systems, see the supplementary information.
                             4        Models
                             In their simplest form RNs operate on objects, and hence do not explicitly operate on images or
                             natural language. A central contribution of this work is to demonstrate the ﬂexibility with which
                             relatively unstructured inputs, such as CNN or LSTM embeddings, can be considered as a set of
                             objects for an RN. Although the RN expects object representations as input, the semantics of what
                             an object is need not be speciﬁed. Our results below demonstrate that the learning process induces
                             upstream processing, comprised of conventional neural network modules, to produce a set of useful
                             “objects” from distributed representations.
                             Dealing with pixels We used a CNN to parse pixel inputs into a set of objects. The CNN took
                             images of size 128 × 128 and convolved them through four convolutional layers to k feature maps of
                             size d × d, where k is the number of kernels in the ﬁnal convolutional layer. We remained agnostic
                             as to what particular image features should constitute an object. So, after convolving the image,
                                                 2
                             each of the d k-dimensional cells in the d × d feature maps was tagged with an arbitrary coordinate
                             indicating its relative spatial position, and was treated as an object for the RN (see Figure 2). This
                             means that an “object” could comprise the background, a particular physical object, a texture,
                             conjunctions of physical objects, etc., which aﬀords the model great ﬂexibility in the learning process.
                             Conditioning RNs with question embeddings The existence and meaning of an object-object
                             relation should be question dependent. For example, if a question asks about a large sphere, then
                             the relations between small cubes are probably irrelevant. So, we modiﬁed the RN architecture such
                                                                                                                             P
                             that g could condition its processing on the question: a = f (                                         g (o ,o ,q)). To get the question
                                       θ                                                                                  φ     i,j   θ    i   j
                             embedding q, we used the ﬁnal state of an LSTM that processed question words. Question words
                             were assigned unique integers, which were then used to index a learnable lookup table that provided
                             embeddings to the LSTM. At each time-step, the LSTM received a single word embedding as input,
                             according to the syntax of the English-encoded question.
                                                                                                         5
