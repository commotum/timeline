                             Point Cloud         Right View         2.5D Dual        City3D/PolyFit        PC2WF          Point2Roof          PBWR              Ours
                   Figure 6. Quantitative evaluation results on the Building3D dataset [28]. The 1-st column is the point clouds segmented with single
                   buildings but messed with noise, the 2-nd column is the right views of the original point clouds in the 1st column but without removing
                   the non-building parts. The results of the traditional methods (3-rd and 4-th columns) are mesh models, while 3D wireframes for deep
                   learning-based methods (5-th to 8-th columns). Though the ground truth wireframe models for the test set are not open-sourced, please
                   refer to the right view and pay attention to the tree noise (1-st and 4-th rows), chimney at the top of the roof (3-rd and 6-th rows), and roof
                   planes of different angles (5-th row). Green boxes mark the details, while the blue ones mark the reconstruction results.
                    Metric            Uni. (90%)   Uni. (85%)   Uni. (80%)    Uni. (Gau)  Ours
                    FID↓       −2        180.2        152.0        140.3        159.5      53.9
                    MMD(×10 )↓           2.10         2.63          2.67         0.89      0.37
                   Table 2. Effetcs of synthetic LiDAR scanning. The methods of
                   Uni. (X%) and Uni. (Gau) are described in the main text.
                   versity, reflecting different sparsities and missing regions
                   that closely resemble the real-world data. Additional visu-                         Wireframe      Real        Uniform           Synthetic LiDAR Scanning
                   alizations are provided in the supplementary materials.                            Figure 7. Examples of simulated LiDAR scanning. Compared
                   4.6. Ablation Studies                                                              with uniform sampling of different sparsities (80%, 85%, 90%,
                   All the ablation studies are done on the test set of the Build-                    and95%fromtoptobottominthe3-rdcolumn),ourmethodhigh-
                                                                                                      lights data diversity in both sparsity and completeness.
                   ing3D dataset [28]. Considering the training time, ablation
                   studies on the 2D and 3D corner number, and number of
                   sampling points are trained without the synthetic data.                            What is more, the adding of edge attention boosts the EF1
                   Different Components. As shown in Table 3, the base-                               by 3.6%. Finally, the use of synthetic height maps en-
                   line method directly predicts 3D corners from height maps.                         hances both precision and completeness in the reconstruc-
                   However, it struggles with sparse point clouds, leading to                         tion, demonstrating the effectiveness of data augmentation.
                   poor results.       The introduction of 2D-3D corner detec-                        2Dand3DCornerNumber. Inthe2D-to-3Dcornerdetec-
                   tion significantly improves model performance by leverag-                          tionprocess,the2Dcornernumber(N)and3Dcornernum-
                   ing dense 2D corner detection and a smaller search space.                          bers (NH) are both significant for the detection of sparse
                                                                                              22221
