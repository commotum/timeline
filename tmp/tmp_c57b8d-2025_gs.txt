                           MathClean:ABenchmarkforSyntheticMathematicalData
                                                                                                Cleaning
                                                           ‚Ä†                                                           ‚Ä†                                                       ‚Ä†
                                         HaoLiang                                                 Meiyi Qiang                                                 Yuying Li
                                      Peking University                                Beijing Institute of Technology                           Beijing Institute of Technology
                                         Beijing, China                                            Beijing, China                                            Beijing, China
                                hao.liang@stu.pku.edu.cn                                    1120213065@bit.edu.cn                                        liyuying@bit.edu.cn
                                          Zefeng He                                             YongzhenGuo                                              ZhengzhouZhu
                                     Nanjing University                                              AntGroup                                             Peking University
                                        Nanjing, China                                             Beijing, China                                            Beijing, China
                              221250021@smail.nju.edu.cn                               yongzhen.gyz@antgroup.com                                          zhuzz@pku.edu.cn
                                                                                            ‚àó                                                   ‚àó
                                                                  WentaoZhang                                                      Bin Cui
                                                                   Peking University                                         Peking University
                                                                      Beijing, China                                            Beijing, China
                                                            wentao.zhang@pku.edu.cn                                         bin.cui@pku.edu.cn
                    Abstract                                                                                     ACMReferenceFormat:
                   With the rapid development of large language models (LLMs),                                   HaoLiang‚Ä†,MeiyiQiang‚Ä†,YuyingLi‚Ä†,ZefengHe,YongzhenGuo,Zhengzhou
                                                                                                                                        ‚àó              ‚àó
                    the quality of training data has become crucial. Among the vari-                             Zhu,WentaoZhang ,andBinCui .2025.MathClean:ABenchmarkforSyn-
                    ous types of training data, mathematical data plays a key role in                            thetic Mathematical Data Cleaning. In . ACM, New York, NY, USA, 13 pages.
                    enabling LLMs to acquire strong reasoning abilities. While high-                             https://doi.org/10.1145/nnnnnnn.nnnnnnn
                    quality open-source data is important, it is often insuf√ècient for                           1 Introduction
                    pre-training, necessitating the addition of synthetic math prob-                             LLMshavedemonstratedexceptional performance across a wide
                    lems. However, synthetic math questions and answers can intro-                               range of tasks in various domains [20, 29]. It has been established
                    duce inaccuracies, which may degrade both the training data and                              that data plays a crucial role in the success of LLMs [1, 3, 34].
                   web data. Therefore, an effective method for cleaning synthetic                               Recently, several studies have focused on data cleaning to improve
                    math data is essential. In this paper, we propose the MathClean                              LLMtraining [5, 8, 15, 33] and achieved success in training LLMs.
                    benchmark to evaluate the effectiveness of math data cleaning                                    AmongthevarioustypesofdataforLLMs,mathematicaldatais
                    models. The MathClean benchmark consists of 2,000 correct ques-                              one of the most crucial, as it enhances a model‚Äôs reasoning capa-
                    tions and 2,000 erroneous questions with additional 2,000 correct                            bilities [14, 34]. However, collecting large amount of mathematical
                    and erroneous answers sourced from augmented data based on                                   data presents several challenges: (1) High-quality MathQA data is
                    GSM8KandMATH.Moreover, we also annotate error types for                                      scarce and often requires data generation [28, 42]. (2) Ensuring the
                    each question or answer, since it can assess whether models can                              correctness of synthetic mathematical data is challenging [28]. (3)
                    correctly identify the error categories for future improvements. Fi-                         Evaluating the correctness of mathematical data remains a com-
                    nally, we present comprehensive evaluations using state-of-the-art                           plex task [25, 41, 43]. To address these challenges, several studies
                   (SOTA)models. Our results demonstrate that even strong models                                 have proposed output reward models (ORMs) [39] and process
                    like GPT-o1 and DeepSeek-R1 perform poorly on this benchmark,                                reward models (PRMs) [19, 25, 30] to assess the correctness of syn-
                    highlightingtheutilityofMathClean.Ourcodeanddataisavailable                                  thetic answers. To evaluate the effectiveness of these ORMs and
            arXiv:2502.19058v1  [cs.CL]  26 Feb 2025at https://github.com/YuYingLi0/MathClean.                   PRMs, researchers in our community have developed ORM and
                                                                                                                 PRMbenchmarks [25, 41, 43]. These benchmarks primarily aim
                    Keywords                                                                                     to enhance PRM performance, thereby improving mathematical
                    Mathematical Data, Synthetic Data Cleaning Benchmark                                         reasoning capabilities. Rather than focusing on inference, our work
                                                                                                                 prioritizes mathematical training data cleaning. We establish the
                                                                                                                 following two tasks as our key objectives for improvement:
                    Permission to make digital or hard copies of all or part of this work for personal or            Correctness of Questions and Answers. Recent advance-
                    classroom use is granted without fee provided that copies are not made or distributed        ments in synthetic mathematical training data have been signifi-
                    for profit or commercial advantage and that copies bear this notice and the full citation    cant [28, 42]. OpenMathInstruct1 and 2 [28] have generated over
                    onthefirst page. Copyrights for components of this work owned by others than the             14 million QA pairs based on GSM8K and MATH. However, it is
                    author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
                    republish,topostonserversortoredistributetolists,requirespriorspecificpermission             reported that approximately 50% of the generated QA pairs are in-
                    and/or a fee. Request permissions from permissions@acm.org.                                  correct. Moreover, OpenMathInstruct1 and 2 [28], Given the large
                    Conference‚Äô17, July 2017, Washington, DC, USA
                   ¬©2025Copyrightheldbytheowner/author(s). Publication rights licensed to ACM.                   0
                   ACMISBN978-x-xxxx-xxxx-x/YY/MM                                                                0‚Ä†: Equal Contribution.
                    https://doi.org/10.1145/nnnnnnn.nnnnnnn                                                       ‚àó: Corresponding Authors
                                                                                                                                   ‚Ä†                    ‚Ä†                ‚Ä†                                                                                       ‚àó                   ‚àó
                           Conference‚Äô17, July 2017, Washington, DC, USA                                            HaoLiang , Meiyi Qiang , Yuying Li , Zefeng He, Yongzhen Guo, Zhengzhou Zhu, Wentao Zhang , and Bin Cui
                                                             Question & Answer Error Detection                                                                                             Question & Answer Error Type
                                                                                                                                                ...               Expression Error                Unrealistic                          Logic Error
                                     Q:... larger rectangle has a perimeter of                 Q: How many triangles with positive ...                         grammar mistake,              against scientific          incorrect math method, faulty 
                                     40 units. What is the area of the region                                                                                  causes ambiguity,             principles, defies          problem-solving logic, incomplete 
                                     that is not covered by the ...                            A: ... there are 10 lines (5 horizontal + 5                     misuse terms...               common sense...             consideration of cases...(52%)
                                   Q: ... has 64 students, and they are to be                  vertical + 2 diagonals), the total number 
                                   divided into groups of 32.5 students                        ofsets of 3 collinear points is ...                               Lack of Conditions              Contradictions               Expression Error             Computing Error
                                   each. How many groups will there be?                          Q: Given that r is a real number with r <                    missing diagrams or           no solution exists,           unclear wording,            wrong program steps, 
                                                                                                 2, and z is a complex number ...                             charts, insufficient          mutually exclusive            grammatical errors,         faulty numerical 
                                     Q: Rodney is guessing a secret number                       A: To solve this problem, we need to                         conditions...                 conditions...                 incomplete...(10%)          approximation...(38%)
                                     based on some clues. The number is ...                      follow these steps: 1. Understand ...                                            Question                                                     Answer
                                                     Question                                                      Answer
                           Figure 1: Overview of MathClean benchmark. MathClean proposed challenges in detecting errors in mathematical Questions
                           andAnswers,aswellasinidentifyingthespecificerrortypeswithinthesemathematicalproblems.
                           volumeofdata,humanevaluationisprohibitivelycostly.Asaresult,                                                                                    Basedontheseprompts,wesynthesizedquestionsandcorre-
                           LLMsareneededtoassessthecorrectness of synthetic math data.                                                                                     sponding answers, ensuring the diversity of our MathClean
                           Therefore, it is crucial to develop a benchmark for evaluating the                                                                              benchmark. Finally, each augmented question was reviewed
                           correctness of synthetic mathematical problems.                                                                                                 byhumanannotatorstoensuredataquality.
                                Diverse Error Types. As noted earlier, LLMs must evaluate                                                                              ‚Ä¢ Diverse Error Categories: In addition to the challenges in
                           the correctness of synthetic math data. Additionally, LLMs need to                                                                              detecting erroneous questions and answers, we propose a
                           identify the types of errors in synthetic math problems to facilitate                                                                           moredif√ècult task: classifying error questions and answers
                           future improvements. However, when determining whether an                                                                                       into different categories. This is intended to assess whether
                           LLMtrulyunderstands the correctness of a question or answer, it                                                                                 models can identify errors in questions and answers, aiding
                           is necessary to create a benchmark that incorporates a variety of                                                                               in the future improvement of synthetic data.
                           error types to evaluate the model‚Äôs ability to recognize different                                                                          ‚Ä¢ ComprehensiveEvaluation:Weconductextensiveexper-
                           error categories.                                                                                                                               iments on the MathClean benchmark, evaluating five widely
                                Toaddressthesetwoaspects,weintroduceMathClean,abench-                                                                                      usedclosed-sourceLLMs,andelevenopen-sourceLLMswith
                           markdesigned to assess models‚Äô ability to (1) distinguish between                                                                               sizes ranging from 7B to 72B. Moreover, we evaluate our
                           correct and erroneous mathematical data and (2) identify the er-                                                                                modelonthreeSOTAPRMs.
                           ror type in erroneous questions or answers. Figure 1 present an                                                                             ‚Ä¢ NewChallenges: Through case studies, we demonstrate
                           overviewoftheerrordetectionanderrortypedetectionintheMath-                                                                                      that the MathClean benchmark introduces new challenges
                           Clean benchmark. To obtain a more diverse set of questions and                                                                                  for LLMs, even for the SOTA models like GPT-o1.
                           answers, we proposed 10 error augmentation prompts and 16 diver-                                                                    2 RelatedWork
                           sity augmentation prompts. Then, we include human annotations
                           to ensure the quality of MathClean. The MathClean benchmark                                                                         2.1         MathematicalBenchmarks
                           consists of 2,000 correctly formulated questions and 2,000 erro-                                                                    GSM8K[6]isadatasetfromOpenAIthatincludes8.5Khigh-quality
                           neous ones. Detecting the correctness of questions is crucial, as                                                                   elementary school math word problems, each requiring 2 to 8
                           synthetic math questions cannot yield correct answers if they are                                                                   steps to solve. These problems primarily involve basic arithmetic
                           inherently flawed. Additionally, it includes 2,000 correct and erro-                                                                operations such as addition, subtraction, multiplication, and divi-
                           neous answers, specifically designed to assess whether models can                                                                   sion. MATH [16] offers a dataset of 12,500 problems sourced from
                           accurately identify valid answers corresponding to correct ques-                                                                    high school math competitions. SuperCLUE-Math [32] is a Chinese
                           tions. Furthermore, each question and answer is annotated with an                                                                   benchmark for multi-step reasoning in mathematics, containing
                           error category, posing additional challenges for models. Accurate                                                                   over 2,000 problems that require multi-step reasoning and offer
                           identification of these categories can guide improvements in the                                                                    natural language solutions. MathBench [18] includes 3,709 math
                           quality of error-laden mathematical data for future use.                                                                            problems ranging from basic arithmetic to college-level questions,
                                Thecorecontributions are summarized as follows:                                                                                covering multiple dif√èculty levels. As LLMs have progressively
                                   ‚Ä¢ NewBenchmark:WeintroduceMathClean,anewbench-                                                                              achieved extremely high accuracy on existing mainstream bench-
                                       mark designed for cleaning mathematical QA data. Our                                                                    marks(e.g., MATH, GSM8K), it is critical to propose benchmarks
                                       benchmark comprises 2,000 correct and 2,000 erroneous                                                                   that are more challenging for LLMs. Omni-MATH [11] contains
                                       questions. Additionally, it includes 2,000 correct and erro-                                                            4428 Olympiad-level math problems sourced from international
                                       neous answers. Each erroneous question and answer is an-                                                                competitions with rigorous manual annotations. All these prob-
                                       notated with an error type, adding further challenges.                                                                  lems are categorized into 33 sub-domains in detail, spanning 10
                                   ‚Ä¢ Diverse Math Data Synthesis Method: Following the                                                                         dif√èculty levels. FrontierMath [12] is a mathematical benchmark
                                       methodology of MuggleMath, we developed 10 types of                                                                     constructed by leading mathematicians, aiming to push AI towards
                                       question augmentation prompts for error synthesis. Addi-                                                                expert-level capabilities. Even the best models solving less than 2%
                                       tionally, we created 16 types of prompts‚Äî11 more than Mug-                                                              of problems. It comprises hundreds of purely original, challenging,
                                       gleMath‚Äîto enable more diverse question augmentation.                                                                   expert-level mathematical problems covering a broad spectrum of
                  MathClean: A Benchmark for Synthetic Mathematical Data Cleaning                                                     Conference‚Äô17, July 2017, Washington, DC, USA
                  modernmathematicalsubjects, minimizing the possibility of data                     question-answer pairs. JiuZhang3.0 [17] trains a specialized model
                  contamination. PRMBench [25] is a benchmark for evaluating the                     for mathematical data synthesis, with the training and retraining
                  error detection capabilities of PRMs from three perspectives: sim-                 datasets generated by GPT-4.
                  plicity, soundness, and sensitivity. It consists of 6,216 questions and               MCTSBased.Thisapproach was first proposed in OpenAI‚Äôs
                  83,456 step-level labels. Similarly, ProcessBench [41] consists of                 o1 [20]. It significantly expands the search space of model outputs.
                  3,400 competition- and olympiad-level math problems that mea-                      Compared to direct distillation, it demonstrates superior perfor-
                  sure the ability to identify the earliest wrong steps in step-level                manceinsynthesizing datasets for step-by-step solutions to com-
                  mathematical reasoning.                                                            plex mathematical problems. In ReST-MCTS* [38], process reward
                                                                                                     value is utilized to guide MCTS, ensuring the accuracy of the data
                  2.2    MathematicalLLMs                                                            reasoning process. Meanwhile, rStar [22] introduces a more ex-
                  Recently, with the emergence of GPT-o1-type models, numerous                       tensive action space at each step of reasoning. LLaMA-Berry [37]
                  mathematical large models have been developed. In this paper, we                   implementsSR-MCTS(Self-refine),whereeachleafnoderepresents
                  summarize the commonly used mathematical large models.                             a complete problem-solving state, and child nodes correspond to
                     The GPT series [4, 21, 23] represents a milestone AI model in                   the criticizing and rewriting of parent nodes. Mulberry [35] pro-
                  humanity‚Äôs journey toward Artificial General Intelligence (AGI),                   poses CoMCTS, which leverages collective knowledge from multi-
                  developed and released by OpenAI. The latest iteration, GPT-4 [2],                 ple models during inference and constructs a multimodal dataset,
                  as a large-scale multimodal language model, has demonstrated                       Mulberry-260k, for training MLLMs.
                  professional-level proficiency in the field of mathematics. OpenAI                 2.4     RewardModels
                  o1-preview [20] integrates slow thinking into the model, designed                  In the Reinforcement Learning from Human Feedback (RLHF) or
                  to allow the model more time for thinking before responding, en-                   MCTS-based inference, Reward Models (RMs) are employed to
                  abling it to learn from mistakes and refine questions like human                   assess and score the quality of model outputs, thereby guiding
                  cognition. It elevates the capabilities of large language models in                the optimization or reasoning path of LLMs. Reward models can
                  complex reasoning and challenging mathematical tasks to a higher                   be categorized into Process Reward Models (PRMs) and Outcome
                  level, achieving a score of 83% on a qualifying exam for the Interna-              RewardModels(ORMs).
                  tional MathematicsOlympiad(IMO).TheQwen2.5-Mathseries[34]                             OutcomeRewardModels.ORMsevaluateonlythefinalmath-
                  excel in mathematical reasoning. It supports solving mathematical                  ematical results without considering the solution process. For in-
                  problems in both Chinese and English through Chain-of-Thought                      stance, Qwen2.5-Math-RM-72B [40], released by the Qwen team,
                 (CoT) and Tool-Integrated Reasoning (TIR).                                          assigns a single score to each mathematical response.
                     TheQwQmodel[27]emphasizesthecultivationofAI‚Äôslogical                               ProcessRewardModels.PRMsaremorefine-grained,focusing
                  reasoning abilities, enabling the model to learn to think, question,               onwhethereachstepofthereasoningpathislogical and correct,
                  andreflect, thereby deepening its understanding of mathematical                    providing step-level feedback and guidance signals. For example,
                  knowledge and achieving breakthroughs in solving complex math-                     Math-Shepherd-Mistral-PRM [30] is trained on an automatically
                  ematical problems. DeepSeek-Math [24] is an open-source math-                      constructed (rather than manually annotated) process supervision
                  ematical reasoning model trained on the DeepSeekMath Corpus                        dataset, scoring each step of mathematical reasoning. MATHMinos-
                  dataset, available in three 7B versions: base, instruction-tuned, and              PRM [10] introduces a novel two-stage training paradigm and
                  reinforcement learning. Its performance on the competition-level                   incorporates step-wise natural language feedback labels. Eurus-
                  MATHbenchmarkapproachesthatofGeminiUltra[26]andGPT-4,                              PRM[7]utilize implicit PRM, where ORM is trained to evaluate
                  supporting mathematical problem-solving, tool usage, and theorem                   response-levellabels.Qwen2.5-Math-PRM[40],currentlytheSOTA
                  proving. As an open source model, DeepSeek-R1 [14] achieves im-                    PRM,proposes a consensus filtering mechanism combining Monte
                  pressive performance in mathematical and reasoning tasks which                     Carlo estimation and LLM-as-a-judge. Additionally, there are the
                  is comparable to OpenAI-o1 with less computational resources. It                   Skywork-PRMseries [19] and RLHFlow-PRM series [31] models.
                  excels in complex reasoning tasks, specializing in complex math-                   For more comprehensive LLM-as-a-Judge please refer to the LLM-
                  ematical reasoning and competition-level problem solving with                      as-a-Judge survey [13].
                  detailed step-by-step solutions.
                  2.3    MathematicalDataSynthesis                                                   3 BenchmarkforDataCleaning
                 Thedemandforhigh-quality data in the field of LLMs has spurred                      In this section, we provide a comprehensive description of the
                  the flourishing development of the data synthesis domain. Existing                 construction process for the MathClean benchmark‚Äîa dataset com-
                  data synthesis approaches can be broadly categorized into two                      prising 4000 mathematical problems that is divided into a question
                  types: those based on large language model distillation and those                  dataset and an answer dataset. Each dataset is annotated to indicate
                  based on Monte Carlo Tree Search (MCTS).                                           both correctness and specific error types.
                     LLM Based Distillation. MetaMath [36] leverages GPT-3.5                         3.1     QuestionDatasetConstruction
                 Turbo models to rewrite existing mathematical problems from mul-
                  tiple perspectives, thereby generating the MetaMathQA dataset.                     3.1.1   Data Preparation. We used GSM8K and MATH train, two
                  KPDDS[17]utilizesGPT-4toextractthetopicsandKeyPointsfrom                           widely recognized mathematical datasets, as seed data to generate
                  seed questions, processing and sampling them to synthesize new                     mathematical questions with various error types. The problems
                                                                                                                                         ‚Ä†                     ‚Ä†                ‚Ä†                                                                                            ‚àó                    ‚àó
                             Conference‚Äô17, July 2017, Washington, DC, USA                                               HaoLiang , Meiyi Qiang , Yuying Li , Zefeng He, Yongzhen Guo, Zhengzhou Zhu, Wentao Zhang , and Bin Cui
                                                                                                                    Erroneous Question                                                                                                         Reason for Question Error: 
                                   Question: Sam and Jeff had a skipping competition at recess. The competition was split into four rounds. Sam                                                                                                 In the real world, the 
                                   completed 1.5 more skips than Jeff in the first round. Jeff skipped 2.5 fewer times than Sam in the second round.                                                                                            number of jumps must be 
                                   Jeff skipped 3.5 more times than Sam in the third round. Jeff got tired and only completed 0.75 the number of                                                                                                an integer; fractional 
                                   skips as Sam in the last round. If Sam skipped 16 times in each round, what is the average number of skips per                                                                                               values such as 1.5, 2.5, or 
                                   round completed by Jeff?                                                                                                                                                                                     3.5 are not possible.
                                   Difficulty: simple; Error Type: unrealistic
                                                                                                                     Erroneous Answer                                                                                                          Reason for Answer Error:
                                   Question: How many triangles with positive area are there whose vertices are points in the xy-plane whose 
                                   coordinates are integers (x, y) satisfying 1 ‚â§ x ‚â§ 5 and 1 ‚â§ y ‚â§ 5?
                                   Answer: To find the number of triangles with positive area whose vertices are points in the xy-plane with integer 
                                   coordinates (x, y) satisfying 1 ‚â§ x ‚â§ 5 and 1 ‚â§ y ‚â§ 5, we first determine the total number of points in this range. 
                                   There are 5 √ó 5 = 25 points. The number of ways to choose 3 points out of 25 is given by the combination 
                                                                           !!                                                                                           '(!
                                   formula: Ì†µ„åµ(Ì†µ„åµ,Ì†µ„åµ) =                     Ì†µ„åµ!       . For n = 25 and k = 3, we have: Ì†µ„åµ 25,3 =                                         25!         =25√ó24√ó23=2300	.                                           1. As shown above,  o1  
                                                                      Ì†µ„åµ!  Ì†µ„åµ ‚àí Ì†µ„åµ !
                                                                      #!(!%#)!                                                                                     )! '(%) !
                                                                                                                                                                   3! 25‚àí3 !                3√ó2√ó1                                               does not account for all 
                                   However, this count includes sets of 3 collinear points, which do not form a triangle with positive area. We need                                                                                            cases of collinear points, 
                                   to subtract the number of such sets. Collinear points can be found in horizontal lines, vertical lines, and diagonals.  and the number of correct 
                                   There are 5 horizontal lines, 5 vertical lines, and 2 sets of 5 points each for the diagonals running from the top-                                                                                          answers should be less 
                                   left to the bottom-right and from the top-right to the bottom-left. For each line, the number of ways                                                                                                        than 2200.
                                                                                                                   5!
                                   to choose 3 collinear points is: Ì†µ„åµ 5,3 =                                      (!         =10	. Since there are 10 lines (5 horizontal + 5                                                                   2. There is a calculation 
                                                                                                             )! (%) !
                                                                                                             3! 5‚àí3 !
                                   vertical + 2 diagonals), the total number of sets of 3 collinear points is: 10 √ó 10 = 100. Therefore,                                                                                                        error. 5+5+2 should be 12. 
                                   the number of triangles with positive area is: 2300 ‚àí 100 = 2200. The answer is: 2200.                                                                                                                       Therefore, this step should 
                                   Difficulty: challenging; Error Type: logic error                                                                                                                                                             be 12 lines. 
                             Figure 2: Two erroneous examples from the MathClean dataset are presented: a simple dif√èculty question with an unrealistic
                             error and a challenging dif√èculty problem, which includes both the question and the answer, with a logic error.
                             generated using GSM8K as seed data are relatively easier and are                                                                         ensures that each generated question contains only one error type,
                             classified as SIMPLE dif√èculty, while those generated using MATH                                                                         minimizing the complexity of mixing multiple error types within a
                             train as seed data are considered more dif√ècult and are classified                                                                       single question. For each error type, we have iteratively optimized
                             as CHALLENGINGdif√èculty. For question synthesis, we employed                                                                             and designed a well-structured prompt, with an example provided
                             the open-source model Qwen2.5-72B-Instruct, known for its strong                                                                         for each type. The complete set of prompts is presented in Figure 7.
                             mathperformance. By carefully designing a diverse set of prompts,                                                                        3.1.2        DataAnnotation. Toensurethatourgeneratedmathematical
                            weguidethemodeltogeneratemathematicalquestionswiththe                                                                                     questions meet the expected requirements, we recruited graduate
                             intended error types based on the seed data.                                                                                             students majoring in science and engineering from top-tier uni-
                                  It is important to note that many synthetic questions concur-                                                                       versities to conduct detailed manual annotations of the data. Prior
                             rently exhibit multiple error types and causes. In this study, we                                                                        to annotation, all annotators underwent rigorous screening and
                             begin by analyzing and categorizing four primary error types: ex-                                                                        assessment of their mathematical abilities. They were required to
                             pression errors, lack of conditionality, contradictions, and unreal-                                                                     have university entrance mathematics examination scores above a
                             istic scenarios. In order to ensure greater diversity in our dataset,                                                                    predetermined baseline, ensuring they possessed suf√ècient mathe-
                            wesubsequently designed specific error conditions for each major                                                                          matical problem-solving skills and attention to detail.
                             error type. Expression errors include: (1) misinterpretation due to                                                                           The annotation process consists of several steps. Annotators
                             unclear references, (2) grammatical errors or awkward phrasing, (3)                                                                      first verify whether a question is correct or incorrect, and if it is
                             inclusion of redundant or irrelevant content and conditions, and (4)                                                                     incorrect, they determine whether it contains a single error type or
                             misuse or confusion of terminology. Lack of conditions include:                                                                          multipletypesoferrors.Theythenannotatethespecificerrortypes,
                            (5) the absence of necessary diagrams or charts, and (6) the omis-                                                                        which are categorized as: expression errors, lack of information,
                             sion of essential conditions required to obtain the correct answer.                                                                      contradictions, and unrealistic scenarios. All annotation data is
                             Contradictions include: (7) the presence of mutually exclusive                                                                           reviewed by a team of reviewers to ensure its accuracy. Annotators
                             conditions, and (8) the solution is either nonexistent or meaning-                                                                       are required to maintain an accuracy rate of over 90%.
                             less. Unrealistic scenarios include: (9) only integer solutions are                                                                           Wefilteredmathquestionsthatcontainedonlyasingleerrortype
                             meaningful, but the conditions or results are non-integer, and (10) a                                                                    or where the second error type was not significant, and then decon-
                             question that violates common sense or fundamental natural laws.                                                                         taminatedthefilteredlabeleddataset.Thefinalproblemdatasetcon-
                            This classification provides a systematic framework for analyzing                                                                         sists of subsets containing four different error types, combined in a
                             the concrete types of errors in synthetic mathematical questions.                                                                        specific ratio, and includes both simple and challenging dif√èculties.
                                  WeemploytheQwen2.5-72B-Instructmodeltogenerateques-                                                                                 Anexampleoferroneousquestion, along with the corresponding
                             tions for each of the 10 error types discussed above. This approach                                                                      explanation, is provided in Figure 2.
                  MathClean: A Benchmark for Synthetic Mathematical Data Cleaning                                                     Conference‚Äô17, July 2017, Washington, DC, USA
                  3.2    AnswerDatasetConstruction
                  3.2.1  DataSynthesize. Toimprovethequalityoftheanswerdataset,
                  it is essential to enhance the diversity of the corresponding ques-
                  tions. To this end, we developed 16 unique question rewriting tech-
                  niques aimed at maximizing the coverage of mathematical domains
                 within our dataset. This data augmentation step generates novel
                  and diverse questions. Moreover, since all questions in MathClean
                  are derived from newly synthesized data, we effectively mitigate
                  commondatacontaminationissues.                                                                                  QUESTION
                     Thesixteen data augmentation strategies we have devised are
                  as follows: (1) modification of numerical values, scores, and per-
                  centages; (2) incorporation of algebraic expressions and variables;
                 (3) adding time variation; (4) introducing cumulative or increasing-
                  decreasing conditions; (5) having special events or contingencies;
                 (6) having events conform to the laws of statistics and probabilistic
                  analysis; (7) adding error rates and rework; (8) setting cost budgets
                  or resource constraints; (9) introducing multivariate comparisons;
                 (10) establishing conditional loops or recursion; (11) setting goals or
                  schedule requirements; (12) including conditions with multiple out-
                  comes;(13)usingnon-uniformunits;(14)inferringconditionsbased                       Figure 3: Proportion of different dif√èculty levels and error
                  ontheresults; (15) storytelling narratives or nested scenarios; and                types in the Question dataset of MathClean.
                 (16) synthesizing interdisciplinary knowledge. Detailed rewriting
                  steps and corresponding examples are provided in Figure 8.
                     In order to broaden the answer dataset to include a wider array
                  of error types and a greater range of error severity, we employed a
                  series of models with markedly different performance levels dur-
                  ing this process. These included Qwen2.5-Math-72B, Qwen2.5-72B,
                  Llama-3.1-8B-Instruct, and Qwen2.5-Math-1.5B-Instruct. We ap-
                  pliedthesemodelstorephrasebothsimpleandchallengingproblem
                  sets, thereby enabling a comprehensive evaluation across different
                  dif√èculty levels. In addition, we combine Chain-of-Thought (CoT)                                                  ANSWER
                  andProgram-of-Thought(PoT)strategieswhengeneratinganswers
                  to provide more detailed steps.
                  3.2.2   Data Annotation. Similar to the question dataset, we re-
                  cruited graduate students with advanced mathematical problem-
                  solving skills to annotate and rigorously review the answer dataset.
                  Duringthisprocess,annotatorswereallowedtousevariouscompu-
                  tational tools and reference materials flexibly to ensure the highest
                  accuracy in annotation.
                     Theannotation process was divided into three steps based on
                  error level and type. First, evaluate the correctness of the ques-                 Figure 4: Proportion of different dif√èculty levels and error
                  tion. Second, for questions that are correct, assess the correctness               types in the Answer dataset of MathClean.
                  of the corresponding answer. Third, for questions with erroneous                   a single or typical error type, thereby forming the answer dataset.
                  answers, label the specific error type and provide a detailed de-                  Anexampleofanerroneousanswerfromthedatasetispresented
                  scription of the error cause to ensure high annotation accuracy                    in Figure 2.
                  during review. Expression errors included incomplete answers,
                  redundant steps, and grammatically incorrect responses. Logic er-                  3.3     Statistics of MathClean
                  rors included the use of incorrect mathematical methods, flawed
                  problem-solving approaches, or failure to consider all cases of the                3.3.1   Question Dataset. The dataset comprises 2,000 erroneous
                  problem. Computing errors included errors in the PoT steps and                     questions, categorized into four types: expression errors, lack of
                  incorrect numerical approximations. Due to the inability to guar-                  conditions, contradictions, and unrealistic scenarios, with 500 in-
                  antee that all 16 rewriting methods in Section 3.2.1 are applicable                stances per category. For each error type, 200 seed questions are
                  to every question scenario, we decontaminated and filtered the                     sourced from GSM8K, representing a simple dif√èculty level, while
                  annotated data by removing questions that were incorrect or un-                    the remaining 300 are drawn from MATH train, reflecting a chal-
                  reasonable. After filtering, we retained only those questions that                 lenging dif√èculty level comparable to high school mathematics
                 were correct and had answers that were either correct or exhibited                  competitions, as illustrated in Figure 3.
                                                                                      ‚Ä†             ‚Ä†          ‚Ä†                                                         ‚àó             ‚àó
                  Conference‚Äô17, July 2017, Washington, DC, USA             HaoLiang , Meiyi Qiang , Yuying Li , Zefeng He, Yongzhen Guo, Zhengzhou Zhu, Wentao Zhang , and Bin Cui
                         Table 1: Error Detection and Error Type Detection in Questions: The best model for each task is highlighted in red.
                                                                                     Error Detection                                 Error Type Detection
                                            Models                            GSM8K                     MATH                      GSM8K                      MATH
                                                                         Acc      F1-Score         Acc      F1-Score        Acc      Macro-F1          Acc      Macro-F1
                                                                          closed-source Lager Language Models
                                            GPT-4o                      72.44        76.38        72.50        75.26       79.13         79.14        74.00         73.90
                                            o1-mini                     74.88        76.66        76.96        78.52       76.00         75.95        74.08         74.26
                                          o1-preview                    72.06        73.97        74.04        75.79       74.25         74.24        70.92         70.73
                                     Claude-3-5-sonnet                  76.31        78.33        75.91        78.25       74.88         74.90        70.67         70.85
                                            Gemini                      71.13        75.43        74.54        77.74       73.75         73.60        72.67         72.75
                                                                           open-sourceLagerLanguageModels
                                   Llama-3.1-8B-Instruct                59.62        46.96        64.88        58.82       56.00         55.08        56.67         55.81
                                  Llama-3.1-70B-Instruct                69.94        72.50        69.13        70.35       69.94         72.50        72.92         73.00
                                  Llama-3.3-70B-Instruct                71.37        76.42        69.71        74.01       75.38         75.24        77.83         77.90
                                   Qwen2.5-7B-Instruct                  67.75        74.02        71.33        76.13       53.00         52.35        54.33         53.64
                                Qwen2.5-Math-7B-Instruct                67.63        71.94        68.00        71.53       46.88         44.33        51.58         49.26
                                   Qwen2.5-72B-Instruct                 72.31        77.22        73.83        78.15       77.62         77.58        73.25         73.39
                               Qwen2.5-Math-72B-Instruct                68.00        74.01        68.87        73.78       67.37         67.35        65.58         65.36
                                     QwQ-32B-Preview                    57.81        40.53        55.50        34.88       67.00         66.85        64.00         63.78
                             DeepSeek-R1-Distill-Qwen-7B                62.38        59.16        65.25        63.61       65.38         65.14        65.25         64.67
                             DeepSeek-R1-Distill-Qwen-32B               72.69        76.26        71.67        73.75       74.75         74.65        74.00         73.98
                                        DeepSeek-R1                     71.25        72.46        74.50        75.94       70.37         70.21        70.75         70.50
                  3.3.2   AnswerDataset. Theanswerdatasetconsistsof2,000correct                          error type detection, and answer error type detection. Error detec-
                  questions paired with their corresponding answers, with 40% cate-                      tion can be regarded as a binary classification task, while error type
                  gorized as simple dif√èculty and 60% as challenging dif√èculty. Chal-                    detection can be viewed as a multi-class classification task.
                  lenging answers contain a higher proportion of errors compared to                         For error detection, we selected Accuracy (Acc) and F1 score
                  simple ones; overall, 30.5% of the 2000 answers are erroneous.                         as evaluation metrics. Accuracy is a traditional metric for assess-
                                                                                                         ing classification tasks, representing the proportion of correctly
                  Table2:Thecorrectnessstatisticsofdifferentdif√ècultylevels                              predicted samples out of the total number of samples. F1 score is
                  in the MathClean Answerdataset.                                                        the harmonic mean of Precision and Recall, providing a balanced
                                                                                                         measure of a model‚Äôs performance.
                                  Dataset          Error      Correct       Total                           For error type detection, we selected both accuracy and the
                                   Simple            163         637         800                         Macro-F1 score as our evaluation metrics. The Macro-F1 score
                                Challenging          447         753         1200                        is particularly appropriate for multi-class classification problems,
                                     Both            610        1390         2000                        especially in scenarios where class imbalance is evident. Specif-
                                                                                                         ically, for an m-class classification problem, the Macro-F1 score
                     For error types, incorrect answers are classified as logic, com-                    is calculated by computing the F1 score for each individual class
                  puting, or expression errors. The proportion of each error type                        and subsequently taking the average of these scores as the final
                  closely corresponds to the frequency with which the model tends                        Macro-F1 score.
                  to commit errors in its mathematical reasoning. Logic errors are                       4.1.2   Models. To comprehensively demonstrate the performance
                  the most common (52%), followed by computing errors (38%), and                         of various models on MathClean benchmark, we evaluate the fol-
                  expression errors (10%). Figure 4 illustrates this distribution, and                   lowing three categories of models:
                  Table 2 details the number of two dif√èculty answers for each error                        Closed-Source Large Language Models. Closed-Source large
                  extent and type.                                                                       language models, represented by the GPT series and the o1 series,
                                                                                                         have shownexceptional performance in mathematical reasoning
                  4 Experiments                                                                          tasks. In our experiment, we choose GPT-4o [2], o1-preview [20],
                  4.1     ExperimentalSetting                                                            o1-mini [20], Gemini [26], and Claude-3-5-sonnet.
                                                                                                            Open-Source Large Language Models. Although there re-
                  4.1.1   Evaluation Metrics. The experiment is divided into four sub-                   mains a slight performance gap between open-source models and
                  sections: question error detection, answer error detection, question                   closed-source models, many open-source large language models
                  MathClean: A Benchmark for Synthetic Mathematical Data Cleaning                                                     Conference‚Äô17, July 2017, Washington, DC, USA
                         Table 3: Error Detection and Error Type Detection in Answers: The best model for each task is highlighted in red.
                                                                                  Error Detection                                Error Type Detection
                                          Models                           GSM8K                    MATH                     GSM8K                      MATH
                                                                       Acc      F1-Score       Acc      F1-Score        Acc      Macro-F1         Acc      Macro-F1
                                                                        closed-source Lager Language Models
                                          GPT-4o                      80.75       88.02       77.25        82.97       59.51        46.93        57.49        42.11
                                          o1-mini                     76.88       84.92       76.75        80.72       56.44        46.78        56.60        46.25
                                        o1-preview                    75.38       83.57       77.33        81.19       62.58        53.73        56.15        45.17
                                    Claude-3-5-sonnet                 73.12       81.98       73.83        78.84       60.12        48.17        56.38        38.21
                                           Gemini                     78.12       85.88       77.33        81.32       60.12        46.46        59.28        46.41
                                                                         open-sourceLagerLanguageModels
                                  Llama-3.1-8B-Instruct               63.25       73.80       62.83        67.25       45.40        40.39        49.22        36.40
                                 Llama-3.1-70B-Instruct               76.62       84.93       75.67        81.01       54.60        48.93        55.93        45.87
                                 Llama-3.3-70B-Instruct               79.25       86.99       76.17        82.01       57.67        51.28        58.61        46.84
                                  Qwen2.5-7B-Instruct                 81.50       88.91       73.17        80.90       46.01        37.10        49.66        36.61
                              Qwen2.5-Math-7B-Instruct                77.88       86.14       71.00        78.30       38.04        27.38        43.85        32.26
                                 Qwen2.5-72B-Instruct                 82.37       89.23       75.08        82.06       50.92        47.85        55.26        45.22
                              Qwen2.5-Math-72B-Instruct               79.13       87.18       71.67        79.09       44.79        37.44        50.78        42.45
                                   QwQ-32B-Preview                    49.75       58.39       53.00        51.63       52.76        41.31        54.59        45.29
                            DeepSeek-R1-Distill-Qwen-7B               76.38       85.01       72.58        78.14       53.37        45.63        52.35        44.06
                            DeepSeek-R1-Distill-Qwen-32B              78.25       86.26       76.92        81.45       58.90        51.70        57.27        46.73
                                       DeepSeek-R1                    76.75       84.78       76.33        80.76       57.06        36.36        57.72        43.37
                                                                         open-sourceProcessRewardModels
                                Math-Shepherd-PRM-7B                  71.88       81.04       68.92        74.75          -            -            -           -
                                Qwen2.5-Math-PRM-7B                   76.38       84.79       75.00        79.76          -            -            -           -
                                    Skywork-PRM-7B                    54.00       61.98       58.17        54.53          -            -            -           -
                  have also achieved excellent results in the mathematical domain.                   top-p parameter to 0.95. The prompts specifically designed for this
                 WeincludedtheLlamaserieslikeLlama-3.1-8B-Instruct, Llama-3.1-                       experiment are shown in Figure 6. In cases where the generated
                 70B-Instruct and Llama-3.3-70B-Instruct [9], the Qwen series such                   text outputs exhibited formatting errors, the corresponding result
                  as Qwen2.5-7B-Instruct, Qwen2.5-Math-7B-Instruct, Qwen2.5-72B-                     wasrandomlyassignedusingtherandomseed42.
                  Instruct[34]andQwQ-32B-Preview[27],aswellastheDeepSeekse-                             All experiments were conducted on a machine running Ubuntu
                  ries like DeepSeek-R1-Distill-Qwen-7B,DeepSeek-R1-Distill-Qwen-                    22.04, equipped with 8 NVIDIA H800 GPUs, a 192-core CPU, and a
                  32BandDeepSeek-R1[14].                                                             total of 960 GB of memory.
                     Open-SourceProcessRewardModels.ProcessRewardMod-
                  els are designed to evaluate the intermediate steps of a model‚Äôs
                  reasoning process, making them suitable only for answer error                      4.2     Error Detection for Questions
                  detection tasks. Compared to ORMs, PRMs place greater emphasis                     AsshowninTable1,closed-source models achieve strong perfor-
                  on the logical coherence of the reasoning path. Inspired by the                    mance. Open-source models, such as Qwen2.5-72B-Instruct, Llama-
                  idea of training ORM as an implicit PRM [7], we treat the entire                   3.3-70B-Instruct, and the DeepSeek-R1 series, also achieve good
                  reasoning process as a single step, with the PRM evaluating scores                 performance. Notably, the DeepSeek series excels due to its strong
                  for correctness and logic of entire answer. Based on the scores ob-                LongCoTreasoningability.Whileafewstrongmodelsdemonstrate
                  tained, we set a specific threshold to determine whether the answer                impressiveperformanceonourbenchmark,theoverallperformance
                  is correct or not. The PRMs utilized in this experiment include                    of these models on the MathClean benchmark remains suboptimal.
                  Math-Shepherd-Mistral-7B-PRM [30], Skywork-PRM-7B [19], and                        Onthe one hand, most models score above 70 in question error
                  Qwen2.5-Math-PRM-7B[40].                                                           detection tasks; however, their performance drops significantly to
                                                                                                     around 50 in question error type detection tasks, indicating weak
                  4.1.3   Settings. We utilized the vLLM framework for inference,                    question error detection capabilities. This suggests that existing
                  setting the maximum token parameter to 4000. For generating                        models struggle to identify errors in questions, highlighting a sub-
                  modeloutputs, the temperature parameter was set to 0.7, and the                    stantial opportunityforimprovement,particularlyinquestionerror
                                                                                            ‚Ä†              ‚Ä†           ‚Ä†                                                             ‚àó              ‚àó
                   Conference‚Äô17, July 2017, Washington, DC, USA                  HaoLiang , Meiyi Qiang , Yuying Li , Zefeng He, Yongzhen Guo, Zhengzhou Zhu, Wentao Zhang , and Bin Cui
                                                           o1 Failed Reasoning                                                                             MathClean
                      Let‚Äôs evaluate the given math question step by step to determine its correctness.                             Question: In a convex quadrilateral ABCD, AB=8, BC=4, 
                      Given: Convex quadrilateral ABCD, Sides: AB = 8, BC = 4, CD = DA = 10, Angle: ‚à†CDA = 60¬∞, Diagonal            CD=DA=10, and ‚à†CDA=60¬∞. If the area of ABCD can be 
                      AC such that ‚à†BAC is either 30¬∞ or 45¬∞, Area of ABCD expressed as ‚àöa + b‚àöc, where a and c have no             written in the form ‚àöa+b‚àöc where a and c have no perfect 
                      perfect square factors greater than 1.                                                                        square factors (greater than 1), and the diagonal AC is such 
                      Step-by-Step Evaluation:                                                                                      that ‚à†BAC is either 30¬∞ or 45¬∞, what is a+b+c?
                      1. Triangle CDA: Given CD = DA = 10 and ‚à†CDA = 60¬∞. Using the Law of Cosines: AC¬≤ = CD¬≤ + DA¬≤ -               Detection: incorrect
                      2 ¬∑ CD ¬∑ DA ¬∑ cos(‚à†CDA) = 100 + 100 - 200 ¬∑ 0.5 = 100. Thus, AC = 10. Triangle CDA is equilateral since 
                      all sides are equal and all angles are 60¬∞.                                                                                          Explanation
                      2. Positioning Points: Place point D at the origin (0,0). Point C at (10,0). Point A at (5, 5‚àö3).             Reason for Question Error: As shown in 
                      3. Finding Point B: B must satisfy: AB = 8, BC = 4, This involves solving the intersection of two circles:    the diagram, the shape of the convex               A
                      Circle centered at A with radius 8. Circle centered at C with radius 4. Solving these equations yields        quadrilateral ABCD is uniquely fixed,                   8
                      valid coordinates for B, ensuring that ABCD is a convex quadrilateral.                                        and the side lengths of ‚àÜABC are 4, 8,         10   10      B
                               ‚à†
                      4. Angle  BAC: Given the symmetry and the calculated positions, ‚à†BAC can indeed be either 30¬∞ or              and 10. Therefore, ‚à†BAC = arc cos                          4
                      45¬∞ based on the specific location of B. This dual possibility is consistent with the construction of         0.925 ‚â† 30¬∞ or 60¬∞. Thus, the conditions  D        10     C
                      the quadrilateral.                                                                                            are contradictory.
                      5. Area Expression: The area can be calculated by summing the areas of triangles ABC and                        Reason for o1 Failure: In Step 4, the positions of  A, B, C, 
                      CDA. The form ‚àöa + b‚àöc is achievable based on the side lengths and angles provided.                             and D are determined, and ‚à†BAC can be calculated. O1 
                      Conclusion: All the given conditions are consistent and solvable. The geometric                                 assumes the condition ‚Äú‚à†BAC is either 30¬∞ or 45¬∞‚Äù holds, 
                      configurations allow for the specified angles and area expression.                                              without recognizing the contradiction with the other 
                      Answer: correct                                                                                                 conditions.
                   Figure 5: Failure case of GPT-o1 in the detection of question correctness in the MathClean benchmark, with explanation. The
                   modelfailstorecognizethecontradictioninthegivenconditions.
                   type detection. Thus, MathClean remains a challenging benchmark                              contradicts the information deduced from the others. During detec-
                   for current models.                                                                          tion, GPT-o1 mistakenly concludes that the condition contributes
                                                                                                                to solving the problem and classifies the question as ‚Äúcorrect.‚Äù In
                   4.3      Error Detection for Answers                                                         reality, the modelfailstofurtherverifythenumericalconsistencyof
                   As shown in Table 3, closed-source models continue to deliver                                different conditions, leading to an incorrect judgment. This demon-
                   strong performance. Some open-source models, such as Qwen2.5-                                stration indicates that when evaluated on the challenging Math-
                   72B-Instruct and Llama-3.3-70B-Instruct, exhibit comparable per-                             Clean benchmark, models with strong mathematical reasoning
                   formanceinanswererrorandtypedetectiontasks,highlightingthe                                   abilities, such as GPT-o1, also reveal subtle, hard-to-detect flaws in
                   potential of open-source models. Additionally, slow-thinking mod-                            their mathematical logic.
                   els like GPT-o1-previewandDeepSeek-R1excelinnoveltasks,such                                      In Appendix A, we provide additional error cases related to the
                   as error type detection, but fail to achieve SOTA performance in                             correctness and error type detection of questions and answers, in
                   error detection. We attribute this to their ability to provide human-                        order to further analyze in depth the reasons why LLM fails to
                   like reasoning; however, they occasionally suffer from overthinking                          achieve excellent performance on the MathClean benchmark.
                   in error detection tasks. Contrary to expectations, Qwen2.5-7B-                              5 Conclusion
                   Instruct outperforms Qwen2.5-Math-7B-Instruct, likely due to the                             In this paper, we introduced the MathClean benchmark as a critical
                   latter‚Äôs ineffective instruction-following. Furthermore, open-source                         tool for evaluating the overall effectiveness of math data-cleaning
                   PRMs,particularly Qwen2.5-Math-PRM-7B, perform similarly to                                  models. As the development of LLMs continues to advance, the
                   general-purpose LLMs, such as Llama-3.1-70B-Instruct, in answer                              quality of the mathematical training data has become increasingly
                   error detection, although they still lag behind Qwen2.5-7B-Instruct.                         important, particularly given the limitations of even high-quality
                   This suggests that while PRMs are effective, further improvements                            datasets. Synthetic math questions, while necessary to augment
                   are necessary.                                                                               training data, can inadvertently introduce errors that hinder model
                       Moreover,asshowninTable3,SOTAmodelslikeo1-previewand                                     performance. Our benchmark addresses this challenge by offering
                   DeepSeek-R1performpoorly(lessthan80pointsinerrordetection                                    a comprehensive evaluation of math data cleaning techniques, in-
                   andless than 70 points in error type detection) on our MathClean                             cluding both correct and erroneous questions and answers, along
                   benchmark, underscoring MathClean is very challenging.                                       with detailed error-type annotations to guide future improvements.
                   4.4      CaseStudy                                                                           ThroughrigoroustestingwithSOTAmodels,wedemonstratedthat
                                                                                                                evenadvancedmodelslikeDeepSeek-R1strugglewithcleaningsyn-
                   In Sections 4.2 and 4.3, we found that MathClean poses a significant                         thetic math data, thus underscoring the significance of MathClean
                   challenge to models. To further analyze this, we examine a failure                           in identifying and addressing errors. Ultimately, MathClean serves
                   case of correctness detection by GPT-o1 on the question dataset as                           as a valuable resource for improving the quality of mathematical
                   an representative example.                                                                   datasets and enhancing the robustness of LLMs, offering important
                       AsshowninFigure5,this question in MathClean is incorrect                                 insights for future research in data-centric AI development.
                   becauseitincorporatesmultiplegeometricconditions,oneofwhich
                   MathClean: A Benchmark for Synthetic Mathematical Data Cleaning                                                                Conference‚Äô17, July 2017, Washington, DC, USA
                   References                                                                                  [24] ZhihongShao,PeiyiWang,QihaoZhu,RunxinXu,JunxiaoSong,XiaoBi,Haowei
                    [1] Marah Abdin, Jyoti Aneja, Harkirat Behl, S√©bastien Bubeck, Ronen Eldan, Suriya              Zhang, Mingchuan Zhang, YK Li, Y Wu, et al. 2024. Deepseekmath: Pushing
                        Gunasekar, Michael Harrison, Russell J Hewett, Mojan Javaheripi, Piero Kauff-               the limits of mathematical reasoning in open language models. arXiv preprint
                        mann,etal. 2024. Phi-4 technical report. arXiv preprint arXiv:2412.08905 (2024).            arXiv:2402.03300 (2024).
                    [2] JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAhmad,IlgeAkkaya,Floren-                    [25] MingyangSong,ZhaochenSu,XiaoyeQu,JiaweiZhou,andYuCheng.2025.PRM-
                        cia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal                    Bench: A Fine-grained and Challenging Benchmark for Process-Level Reward
                        Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774               Models. arXiv preprint arXiv:2501.03124 (2025).
                        (2023).                                                                                [26] Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui
                    [3] Tianyi Bai, Hao Liang, Binwang Wan, Ling Yang, Bozhou Li, Yifan Wang, Bin                   Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, Katie Millican,
                        Cui, Conghui He, Binhang Yuan, and Wentao Zhang. 2024. A Survey of Multi-                   et al. 2023. Gemini: a family of highly capable multimodal models. arXiv preprint
                        modalLargeLanguageModelfromAData-centricPerspective. arXiv preprint                         arXiv:2312.11805 (2023).
                        arXiv:2405.16640 (2024).                                                               [27] Qwen Team. 2024. QwQ: Reflect Deeply on the Boundaries of the Unknown.
                    [4] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,                      https://qwenlm.github.io/blog/qwq-32b-preview/
                        Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda             [28] Shubham Toshniwal, Wei Du, Ivan Moshkov, Branislav Kisacanin, Alexan
                        Askell, et al. 2020. Language models are few-shot learners. Advances in neural              Ayrapetyan, and Igor Gitman. 2024. Openmathinstruct-2: Accelerating ai for
                        information processing systems 33 (2020), 1877‚Äì1901.                                        mathwithmassiveopen-source instruction data. arXiv preprint arXiv:2410.01560
                    [5] Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav,                  (2024).
                        ZhengTang,Vijay Srinivasan, Tianyi Zhou, Heng Huang, et al. 2023. Alpagasus:           [29] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
                        Training a better alpaca with fewer data. arXiv preprint arXiv:2307.08701 (2023).           Lachaux, Timoth√©e Lacroix, Baptiste Rozi√®re, Naman Goyal, Eric Hambro, Faisal
                    [6] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun,                      Azhar, et al. 2023. Llama: Open and ef√ècient foundation language models. arXiv
                        Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano,             preprint arXiv:2302.13971 (2023).
                        et al. 2021. Training verifiers to solve math word problems. arXiv preprint            [30] Peiyi Wang, Lei Li, Zhihong Shao, Runxin Xu, Damai Dai, Yifei Li, Deli Chen, Yu
                        arXiv:2110.14168 (2021).                                                                    Wu,andZhifangSui.2024. Math-shepherd:Verifyandreinforcellmsstep-by-step
                    [7] Ganqu Cui, Lifan Yuan, Zefan Wang, Hanbin Wang, Wendi Li, Bingxiang He,                     without human annotations. In Proceedings of the 62nd Annual Meeting of the
                        YuchenFan,TianyuYu,QixinXu,WeizeChen,etal.2025. ProcessReinforcement                        Association for Computational Linguistics (Volume 1: Long Papers). 9426‚Äì9439.
                        through Implicit Rewards. arXiv preprint arXiv:2502.01456 (2025).                      [31] Wei Xiong, Hanning Zhang, Nan Jiang, and Tong Zhang. 2024. An Implementa-
                    [8] Qianlong Du, Chengqing Zong, and Jiajun Zhang. 2023. Mods: Model-oriented                   tion of Generative PRM. https://github.com/RLHFlow/RLHF-Reward-Modeling.
                        data selection for instruction tuning. arXiv preprint arXiv:2311.15653 (2023).              https://github.com/RLHFlow/RLHF-Reward-Modeling
                    [9] AbhimanyuDubey,AbhinavJauhri, Abhinav Pandey, Abhishek Kadian, Ahmad                   [32] Liang Xu, Hang Xue, Lei Zhu, and Kangkang Zhao. 2024. SuperCLUE-Math6:
                        Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan,                 Graded Multi-Step Math Reasoning Benchmark for LLMs in Chinese. arXiv
                        et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783 (2024).            preprint arXiv:2401.11819 (2024).
                   [10] Bofei Gao, Zefan Cai, Runxin Xu, Peiyi Wang, Ce Zheng, Runji Lin, Keming Lu,           [33] Yang Xu, Yongqiang Yao, Yufan Huang, Mengnan Qi, Maoquan Wang, Bin Gu,
                        Junyang Lin, Chang Zhou, Wen Xiao, et al. 2024. Llm critics help catch bugs                 and Neel Sundaresan. 2023. Rethinking the Instruction Quality: LIFT is What
                        in mathematics: Towards a better mathematical verifier with natural language                YouNeed. arXiv:2312.11508 [cs.CL]
                        feedback. CoRR (2024).                                                                 [34] An Yang, Beichen Zhang, Binyuan Hui, Bofei Gao, Bowen Yu, Chengpeng Li,
                   [11] Bofei Gao, Feifan Song, Zhe Yang, Zefan Cai, Yibo Miao, Qingxiu Dong, Lei Li,               Dayiheng Liu, Jianhong Tu, Jingren Zhou, Junyang Lin, et al. 2024. Qwen2. 5-
                        Chenghao Ma, Liang Chen, Runxin Xu, et al. 2024. Omni-math: A universal                     mathtechnical report: Toward mathematical expert model via self-improvement.
                        olympiad level mathematic benchmark for large language models. arXiv preprint               arXiv preprint arXiv:2409.12122 (2024).
                        arXiv:2410.07985 (2024).                                                               [35] Huanjin Yao, Jiaxing Huang, Wenhao Wu, Jingyi Zhang, Yibo Wang, Shunyu
                   [12] Elliot Glazer, Ege Erdil, Tamay Besiroglu, Diego Chicharro, Evan Chen, Alex                 Liu, Yingjie Wang, Yuxin Song, Haocheng Feng, Li Shen, et al. 2024. Mulberry:
                        Gunning, Caroline Falkman Olsson, Jean-Stanislas Denain, Anson Ho, Emily                    Empowering mllm with o1-like reasoning and reflection via collective monte
                        de Oliveira Santos, et al. 2024. Frontiermath: A benchmark for evaluating ad-               carlo tree search. arXiv preprint arXiv:2412.18319 (2024).
                        vanced mathematical reasoning in ai. arXiv preprint arXiv:2411.04872 (2024).           [36] Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang,
                   [13] Jiawei Gu, Xuhui Jiang, Zhichao Shi, Hexiang Tan, Xuehao Zhai, Chengjin Xu,                 James T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023. Metamath:
                        Wei Li, Yinghan Shen, Shengjie Ma, Honghao Liu, et al. 2024. A Survey on                    Bootstrap your own mathematical questions for large language models. arXiv
                        LLM-as-a-Judge. arXiv preprint arXiv:2411.15594 (2024).                                     preprint arXiv:2309.12284 (2023).
                   [14] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin                 [37] DiZhang,JianboWu,JingdiLei,TongChe,JiatongLi,TongXie,XiaoshuiHuang,
                        Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. 2025. Deepseek-r1:                   Shufei Zhang, Marco Pavone, Yuqiang Li, et al. 2024. Llama-berry: Pairwise
                        Incentivizing reasoning capability in llms via reinforcement learning. arXiv                optimization for o1-like olympiad-level mathematical reasoning. arXiv preprint
                        preprint arXiv:2501.12948 (2025).                                                           arXiv:2410.02884 (2024).
                   [15] Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2020. DEBERTA:              [38] Dan Zhang, Sining Zhoubian, Ziniu Hu, Yisong Yue, Yuxiao Dong, and Jie Tang.
                        DECODING-ENHANCEDBERTWITHDISENTANGLEDATTENTION.InInter-                                     2024. Rest-mcts*: Llm self-training via process reward guided tree search. arXiv
                        national Conference on Learning Representations.                                            preprint arXiv:2406.03816 (2024).
                   [16] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric          [39] LunjunZhang,ArianHosseini,HritikBansal,MehranKazemi,AviralKumar,and
                        Tang, Dawn Song, and Jacob Steinhardt. 2021. Measuring mathematical problem                 Rishabh Agarwal. 2024. Generative verifiers: Reward modeling as next-token
                        solving with the math dataset. arXiv preprint arXiv:2103.03874 (2021).                      prediction. arXiv preprint arXiv:2408.15240 (2024).
                   [17] Yiming Huang, Xiao Liu, Yeyun Gong, Zhibin Gou, Yelong Shen, Nan Duan, and             [40] Zhenru Zhang, Chujie Zheng, Yangzhen Wu, Beichen Zhang, Runji Lin, Bowen
                        WeizhuChen.2024. Key-point-driven data synthesis with its enhancement on                    Yu,DayihengLiu,JingrenZhou,andJunyangLin.2025. Thelessonsofdeveloping
                        mathematical reasoning. arXiv preprint arXiv:2403.02333 (2024).                             processrewardmodelsinmathematicalreasoning.arXivpreprintarXiv:2501.07301
                   [18] Hongwei Liu, Zilong Zheng, Yuxuan Qiao, Haodong Duan, Zhiwei Fei, Fengzhe                   (2025).
                        Zhou, Wenwei Zhang, Songyang Zhang, Dahua Lin, and Kai Chen. 2024. Math-               [41] Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu,
                        Bench: Evaluating the Theory and Application Proficiency of LLMs with a Hier-               Dayiheng Liu, Jingren Zhou, and Junyang Lin. 2024. Processbench: Identifying
                        archical Mathematics Benchmark. arXiv preprint arXiv:2405.12209 (2024).                     processerrorsinmathematicalreasoning. arXivpreprintarXiv:2412.06559 (2024).
                   [19] Skywork o1 Team. 2024. Skywork-o1 Open Series. https://huggingface.co/                 [42] Kun Zhou, Beichen Zhang, Jiapeng Wang, Zhipeng Chen, Wayne Xin Zhao,
                        Skywork. https://huggingface.co/Skywork                                                     Jing Sha, Zhichao Sheng, Shijin Wang, and Ji-Rong Wen. 2024. JiuZhang3. 0:
                   [20] OpenAI. 2023. ChatGPT. https://openai.com/blog/chatgpt                                      Ef√èciently Improving Mathematical Reasoning by Training Small Data Synthesis
                   [21] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela                Models. arXiv preprint arXiv:2405.14365 (2024).
                        Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022.         [43] Zihao Zhou, Shudong Liu, Maizhen Ning, Wei Liu, Jindong Wang, Derek F Wong,
                        Training language models to follow instructions with human feedback. Advances               Xiaowei Huang, Qiufeng Wang, and Kaizhu Huang. 2024. Is your model really a
                        in neural information processing systems 35 (2022), 27730‚Äì27744.                            goodmathreasoner?evaluating mathematical reasoning with checklist. arXiv
                   [22] ZhentingQi,MingyuanMa,JiahangXu,LiLynaZhang,FanYang,andMaoYang.                             preprint arXiv:2407.08733 (2024).
                        2024. Mutual reasoning makes smaller llms stronger problem-solvers. arXiv
                        preprint arXiv:2408.06195 (2024).
                   [23] AlecRadford,JeffreyWu,RewonChild,DavidLuan,DarioAmodei,IlyaSutskever,
                        et al. 2019. Language models are unsupervised multitask learners. OpenAI blog
                        1, 8 (2019), 9.
                                                                                         ‚Ä†              ‚Ä†          ‚Ä†                                                           ‚àó             ‚àó
                   Conference‚Äô17, July 2017, Washington, DC, USA               HaoLiang , Meiyi Qiang , Yuying Li , Zefeng He, Yongzhen Guo, Zhengzhou Zhu, Wentao Zhang , and Bin Cui
                   A ExampleAppendix
                   In this section, we provide several examples in which GPT-o1 fails in either correctness or error type detection on the MathClean benchmark,
                   accompanied by corresponding explanations, in order to more fully and convincingly demonstrate the significant role of the MathClean
                   benchmarkinimprovingthemathematical reasoning capabilities of current models.
                                                                                           MathClean
                     Question:Find the integer Ì†µ„åµ,  ‚àí180 ‚â§ Ì†µ„åµ ‚â§ 180, such that sin	Ì†µ„åµ¬∞ = sin	724¬∞.
                     Answer:To find the integer Ì†µ„åµ	such that sin	Ì†µ„åµ¬∞ = sin	724¬∞ and ‚àí180 ‚â§ Ì†µ„åµ ‚â§ 180, we need to use the periodicity and symmetry properties of the sine function. 
                     The sine function is periodic with a period of 360¬∞, meaning  sinÌ†µ„åµ = sin(	Ì†µ„åµ + 360¬∞Ì†µ„åµ)  for any integer Ì†µ„åµ. Additionally, sinÌ†µ„åµ = sin(180¬∞ ‚àí Ì†µ„åµ) . First, we reduce 
                     724¬∞	to an angle between 0¬∞	and 360¬∞: 724¬∞	mod	360¬∞ = 724¬∞‚àí2√ó360¬∞ = 724¬∞‚àí720¬∞ = 4¬∞. So, sin724¬∞ = sin4¬∞.Now, we need to find an angle	Ì†µ„åµ such 
                     that	sin	Ì†µ„åµ¬∞ = sin	724¬∞	and ‚àí180 ‚â§ Ì†µ„åµ ‚â§ 180. The sine function is equal for angles that are coterminal or supplementary. Therefore, the possible values for	Ì†µ„åµ 
                                                                                                                                                                                  (
                     are: Ì†µ„åµ = 4¬∞ since	sin4¬∞ = sin4¬∞ , Ì†µ„åµ	 = 180¬∞ ‚àí 4¬∞ = 176¬∞ since	sin4¬∞ = sin176¬∞ 	, Ì†µ„åµ	 = ‚àí4¬∞ since	sin4¬∞ = sin(‚àí4¬∞) , Ì†µ„åµ = ‚àí180¬∞ ‚àí 4¬∞ = 184¬∞	 since
                                            )
                      sin4¬∞ = sin(‚àí184¬∞) , but 184¬∞ is not in the range ‚àí180 ‚â§ Ì†µ„åµ ‚â§ 180, so we discard it. Thus, the possible values of	Ì†µ„åµ within the range are 4¬∞, 176¬∞, and ‚àí4¬∞. 
                     Since we are asked to find the integer Ì†µ„åµ , the possible values are 4 , 176 , and -4. However, the problem does not specify which one to choose, so we can choose 
                     any one of them. For simplicity, we choose 4 . So the integer Ì†µ„åµ	is 4.
                     Correctness Detection: incorrect
                                                               Failed Reasoning                                                                            Explanation
                     To evaluate the given answer, let‚Äôs break it down step by step: 1. The given solution correctly uses the periodicity     Reason for Answer Error: The first error 
                     and symmetry properties of the sine function. It reduces 724¬∞	to an angle between 0¬∞	and 360¬∞	, which is 4¬∞.             arises from the incorrect assumption 
                     2. The solution then applies the symmetry property of the sine function, sin Ì†µ„åµ = sin	(180¬∞ ‚àí Ì†µ„åµ), to find possible      of sin4¬∞ = sin(‚àí4¬∞). The second error 
                                                                                                                           (
                     values of Ì†µ„åµ such sin	Ì†µ„åµ¬∞ = sin	4¬∞ and ‚àí180 ‚â§ Ì†µ„åµ ‚â§ 180	. 3. The possible values of	Ì†µ„åµ	found are: Ì†µ„åµ = 4¬∞ since sin4¬∞ =   stems from overlooking all aspects of the 
                           )
                     sin4¬∞ , Ì†µ„åµ	 = 180¬∞ ‚àí 4¬∞ = 176¬∞ since	sin4¬∞ = sin176¬∞ 	, Ì†µ„åµ	 = ‚àí4¬∞ since	sin4¬∞ = sin ‚àí4¬∞ .	4. The solution                problem, as only one valid scenario was 
                     correctly discards ‚àí184¬∞	because it‚Äôs outside the specified range of ‚àí180 ‚â§ Ì†µ„åµ ‚â§ 180. 5.The solution states that         considered.
                     there are three possible values of  n  within the given range: 4¬∞, 176¬∞, and ‚àí4¬∞, which correspond to the integers       Reason for Failure: During model 
                     4, 176, and -4. 6. The solution chooses the value of Ì†µ„åµ to be 4 for simplicity, stating that the problem does not        inference, the error in the sine function 
                     specify which one to choose. The final answer provided in the solution is indeed correct because it follows the          formula was not identified, and the 
                     steps of using the periodicity and symmetry properties of the sine function, and it also correctly selects a value       incorrect approach of selecting one 
                     within the given range.                                                                                                  among multiple possibilities as the final 
                     Answer: Correct.                                                                                                         answer was accepted.
                                                            Failed Reasoning                                                                          MathClean
                      To identify the type of error in the given answer, let's go through the steps and code provided. 1.         Question: What is the smallest prime factor of the 
                      Step 1: Identify the first three prime numbers. The code correctly identifies the first three prime         number obtained by adding 1821 to the product of 
                      numbers as 2, 3, and 5. 2. Step 2: Calculate the product of these prime numbers. The code uses              the first three prime numbers?
                      the sp.prod() function from the sympy library to calculate the product of the prime numbers,                Answer:To find the smallest prime factor of the 
                      which is correct. 3. Step 3: Add 1821 to the product. The code adds 1821 to the product correctly.          number obtained by adding 1821 to the product of 
                      4. Step 4: Find the smallest prime factor of the resulting number. The code uses the                        the first three prime numbers, we can break down 
                      sp.primefactors() function to find all prime factors of the resulting number and then selects the           the problem into the following steps: 1. Identify the 
                      smallest one. However, let's analyze the code and result: The result obtained by adding 1821 to             first three prime numbers, which are 2, 3, and 5. 2. 
                      the product of the first three prime numbers is 1836. The prime factors of 1836 are 2, 2, 3, 3, 3,          Calculate the product of these prime numbers. 3. 
                      and 17. Among these, the smallest prime factor is indeed 2. But the smallest prime factor should            Add 1821 to the product obtained in step 2. 4. Find 
                      be the smallest prime factor of the resulting number, not necessarily the smallest prime number             the smallest prime factor of the resulting number.
                      among the factors. In this case, the smallest prime factor of 1836 is 2. However, this answer is            Let's implement this step-by-step in Python using the 
                      incorrect because it does not give the correct result.                                                      sympy library.
                      Error Analysis: Upon further examination, let's consider an alternative approach. When adding                 import sympy as sp
                      1821 to the product of 2, 3, and 5 (which is 30), we get 1851. The prime factors of 1851 are 3, 617.          Step 1: Identify the first three prime numbers
                      In this case, the smallest prime factor of the resulting number is actually 3. Therefore, the                 prime_numbers = [2, 3, 5]
                      smallest prime factor of the number obtained by adding 1821 to the product of the first three                 Step 2: Calculate the product of these prime numbers
                      prime numbers is 3. This shows that the answer provided is incorrect.                                         product_of_primes = sp.prod(prime_numbers)
                      Error Type: Based on the analysis, the error in the given answer is a logic error. The logic of the           Step 3: Add 1821 to the product
                      steps and the interpretation of the problem were incorrect.                                                   result = product_of_primes + 1821
                                                                                                                                    Step 4: Find the smallest prime factor of the resulting 
                                                                Explanation                                                         number
                                                                                                                                    smallest_prime_factor = sp.primefactors(result)[0]
                      Reason for Answer Error: The error in the answer arises from a computational issue when                       print(smallest_prime_factor)
                      calling the PoT program. The expected output should be 3, but the program returned 2. The                     Output 2
                      mathematical method and program design are both correct. According to the definition in the                 The smallest prime factor of the number obtained by 
                      paper, this is classified as a competing error.                                                             adding 1821 to the product of the first three prime 
                      Reason for Failure: Although the model provided the correct answer, no specific error steps                 numbers is 2.
                      were identified during the error analysis. Therefore, it was broadly categorized as a logic error.          Error Type Detection: computing error
                     MathClean: A Benchmark for Synthetic Mathematical Data Cleaning                                                                             Conference‚Äô17, July 2017, Washington, DC, USA
                                              Failed Reasoning                                                                                MathClean
                          To evaluate the given answer, let‚Äôs break down the solution            Question:Let S be a square of side length 1. Two points are chosen independently at random on the sides 
                          step by step. 1. The given solution is mathematically correct up       of S. If the points are on adjacent sides, the probability that the straight-line distance between the points 
                                                                                                            !   &'(#
                          to the point where it calculates the probability of the distance       is at least  is     , where a, b, and c are positive integers with  gcd(Ì†µ„åµ,Ì†µ„åµ,Ì†µ„åµ)	= 	1	. What is  a + b + c ?
                                                                                                            "    )
                          between two randomly chosen points on adjacent sides of a              Answer:To solve the problem, we need to calculate the probability that the straight-line distance 
                                                     !                                                                                                                                   !
                          unit square being at least   . 2. The solution calculates the area     between two randomly chosen points on adjacent sides of a unit square is at least  . Let's denote the 
                                                     "                                #                                                                                                  "
                          outside the circle within the unit square correctly as 1 ‚àí $ . 3.      vertices of the square S as A, B, C and D in clockwise order, with AB, BC, CD and DA being the sides of the 
                          The solution then calculates the probability as the ratio of the       square. 1. Define the positions of the points: Let P be a point on side AB with position x (where 0 ‚â§ Ì†µ„åµ ‚â§ 1). 
                          area outside the circle to the area of the square, which is also       Let Q be a point on side BC with position y (where 0 ‚â§ Ì†µ„åµ ‚â§ 1	). 2. Calculate the distance between P and Q: 
                          correct. 4. The solution correctly expresses the probability in        The coordinates of P are  Ì†µ„åµ,0 . The coordinates of Q are  1,Ì†µ„åµ . The distance d between P and Q is given by: 
                                          !"#$                                                   Ì†µ„åµ =   1‚àíÌ†µ„åµ * +Ì†µ„åµ*. 3. Set up the inequality for the distance: We need Ì†µ„åµ ‚â• ! .     1‚àíÌ†µ„åµ * +Ì†µ„åµ* ‚â• !, Squaring 
                          the given form    %   , where  a = 4 ,  b = 1 , and  c = 4 . 5. Finally,                   *    *   !                                                 "                   "
                          the solution calculates  a + b + c  correctly as  4 + 1 + 4 = 9 .      both sides:  1‚àíÌ†µ„åµ    +Ì†µ„åµ ‚â•#. 4. Analyze the inequality: This inequality represents the region in the unit 
                                                                                                 square 0 ‚â§ Ì†µ„åµ ‚â§ 1	and 0 ‚â§ Ì†µ„åµ ‚â§ 1	where the distance between P and Q is at least ! . 5. Visualize the region: 
                          Therefore, the answer is: Correct.                                                                                                                        "
                                                                                                                        *    *   !                                                  !
                                                                                                 The inequality  1‚àíÌ†µ„åµ     +Ì†µ„åµ ‚â•#	describes a circle with center  1,0 and radius  	. We need to find the area 
                                                                                                                                                                                    "
                                                  Explanation                                    of the region within the unit square that lies outside this circle. 6. Calculate the area of the circle and the 
                         Reason for AnswerError: The answer overlooked the restriction           square: The area of the circle is: Area of circle = Ì†µ„åµ ! & = #	. The area of the unit square is: Area of square 
                                                                                                                                                       "      $
                         ‚Äúwithin the unit square.‚Äù Under this constraint, the correct area       = 1 . 7. Calculate the area outside the circle: The area outside the circle within the unit square is: Area 
                         should correspond to a quarter of a circle, and the result at this      outside circle = 1 ‚àí # . 8. Calculate the probability: The probability that the distance between P and Q is 
                                              #                                                           !            $                                                                             #
                         step should be 1 ‚àí!%  .                                                 at least "	is the ratio of the area outside the circle to the area of the square: Probability = 1 ‚àí $ . 9. 
                         Reason for Failure: The model only verified the correctness of                                                                          !"#$                    #      !"#$
                         the problem-solving approach, overlooking the logical errors in         Express the probability in the given form: The given form is  %  . Comparing 1 ‚àí $ with  %  , we get: a 
                                                                                                 = 4, b = 1, c = 4 . 10. Calculate a + b + c : a + b + c = 4 + 1 + 4 = 9 . Thus, the final answer is: 9 .
                         the specific steps and failing to validate the computed results.        Correctness Detection: incorrect
                                                          Failed Reasoning                                                                                       MathClean
                         To determine the type of error in the given answer, let's evaluate the math steps                      Question:A 10-meter ladder is leaning against a vertical wall. If the 
                         and Python code. Step 1: Initial Position. The initial height is 8 meters, and the                     ladder reaches 8 meters up the wall, how far is its base from the wall? 
                         ladder length is 10 meters. Using the Pythagorean theorem, we can calculate the                        Additionally, if the ladder slips down 1 meter, how far will the base 
                                                        !            !             !       !     !     !        !               move away from the wall?
                         initial base distance: base + height = ladder , base 	+ 8  = 10 	, base 	+ 64 = 
                         100, base!	= 36, base=      36 = 6	meters. This step is correct. Step 2: After slipping.               Answer:To solve the problem, we need to use the Pythagorean 
                         The ladder slips down 1 meter, so the new height is 7 meters. Using the                                theorem and some basic geometry. Let‚Äòs break it down step-by-step. 1. 
                         Pythagorean theorem again: base!	+ 7! = 10!	, base!	+ 49 = 100, base!	= 51, base =                     Initial Position: The ladder is 10 meters long. The ladder reaches 8 
                           51	 meters. However, this calculation is incorrect. The correct calculation should be:               meters up the wall. We need to find the distance of the base of the 
                              !     !      !       !                   !                                                        ladder from the wall. Using the Pythagorean theorem: base! +
                         base 	+ 7  = 10 	, base 	+ 49 = 100, base 	= 51, base =         51	 approx 7.14142842854285.           height! = ladder!, base!	+ 8! = 10!	, base!	+ 64 = 100, base!	= 36, 
                         This calculation is correct, but the final answer should be rounded to two decimal                     base= 36=6. After slipping: The ladder slips down 1 meter, so the 
                         places. The Python code is correct in terms of logic, but it should round the final 
                         answer to two decimal         import math                                                              new height is 7 meters. We need to find the new distance of the base 
                         places.Given the              initial_height = 8                                                       of the ladder from the wall. Using the Pythagorean theorem again: 
                                                       ladder_length = 10                                                            !     !     !        !                  !
                         calculation error in the      initial_base = math.sqrt(ladder_length**2 - initial_height**2)           base 	+ 7  = 10 	, base 	+ 49 = 100, base 	= 51, base =         51	 meters. The 
                          original answer, the         new_height = initial_height - 1                                          distance the base has moved is the difference between the new base 
                         type of error is:             new_base = math.sqrt(ladder_length**2 - new_height**2)                   and the original base: distance moved =           51	‚àí6. Now let's use 
                         computing error:              distance_moved = round(new_base - initial_base, 2)                       Python to compute these values.
                         Calculation errors,           print((initial_base, new_base, distance_moved))                                   import math
                         including mistakes in program steps, numerical approximation issues, etc. However,                              initial_height = 8
                         the answer is incorrect due to a small calculation error. If you round the answer to                            ladder_length = 10
                         two decimal places, the correct answer is approximately 1.14 meters.                                            initial_base = math.sqrt(ladder_length**2 - initial_height**2)
                                                                                                                                         new_height = initial_height - 1
                                                                                                                                         new_base = math.sqrt(ladder_length**2 - new_height**2)
                                                               Explanation                                                               distance_moved = new_base - initial_base
                         Reason for AnswerError: The solution process is entirely correct, but there is an                               print(((initial_base, new_base, distance_moved)))
                         expression error in the answer. The correct result should be 7.14, but an extra step                   The initial distance of the base of the ladder from the wall is 6 meters. 
                         was taken, leading to the incorrect answer of 1.14.                                                    After the ladder slips down 1 meter, the new distance of the base 
                         Reason for Failure: The model identified the error and obtained the correct                            from the wall is approximately 7.14 meters. Therefore, the base of the 
                         answer, but failed to realize that the error was caused by a misinterpretation of                      ladder moves an additional distance of approximately 1.14 meters. So, 
                         the language expression. It mistakenly attributed the issue to a computing error                       the final answer is: 1.14142842854285 meters.
                         in the PoT steps, leading to an incorrect classification of the error type.                            Error Type Detection: expression error
                     B PromptAppendix
                     This section provides a detailed list of all the prompts mentioned in this paper, including those for data preparation, data synthesis, and
                     the experimental section. All the prompts were carefully designed and iteratively refined and validated during the experiments, ultimately
                     yielding excellent results that can serve as a valuable reference for researchers.
                                                                                      ‚Ä†             ‚Ä†          ‚Ä†                                                         ‚àó             ‚àó
                  Conference‚Äô17, July 2017, Washington, DC, USA             HaoLiang , Meiyi Qiang , Yuying Li , Zefeng He, Yongzhen Guo, Zhengzhou Zhu, Wentao Zhang , and Bin Cui
                              Promptof Experiment
                        Question Correctness                                                      Question Type
                        SystemPrompt:You are an intelligent chatbot designed for                  SystemPrompt:You are an intelligent chatbot designed for evaluating 
                        evaluating math questions.                                                math questions. 
                        FormattedPrompt:I want you to evaluate the following math                 FormattedPrompt: I want you to evaluate the following math 
                        question:                                                                 question:
                        Question: {question}                                                      Question: {question}
                        Please determine if the question is correct or not. Answer Step           You need to determine the type of error in the question. The question 
                        By Step, and finally answer 'Correct' or 'Incorrect‚Äô.                     is incorrect, and your task is to classify the type of error. 
                        Answer Correctness                                                        Answer Type
                        SystemPrompt:You are an intelligent chatbot designed for                  SystemPrompt:You are an intelligent chatbot designed for evaluating 
                        evaluating math questions and answers.                                    math questions and answers. 
                        FormattedPrompt:I want you to evaluate the following math                 FormattedPrompt:I want you to evaluate the following math 
                        question and answer:                                                      question and answer:
                        Question: {question}                                                      Question: {question}
                        Answer: {answer}                                                          Answer: {answer}
                        Please determine if the answer is correct or not. Answer Step             You need to determine the type of error in the answer. The answer is 
                        By Step, and finally answer 'Correct' or 'Incorrect‚Äô.                     incorrect, and your task is to classify the type of error.
                           Figure 6: The prompt for the experimental design of question and answer correctness and error type detection.
                              Promptof Error Question Construction                                                                                   10 different types
                       Expression Error                                                             the student score data. Please answer how many students scored in 
                       Type: The problem should intentionally include ambiguous                     level B. ‚Äù 
                       pronouns or expressions, making it challenging to interpret and              Type: The problem should intentionally omit key conditions or details 
                       solve due to multiple possibilities.                                         necessary for solving, making the problem unanswerable.  
                       Example: ‚ÄúA rope is cut into two pieces, one of which is twice as            Example: ‚ÄúA rectangle's length-to-width ratio is 2:1. What is its area?‚Äù        
                       long as the other. Someone took one piece, and the remaining 
                       length is one-third of the original length. What was the original            Contradictions
                       length of the rope?‚Äù                                                         Type: The problem should deliberately include contradictory 
                       Type: The problem should deliberately include grammatical errors  conditions, making the information provided conflict with each other, 
                       that render the question incoherent, unreadable, or even                     and therefore unsolvable or leading to incorrect conclusions.   
                       nonsensical.                                                                 Example: ‚ÄúA rectangle's length is 10 meters, and its width is 5 meters. 
                       Example: ‚ÄúA apple tree hang on som apple, red an green kinds got  The perimeter of the rectangle is 50 meters. What is the area of the 
                       10 some. Take few, how mant tree left now?‚Äù                                  rectangle?‚Äù     
                       Type: The problem should deliberately include unnecessary or                 Type: The problem should intentionally contain that the solution 
                       irrelevant details, making the problem appear more complicated                 z
                                                                                                    given by the problem does not exist. 
                       without affecting its solution.                                              Example: ‚ÄúA square has a side length of 5 cm, but its perimeter is 30 
                       Example: ‚ÄúA car travels at 60 km/h from point A to point B, taking           cm. What is the area of the square?‚Äù   
                       2 hours. The car is red, with the license plate ABC123, driven by a 
                       35-year-old male. What is the distance from A to B?‚Äù                         Unrealistic
                       Type: The problem should intentionally misuse technical terms,               Type: The problem should intentionally include flawed conditions, 
                       jargon, or concepts, causing the problem to be incorrect.                    leading to a result that is a non-integer, even though the real-world 
                       Example: ‚ÄúA square has a radius of 10 cm. What is the perimeter              context makes non-integer results impossible.    
                       of the square?‚Äù                                                              Example: ‚ÄúA train has 10 carriages, and each carriage can hold an 
                                                                                                    average of 32.5 passengers. How many passengers are on the train?‚Äù     
                       Lack of Conditions                                                           Type: The problem should deliberately violate common sense or 
                       Type: The problem must rely on charts or diagrams to understand              natural laws, resulting in an unrealistic or meaningless scenario.   
                       and solve, but these essential visuals should be intentionally               Example: ‚ÄúA car travels at 120 km/h from Earth, heading directly 
                       omitted, making the problem unsolvable.                                      toward the Moon (average distance: 380,000 km). The car must 
                       Example: ‚ÄúA school held a math competition, and the scores were              refuel every 10 km, taking 5 minutes each time. How long will it take 
                       categorized into different levels (e.g., A, B, C, D). Below is part of       the car to reach the Moon?‚Äù    
                                     Figure 7: The prompt for expanding error types during the construction of the question dataset.
                  MathClean: A Benchmark for Synthetic Mathematical Data Cleaning                                                     Conference‚Äô17, July 2017, Washington, DC, USA
                              Promptof Question Extension Rewriting                                                                          16 different methods
                      If the original question is: ‚ÄúJames writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year?‚Äù. 
                      There are the following ways to rewrite and expand the question.
                      Method1: Change specific numbers, fractions, or percentages.               three other friends, he writes 5 pages weekly. How many pages does 
                      Example: ‚ÄúJames writes a 3-page letter twice a week to two                 he write in a year?‚Äù 
                      different friends. Each week, he increases each letter by 50% in           Method10: Establish conditional looping or recursion.
                      pages. How many pages does he write in a month?‚Äù                           Example: ‚ÄúJames writes 3 pages weekly to two friends. If he receives 
                      Method2: Introduce algebra and variables.                                  a reply, he writes an extra page the following week. Assuming he 
                      Example: ‚ÄúJames writes x pages to y friends per week, with a               receives 8 replies in a year, how many pages does he write in total?‚Äù  
                      frequency of z times per week. How many pages does he write in             Method11: Set a goal or progress requirement.
                      w weeks?‚Äù                                                                  Example: ‚ÄúJames aims to write 200 pages in six months. With a 
                      Method3: Add time variation.                                               current frequency of two 3-page letters per week, how many extra 
                      Example: ‚ÄúOn top of his weekly letter-writing, James writes an             pages should he write each week to reach his goal?‚Äù  
                      additional 5 pages for each holiday. Considering there are 12              Method12: Include conditions with multiple outcomes.
                      holidays in a year, how many pages does he write in a year?‚Äù               Example: ‚ÄúJames writes 3 pages twice a week to his friend. If he gets 
                      Method4: Introduce accumulation or incremental/decremental                 a reply, he writes one additional letter; if no reply, he writes one less. 
                      conditions.                                                                Assuming he receives 20 replies in a year, how many pages does he 
                      Example: ‚ÄúAt the beginning of the year, James writes 3 pages to            write?‚Äù  
                      his friends weekly, increasing by 1 page every three months. How             z
                      many pages does he write in total over the year?‚Äù                          Method13: Use multiple units.
                                                                                                 Example: ‚ÄúJames writes 3 pages weekly to his friend. If each page 
                      Method5: Introduce special events or unexpected circumstances.             takes 10 minutes to write, how many hours does he spend writing in 
                      Example: ‚ÄúJames writes 3 pages twice a week, but if he travels on  a year??‚Äù  
                      the weekend, he writes only once that week. Assuming he travels  Method14: Reverse calculation.
                      8 times in a year, how many pages does he write in a year?‚Äù                Example: ‚ÄúJames wrote 624 pages in a year, writing to two friends 
                      Method6: Apply statistics and probability.                                 twice weekly. How many pages did he write per letter?‚Äù  
                      Example: ‚ÄúJames‚Äôs letters have a 5% chance of being returned. If           Method15: Storytelling or nested situations.
                      he writes 100 letters in a year, how many are expected to be               Example: ‚ÄúJames is attempting to write a book about his friends. He 
                      successfully delivered?‚Äù                                                   writes letters weekly to record their daily lives, planning to compile 
                      Method7: Include error rate or rework.                                     every 20 pages into a chapter. At his current writing rate, how many 
                      Example: ‚ÄúJames finds that 5% of his letters need to be rewritten.  chapters can he complete in a year?‚Äù  
                      How many pages does he write in total over the year?‚Äù                      Method16: Interdisciplinary approach.
                      Method8: Set a cost budget or resource limit.                              Example: ‚ÄúJames writes a 3-page letter to two friends every week and 
                      Example: ‚ÄúEach page costs James $1, and his budget is $200. At             sends them by airmail. Assuming each letter weighs approximately 20 
                      his current writing frequency, how long can he continue writing?‚Äù   grams, calculate the total weight required to send all these letters to 
                      Method9: Multi-variable comparison.                                        his friends over a year, given an average flight speed of 900 km/h and 
                      Example: ‚ÄúJames writes 3 pages weekly to two friends, and for              that both friends are 1,000 km away.?‚Äù  
                            Figure 8: The prompt for enhancing the diversity of questions during the construction of the answer dataset.
