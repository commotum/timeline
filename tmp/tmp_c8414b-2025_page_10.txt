                                 Product of Experts with LLMs: Boosting Performance on ARC Is a Matter of Perspective
               Acknowledgement                                                 Bostrom, K. and Durrett, G.             Byte pair encod-
               Wewouldliketoexpressoursincere gratitude to Lambda,               ing is suboptimal for language model pretraining,
               for providing computational resources essential for optimiz-      2020.    URL https://doi.org/10.18653/v1/
               ing our pipeline. Specifically, they supplied us with a server    2020.findings-emnlp.414.
               equipped with 8xH100 GPUs, enabling rapid iteration on          Chollet, F.    On the measure of intelligence.       CoRR,
               our ideas. Their support was instrumental in winning the          abs/1911.01547, 2019. URL http://arxiv.org/
               ARCKaggleCompetition2024usingtheapproachshown                     abs/1911.01547.
               in this paper.
               This work has been supported by the ”Research Center            Cole, J.    Community Interview Jack Cole – Lab42
               for Algorithmic Intelligence as an Emergent Phenomenon”           — lab42.global.           https://lab42.global/
               (funded by the Carl-Zeiss-Stiftung) and by the Deutsche           community-interview-jack-cole/,                     2024.
               Forschungsgemeinschaft (DFG, German Research Founda-              [Accessed 29-01-2025].
               tion), project 233630050 (Collaborative Research Center
               TRR146).                                                        Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A.,
               Generative AI language tools were used for text editing; all      Letman, A., Mathur, A., Schelten, A., Yang, A., Fan, A.,
               AI-generated output was subsequently reviewed, revised,           Goyal, A., Hartshorn, A., Yang, A., Mitra, A., Sravanku-
               and validated by the authors, who assume full responsibility      mar, A., Korenev, A., Hinsvark, A., Rao, A., Zhang, A.,
                                                                                                                                   `
               for the final revision.                                           Rodriguez, A., Gregerson, A., Spataru, A., Roziere, B.,
                                                                                 Biron, B., Tang, B., Chern, B., Caucheteux, C., Nayak, C.,
               ImpactStatement                                                   Bi, C., Marra, C., McConnell, C., Keller, C., Touret, C.,
                                                                                 Wu,C.,Wong,C.,Ferrer,C.C.,Nikolaidis, C., Allonsius,
               This paper presents work whose goal is to advance the field       D., Song, D., Pintz, D., Livshits, D., Esiobu, D., Choud-
               of Machine Learning. There are many potential societal            hary, D., Mahajan, D., Garcia-Olano, D., Perino, D., Hup-
               consequences of our work, none which we feel must be              kes, D., Lakomkin, E., AlBadawy, E., Lobanova, E., Di-
               specifically highlighted here.                                    nan, E., Smith, E. M., Radenovic, F., Zhang, F., Synnaeve,
                                                                                 G., Lee, G., Anderson, G. L., Nail, G., Mialon, G., Pang,
               References                                                        G., Cucurell, G., Nguyen, H., Korevaar, H., Xu, H., Tou-
                                                                                 vron, H., Zarov, I., Ibarra, I. A., Kloumann, I. M., Misra,
                   ¨                                                             I., Evtimov, I., Copet, J., Lee, J., Geffert, J., Vranes, J.,
               Akyurek, E., Damani, M., Qiu, L., Guo, H., Kim, Y., and           Park, J., Mahadeokar, J., Shah, J., van der Linde, J., Bil-
                 Andreas, J. The surprising effectiveness of test-time           lock, J., Hong, J., Lee, J., Fu, J., Chi, J., Huang, J., Liu,
                 training for abstract reasoning, 2024. URL https://             J., Wang, J., Yu, J., Bitton, J., Spisak, J., Park, J., Rocca,
                 arxiv.org/abs/2411.07279.                                       J., Johnstun, J., Saxe, J., Jia, J., Alwala, K. V., Upasani,
               Allen-Zhu, Z. and Li, Y.       Physics of language mod-           K., Plawiak, K., Li, K., Heafield, K., Stone, K., and et al.
                 els:   Part 3.1, knowledge storage and extraction,              The llama 3 herd of models. CoRR, abs/2407.21783,
                 2024. URL https://openreview.net/forum?                         2024. doi: 10.48550/ARXIV.2407.21783. URL https:
                 id=5x788rqbcj.                                                  //doi.org/10.48550/arXiv.2407.21783.
               Allen-Zhu, Z. and Li, Y. Physics of language models: Part       Greenblatt, R. Getting 50% (SoTA) on ARC-AGI with
                 3.2, knowledge manipulation, 2025. URL https://                 GPT-4o — redwoodresearch.substack.com.           https:
                 openreview.net/forum?id=oDbiL9CLoS.                             //redwoodresearch.substack.com/p/
                                                                                 getting-50-sota-on-arc-agi-with-gpt,
               arcprize.org.  OpenAI o3 Breakthrough High Score on               2024. [Accessed 25-01-2025].
                 ARC-AGI-Pub—arcprize.org. https://arcprize.
                 org/blog/oai-o3-pub-breakthrough, 2025.                       Hinton, G. E. Products of experts. In 9th International
                 [Accessed 25-01-2025].                                          Conference on Artificial Neural Networks: ICANN ’99.
                                                                                 IEE, 1999.
               Berman, J.       How I came in first on ARC-AGI-
                 Pub using Sonnet 3.5 with Evolutionary Test-                  Hinton,   G. E.       Training products of experts by
                 time    Compute      — jeremyberman.substack.com.               minimizing contrastive divergence.         Neural Com-
                 https://jeremyberman.substack.com/p/                            put.,   14(8):1771–1800,     2002.       doi:    10.1162/
                 how-i-got-a-record-536-on-arc-agi,                              089976602760128018. URLhttps://doi.org/10.
                 2024. [Accessed 25-01-2025].                                    1162/089976602760128018.
                                                                           10
