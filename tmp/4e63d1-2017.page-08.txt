                                     Table 1: AUC-PR results on Countries and MRR and HITS@m on Kinship, Nations, and UMLS.
                                         Corpus       Metric                    Model                             Examples of induced rules and their conﬁdence
                                                                 ComplEx        NTP          NTPλ
                                                S1   AUC-PR     99.37±0.4   90.83±15.4    100.00± 0.0    0.90 locatedIn(X,Y) :– locatedIn(X,Z), locatedIn(Z,Y).
                                     Countries  S2   AUC-PR     87.95±2.8   87.40±11.7     93.04± 0.4    0.63 locatedIn(X,Y) :– neighborOf(X,Z), locatedIn(Z,Y).
                                                S3   AUC-PR     48.44±6.3   56.68±17.6     77.26±17.0    0.32 locatedIn(X,Y) :–
                                                                                                               neighborOf(X,Z), neighborOf(Z,W), locatedIn(W,Y).
                                                     MRR              0.81          0.60           0.80  0.98 term15(X,Y) :– term5(Y,X)
                                     Kinship         HITS@1           0.70          0.48          0.76   0.97 term18(X,Y) :– term18(Y,X)
                                                     HITS@3          0.89           0.70           0.82  0.86 term4(X,Y) :– term4(Y,X)
                                                     HITS@10         0.98           0.78           0.89  0.73 term12(X,Y) :– term10(X, Z), term12(Z, Y).
                                                     MRR             0.75          0.75            0.74  0.68 blockpositionindex(X,Y) :– blockpositionindex(Y,X).
                                     Nations         HITS@1          0.62          0.62            0.59  0.46 expeldiplomats(X,Y) :– negativebehavior(X,Y).
                                                     HITS@3           0.84          0.86          0.89   0.38 negativecomm(X,Y) :– commonbloc0(X,Y).
                                                     HITS@10         0.99          0.99           0.99   0.38 intergovorgs3(X,Y) :– intergovorgs(Y,X).
                                                     MRR              0.89          0.88          0.93   0.88 interacts_with(X,Y) :–
                                     UMLS            HITS@1           0.82          0.82          0.87         interacts_with(X,Z), interacts_with(Z,Y).
                                                     HITS@3           0.96          0.92          0.98   0.77 isa(X,Y) :– isa(X,Z), isa(Z,Y).
                                                     HITS@10         1.00           0.97          1.00   0.71 derivative_of(X,Y) :–
                                                                                                               derivative_of(X,Z), derivative_of(Z,Y).
                                    is a subregion. The location of test countries needs to be inferred from the location of its neighboring
                                    countries: locatedIn(X,Y) :– neighborOf(X,Z),locatedIn(Z,Y). This task is more difﬁcult
                                    than S1, as neighboring countries might not be in the same region, so the rule above will not always
                                    hold.
                                    S3:     In addition to S2, all ground atoms locatedIn(c,r) where r is a region and c
                                    is a training country that has a test or dev country as a neighbor are also removed.
                                    The location of test countries can for instance be inferred using the three-hop rule
                                    locatedIn(X,Y):–neighborOf(X,Z),neighborOf(Z,W),locatedIn(W,Y).
                                    Kinship, Nations &UMLS WeusetheNations,Alyawarrakinship(Kinship)andUniﬁedMedical
                                    Language System (UMLS) KBs from [10]. We left out the Animals dataset as it only contains unary
                                    predicates and can thus not be used for evaluating multi-hop reasoning. Nations contains 56 binary
                                    predicates, 111 unary predicates, 14 constants and 2565 true facts, Kinship contains 26 predicates,
                                   104 constants and 10686 true facts, and UMLS contains 49 predicates, 135 constants and 6529 true
                                    facts. Since our baseline ComplEx cannot deal with unary predicates, we remove unary atoms from
                                    Nations. We split every KB into 80% training facts, 10% development facts and 10% test facts. For
                                    evaluation, we take a test fact and corrupt its ﬁrst and second argument in all possible ways such that
                                    the corrupted fact is not in the original KB. Subsequently, we predict a ranking of every test fact and
                                    its corruptions to calculate MRR and HITS@m.
                                    6    Results and Discussion
                                    Results for the different model variants on the benchmark KBs are shown in Table 1. Another method
                                    for inducing rules in a differentiable way for automated KB completion has been introduced recently
                                    by[37] and our evaluation setup is equivalent to their Protocol II. However, our neural link prediction
                                    baseline, ComplEx, already achieves much higher HITS@10 results (1.00 vs. 0.70 on UMLS and
                                    0.98 vs. 0.73 on Kinship). We thus focus on the comparison of NTPs with ComplEx.
                                    First, we note that vanilla NTPs alone do not work particularly well compared to ComplEx. They only
                                    outperform ComplEx on Countries S3 and Nations, but not on Kinship or UMLS. This demonstrates
                                    the difﬁculty of learning subsymbolic representations in a differentiable prover from uniﬁcation
                                    alone, and the need for auxiliary losses. The NTPλ with ComplEx as auxiliary loss outperforms the
                                    other models in the majority of tasks. The difference in AUC-PR between ComplEx and NTPλ is
                                    signiﬁcant for all Countries tasks (p < 0.0001).
                                    AmajoradvantageofNTPsisthatwecaninspectinducedruleswhichprovideuswithaninterpretable
                                    representation of what the model has learned. The right column in Table 1 shows examples of induced
                                    rules by NTPλ (note that predicates on Kinship are anonymized). For Countries, the NTP recovered
                                    those rules that are needed for solving the three different tasks. On UMLS, the NTP induced
                                    transitivity rules. Those relationships are particularly hard to encode by neural link prediction models
                                    like ComplEx, as they are optimized to locally predict the score of a fact.
                                                                                                   8
