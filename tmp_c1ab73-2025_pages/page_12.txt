                   Preprint: Don’t throw the baby out with the bathwater: How and why deep learning for ARC
                   These studies highlight that frozen LLMs possess some pattern recognition abilities and may possess some associative
                   learning abilities out of the box in their pretrained forward pass, but they struggle with the abstraction and reasoning
                   required for ARC tasks.
                   5.3.2  Neuro-Symbolic and Program Synthesis Approaches
                   Another line of research focuses on combining neural networks with symbolic reasoning or program synthesis to solve
                   ARCtasks. Wangetal.[62] proposed a method where GPT-4 generates high-level textual hypotheses about the task,
                   then translates these into code to solve the task. Testing on a subset of 40 ARC training tasks, they achieved a success
                   rate of 27.5%, which increased to 37.5% with human selection of correct hypotheses. However, this again relies heavily
                   onthe frozen LLM’s forward pass to be powerful enough to do the reasoning required for ARC tasks.
                   [63] introduced CodeIt, a method that generates code based on grid-pairs and uses a self-improving loop during
                   evaluation. CodeIt solves 14.8% of the ARC evaluation tasks and runs into the limitations we describe in 2.3.
                   [64] developed Generalized Planning for ARC (GPAR), modeling ARC tasks as generalized planning problems in the
                   Planning Domain Definition Language (PDDL) coupled with external functions representing object-centric abstractions
                   of the grids. [64] achieved 50% accuracy on a subset of object-centric tasks. [22] used a dreamcoder inspired approach
                   [65] with a domain-specific language for ARC tasks, achieving 18 out of 400 tasks on the ARC evaluation set.
                   These highlighted approaches attempt to incorporate a more symbolic reasoning approach to solve ARC tasks yet can
                   only achieve a limited success rate or work only within a specialized domain. This may be due to the limitations of
                   perceptual reasoning with these symbolic approaches, or may also be in some cases due to the added complexity of
                   fully representing ARC transformations in code or domain-specific languages.
                   [14] utilized neural embeddings and vector arithmetic to solve ARC visual analogies but achieved only 2% accuracy on
                   the public evaluation set. We discussed this weaknesses of this approach further in 2.3.
                   5.3.3  Brute Force Search
                   Icecuber [26] attempts to solve ARC by performing a brute force search over unary functions on pieces of input grids,
                   forming a directed acyclic graph (DAG) of many possible transformations, until a DAG that creates the training output
                   grid is found. This method won the 2020 ARC challenge competition on Kaggle [7].
                   5.3.4  OtherDatasets
                   Other works have focused on simplified versions of ARC. [66] state that ARC is impenetrable for the time being and
                   introduce the Sort-of-ARC dataset, which is only limited to 20x20 grids and only contains 3 objects with a limited set
                   of transformations only. They emphasize object centric reasoning by using a controller to generate a solution vector,
                   use slot attention transformer to extract object vectors, then update the solution and object vectors in an object centric
                   waybeforegenerating the final solution using a spatial decoder on the result. We believe that a purely object centric
                   approach does not generalize to tasks where objects are ambiguous, and the correct “object” is very task specific. [66]
                   achieved 59% accuracy on out-of-distribution tasks in the Sort-of-ARC dataset.
                   [61] introduce the 1D ARC dataset, which is a simplified version of ARC with only one dimension. They emphasize
                   the importance of object centric input representations and prompt GPT-4 with their object centric representations of the
                   tasks. They state that they strategically select the easiest 50 tasks out of the training set and solve 23 out of the 50 tasks.
                   5.3.5  Summaryandlimitationsofrelatedwork
                   Tosummarize, ARChasindeedproventobeachallengingproblemforthecurrent paradigm of AI, with state-of-the-art
                   results remaining low on the private test set compared to other datasets in the field, despite 3 recent competitions on the
                   ARC[7,40].
                  Weidentify the following limitations of previous approaches:
                          • Comparisons without computational constraints: Some studies compare their score to others without
                            reporting the computational cost of their methods, making it difficult to make an apples to apples comparison.
                            Werather rely on private test set performance and the computational constraints set by kaggle to avoid this
                            issue. This is a major weakness of related work, we find that our method is much more computate efficient
                            while still achieving state-of-the-art.
                          • Limited Generalization: Many methods perform well on subsets of ARC tasks or simplified versions but fail
                            to generalize across the full spectrum of ARC tasks.
                                                                            12
