                   Preprint: Don’t throw the baby out with the bathwater: How and why deep learning for ARC
                   based solution must be much more explicit and well defined, and it must be syntactically correct, working correctly
                   with all the different possible input grids. A human solver would make a similar argument, preferring to just solve the
                   riddle directly, and would typically require a much shorter time to do so, compared to coding a working program that
                   solves the riddle.
                   This direct output approach stands in contrast to earlier methods that generate code as an intermediate step, which can
                   then be executed to produce the solution grid [16, 22]. On the one hand, such code-based methods have the advantage
                   of verifiability: running the program directly tests its correctness. On the other hand, producing code to solve a riddle is
                   typically more difficult than simply generating the final grid. [21] specifying a concept or process in full detail often
                   proves more demanding than acting out the game or task itself. A code-based solution must be thoroughly defined,
                   syntactically valid, and capable of handling multiple potential input grids. By contrast, a human solver typically finds
                   it more straightforward and faster to solve the riddle outright than to write, debug a general-purpose program that
                   performs the same task.
                   Generating code as the final output does not fundamentally alter the broad dynamic search process through which LLMs
                   solve riddles—this internal flexibility and reasoning remain essential. However, it does shift the abstraction space,
                   training the model to handle perception and action via programming constructs instead of direct grid outputs. A notable
                   benefit of code generation lies in its strong validation: one can run the generated program on the provided examples
                   to confirm correctness. Yet, our experiments found that the added complexity of producing a syntactically correct,
                   general-purpose solution introduced extra challenges and did not match the performance of direct output generation in
                   initial trials.
                   3.1.2  Multi-task Training
                   Multi-task training compels the model to manage multiple modes and contexts simultaneously, thereby reducing
                   its reliance on memorizing individual task details and nudging it toward genuine contextual reasoning [23]. In our
                   setup, we integrate additional tasks requiring high levels of contextualization and reasoning—drawn from various
                   NLPdatasets—alongside the ARC data. This approach boosts ARC performance, mirroring findings by [23], who
                   demonstrated that vanilla transformers can exhibit robust learning-to-learn capabilities when trained on a sufficiently
                   large and varied set of tasks. Although [23] employed simpler permuted vision tasks rather than abstraction- or
                   reasoning-based datasets, their conclusion that scaling task diversity helps escape the “memorization regime” remains
                   consistent with our observations.
                   3.1.3  Codepre-training and contextualization
                  Weobservethat training on coding tasks offers a more pronounced performance boost on ARC than merely adding
                   multi-task training derived from language or NLP domains. It is generally easier to continue a sentence halfway through
                   a paragraph than a code file halfway. Code datasets inherently demand meticulous attention to detail and context,
                   requiring the model to keep track of variables and resolve dependencies. This greater focus on accuracy and hierarchical
                   reasoning means that memorization alone is insufficient—an important distinction from many NLP tasks where world
                   knowledge and memorized associations play a larger role. As noted by [24], coding data “is more logical and less
                   ambiguous” ultimately fostering a better focus on context.
                   Amore complete discussion of recent literature supporting the use of code data in LLM training can be found in
                   section 5.
                   3.1.4  Automatic Riddle Generators
                   Programmatic riddle generation is a valuable strategy to expand ARC training data and enhance model learning. To
                   facilitate this, we employ Domain Specific Language (DSL) techniques, drawing inspiration from the work of Andreas
                   Koepf [25] and Johan Sokrates Wind’s (Icecuber) DSL [26], to construct synthetic riddles by sampling function names
                   and their parameters. A key aspect of our training approach involves training the model to infer these underlying
                   DSLfunctionnamesandparametersfromtheinputriddlegrids, in addition to predicting the final output grids. This
                   dual-prediction strategy, where models learn to predict both the output grid and the DSL function names, contributes to
                   morerobust performance compared to training on either target alone. While DSL-generated data represents a portion of
                   our overall training corpus, it serves to illustrate important data generation concepts we utilize.
                   Tofurther diversify our ARC-specific training data, we also employ various more traditional riddle generators. These
                   generators produce complete input-output pairs and test grids, enriching our training dataset. We observe that if
                   riddle examples leave aspects of the transformation underspecified, the model may inadvertently learn to encode these
                   ambiguities directly into its weights, rather than inferring them contextually. This can lead to undesirable biases and
                                                                             5
