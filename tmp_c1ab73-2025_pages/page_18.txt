                Preprint: Donâ€™t throw the baby out with the bathwater: How and why deep learning for ARC
                A TrainingDatasetConstructionandComposition
                Ourapproach to solving the Abstraction and Reasoning Corpus (ARC) Challenge incorporated a diverse set of training
                datasets, combining both existing public resources and custom-generated synthetic data. This data strategy was designed
                to develop robust abstract reasoning capabilities and improve grid-based pattern recognition tasks.
                MultimodalGridTranslationDatasets:    These datasets facilitate translation between visual and symbolic represen-
                tations of grids - including Base64 images, text, English descriptions, and code implementations. They focus on simple
                shapes and positions to bridge visual and symbolic reasoning relevant to ARC.
                ExtendedPCFGDatasets: BuildingupontheprinciplesofProbabilistic Context-Free Grammars (PCFGs), we use
                an expanded PCFG dataset with 100 distinct string operations, designed to resemble ARC riddles. These datasets
                incorporate program synthesis components, emphasizing function name generation as part of the learning process.
                Cellular Automata and Mathematical Pattern Datasets:  Wegenerate cellular automata tasks within the ARC
                framework and create riddle boards using mathematical equations. These datasets introduce varied pattern complexities
                and cross-item riddles that require learning underlying concepts across multiple examples. Repair-type riddles are also
                generated to induce priors related to fundamental visual reasoning concepts like symmetries, shapes, progression, and
                counting.
                Our data generation strategy also leverages frameworks such as ARC_gym [67] for supplementary examples with
                customizable grid characteristics. We also enhance existing datasets, including augmented ConceptARC data [3] and
                augmented official public ARC datasets. The recent integration of RE-ARC data [68], with its procedurally generated
                examples for the 400 ARC training tasks, has further improved performance by increasing exposure to task-specific
                patterns and transformations.
                A.1  Public Datasets
                Thetraining pipeline incorporated several established datasets from the research community:
                A.1.1  LanguageandReasoningDatasets
                     1. WizardLMEvolution Instruct V2 (196k examples)
                     2. TinyStories-GPT4 (150,000 examples)
                     3. SQuADv2
                     4. Chain-of-Thought Submix
                     5. Open-Platypus
                     6. SlimOrca
                A.1.2  Domain-Specific Scientific Datasets
                     1. Arxiv Math Instruct (50k examples)
                     2. Arxiv CS/ML Instruct (50k examples)
                     3. MathInstruct
                     4. Arxiv Physics Instruct (30k examples)
                A.1.3  MultimodalandVisualReasoningDatasets
                Weintegrated several multimodal reasoning datasets from the M3IT collection, specifically focusing on:
                     1. CLEVR
                     2. NLVR
                     3. VCR
                     4. Visual-MRC
                                                                 18
