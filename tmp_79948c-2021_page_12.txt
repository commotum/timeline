           [19] Mingxing Tan and Quoc V Le. Efﬁcientnetv2: Smaller models and faster training. ICML, 2021.
           [20] Andrew Brock, Soham De, Samuel L Smith, and Karen Simonyan. High-performance large-
              scale image recognition without normalization. arXiv preprint arXiv:2102.06171, 2021.
           [21] Ashish Vaswani, Prajit Ramachandran, Aravind Srinivas, Niki Parmar, Blake Hechtman, and
              Jonathon Shlens. Scaling local self-attention for parameter efﬁcient visual backbones. arXiv
              preprint arXiv:2103.12731, 2021.
           [22] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining
              Guo. Swin transformer: Hierarchical vision transformer using shifted windows. arXiv preprint
              arXiv:2103.14030, 2021.
           [23] Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, and Lei Zhang.
              Cvt: Introducing convolutions to vision transformers. arXiv preprint arXiv:2103.15808, 2021.
           [24] Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Hervé Jégou,
              andMatthijs Douze. Levit: a vision transformer in convnet’s clothing for faster inference. arXiv
              preprint arXiv:2104.01136, 2021.
           [25] Li Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Francis EH Tay, Jiashi Feng, and
              Shuicheng Yan. Tokens-to-token vit: Training vision transformers from scratch on imagenet.
              arXiv preprint arXiv:2101.11986, 2021.
           [26] Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer. Scaling vision transform-
              ers. arXiv preprint arXiv:2106.04560, 2021.
           [27] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen.
              Mobilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE conference
              oncomputervision and pattern recognition, pages 4510–4520, 2018.
           [28] Laurent Sifre. Rigid-motion scattering for image classiﬁcation. Ph.D. thesis section 6.2, 2014.
           [29] Mirgahney Mohamed, Gabriele Cesa, Taco S Cohen, and Max Welling. A data and compute
              efﬁcient design for limited-resources deep learning. arXiv preprint arXiv:2004.09691, 2020.
           [30] Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani. Self-attention with relative position repre-
              sentations. arXiv preprint arXiv:1803.02155, 2018.
           [31] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,
              Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a uniﬁed
              text-to-text transformer. arXiv preprint arXiv:1910.10683, 2019.
           [32] Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and François Fleuret. Transformers
              are rnns: Fast autoregressive transformers with linear attention. In International Conference on
              Machine Learning, pages 5156–5165. PMLR, 2020.
           [33] Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane,
              TamasSarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin, Lukasz Kaiser, et al. Rethinking
              attention with performers. arXiv preprint arXiv:2009.14794, 2020.
           [34] Prajit Ramachandran, Niki Parmar, Ashish Vaswani, Irwan Bello, Anselm Levskaya, and
              Jonathon Shlens. Stand-alone self-attention in vision models. arXiv preprint arXiv:1906.05909,
              2019.
           [35] Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, and
              QuocVLe. Mnasnet: Platform-aware neural architecture search for mobile. In Proceedings
              of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2820–2828,
              2019.
           [36] Kai Han, Yunhe Wang, Hanting Chen, Xinghao Chen, Jianyuan Guo, Zhenhua Liu, Yehui
              Tang, An Xiao, Chunjing Xu, Yixing Xu, et al. A survey on visual transformer. arXiv preprint
              arXiv:2012.12556, 2020.
           [37] Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan,
              and Mubarak Shah. Transformers in vision: A survey. arXiv preprint arXiv:2101.01169, 2021.
           [38] Cheng-Zhi Anna Huang, Ashish Vaswani, Jakob Uszkoreit, Noam Shazeer, Ian Simon, Curtis
              Hawthorne, AndrewMDai,MatthewDHoffman,MonicaDinculescu,andDouglasEck. Music
              transformer. arXiv preprint arXiv:1809.04281, 2018.
                               12
