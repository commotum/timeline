                                                                Test-Time Learning for Large Language Models
                                                                          Datasets             1200                                       Datasets
                                 700                                      AlpacaGpt4En                                                   AlpacaGpt4En
                                 600                                      Dolly                1000                                      Dolly
                                                                          InstructionWild                                                InstructionWild
                                 500                                                            800
                                Density400                                                    Density600
                                 300
                                                                                                400
                                 200
                                 100                                                            200
                                   0 0     20    40     60     80    100   120    140             0  0          100         200         300         400
                                                     Input Sequence Length                                          Output Sequence Length
                                                  Figure 6. Distribution of Sequence Lengths for Samples in InstructionBench.
                                 400                                         Datasets          5000                                         Datasets
                                 350                                           GSM8K                                                          GSM8K
                                                                               Logiqa          4000                                           Logiqa
                                 300                                           MetaMath                                                       MetaMath
                                 250                                                           3000
                                Density200                                                    Density
                                 150                                                           2000
                                 100                                                           1000
                                  50
                                   0   50    100    150    200    250   300    350    400         0 0      2      4      6      8     10     12     14
                                                     Input Sequence Length                                          Output Sequence Length
                                                  Figure 7. Distribution of Sequence Lengths for Samples in ReasoningBench.
                  dataset is constructed by first manually creating a comprehensive set of instructions across a wide range of tasks, followed
                  bydata generation and quality assurance using GPT-4. It includes diverse task types, such as various QA and summarization
                  tasks. From this dataset, we randomly select 5k samples to test the model’s generalization capabilities and performance on
                  instruction tasks.
                                                            8
                  InstructionWild: InstructionWild is a large dataset focused on real-world user instructions, consisting of over 50k high-
                  quality bilingual (Zh-En) instructions. The data is derived from real user-shared scenarios, offering diversity and broad
                  applicability. Its format aligns with that of the Alpaca dataset, enabling seamless integration and usage. The dataset covers
                  commoninstruction fine-tuning tasks such as QA and summarization. We randomly extract 5k samples to evaluate the
                  model’s ability to understand and execute instructions effectively.
                  B.3. ReasoningBench
                  ReasoningBench is designed to evaluate models’ logical reasoning and problem-solving abilities through tasks such as
                  mathematical problem solving, multi-step reasoning, and logical reading comprehension. This benchmark integrates
                  three high-quality reasoning datasets, GSM8K, MetaMath, and LogiQA, to comprehensively assess models’ reasoning
                  performance across diverse dimensions and task types. The distribution of dataset samples and an example table of dataset
                  entries are provided in Figure 7 and Table 9.
                     8https://huggingface.co/datasets/fuliucansheng/InstructionWild
                                                                                           20
