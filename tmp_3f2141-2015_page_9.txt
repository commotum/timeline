                                                                              Training         Testing
                                             Experiment    Model           Coarse   Fine    Coarse   Fine
                                                           4-layer LSTM    0.98     0.98    0.01     0.50
                                             Sequence      Stack-LSTM      0.89     0.94    0.00     0.22
                                             Copying       Queue-LSTM      1.00     1.00    1.00     1.00
                                                           DeQue-LSTM      1.00     1.00    1.00     1.00
                                                           8-layer LSTM    0.95     0.98    0.04     0.13
                                             Sequence      Stack-LSTM      1.00     1.00    1.00     1.00
                                             Reversal      Queue-LSTM      0.44     0.61    0.00     0.01
                                                           DeQue-LSTM      1.00     1.00    1.00     1.00
                                                           2-layer LSTM    0.54     0.93    0.02     0.52
                                             Bigram        Stack-LSTM      0.44     0.90    0.00     0.48
                                             Flipping      Queue-LSTM      0.55     0.94    0.55     0.98
                                                           DeQue-LSTM      0.55     0.94    0.53     0.98
                                                           8-layer LSTM    0.98     0.99    0.98     0.99
                                             SVOto         Stack-LSTM      1.00     1.00    1.00     1.00
                                             SOV           Queue-LSTM      1.00     1.00    1.00     1.00
                                                           DeQue-LSTM      1.00     1.00    1.00     1.00
                                             Gender        8-layer LSTM    0.98     0.99    0.99     0.99
                                             Conju-        Stack-LSTM      0.93     0.97    0.93     0.97
                                             gation        Queue-LSTM      1.00     1.00    1.00     1.00
                                                           DeQue-LSTM      1.00     1.00    1.00     1.00
                                                   (a) Comparing Enhanced LSTMs to Best Benchmarks
                                                  (b) Comparison of Model Convergence during Training
                                        Figure 2: Results on the transduction tasks and convergence properties
                                                                          9
