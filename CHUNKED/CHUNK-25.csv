year,title,url
2022,TransFusion: Robust LiDAR-Camera Fusion for 3D Object Detection with Transformers,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_TransFusion_Robust_LiDAR-Camera_Fusion_for_3D_Object_Detection_With_Transformers_CVPR_2022_paper.pdf
2022,TransNeRF: Generalizable Neural Radiance Fields for Novel View Synthesis with Transformer,https://arxiv.org/abs/2206.05375
2025,TransXSSM: Hybrid Transformer–SSM with Unified RoPE,"https://arxiv.org/pdf/2506.09507.pdf ""TransXSSM (2025) — arXiv"""
2022,Transformer Language Models without Positional Encodings Still Learn Positional Information,"https://arxiv.org/pdf/2203.16634.pdf ""Transformers without PEs still learn position (2022) — arXiv"""
2021,Transformer in Transformer,"https://arxiv.org/pdf/2103.00112.pdf ""Transformer in Transformer (2021) — arXiv"""
2021,Transformer in Transformer,"https://arxiv.org/pdf/2103.00112.pdf ""Transformer in Transformer (2021) — arXiv"""
2019,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context,https://arxiv.org/abs/1901.02860
2019,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context,https://aclanthology.org/P19-1285.pdf
2023,Transformer-based 3D point cloud generation networks,https://dl.acm.org/doi/10.1145/3581783.3612226
2024,Transformers Can Do Arithmetic with the Right Embeddings,https://proceedings.neurips.cc/paper_files/paper/2024/file/c35986bc1ee29b31c1011481b77fe540-Paper-Conference.pdf
2024,Transformers Can Do Arithmetic with the Right Embeddings,https://proceedings.neurips.cc/paper_files/paper/2024/hash/c35986bc1ee29b31c1011481b77fe540-Abstract-Conference.html
1949,Translation (Weaver Memorandum),https://www.mt-archive.net/50/Weaver-1949.pdf
1928,Transmission of Information,https://monoskop.org/images/a/a6/Hartley_Ralph_VL_1928_Transmission_of_Information.pdf
2023,Tree of Thoughts (ToT),https://arxiv.org/abs/2305.10601
2023,Tree of Thoughts (ToT),https://arxiv.org/abs/2305.10601
2023,Tree of Thoughts (ToT): Deliberate Problem Solving with Large Language Models,https://arxiv.org/abs/2305.10601
2005,Tree-Based Batch Mode Reinforcement Learning,https://www.jmlr.org/papers/volume6/ernst05a/ernst05a.pdf
2015,Trust Region Policy Optimization (TRPO),https://arxiv.org/abs/1502.05477
2015,Trust Region Policy Optimization (TRPO),https://arxiv.org/abs/1502.05477
2021,TruthfulQA: Measuring How Models Mimic Human Falsehoods,https://arxiv.org/abs/2109.07958
2018,Twin Delayed DDPG (TD3),https://arxiv.org/pdf/1802.09477
2021,Twins: Revisiting the Design of Spatial Attention in Vision Transformers,"https://arxiv.org/pdf/2104.13840.pdf ""Twins (2021) — arXiv"""
2021,Twins: Revisiting the Design of Spatial Attention in Vision Transformers,"https://arxiv.org/pdf/2104.13840.pdf ""Twins (2021) — arXiv"""
1982,Two cortical visual systems,https://www.cns.nyu.edu/~tony/vns/readings/ungerleider-mishkin-1982.pdf
2020,UNITER: Universal Image-Text Representation Learning,"https://arxiv.org/pdf/1909.11740.pdf ""UNITER (2020) — arXiv"""
2025,Understanding the RoPE Extensions of Long-Context LLMs,https://aclanthology.org/2025.coling-main.600.pdf
2023,Uni3DL: Unified Model for 3D and Language Understanding,"https://arxiv.org/pdf/2312.03026.pdf ""Uni3DL (2023) — arXiv"""
1990,Unified Theories of Cognition,https://www.hup.harvard.edu/books/9780674921016
2018,Universal Transformer (UT),MISSING
2018,Universal Transformers,"https://arxiv.org/pdf/1807.03819.pdf ""Universal Transformers (2018) — arXiv"""
2018,Universal Transformers (UT),https://arxiv.org/abs/1807.03819
