year,title,url
2018,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis,https://arxiv.org/pdf/1805.04276.pdf
2018,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis,https://arxiv.org/pdf/1805.04276.pdf
2017,Lie-Access Neural Turing Machines (LANTM),https://openreview.net/pdf?id=Byiy-Pqlx
2024,LieRE: Lie Rotational Positional Encodings,"https://arxiv.org/pdf/2406.10322.pdf ""LieRE (2024) — arXiv"""
2018,ListOps: A Diagnostic Dataset for Latent Tree Learning,https://arxiv.org/pdf/1804.06028.pdf
2018,ListOps: A Diagnostic Dataset for Latent Tree Learning,https://aclanthology.org/N18-4013/
2024,"LiveBench: A Challenging, Contamination-Free LLM Benchmark",https://arxiv.org/pdf/2406.19314.pdf
2021,LoRA: Low-Rank Adaptation of Large Language Models,https://arxiv.org/pdf/2106.09685.pdf
2023,LogiQA 2.0 - An Improved Dataset for Logical Reasoning in NLU,https://frcchang.github.io/pub/An%20Improved%20Dataset%20for%20Logical%20Reasoning%20in%20Natural%20Language%20Understanding.pdf
2020,LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning,https://www.ijcai.org/proceedings/2020/501
2016,Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and Knowledge,https://arxiv.org/pdf/1606.04422.pdf
2020,Long Range Arena (LRA): A Benchmark for Efficient Transformers,https://arxiv.org/pdf/2011.04006.pdf
1997,Long Short-Term Memory (LSTM),https://www.bioinf.jku.at/publications/older/2604.pdf
2023,"LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding",https://arxiv.org/pdf/2308.14508.pdf
2024,LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens,https://arxiv.org/pdf/2402.13753
2024,LookHere: Vision Transformers with Directed Attention Generalize and Extrapolate,https://arxiv.org/pdf/2405.13985.pdf
2021,MATH: Measuring Mathematical Problem Solving,https://arxiv.org/pdf/2103.03874.pdf
2024,"MHaluBench (from ""Unified Hallucination Detection..."")",https://aclanthology.org/2024.acl-long.178.pdf
2024,MM-Vet v2,https://arxiv.org/pdf/2408.00765.pdf
2023,MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities,https://arxiv.org/pdf/2308.02490.pdf
2023,MMBench: Evaluating Multimodal LLMs,"https://arxiv.org/pdf/2307.06281.pdf ""MMBench (2023) — arXiv"""
2023,MMBench: Is Your Multi-modal Model an All-around Player?,https://arxiv.org/pdf/2307.06281.pdf
2023,MMBench: Is Your Multi-modal Model an All-around Player?,https://arxiv.org/pdf/2307.06281.pdf
2023,MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models,https://arxiv.org/pdf/2306.13394.pdf
2024,MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark,https://arxiv.org/pdf/2406.01574.pdf
2025,MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding and Reasoning Benchmark,https://aclanthology.org/2025.acl-long.736.pdf
2023,MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI,https://arxiv.org/pdf/2311.16502.pdf
2023,MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI,https://arxiv.org/pdf/2311.16502.pdf
2023,MMMU: A Massive Multidiscipline Multimodal Benchmark,"https://arxiv.org/pdf/2311.16502.pdf ""MMMU (2023) — arXiv"""
2024,MT-Bench-101,https://aclanthology.org/2024.acl-long.401.pdf
