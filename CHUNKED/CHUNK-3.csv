year,title,url
2020,An Image Is Worth 16x16 Words (ViT),https://arxiv.org/pdf/2010.11929.pdf
2020,An Image Is Worth 16x16 Words (ViT),https://arxiv.org/pdf/2010.11929.pdf
2020,An Image is Worth 16×16 Words: Vision Transformer (ViT),"https://arxiv.org/pdf/2010.11929.pdf ""Vision Transformer (ViT) (2020) — arXiv"".pdf"
2001,An Integrative Theory of Prefrontal Cortex Function,https://pubmed.ncbi.nlm.nih.gov/11283309/
2019,Analysing Mathematical Reasoning Abilities of Neural Models,https://arxiv.org/pdf/1904.01557.pdf
2019,Analysing Mathematical Reasoning Abilities of Neural Models,https://arxiv.org/pdf/1904.01557.pdf
2002,Approximately Optimal Approximate Reinforcement Learning,https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/KakadeLangford-icml2002.pdf
2025,ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory,https://ar5iv.org/abs/2509.04439
2025,ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory,https://arcprize.org/blog/arc-prize-2025-results-analysis
2025,Arithmetic-Bench: Evaluating Multi-Step Reasoning in LLMs through Basic Arithmetic Operations,https://openreview.net/forum?id=ae6bKeffGZ
2016,Asynchronous Methods for Deep Reinforcement Learning (A3C),https://arxiv.org/pdf/1602.01783.pdf
2017,Attention Is All You Need,https://arxiv.org/pdf/1706.03762.pdf
2017,Attention Is All You Need,https://arxiv.org/pdf/1706.03762.pdf
2017,Attention Is All You Need,https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf
2017,Attention Is All You Need,https://arxiv.org/pdf/1706.03762.pdf
2017,Attention Is All You Need,https://arxiv.org/pdf/1706.03762.pdf
2017,Attention Is All You Need,https://arxiv.org/pdf/1706.03762.pdf
2017,Attention Is All You Need,"https://arxiv.org/pdf/1706.03762.pdf ""Attention Is All You Need (2017) — arXiv"".pdf"
2014,Auto-Encoding Variational Bayes (VAE),MISSING
2011,Automating String Processing in Spreadsheets Using Input-Output Examples (FlashFill),https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/popl11-synthesis.pdf
2011,Automating String Processing in Spreadsheets using Input-Output Examples (FlashFill),https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/synasc12.pdf
2025,"Autoregressive Modeling as Iterative Latent Equilibrium (Equilibrium Transformers, EqT)",https://arxiv.org/html/2511.21882v1
2023,Average-Hard Attention Transformers Are Threshold Circuits,"https://arxiv.org/pdf/2308.03212.pdf ""Average-Hard Attention as Threshold Circuits (2023) — arXiv"".pdf"
2018,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,MISSING
2018,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/pdf/1810.04805.pdf
2018,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/pdf/1810.04805.pdf
2018,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,"https://arxiv.org/pdf/1810.04805.pdf ""BERT (2018) — arXiv"".pdf"
2022,BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers,https://arxiv.org/pdf/2203.17270.pdf
