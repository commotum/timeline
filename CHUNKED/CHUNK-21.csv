year,title,url
2022,"ScienceQA (""Learn to Explain..."")",https://arxiv.org/pdf/2209.09513.pdf
2022,ScienceQA: Benchmark for Multimodal Reasoning,"https://arxiv.org/pdf/2209.09513.pdf ""ScienceQA (2022) — arXiv"".pdf"
2018,Search-based Program Synthesis,https://www.cis.upenn.edu/~alur/CACM18.pdf
2024,Searching Latent Program Spaces,https://arcprize.org/competitions/2024/
2024,Searching Latent Program Spaces,"https://arxiv.org/pdf/2411.08706.pdf ""Searching Latent Program Spaces (2024) — arXiv"".pdf"
2021,SegFormer,https://arxiv.org/pdf/2105.15203.pdf
2021,SegFormer,https://arxiv.org/pdf/2105.15203.pdf
2021,SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers,"https://arxiv.org/pdf/2105.15203.pdf ""SegFormer (2021) — arXiv"".pdf"
2021,SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers,"https://arxiv.org/pdf/2105.15203.pdf ""SegFormer (2021) — arXiv"".pdf"
2024,SegPoint: Segment Any Point Cloud via Large Language,MISSING
2023,Segment Anything,"https://arxiv.org/pdf/2304.02643.pdf ""Segment Anything (2023) — arXiv"".pdf"
2023,Segment Anything,"https://arxiv.org/pdf/2304.02643.pdf ""Segment Anything (2023) — arXiv"".pdf"
2023,Segment Anything (SAM),https://openaccess.thecvf.com/content/ICCV2023/papers/Kirillov_Segment_Anything_ICCV_2023_paper.pdf
2025,Selective Rotary Position Embedding,"https://arxiv.org/pdf/2511.17388.pdf ""Selective Rotary Position Embedding (2025) — arXiv"".pdf"
2018,Self-Attention with Relative Position Representations,https://arxiv.org/pdf/1803.02155.pdf
2018,Self-Attention with Relative Position Representations,https://arxiv.org/pdf/1803.02155.pdf
2018,Self-Attention with Relative Position Representations,https://arxiv.org/pdf/1803.02155.pdf
2018,Self-Attention with Relative Position Representations,https://arxiv.org/pdf/1803.02155.pdf
2022,Self-Consistency Improves Chain-of-Thought Reasoning,https://arxiv.org/pdf/2203.11171.pdf
2022,Self-Consistency for Chain-of-Thought,MISSING
2025,Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI (SOAR),https://openreview.net/pdf?id=z4IG090qt2
2025,Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI (SOAR),https://arcprize.org/blog/arc-prize-2025-results-analysis
2023,Self-Refine: Iterative Refinement with Self-Feedback,https://arxiv.org/pdf/2303.17651.pdf
1992,Separate visual pathways for perception and action,https://pubmed.ncbi.nlm.nih.gov/1374953/
2018,Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks,https://arxiv.org/pdf/1810.00825.pdf
2018,Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks,MISSING
2020,Sharpness-Aware Minimization (SAM),MISSING
2020,Shortformer: Better Language Modeling using Shorter Inputs,https://arxiv.org/pdf/2012.15832.pdf
2020,Shortformer: Better Language Modeling using Shorter Inputs,https://arxiv.org/pdf/2012.15832.pdf
1992,Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning (REINFORCE),https://link.springer.com/article/10.1007/BF00992696
2024,Simultaneous Instance Pooling & Bag Selection for MIL using ViTs,"https://doi.org/10.1007/s00521-024-09417-3 ""MIL with ViTs (2024) — Springer"""
