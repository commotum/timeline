year,title,url
2018,Recurrent Relational Networks,"https://proceedings.neurips.cc/paper_files/paper/2018/file/b9f94c77652c9a76fc8a442748cd54bd-Paper.pdf ""Recurrent Relational Networks (2018) — NeurIPS"""
2018,Recurrent Relational Networks (RRN),https://papers.neurips.cc/paper/7597-recurrent-relational-networks.pdf
2018,Recurrent Relational Networks (RRN),https://arxiv.org/pdf/1711.08028.pdf
2025,Reflection System for the Abstraction and Reasoning Corpus,https://openreview.net/forum?id=kRFwzuv0ze
2023,Reflexion / Self-Refine family (test-time improvement loops),MISSING
2023,Reflexion: Language Agents with Verbal Reinforcement Learning,https://arxiv.org/pdf/2303.11366.pdf
2025,Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_Relation3D__Enhancing_Relation_Modeling_for_Point_Cloud_Instance_Segmentation_CVPR_2025_paper.html
2010,Relative Entropy Policy Search (REPS),https://ojs.aaai.org/index.php/AAAI/article/view/7727
2024,Repeated Examples Help Learn Arithmetic,https://openreview.net/pdf?id=qoUHqnE6A0
2024,Resonance RoPE: Improving Context Length Generalization of Large Language Models,https://arxiv.org/pdf/2403.00071.pdf
2024,Resonance RoPE: Improving Context Length Generalization of Large Language Models,https://aclanthology.org/2024.findings-acl.32.pdf
2025,RetentiveBEV: BEV transformer for visual 3D object detection,https://journals.sagepub.com/doi/10.1177/01423312241308367
2020,Rethinking Attention with Performers,https://arxiv.org/pdf/2009.14794
2020,Rethinking Attention with Performers,https://arxiv.org/pdf/2009.14794
2020,Rethinking Positional Encoding in Language Pre-training (TUPE),https://openreview.net/pdf?id=09-528y2Fgf
2020,Rethinking Positional Encoding in Language Pre-training (TUPE),https://arxiv.org/pdf/2006.15595
2020,Rethinking Positional Encoding in Language Pre-training (TUPE),https://arxiv.org/pdf/2006.15595
2020,Rethinking Positional Encoding in Language Pre-training (TUPE),https://arxiv.org/pdf/2006.15595
2025,Rethinking Visual Intelligence: Insights from Video Pretraining,https://arcprize.org/blog/arc-prize-2025-results-analysis
2021,Rethinking and Improving Relative Position Encoding for Vision Transformer (iRPE),https://arxiv.org/pdf/2107.14222.pdf
2025,Revisiting the Test-Time Scaling of o1-like Models,https://aclanthology.org/2025.acl-long.232.pdf
2024,"Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning (PAV / ""progress rewards"")",https://arxiv.org/pdf/2410.08146.pdf
2021,RoFormer: Enhanced Transformer with Rotary Position Embedding,https://arxiv.org/pdf/2104.09864
2021,RoFormer: Enhanced Transformer with Rotary Position Embedding,https://arxiv.org/pdf/2104.09864
2021,RoFormer: Enhanced Transformer with Rotary Position Embedding,https://arxiv.org/pdf/2104.09864
2021,RoFormer: Enhanced Transformer with Rotary Position Embedding (RoPE),https://arxiv.org/pdf/2104.09864.pdf
2021,RoFormer: Enhanced Transformer with Rotary Position Embedding (RoPE),"https://arxiv.org/pdf/2104.09864.pdf ""RoFormer (2021) — arXiv"""
2024,RoPE scaling analysis + new scaling,https://aclanthology.org/2024.emnlp-main.414.pdf
2024,RoTHP: Rotary Position Embedding-based Transformer Hawkes Process,"https://arxiv.org/pdf/2405.06985.pdf ""RoTHP (2024) — arXiv"""
2017,RobustFill: Neural Program Learning under Noisy I/O,https://arxiv.org/pdf/1703.07469.pdf
2017,RobustFill: Neural Program Learning under Noisy I/O,https://github.com/thelmuth/program-synthesis-benchmark-datasets
