                                    (a) Learned Frey Face manifold                   (b) Learned MNIST manifold
                             Figure 4: Visualisations of learned data manifold for generative models with two-dimensional latent
                             space, learned with AEVB. Since the prior of the latent space is Gaussian, linearly spaced coor-
                             dinates on the unit square were transformed through the inverse CDF of the Gaussian to produce
                             values of the latent variables z. For each of these values z, we plotted the corresponding generative
                             p (x|z) with the learned parameters θ.
                              θ
                                   (a) 2-D latent space     (b) 5-D latent space    (c) 10-D latent space    (d) 20-D latent space
                             Figure 5: RandomsamplesfromlearnedgenerativemodelsofMNISTfordifferentdimensionalities
                             of latent space.
                             B Solutionof−D                (q (z)||p (z)), Gaussian case
                                                       KL φ           θ
                             The variational lower bound (the objective to be maximized) contains a KL term that can often be
                             integrated analytically. Here we give the solution when both the prior pθ(z) = N(0,I) and the
                             posterior approximation qφ(z|x(i)) are Gaussian. Let J be the dimensionality of z. Let µ and σ
                             denote the variational mean and s.d. evaluated at datapoint i, and let µ and σ simply denote the
                                                                                                         j       j
                             j-th element of these vectors. Then:
                                                    Z q (z)logp(z)dz = Z N(z;µ,σ2)logN(z;0,I)dz
                                                        θ
                                                                                                 J
                                                                               J             1 X 2          2
                                                                          =− log(2π)−              (µ +σ )
                                                                               2             2        j     j
                                                                                               j=1
                                                                                10
