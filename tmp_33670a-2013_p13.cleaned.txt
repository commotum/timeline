                             whereagaintheÔ¨ÅrstRHStermistheKLdivergenceoftheapproximatefromthetrueposterior,and
                             L(Œ∏,œÜ;x)isthevariational lower bound of the marginal likelihood of datapoint i:
                                                     (i)    Z                     (i)                                
                                          L(Œ∏,œÜ;x )=           q (z|x) logp (x |z)+logp (z)‚àílogq (z|x) dz                          (16)
                                                                œÜ              Œ∏                 Œ∏            œÜ
                             TheexpectationsontheRHSofeqs (14)and(16)canobviouslybewrittenasasumofthreeseparate
                             expectations, of which the second and third component can sometimes be analytically solved, e.g.
                             when both p (x) and q (z|x) are Gaussian. For generality we will here assume that each of these
                                           Œ∏          œÜ
                             expectations is intractable.
                             Under certain mild conditions outlined in section (see paper) for chosen approximate posteriors
                                                                                                 e
                             q (Œ∏) and q (z|x) we can reparameterize conditional samples z ‚àº q (z|x) as
                               œÜ          œÜ                                                            œÜ
                                                                 e
                                                                 z = g (,x)      with     ‚àº p()                                 (17)
                                                                        œÜ
                             where we choose a prior p() and a function gœÜ(,x) such that the following holds:
                                              (i)    Z                     (i)                                
                                   L(Œ∏,œÜ;x )=           q (z|x) logp (x |z)+logp (z)‚àílogq (z|x) dz
                                                         œÜ              Œ∏                 Œ∏            œÜ
                                                     Z                                                    
                                                                        (i)                                  
                                                  = p() logp (x |z)+logp (z)‚àílogq (z|x)                                 d       (18)
                                                                    Œ∏                 Œ∏            œÜ         
                                                                                                              z=gœÜ(,x(i))
                             Thesamecanbedonefortheapproximateposterior qœÜ(Œ∏):
                                                                  e
                                                                  Œ∏ = h (Œ∂)      with    Œ∂ ‚àº p(Œ∂)                                  (19)
                                                                         œÜ
                             where we, similarly as above, choose a prior p(Œ∂) and a function h (Œ∂) such that the following
                                                                                                        œÜ
                             holds:                       Z
                                             L(œÜ;X)=         q (Œ∏)(logp (X)+logp (Œ∏)‚àílogq (Œ∏)) dŒ∏
                                                              œÜ           Œ∏             Œ±             œÜ
                                                          Z                                                
                                                                                                           
                                                       = p(Œ∂)(logp (X)+logp (Œ∏)‚àílogq (Œ∏))                           dŒ∂            (20)
                                                                         Œ∏             Œ±             œÜ     
                                                                                                            Œ∏=h (Œ∂)
                                                                                                                œÜ
                             For notational conciseness we introduce a shorthand notation fœÜ(x,z,Œ∏):
                                   f (x,z,Œ∏) = N ¬∑(logp (x|z)+logp (z)‚àílogq (z|x))+logp (Œ∏)‚àílogq (Œ∏)                               (21)
                                    œÜ                        Œ∏               Œ∏            œÜ                Œ±            œÜ
                             Using equations (20) and (18), the Monte Carlo estimate of the variational lower bound, given
                             datapoint x(i), is:
                                                                        L
                                                                     1 X         (l)      (l)  (l)       (l)
                                                       L(œÜ;X)'             f (x ,g ( ,x ),h (Œ∂ ))                                 (22)
                                                                    L        œÜ        œÜ              œÜ
                                                                       l=1
                                      (l)                (l)
                             where       ‚àº p() and Œ∂      ‚àº p(Œ∂). The estimator only depends on samples from p() and p(Œ∂)
                             which are obviously not inÔ¨Çuenced by œÜ, therefore the estimator can be differentiated w.r.t. œÜ.
                             The resulting stochastic gradients can be used in conjunction with stochastic optimization methods
                             such as SGD or Adagrad [DHS10]. See algorithm 1 for a basic approach to computing stochastic
                             gradients.
                             F.1   Example
                             Let the prior over the parameters and latent variables be the centered isotropic Gaussian pŒ±(Œ∏) =
                             N(z;0,I) and p (z) = N(z;0,I). Note that in this case, the prior lacks parameters. Let‚Äôs also
                                               Œ∏
                             assume that the true posteriors are approximatily Gaussian with an approximately diagonal covari-
                             ance. In this case, we can let the variational approximate posteriors be multivariate Gaussians with
                             a diagonal covariance structure:
                                                                  logq (Œ∏) = logN(Œ∏;¬µ ,œÉ2I)
                                                                        œÜ                    Œ∏   Œ∏
                                                                logq (z|x) = logN(z;¬µ ,œÉ2I)                                        (23)
                                                                     œÜ                      z    z
                                                                                 13
