of the time-dependent data corruptions.

Regarding the second challenge of how to use the
frames, we design a frame-guided 4D leaming scheme
as shown in Figure 2. Particularly, we design a frame-
guided 4D convolution operator which can generate local
and global features based on different frames at different
scales. By cascading a series of frame-guided 4D con-
volution operators in a similar way to existing 4D back-
bones [9, |!], we can extract 4D features under the guid-
ance of hierarchical frames. To keep the motion information
from the 4D input, we leverage two frame-guided 4D con-
volution branches with shared weights. For one branch, the
frames are just our learned region frames from the frame
learning module. For the other branch, we use a constant
camera frame across all timestamps and at all scales. The
first branch focuses on motion-agnostic geometric feature
learning while the second branch complements the motion
cues. A region frame-guided transformer is designed to fuse
the two branches for effective spatial-temporal features.

The designs above enable us to achieve various 4D point
cloud understanding tasks effectively including 3D action
segmentation, 3D action recognition, and 4D semantic seg-
mentation for both indoor and outdoor scenarios.

3.2. Hierarchical Frame Learning Module

In this section, we first revisit the concept of SO(3)-
equivariance and SO(3)-invariance of 3D point cloud. Then
we introduce the local-global frame learning pipeline with
equivariant neural network in detail. Besides, in order to
learn geometrically-stable and temporally-consistent local
coordinate frames, we also introduce a frame stabilization
scheme to regularize the frame leaming process.

Revisit equivariance and invariance. Given a group G
and a certain domain V, a group action of G on V is a map-
ping from G x V to V (written as g - v for all g € G and
v € V), where each g corresponds to a bijection on V. A
mapping ® : X — Y is equivariant with respect to a group
G (and its group action on X, Y), if for every g € G,a € X,

(gx) =9- P(x). (dy

Further, if the group action of G on Y is trivial, (‘.e.,
g-y = y for any g € G,y € Y,) we say © is invariant
with respect to G. For convenience, we also say ®(a:) is
equivariant or invariant if is equivariant or invariant.

For point clouds, let X = R”*® be the input domain,
and Y be the output domain. Permutation, translation, and
SO(3) rotation equivariance are usually taken into consid-
eration for point cloud networks. Consider a point cloud
X = (x1, X2,-+ Xn)? © X. For the * permutation group
Sn, for some o € Sy,o-X = (Kea WXo(n))E
For the translation group R*, for some . ¢ Riv-X=
(X1+V, Xo +V,-+- ,Xn+v)”. For the rotation group SO(3),

607

EJ)

ra Sequence

Equivtayer!

)== BramcGen es)
Local i Local Frames
EquivLays

a Pamecen (A |

Global Anchor Global Frame
Figure 3. Illustration of hierarchical Frame Learning Module. In-
variant features and equivariant features are extracted progres-
sively by EquivLayer, and are then used to generate frames by
FrameGen at each scale.

)?, where each g corresponds
and g:x = Rx.

9X = (9X1, 9X2 Gg
to a rotation matrix R € R

Hierarchical frame learning. It is a challenging problem
to learn geometry-based and temporally-consistent local co-
ordinate frames to align the local region and factorize the
underlying geometry feature from its motion. We need to
construct hierarchical local region frames to accurately de-
pict the orientations of local regions. And the established
local coordinate frames should be based upon the 3D ge-
ometry in each timestamp and transform in the same way as
the underlying geometry changes. To satisfy such require-
ments, we draw inspiration from the equivariant 3D point
cloud analysis [22] and propose to use an equivariant net-
work to learn the geometry-based rotation equivariant local
coordinate frames F at different scales as shown in Figure 3.

Let X' denote the downsampled point cloud at layer
1 with N’ points. Let H' and V! denote per-point in-
variant jar features and equivariant vector features of
X', respectively. We use X°, H°,V° to denote the input
point cloud, invariant scalar and equivariant vector features,
where H®, V° are all zeros. And we pass the featured point
cloud to a hierarchical equivariant network that aims to ex-
tract hierarchical invariant and equivariant features. Our
EquivLayer is adapted from the GVP-GNN layer [141] and
we defer the details to the supplementary material.

cx’) Att w+1) < EquivLayer’+(x!, H!,v'). (2)

Since EquivLayer'*! is equivariant at all the layers, and

the inputs H°, V° are invariant and equivariant features, the
output H', V! of each layer are also invariant and equivari-
