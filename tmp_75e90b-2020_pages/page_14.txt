Published as a conference paper at ICLR 2021

Table 4: GLUE scores on dev set. Different models are pre-trained in the ELECTRA-Base setting
(120M) with 16GB data. Electra-TUPE™ is the intermediate 600k-step checkpoint of ELECTRA-
TUPE.

Steps MNLI-m/nmm QNLI QQP SST CoLA MRPC RTE STS Avg.

ELECTRA IM 86.42/86.14 92.19 91.45 92.97 65.92 89.74 73.56 89.99 85.38
ELECTRA-TUPE 1M  86.98/87.01 92.03 91.75 93.97 66.51 89.74 76.53 90.13 86.07
ELECTRA-TUPE™ 600k 86.72/86.74 91.84 91.72 93.30 66.42 89.34 75.64 89.67 85.71

14
