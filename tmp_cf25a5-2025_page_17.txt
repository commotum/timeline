                                                          Test-Time Learning for Large Language Models
                                                                       Geography         Logiqa
                                                          Agriculture                               MetaMath
                                                                                     ReasoningBench
                                                                     DomainBench
                                                       Medicine                                           GSM8K
                                                                                InstructionBench
                                                            Finance                               InstructionWild
                                                                          Dolly       AlpacaGpt4En
                                                                 Figure 4. Distributions of AdaptEval.
                backpropagation by learning a prompt through a derivative-free covariance matrix adaptation strategy and adjusting model
                activations to align with the source training domain. Looking forward, there is great potential to extend our method to the
                realm of efficient BP-Free TTA, thereby further broadening the practical applicability of our approach in diverse real-world
                scenarios.
                B. AdaptEval Benchmark
                Tothe best of our knowledge, no existing benchmark is specifically designed to evaluate the adaptability of Large Language
                Models(LLMs)acrossdiversedata distributions. Since the diversity of tasks and domains inherently captures variations
                in data distributions, we address this gap by introducing a comprehensive benchmark, AdaptEval, which spans a wide
                range of tasks and domains to thoroughly assess the effectiveness of our proposed TLM. AdaptEval is designed to capture
                two primary types of out-of-distribution (OOD) scenarios at test time: vertical domain shift and distributional shift in
                non-specific domains, as described in the previous section. To build a diverse and challenging evaluation framework, we
                collect high-quality datasets from HuggingFace, ensuring coverage across various data distributions. Specifically, AdaptEval
                consists of three categories of datasets: DomainBench, InstructionBench, and ReasoningBench. These categories are
                tailored to evaluate LLMs’ adaptability to tasks requiring vertical knowledge, instruction-following capabilities, and logical
                reasoning under distribution shifts. A summary of the datasets included in AdaptEval is presented in Table 6, with further
                analysis provided below.
                AdaptEval consists of the following three core categories, as shown in Figure 4.
                   • DomainBench. This category includes four vertical domain knowledge datasets: Geography, Agriculture, Medicine,
                      andFinance. ItevaluatestheadaptabilityofLLMstospecializedfieldsbyassessingtheirabilitytohandletasksrequiring
                      domain-specific expertise, such as named entity recognition, judgment, and question answering. By incorporating
                      domain-specific terminology and real-world complexities that may challenge model performance, DomainBench
                      provides a rigorous evaluation of models’ proficiency in mastering and applying specialized knowledge.
                   • InstructionBench. This category comprises three general-purpose instruction-following datasets: Alpaca-GPT4, Dolly,
                      and InstructionWild. It evaluates the adaptability of LLms to instruction-based tasks by assessing their ability to
                      comprehend, interpret, and execute a diverse range of user instructions. The datasets cover various task types, such as
                      question answering, text classification, and summarization, while introducing variations in user intent, phrasing, and
                                                                                  17
