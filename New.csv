2023,Sigmoid Loss for Language Image Pre-Training,https://arxiv.org/pdf/2303.15343.pdf
2020,Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains,https://arxiv.org/pdf/2006.10739.pdf
2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf
2023,Visual Instruction Tuning,https://arxiv.org/pdf/2304.08485.pdf
2015,"You Only Look Once: Unified, Real-Time Object Detection",https://arxiv.org/pdf/1506.02640.pdf
2025,Positional Encoding Field,https://arxiv.org/pdf/2510.20385v1.pdf
2025,Behind RoPE: How Does Causal Mask Encode Positional Information?,https://arxiv.org/pdf/2509.21042.pdf
2025,Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features,https://arxiv.org/pdf/2509.16629.pdf
2025,HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models,https://arxiv.org/pdf/2509.05218.pdf
2024,Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics,https://arxiv.org/pdf/2405.14806.pdf
2019,LXMERT: Learning Cross-Modality Encoder Representations from Transformers,https://arxiv.org/pdf/1908.07490
2019,ViLBERT: Pretraining Task-Agnostic V-L Representations,https://arxiv.org/pdf/1908.02265.pdf
2019,VisualBERT: A Simple and Performant Baseline for Vision and Language,https://arxiv.org/pdf/1908.03557.pdf
2019,Deep Equilibrium Models,https://arxiv.org/pdf/1909.01377.pdf
2019,VideoBERT: A Joint Model for Video and Language Representation Learning,https://arxiv.org/pdf/1904.01766.pdf
2020,Deformable DETR: Deformable Transformers for End-to-End Object Detection,https://arxiv.org/pdf/2010.04159.pdf
2020,Training data-efficient image transformers & distillation through attention,https://arxiv.org/pdf/2012.12877.pdf
2020,Taming Transformers for High-Resolution Image Synthesis,https://arxiv.org/pdf/2012.09841.pdf
2021,Zero-Shot Text-to-Image Generation,https://arxiv.org/pdf/2102.12092.pdf
2021,Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions,https://arxiv.org/pdf/2102.12122.pdf
2021,CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification,https://arxiv.org/pdf/2103.14899.pdf
2021,CvT: Introducing Convolutions to Vision Transformers,https://arxiv.org/pdf/2103.15808.pdf
2021,Transformer in Transformer,https://arxiv.org/pdf/2103.00112.pdf
2021,Twins: Revisiting the Design of Spatial Attention in Vision Transformers,https://arxiv.org/pdf/2104.13840.pdf
2021,SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers,https://arxiv.org/pdf/2105.15203.pdf
2021,BEiT: BERT Pre-Training of Image Transformers,https://arxiv.org/pdf/2106.08254.pdf
2021,CoAtNet: Marrying Convolution and Attention for All Data Sizes,https://arxiv.org/pdf/2106.04803.pdf
2021,CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows,https://arxiv.org/pdf/2107.00652.pdf
2021,Swin Transformer V2: Scaling Up Capacity and Resolution,https://arxiv.org/pdf/2111.09883.pdf
2022,MaxViT: Multi-Axis Vision Transformer,https://arxiv.org/pdf/2204.01697.pdf
2022,Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks,https://arxiv.org/pdf/2208.10442.pdf
2023,Segment Anything,https://arxiv.org/pdf/2304.02643.pdf
2021,3DETR: An End-to-End Transformer Model for 3D Object Detection,https://arxiv.org/pdf/2109.08141.pdf
2025,Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical Abilities in Large Language Models,https://arxiv.org/pdf/2502.11075.pdf
2017,A Distributional Perspective on Reinforcement Learning,https://arxiv.org/pdf/1707.06887.pdf
2025,A Fully First-Order Layer for Differentiable Optimization,https://arxiv.org/pdf/2512.02494.pdf
1984,A Theory of the Learnable (PAC Learning),https://web.mit.edu/6.435/www/Valiant84.pdf
2022,A-OKVQA: A Benchmark for VQA Using World Knowledge,https://arxiv.org/pdf/2206.01718.pdf
2022,miniF2F: a cross-system benchmark for formal Olympiad-level mathematics,https://arxiv.org/pdf/2109.00110.pdf
