                                                        Test-Time Learning for Large Language Models
               However, it is often constrained by the need for extensive          is often impractical. Unlike TTT, our focus is on TTL,
               labeled datasets and high computational costs, which limit          whichdynamicallyupdatesLLMsduringtesttimeusing
               its practicality in dynamic environments where data distri-         only unlabeled test data.
               butions are continuously evolving. In contrast, our work
               aims to dynamically update the model at test-time using             3. Problem Formulation
               unlabeled input data, eliminating the need for extensive
               labeled datasets and addressing the challenges posed by             Without loss of generality, let P(x) denote the distribution
               evolving data distributions.                                                                 N                                ◦
                                                                                   of the training data {x }    , where x ∼ P(x). The f       (x)
                                                                                                          i i=1           i                Θ
               Retrieval-Augmented Generation (RAG) incorporates ex-               represent a general Large Language Model (LLM) that has
               ternal knowledge by retrieving relevant information from a          been supervised fine-tuned (SFT) on labeled training data
                                                                                             N                          ◦
                                                                                   {(x ,y )}     , with parameters Θ . During training, the
               knowledge base during inference (Jiang et al., 2024; Qian               i  i  i=1
                                                                                   modelf ◦(x)isoptimizedtogenerate coherent and contex-
               et al., 2024; Asai et al., 2024). This allows the model to gen-             Θ
               erate more accurate and contextually grounded responses             tually appropriate sequences by predicting the next token
               without requiring parameter updates. Qian et al. (2024) pro-        in an autoregressive manner, effectively fitting the training
               pose MemoRAG,aretrieval-augmented generation frame-                 data and generalizing to test data from the same distribution
               work enhanced by long-term memory for improved task                 x∼P(x). However,inreal-world deployments, the distri-
               performance. RAG is effective for tasks requiring up-to-            bution of test data may differ significantly from the training
               date or domain knowledge but relies heavily on the quality          distribution due to various factors, leading to a phenomenon
               of retrieved information and incurs additional computational        knownasdistributionshift. ForgeneralLLMs(e.g.,LLaMA
               latency, limiting its suitability for time-sensitive tasks.         and Qwen), two primary types of out-of-distribution (OOD)
                                                                                   scenarios can occur during inference: 1) Vertical Domain
               Test-Time Adaptation (TTA) dynamically updates model                Shift: This occurs when test data contains domain-specific
               parameters during inference by utilizing unlabeled test data        terminology, such as in medical, legal, or technical fields,
               (Wang et al., 2021; Niu et al., 2022a; 2023; Chen et al.,           which the model was not explicitly trained on, impairing its
               2024b;a; Liang et al., 2024; Yi et al., 2024). This approach        performance. 2) Distributional Shift in Non-Specific Do-
               enables real-time adaptation to distributional shifts, making       mains: Even without a specific vertical domain, factors like
               it suitable for scenarios where labeled data is unavailable         user intent variations and linguistic diversity (e.g., dialects,
               or the test data distribution deviates significantly from the       slang) can shift test data distribution from training data, af-
               training distribution. Wang et al. (2021) propose the test          fecting model understanding and response generation. In
               entropy minimization method, which improves model con-              these cases, the generative performance of the model f ◦(x)
                                                                                                                                           Θ
               fidence by minimizing prediction entropy through online             maydeterioratesignificantlybecausethemodelhasnotbeen
               updates of normalization statistics and affine transforma-          explicitly trained to handle such distribution shifts, resulting
               tions. Most TTA methods rely on entropy minimization,               in less coherent or contextually appropriate text generation
               but this approach is not well-suited for the dynamic updates        onOODtestsamplesx ∼ Q(x),whereQ(x) ̸= P(x).
               required by LLMs, as shown in Figure 1a. To address this            Test-Time Learning (TTL) seeks to improve the perfor-
               issue, we propose minimizing the perplexity of test samples         manceofLLMsinthetargetdomainbyadjustingthemodel
               as the optimization objective, which effectively enhances           using only test data. Specifically, given a set of OOD test
               the performance of LLMs in dynamic environments.                    samples {x }M , where x ∼ Q(x), the goal of TTL is to
                                                                                               j j=1           j
               Test-Time Training (TTT) retrieves relevant data from               optimize the model parameters Θ to improve the quality and
               the training set or a knowledge base during inference and           coherence of generated text for these test samples. Formally,
               uses it to fine-tune the models (Niu et al., 2022b; Hardt &         TTLcanbeframedasthefollowingoptimization problem,
                              ¨
               Sun, 2024; Hubotter et al., 2024). This allows the model to         wheretheobjective is to minimize an unsupervised criterion
               leverage adjacent data to better adapt to current test inputs,      defined over the test data:
               improving its performance in dynamic scenarios. Hardt &
               Sun(2024) propose a test-time training approach for LLMs                             minL(x;Θ), x∼Q(x),                         (1)
               byfine-tuningthemodelonretrievednearestneighborsfrom                                  Θ
                                                         ¨
               a large-scale text embedding index. Hubotter et al. (2024)
               propose SIFT, a data selection algorithm that optimizes             where Θ ⊆ Θrepresents the subset of model parameters to
               information gain to outperform Nearest Neighbor retrieval           beupdatedduringtheTTL.TheTTLobjectiveL(·)cantake
               for test-time fine-tuning with low computational overhead.          various forms, such as minimizing the perplexity. The key
               However, TTT assumes that the model’s training data or              challenge of TTL is to design efficient adaptation strategies
               knowledge base is accessible during deployment, and the             that can utilize unlabeled test data to improve performance
               retrieval process introduces computational overhead, which          on OODsampleswhilemaintaining training efficiency and
                                                                                   effectively mitigating catastrophic forgetting.
                                                                                3
