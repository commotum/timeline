                           Preprint.
                           memorymodality (text vs. continuous vectors/embeddings), and (3) emphasis on abstraction and
                           modularity for reasoning. We discuss related lines (1) and (2) as well as other related work in
                           Appendix E and emphasize reasoning and abstraction here.
                           Memory for Test-Time Reasoning and Concept Abstraction.           More recent work has shifted
                           toward reasoning-centric uses of memory, particularly test-time learning. Think-in-Memory records
                           intermediate reasoning steps as structured triples, storing them in a locality-sensitive hash table to
                           enable reuse in multi-step reasoning tasks (Liu et al., 2023). Buffer of Thoughts stores problem
                           specific reasoning templates, retrieved by embedding similarity and instantiated for new inputs (Yang
                           et al., 2024). It categorizes and summarizes solution attempts into templated insights, which are
                           then added to memory. In contrast, Dynamic Cheatsheet maintains a unified buffer that is adapted
                           continuously. With each problem query, the LLM updates this memory blob by rewriting the entire
                           buffer (Suzgun et al., 2025). Rather than retrieving specific entries, the entire cheatsheet is appended
                           to the prompt, functioning as a persistent cache of problem-solving strategies.
                           ARC-AGIApproaches. OurworkisprimarilyevaluatedagainstARC-AGIasabenchmarkthat
                           simulates complex reasoning on frontier tasks without requiring frontier-level knowledge. Various
                           techniques and findings have been developed against this benchmark. Li et al. (2024) demonstrates
                           the efficacy of synthetic data and the complementary approaches of (i) learning to infer the underlying
                           transformation via program synthesis and (ii) using test-time weight adaptation to directly learn the
                           transformation function in the neural net. Akyürek et al. (2025) further investigates the test-time
                           adaptation method, producing various insights, including that low rank adapters are poorly suited
                           to retaining practical experience across puzzles. Our program synthesis approach can be viewed
                           as a memory-augmented version of Wang et al. (2024)’s hypothesis search or Qiu et al. (2024)’s
                           hypothesis refinement with execution feedback-based retry. Other recent approaches to ARC-AGI
                           include brain-inspired architectural innovations such as Wang et al. (2025)’s hierarchical reasoning
                           model, achieving impressive performance through a recurrent architecture that iteratively refines
                           its output until a halt signal is predicted, together with data augmentation techniques. Finally, the
                           relative ease of generating new ARC-AGI tasks compared to solving them is exploited in Pourcel
                           et al. (2025)’s self-improving system that relabels incorrect programs as the correct program for a
                           different puzzle and trains a model on its generations this way.
                           3   METHODS
                           3.1  PROBLEM STATEMENT
                           Algorithm 1: Inference with Continually Updating External Memory
                           Input: Dataset D = {x ,y }n  (labels y optional), External memory M, Operations MEMREAD,
                                                i  i i=1        i
                                 MEMWRITE,GETFEEDBACK,Updateintervalk,
                           Output: Predictions {yˆ }
                                               i
                           for i ← 1 to n do
                              (x ,y ) ← GETITEM(D,i);                 // Label y may be absent at inference
                                i  i                                               i
                              s ←MEMREAD(M,x );                           // Retrieve relevant memory entries
                               i                   i
                              yˆ ← LLM_GENERATE(x ,s );               // Predict using LLM + selected memory
                               i                      i  i
                              if i mod k = 0 then
                                  f ←GETFEEDBACK(yˆ,y );              // test verification, reflection, etc.
                                   i                   i  i
                                  MEMWRITE(M,x ,yˆ,f );                   // Incorporate feedback into memory
                                                   i  i i
                           Weformulate a memory system as a collection of memory entries associated with read and write op-
                           erations. Problem solving with memory augmented LLMs thus requires designing three components
                           as seen in algorithm 1:
                                1. MemoryFormat(3.2): Whatisstored in individual entries?
                                2. MemoryWrite(3.3): Howismemoryupdatedfromareasoningtrace?
                                3. MemoryRead(3.4): Howismemoryusedfortacklingnewproblems?
                           These are generic design considerations for any memory. Our method’s novelty lies in the choices
                           madetotarget (1) abstracting a memory to be less specific to the problem it was derived from (2)
                                                                          3
