                                                                                                                                                                                                                                                                                                                      Available  online  at  www.sciencedirect.com
                                                                                                                                                                                                                                                                                                                                                                                      ScienceDirect
                                                                                                Going  in  circles  is  the  way  forward:  the  role  of
                                                                                                recurrence
                                                                                                                                                                                                                                                           in  visual  inference
                                                                                                Ruben  S  van  Bergen1 and  Nikolaus  Kriegeskorte1,2,3,4
                                                                                                Biological  visual  systems  exhibit  abundant  recurrent                                                                                                                                                                                                                                                                                                                                                                                                             visual  perception  can  be  disturbed  by  carefully  timed
                                                                                                connectivity.  State-of-the-art  neural  network  models  for  visual                                                                                                                                                                                                                                                                                                                                                                                                 interventions  that  coincide  with  the  arrival  of  re-entrant
                                                                                                recognition,  by  contrast,  rely  heavily  or  exclusively  on                                                                                                                                                                                                                                                                                                                                                                                                       information  to  a  visual  area  [12–15].  The  evidence  for
                                                                                                feedforward  computation.  Any  ﬁnite-time  recurrent  neural                                                                                                                                                                                                                                                                                                                                                                                                         recurrent  computation  in  the  primate  brain,  thus,  is
                                                                                                network (RNN) can be unrolled along time to yield an equivalent                                                                                                                                                                                                                                                                                                                                                                                                       unequivocal.  What  is  less  obvious,  however,  is  why  the
                                                                                                feedforward  neural  network  (FNN).  This  important  insight                                                                                                                                                                                                                                                                                                                                                                                                        brain  uses  a  recurrent  algorithm.
                                                                                                suggests  that  computational  neuroscientists  may  not  need  to
                                                                                                engage  recurrent  computation,  and  that  computer-vision                                                                                                                                                                                                                                                                                                                                                                                                           This  question  has  recently  been  brought  into  sharper  focus
                                                                                                engineers  may  be  limiting  themselves  to  a  special  case  of  FNN                                                                                                                                                                                                                                                                                                                                                                                               by the successes of deep feedforward neural network models
                                                                                                if  they  build  recurrent  models.  Here  we  argue,  to  the  contrary,                                                                                                                                                                                                                                                                                                                                                                                             (FNNs) [16,17]. These models now match or exceed human
                                                                                                that  FNNs  are  a  special  case  of  RNNs  and  that  computational                                                                                                                                                                                                                                                                                                                                                                                                 performance  on  certain  visual  tasks  [18–20],  and  better
                                                                                                neuroscientists  and  engineers  should  engage  recurrence  to                                                                                                                                                                                                                                                                                                                                                                                                       predict  primate  recognition  behavior  [21,22,23]  and  neural
                                                                                                understand  how  brains  and  machines  can  (1)  achieve  greater                                                                                                                                                                                                                                                                                                                                                                                                    activity  [24–29]  than  current  alternative  models.
                                                                                                and  more  ﬂexible  computational  depth  (2)  compress  complex
                                                                                                computations  into  limited  hardware  (3)  integrate  priors  and                                                                                                                                                                                                                                                                                                                                                                                                    Although  computer  vision  and  computational  neurosci-
                                                                                                priorities  into  visual  inference  through  expectation  and                                                                                                                                                                                                                                                                                                                                                                                                        ence both have a long history of recurrent models [30–33],
                                                                                                attention  (4)  exploit  sequential  dependencies  in  their  data  for                                                                                                                                                                                                                                                                                                                                                                                               feedforward  models  have  earned  a  dominant  status  in
                                                                                                better  inference  and  prediction  and  (5)  leverage  the  power  of                                                                                                                                                                                                                                                                                                                                                                                                both  ﬁelds.  How  should  we  account  for  this  discrepancy
                                                                                                iterative  computation.                                                                                                                                                                                                                                                                                                                                                                                                                                               between  brains  and  models?
                                                                                                Addresses                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  answer  is  that  the  discrepancy  reﬂects  the  fact  that
                                                                                                1Zuckerman  Mind  Brain  Behavior  Institute,  Columbia  University,  New                                                                                                                                                                                                                                                                                                                                                                                             One
                                                                                                York,  NY,  United  States                                                                                                                                                                                                                                                                                                                                                                                                                                            brains  and  computer-vision  systems  operate  on  different
                                                                                                2Department of Psychology,  Columbia  University,  New  York,  NY,  United                                                                                                                                                                                                                                                                                                                                                                                            hardware  and  under  different  constraints  on  space,  time,
                                                                                                States                                                                                                                                                                                                                                                                                                                                                                                                                                                                and energy. Perhaps we have come to a point at which the
                                                                                                3Department  of  Neuroscience,  Columbia  University,  New  York,  NY,                                                                                                                                                                                                                                                                                                                                                                                                two  ﬁelds  must  go  their  separate  ways.  However,  this
                                                                                                United  States                                                                                                                                                                                                                                                                                                                                                                                                                                                        answer  is  unsatisfying.  Computational  neuroscience  must
                                                                                                4Afﬁliated  member,  Electrical  Engineering,  Columbia  University,  New                                                                                                                                                                                                                                                                                                                                                                                             still  ﬁnd  out  how  visual  inference  works  in  brains.  And
                                                                                                York,  NY,  United  States                                                                                                                                                                                                                                                                                                                                                                                                                                            although  engineers  face  quantitatively  different  con-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      straints  when  building  computer-vision  systems,  they,
                                                                                                     Current  Opinion  in  Neurobiology  2020,  65:176–193                                                                                                                                                                                                                                                                                                                                                                                                            too,  must  care  about  the  spatial,  temporal,  and  energetic
                                                                                                     This  review  comes  from  a  themed  issue  on  Whole-brain  interactions                                                                                                                                                                                                                                                                                                                                                                                       limitations  their  models  must  operate  under  when
                                                                                                     between  neural  circuits                                                                                                                                                                                                                                                                                                                                                                                                                                        deployed  in,  for  example,  a  smartphone.  Moreover,  as
                                                                                                     Edited  by  Larry  Abbott  and  Karel  Svoboda                                                                                                                                                                                                                                                                                                                                                                                                                   long  as  neural  network  models  continue  to  dominate
                                                                                                     For  a  complete  overview  see  the  Issue  and  the  Editorial                                                                                                                                                                                                                                                                                                                                                                                                 computer  vision,  more  efﬁcient  hardware  implementa-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      tions  are  likely  to  be  more  similar  to  biological  neural
                                                                                                     Available  online  3rd  December  2020                                                                                                                                                                                                                                                                                                                                                                                                                           networks  than  current  implementations  using  conven-
                                                                                                     https://doi.org/10.1016/j.conb.2020.11.009                                                                                                                                                                                                                                                                                                                                                                                                                       tional  processors  and  graphics  processing  units  (GPUs).
                                                                                                     0959-4388/ã  2020  The  Authors.  Published  by  Elsevier  Ltd.  This  is  an
                                                                                                     open  access  article  under  the  CC  BY  license  (http://creativecommons.                                                                                                                                                                                                                                                                                                                                                                                     A  second  explanation  for  the  discrepancy  is  that  the
                                                                                                     org/licenses/by/4.0/).                                                                                                                                                                                                                                                                                                                                                                                                                                           abundance  of  recurrent  connections  in  cortex  belies  a
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      superﬁcial  role  in  neural  computation.  Perhaps  the  core
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      computations can be performed by a feedforward network
                                                                                                Introduction                                                                                                                                                                                                                                                                                                                                                                                                                                                          [34],  while  recurrent  processing  serves  more  auxiliary  and
                                                                                                The  primate  visual  cortex  uses  a  recurrent  algorithm  to                                                                                                                                                                                                                                                                                                                                                                                                       modulatory  functions,  such  as  divisive  normalization  [35]
                                                                                                process  sensory  input  [1–3].  Anatomically,  connectivity  is                                                                                                                                                                                                                                                                                                                                                                                                      and  attention  [36–39].  This  perspective  is  convenient
                                                                                                cyclic.  Neurons  are  connected  in  cycles  within  local                                                                                                                                                                                                                                                                                                                                                                                                           because  it  enables  us  to  hold  on  to  the  feedforward
                                                                                                cortical  circuits  [4–6].  Global  inter-area  connections  are                                                                                                                                                                                                                                                                                                                                                                                                      model  in  our  minds.  The  auxiliary  and  modulatory  func-
                                                                                                dense  and  mostly  bidirectional  [7–9].  Physiologically,  the                                                                                                                                                                                                                                                                                                                                                                                                      tions  let  us  acknowledge  recurrence  without  fundamen-
                                                                                                dynamics  of  neural  responses  bear  temporal  signatures                                                                                                                                                                                                                                                                                                                                                                                                           tally  changing  the  way  we  envision  the  algorithm  of
                                                                                                indicative  of  recurrent  processing  [10,1,11].  Behaviorally,                                                                                                                                                                                                                                                                                                                                                                                                      recognition.
                                                                                                Current  Opinion  in  Neurobiology  2020,  65:176–193                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          www.sciencedirect.com
                                                                                                                                                                                                                                                Going  in  circles  is  the  way  forward:  the  role  of  recurrence  in  visual  inference  van  Bergen  and  Kriegeskorte                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       177
                                                                                                            However, there is a third and more exciting explanation for                                                                                                                                                                                                                                                                                                                                                                                                           notion  we  will  return  to  later.  Notice  how  this  temporally
                                                                                                            the  discrepancy between recurrent brains and feedforward                                                                                                                                                                                                                                                                                                                                                                                                             unrolled,  small  network  resembles  a  larger  feedforward
                                                                                                            models:  although  feedforward  computation  is  powerful,  a                                                                                                                                                                                                                                                                                                                                                                                                         neural  network  with  more  connections  and  areas  between
                                                                                                            recurrent  algorithm  provides  a  fundamentally  superior                                                                                                                                                                                                                                                                                                                                                                                                            its  input  and  output.  We  can  emphasize  this  recurrent-
                                                                                                            solution  to  the  problem  of  visual  inference,  and  this  algo-                                                                                                                                                                                                                                                                                                                                                                                                  feedforward  equivalence  by  interpreting  the  computa-
                                                                                                            rithm is  implemented in primate visual cortex. This recur-                                                                                                                                                                                                                                                                                                                                                                                                           tional  graph  over  time  as  a  spatial  architecture,  and
                                                                                                            rent  algorithm  explains  how  primate  vision  can  be  so                                                                                                                                                                                                                                                                                                                                                                                                          visually  arranging  the  induced  areas  and  connections  in
                                                                                                            efﬁcient  in  terms  of  space,  time,  energy,  and  data,  while                                                                                                                                                                                                                                                                                                                                                                                                    a  linear  spatial  sequence  —  an  operation  we  call  unrolling
                                                                                                            being so rich and robust in terms of the inferences and their                                                                                                                                                                                                                                                                                                                                                                                                         in  space  (Figure  1d).  This  results  in  a  deep  feedforward
                                                                                                            generalization  to  novel  environments.                                                                                                                                                                                                                                                                                                                                                                                                                              architecture  with  many  skip  connections  between  areas  that
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  are  separated  by  more  than  one  level  in  this  new  hierar-
                                                                                                            In  this  review,  we  argue  for  the  latter  possibility,  discuss-                                                                                                                                                                                                                                                                                                                                                                                                chy,  and  with  many  connections  that  are  exact  copies  of
                                                                                                            ing  a  range  of  potential  computational  functions  of  recur-                                                                                                                                                                                                                                                                                                                                                                                                    one  another  (sharing  identical  connection  weights).
                                                                                                            rence  and  citing  the  evidence  suggesting  that  the  primate
                                                                                                            brain  employs  them.  We  aim  to  distinguish  established                                                                                                                                                                                                                                                                                                                                                                                                          Thus,  any  ﬁnite-time  RNN  can  be  transformed  into  an
                                                                                                            from  more  speculative,  and  superﬁcial  from  more  pro-                                                                                                                                                                                                                                                                                                                                                                                                           equivalent  FNN. But this should not be taken to  mean that
                                                                                                            found  forms  of  recurrence,  so  as  to  clarify  the  most                                                                                                                                                                                                                                                                                                                                                                                                         RNNs are a special case of FNNs. In fact, FNNs are a special
                                                                                                            exciting  directions  for  future  research  that  will  close                                                                                                                                                                                                                                                                                                                                                                                                        case  of  ﬁnite-time  RNNs  (Figure  2a),  comprising  those
                                                                                                            the  gap  between  models  and  brains.                                                                                                                                                                                                                                                                                                                                                                                                                               which happen to have no cycles. More practically, not every
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  unrolled  ﬁnite-time  RNN  is  a  realistic  FNN  (Figure  2b).  By
                                                                                                            Unrolling  a  recurrent  network                                                                                                                                                                                                                                                                                                                                                                                                                                      realistic  networks,  we  mean  networks  that  conform  to  the
                                                                                                            What  exactly  do  we  mean  when  we  say  that  a  neural                                                                                                                                                                                                                                                                                                                                                                                                           real-world  constraints  the  system  must  operate  under.  For
                                                                                                            network  —  whether  biological  or  artiﬁcial  —  is  recurrent                                                                                                                                                                                                                                                                                                                                                                                                      computational  neuroscience,  a  realistic  network  is  one  that
                                                                                                            rather  than  feedforward?  This  may  seem  obvious,  but  it                                                                                                                                                                                                                                                                                                                                                                                                        ﬁts  in  the  brain  of  the  animal  and  does  not  require  a  deeper
                                                                                                            turns outthat the distinctioncaneasily be blurred.Consider                                                                                                                                                                                                                                                                                                                                                                                                            network  architecture  or  more  processing  steps  than  the
                                                                                                            the  simple  network  in  Figure  1a.  It  consists  of  three                                                                                                                                                                                                                                                                                                                                                                                                        animal  can  accommodate.  For  computer  vision,  a  realistic
                                                                                                            processing  stages,  arranged  hierarchically,  which  we  will                                                                                                                                                                                                                                                                                                                                                                                                       network is one that can be trained and deployed on available
                                                                                                            refer  to  as  areas,  by  analogy  to  cortex.  Each  area  contains  a                                                                                                                                                                                                                                                                                                                                                                                              hardware  at  the  training  and  deployment  stages.  For  exam-
                                                                                                            number  of  neurons  (real  or  artiﬁcial)  that  apply  ﬁxed                                                                                                                                                                                                                                                                                                                                                                                                         ple,  there  may  be  limits  on  the  storage  and  energy  available,
                                                                                                            operations  to  their  input.  Visual  input  enters  in  the  ﬁrst                                                                                                                                                                                                                                                                                                                                                                                                   which  would  limit  the  complexity  of  the  architecture  and
                                                                                                            area,  where it undergoes some transformation, the result of                                                                                                                                                                                                                                                                                                                                                                                                          computational  graph.  A  realistic  ﬁnite-time  RNN,  when
                                                                                                            which  is  passed  as  input  to  the  second  area,  and  so  forth.                                                                                                                                                                                                                                                                                                                                                                                                 unrolled,  can  yield  an  unworkably  deep  FNN.  Although
                                                                                                            Information  travels  exclusively  in  one  direction  —  the                                                                                                                                                                                                                                                                                                                                                                                                         the  most  widely  used  current  method  for  training  RNNs
                                                                                                            ‘forward’  direction,  from  input  to  output  —  and  so  this  is                                                                                                                                                                                                                                                                                                                                                                                                  (backpropagation through time) requires unrolling, an RNN
                                                                                                            an  example  of  a  feedforward  architecture.  Notably,  the                                                                                                                                                                                                                                                                                                                                                                                                         is  not equivalent to its unrolled FNN twin at the stage of real-
                                                                                                            number  of  transformations  between  input  and  output  is                                                                                                                                                                                                                                                                                                                                                                                                          world  deployment:  the  RNN’s  recurrent  connections  need
                                                                                                            ﬁxed,  and  equal  to  the  number  of  areas  in  the  network.                                                                                                                                                                                                                                                                                                                                                                                                      not  be  physically  duplicated, but can be reused across cycles
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  of  computation.
                                                                                                            Now compare this  to  the  architecture  in  Figure  1b.  Here,
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  An                                                                                                                                                                                                                                                                                  
                                                                                                            we  have  added  lateral  and  feedback  connections  to  the                                                                                                                                                                                                                                                                                                                                                                                                                                     important  recent  observation  [40 ,41,42]  is  that  the
                                                                                                            network.  Lateral  connections  allow  the  output  of  an  area                                                                                                                                                                                                                                                                                                                                                                                                      architecture that results from spatially unrolling a recurrent
                                                                                                                                     be  fed  back  into  the  same  area,  to  inﬂuence  its                                                                                                                                                                                                                                                                                                                                                                                                                                                              resembles  the  architectures  of  state-of-the  art
                                                                                                            to                                                                                                                                                                                                                                                                                                                                                                                                                                                                    network,
                                                                                                            computations  in  the  next  processing  step.  Feedback                                                                                                                                                                                                                                                                                                                                                                                                              FNNs  used  in  computer  vision,  which  similarly  contain
                                                                                                            connections  allow  the  output  of  an  area  to  inﬂuence                                                                                                                                                                                                                                                                                                                                                                                                           skip connections and can be very deep. These deep FNNs
                                                                                                            information  processing  in  a  lower  area.  There  is  some                                                                                                                                                                                                                                                                                                                                                                                                         may form a super-class of models (Figure 1e), which reduce
                                                                                                            freedom in  the  order  in  which  computations  may  occur  in                                                                                                                                                                                                                                                                                                                                                                                                       to  (recurrent-equivalent)  architectures  when  certain  sub-
                                                                                                            such  a  network.  The  order  we  illustrate  here  starts  with  a                                                                                                                                                                                                                                                                                                                                                                                                  sets  of  weights  are  constrained  to  be  identical.  Liao  and
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
                                                                                                            full  feed-forward  pass  through  the  network.  In  subse-                                                                                                                                                                                                                                                                                                                                                                                                          Poggio  [40 ]  showed  that  deep  feedforward  architectures
                                                                                                            quent  time  steps,  neural  activations  are  updated  in                                                                                                                                                                                                                                                                                                                                                                                                            known  as  residual  networks  (ResNets)  [19]  are  formally
                                                                                                            ascending  order  through  the  hierarchy,  based  on  the                                                                                                                                                                                                                                                                                                                                                                                                            equivalent to recurrent architectures when certain connec-
                                                                                                                                                                                               that  were  computed  in  the  previous  time  step.                                                                                                                                                                                                                                                                                                                                                                    weights  are  constrained  to  be  identical.  Moreover,
                                                                                                            activations                                                                                                                                                                                                                                                                                                                                                                                                                                                           tion
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  whenResNetsweretrainedwith such recurrent-equivalent
                                                                                                            This  order  of  operations  can  be  seen  more  clearly  if  we                                                                                                                                                                                                                                                                                                                                                                                                     weight-sharing constraints, their performance on computer
                                                                                                            ‘unroll’  the  network  in  time,  as  shown  in  Figure  1c.  In  this                                                                                                                                                                                                                                                                                                                                                                                               vision  benchmarks  was  similar  to  unconstrained  ResNets
                                                                                                            illustration,  the  network  is  unrolled  for  a  ﬁxed  number  of                                                                                                                                                                                                                                                                                                                                                                                                   (even  though  the  weight  sharing  drastically  reduces  the
                                                                                                            time  steps  (3).  In  fact,  recurrent  processing  can  be  run  for                                                                                                                                                                                                                                                                                                                                                                                                parameter  count  and  limits  the  component  computations
                                                                                                            any  desired  duration  before  its  output  is  read  out  —  a                                                                                                                                                                                                                                                                                                                                                                                                      that                                       the                                   network  can  perform).  This  is  especially
                                                                                                            www.sciencedirect.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Current  Opinion  in  Neurobiology  2020,  65:176–193
                 178   Whole-brain  interactions  between  neural  circuits
                 Figure  1
                                             (a)                       (b)                    (c)
                                             (d)                                              (e)
                                                                                                                Current Opinion in Neurobiology
                 Unrolling  recurrent  neural  networks.  (a)  A  simple  feedforward  neural  network.  (b)  The  same  network  with  lateral  (blue)  and  feedback  (red)
                 connections  added,  to  make  it  recurrent.  (c)  ‘Unrolling’  the  network  in  time  clarifies  the  order  of  its  computations.  Here,  the  network  is  unrolled  for
                 three  time  steps  before  its  output  is  read  out,  but  we  could  choose  to  run  the  network  for  more  or  fewer  steps.  Areas  are  staggered  from  left  to
                 right  to  show  the  order  in  which  their  neural  activities  are  updated.  (d)  Alternatively,  we  can  unroll  the  recurrent  network’s  time  steps  in  space,  by
                 arranging  the  areas  and  connections  from  different  time  steps  in  a  linear  spatial  sequence.  Note  how  all  arrows  now  once  again  point  in  the  same
                 (forward)  direction,  from  input  to  output.  Throughout  panels  (a-d),  connections  that  are  identical  (sharing  the  same  weight  matrices)  are  indicated
                 by  corresponding  symbols.  (e)  If  we  lift  the  weight-sharing  constraints  from  the  previous  network,  this  induces  a  deep  feedforward  ‘super-model’,
                 which  can  implement  the  spatially  unrolled  recurrent  network  as  a  special  case.  This  more  general  architecture  may  include  additional  connections
                 (examples  shown  as  light  gray  arrows)  not  present  in  the  spatially  unrolled  recurrent  net.
                 Current  Opinion  in  Neurobiology  2020,  65:176–193                                                                        www.sciencedirect.com
                                                                                                                                                                                                                                                Going  in  circles  is  the  way  forward:  the  role  of  recurrence  in  visual  inference  van  Bergen  and  Kriegeskorte                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       179
                                                                                                            Figure  2
                                                                                                                                                                                                                                                                              (a)                                                                                                                                                                                                                                                                                     (b)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Current Opinion in Neurobiology
                                                                                                            Relationships  between  recurrent  and  feedforward  networks.  This  figure  illustrates  relationships  between  discrete-time  feedforward  (FNN)  and
                                                                                                            discrete-time  recurrent  (RNN)  neural  network  models.  (a)  The  architecture  of  any  RNN  can  be  reduced  to  an  FNN  by  removing  all  its  recurrent
                                                                                                            connections  (e.g.  going  from  Figure  1b  back  to  Figure  1a),  or  equivalently,  setting  the  weights  of  these  connections  to  zero.  Vice  versa,  any  FNN
                                                                                                            can
                                                                                                                                      be  expanded  to  an  infinite  variety  of  RNNs  by  adding  lateral  or  feedback  connections.  Feedforward  networks,  thus,  form  an  architectural
                                                                                                            subset  of  RNNs.  Here  we  specifically  consider  RNNs  that  accomplish  their  task  in  a  finite  number  of  time  steps.  These  finite-time  RNNs  (ftRNNs)
                                                                                                            have  the  special  property  that  they  can  be  unrolled  into  equivalent  FNNs.  White  points  linked  by  arcs  indicate  pairs  of  computationally  equivalent
                                                                                                            architectures.  Thus,  the  feedforward  NNs  contain  a  subset  of  architectures  that  can  be  obtained  by  unrolling  a  ftRNN.  (b)  These  sets  of  networks
                                                                                                            can  be  further  subdivided  into  subsets  that  are  or  are  not  realistic  to  implement  with  the  computational  resources  available  for  a  brain  or
                                                                                                            engineered  device  (areas  below  and  above  the  dotted  line,  respectively).  Deeper  networks  and,  more  generally,  networks  with  more  neurons  and
                                                                                                            connections  tend  to  require  more  memory  and  computation  to  train  and  run.  Some  realistic  ftRNNs  remain  realistic  when  expressed  as  an  FNN
                                                                                                            (blue  ellipse).  Others,  however,  become  too  complex,  when  unrolled,  to  be  feasible  (black  arc  crossing  the  realism  line).  This  is  because  the
                                                                                                            unrolling  operation  induces  a  much  deeper  architecture  with  many  more  neural  connections  to  be  stored.  These  not-realistically-unrollable  ftRNNs
                                                                                                            are  especially  interesting,  since  they  correspond  to  recurrent  solutions  that  cannot  be  replaced  by  feedforward  architectures.
                                                                                                            noteworthy given that ResNets, and architecturally related                                                                                                                                                                                                                                                                                                                                                                                                            Computational  neuroscientists  commonly  study  models  of
                                                                                                            DenseNets, are currently among the top-ranking FNNs on                                                                                                                                                                                                                                                                                                                                                                                                                feedforward and recurrent neural networks with continuous-
                                                                                                            prominent computer vision benchmarks [19,43], as well as                                                                                                                                                                                                                                                                                                                                                                                                              time  dynamics  [44].  Here  our  focus  is  on  neural  network
                                                                                                            measures  of  brain-similarity  [29].  Today’s  best  artiﬁcial                                                                                                                                                                                                                                                                                                                                                                                                       models  that  are  motivated  by  the  goal  to  capture  computa-
                                                                                                            vision  models,  thus,  actually  implement  computational                                                                                                                                                                                                                                                                                                                                                                                                            tions,  rather  than  their  precise  neural  implementation.  The
                                                                                                            graphs closely  related  to  those  of  recurrent  networks,  even                                                                                                                                                                                                                                                                                                                                                                                                    discrete-time behavior of such a model is not derived from a
                                                                                                            though these models are strictly feedforward architectures.                                                                                                                                                                                                                                                                                                                                                                                                           continuous-time description in differential equations. More-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  over,  the  model is  optimized in its  discrete-time  implemen-
                                                                                                            Continuous-time  versus  discrete-time                                                                                                                                                                                                                                                                                                                                                                                                                                tation.  However,  an  implicit  assumption  in  the  ﬁeld  is  that
                                                                                                            dynamics                                                                                                                                                                                                                                                                                                                                                                                                                                                              such models could be implemented in biological brains, and
                                                                                                            FNNs  used  in  computer  vision  do  not  have  meaningful                                                                                                                                                                                                                                                                                                                                                                                                           thus  in  continuous-time  dynamical  systems.
                                                                                                            dynamics.  Each  unit  in  the  network  instantaneously
                                                                                                            transforms  its  input  into  an  output.  This  is  in  contrast                                                                                                                                                                                                                                                                                                                                                                                                     Reasons  to  recur
                                                                                                            to  a  feedforward  network  of  biological  neurons.  When                                                                                                                                                                                                                                                                                                                                                                                                           We  have  described  how  a  recurrent  network  can  be
                                                                                                            given  a  static  input,  biological  neurons  do  not  immedi-                                                                                                                                                                                                                                                                                                                                                                                                       unrolled into a deep feedforward architecture. The result-
                                                                                                            ately  produce  their  ﬁnal  responses.  The  movement  of                                                                                                                                                                                                                                                                                                                                                                                                            ing  feedforward  super-model  offers  greater  computa-
                                                                                                                                                                         charges  and  neurotransmitters,  and  the  opening                                                                                                                                                                                                                                                                                                                                                                                                          ﬂexibility,  since  weight-sharing  constraints  can
                                                                                                            electric                                                                                                                                                                                                                                                                                                                                                                                                                                                              tional
                                                                                                            and  closing  of  ion  channels  takes  time,  so  the  network                                                                                                                                                                                                                                                                                                                                                                                                       be  omitted  and  additional  skip  connections  added  to
                                                                                                            will  gradually  transition  from  its  initial  to  its  ﬁnal  state,                                                                                                                                                                                                                                                                                                                                                                                                the  network  (Figure  1e).  So  what  would  be  the  beneﬁt
                                                                                                            with  its  trajectory  continually  perturbed  by  noise.  Such                                                                                                                                                                                                                                                                                                                                                                                                       of  restricting  ourselves  to  recurrent  architectures?  We  will
                                                                                                            continuous-time  dynamics  can  be  described  by  differ-                                                                                                                                                                                                                                                                                                                                                                                                            ﬁrst  discuss  the  beneﬁts  of  recurrence  in  terms  of  over-
                                                                                                            ential  equations.  When  these  cannot  be  solved  analyti-                                                                                                                                                                                                                                                                                                                                                                                                         arching  principles,  before  considering  more  speciﬁc
                                                                                                            cally  (as  is  typically  the  case),  the  dynamics  can  be                                                                                                                                                                                                                                                                                                                                                                                                        implementations  of  these  principles.
                                                                                                            simulated  in  discrete  steps.  In  each  step,  the  current
                                                                                                            state  of  each  simulated  neuron  is  updated.  The  future                                                                                                                                                                                                                                                                                                                                                                                                         Recurrence  provides  greater  and  more  ﬂexible
                                                                                                                                                    of  the  network  thus  depends  on  its  current  state,  as                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   depth
                                                                                                            state                                                                                                                                                                                                                                                                                                                                                                                                                                                                 computational
                                                                                                            it                 does  in  an  RNN.  Consequently,  the  computational                                                                                                                                                                                                                                                                                                                                                                                              Recurrence  enables  arbitrary  computational  depth
                                                                                                            graph  of  the  simulation  algorithm  contains  loops  from                                                                                                                                                                                                                                                                                                                                                                                                          One  important  advantage  of  recurrent  algorithms  is  that
                                                                                                            each  neuron  back  to  itself.  Running  the  simulation  over                                                                                                                                                                                                                                                                                                                                                                                                       they  can  be  run  for  any  desired  length  of  time  before  their
                                                                                                            time  amounts  to  unrolling  this  loopy  computational                                                                                                                                                                                                                                                                                                                                                                                                              output is collected. We can deﬁne computational depth as
                                                                                                            graph,  even  though  the  network  architecture  did  not                                                                                                                                                                                                                                                                                                                                                                                                            the  maximum  path  length  (i.e.  number  of  successive
                                                                                                            contain  loops.                                                                                                                                                                                                                                                                                                                                                                                                                                                       connections  and  nonlinear  transformations)  between
                                                                                                            www.sciencedirect.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Current  Opinion  in  Neurobiology  2020,  65:176–193
                 180   Whole-brain  interactions  between  neural  circuits
                 input  and  output.  A  recurrent  neural  network  (RNN)  can               Spoerer  et  al.  implemented  a  recurrent  model  that  termi-
                 achieve  arbitrary  computational  depth  despite  having  a                 nates  computations  when  it  reaches  a  conﬁdence  thresh-
                 ﬁnite  count  of  parameters  and  being  limited  to  ﬁnite                 old  (deﬁned  by  the  entropy  of  the  posterior,  a  measure  of
                 spatial  components.  In  other  words,  it  can  multiply  its              the  model’s  uncertainty)  [23].  The  model  terminates
                 limited  spatial  resources  along  time.  These  deeper                     rapidly  for  many  images,  but  expends  more  time  and
                 computations  can  serve  to  expand  on  the  number  of                    energy  on  hard  images  to  reach  its  conﬁdence  threshold.
                 hypotheses  considered  (in  generative  inference)  or  on                  Adjusting  the  conﬁdence  threshold  enables  trading  off
                 the  number  of  nonlinear  features  computed  (in  discrimi-               speed  for  accuracy  in  terms  of  average  performance.
                 native  inference),  or  to  extend  the  representation  into  the          When  compared  to  a  range  of  FNNs  requiring  different
                 future or  past,  or  to  iteratively  converge  to  a  good  estimate       amounts  of  computation,  the  RNN  achieved  roughly  the
                 of  some  latent  variable  of  interest.                                    same  accuracy  as  each  of  the  FNNs  when  its  conﬁdence
                                                                                              threshold  was  set  to  match  the  FNN’s  computational  cost
                                                                                              (number  of  ﬂoating  point  operations)  on  average  across
                 Recurrence  enables  more  ﬂexible  expenditure  of  energy  and             images  (Figure  3).  Flexible  computational  depth  would
                 time  in  exchange  for  inferential  accuracy                               be  advantageous  for  animals,  who  may  need  to  respond
                 In  addition  to  enabling  an  arbitrarily  deep  computation               rapidly  in  some  situations,  must  limit  metabolic  expen-
                 given  enough  time,  an  RNN  can  adjust  its  computational               ditures  in  general,  and  may  beneﬁt  from  slower  and  more
                 depth  to  the  task  at  hand.  The  computational  depth  of  a            energetically  costly  inferences  when  high  accuracy  is
                 feedforward  net,  by  contrast,  is  a  ﬁxed  number  deter-                required.  Computer  vision  faces  similar  requirements
                 mined  by  the  architecture.                                                in  certain  applications.  For  example,  a  vision  algorithm
                 Figure  3
                                                                                                  RNN
                                                                                                                                        entropy threshold [nats]
                                               accuracy
                                                   [proportion top-1 correct]                     FNNs
                                                                     computational cost
                                                                                                               11
                                                             [number of ﬂoating-point operations ×10             ]
                                                                                                                 Current Opinion in Neurobiology
                 Recurrence  enables  a  network  to  trade  speed  for  accuracy  while  approximately  emulating  the  accuracies  of  feedforward  models  on  average  at
                 matched  computational  cost.  Circles  denote  the  performance  of  a  recurrent  neural  network  (RNN)  that  was  run  for  different  numbers  of  time
                 steps,  until  it  achieved  a  desired  threshold  of  image  classification  confidence  (quantified  by  the  entropy  of  the  class  probabilities  in  the  final
                 network  layer).  Squares  correspond  to  three  architecturally  similar  feedforward  networks  (FNN)  with  different  computational  costs.  On  the  x-axis  is
                 the  computational  cost  of  running  these  models,  measured  by  the  number  of  floating  point  operations.  For  the  feedforward  models,  this  cost  is
                 fixed  by  the  architecture.  For  the  recurrent  models,  it  is  the  average  number  of  operations  that  was  required  to  meet  the  given  entropy  threshold.
                 The  y-axis  shows  the  classification  accuracy  achieved  by  each  model.  The  performance  of  the  recurrent  model  for  different  certainty  thresholds
                 follows  a  smooth  curve,  trading  off  computational  cost  (and  thus  computational  speed)  and  accuracy.  Note  that  this  curve  passes  almost  exactly
                 through  the  cost-accuracy  combinations  achieved  by  the  feedforward  models.  Thus,  a  single  recurrent  model  can  emulate  the  performance  of
                 multiple  feedforward  models  as  it  trades  off  speed  and  accuracy.  When  the  confidence  threshold  of  termination  was  set  such  that  the  RNN
                 matched  the  accuracy  of  a  given  FNN,  the  RNN  required  a  similar  number  of  floating-point  operations  on  average  as  the  FNN.  (Figure  adapted
                                                      
                 with  permission  from  the  authors  [23 ].
                 Current  Opinion  in  Neurobiology  2020,  65:176–193                                                                        www.sciencedirect.com
                                                                                                                                                                                                                                                Going  in  circles  is  the  way  forward:  the  role  of  recurrence  in  visual  inference  van  Bergen  and  Kriegeskorte                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       181
                                                                                                            in  a  smartphone  should  respond  rapidly  and  conserve                                                                                                                                                                                                                                                                                                                                                                                                            power  —  a  trend  that  is  not  sustainable.  In  the  long
                                                                                                            energy  in  general,  but  should  also  be  able  to  recognize                                                                                                                                                                                                                                                                                                                                                                                                      run,  therefore,  computer  vision  too  may  beneﬁt  from
                                                                                                            hard  images,  and  it  should  allow  trading  off  mean  accu-                                                                                                                                                                                                                                                                                                                                                                                                      the  anatomical  compression  that  can  be  achieved  through
                                                                                                            racy  for  speed  and  energy  (e.g.  when  the  battery  is  low).                                                                                                                                                                                                                                                                                                                                                                                                   clever  use  of  recurrence.
                                                                                                            Recurrent  architectures  can  compress  complex                                                                                                                                                                                                                                                                                                                                                                                                                      Importantly,  however,  not  every  deep  feedforward  model
                                                                                                            computations  in  limited  hardware                                                                                                                                                                                                                                                                                                                                                                                                                                   can  be  compressed  into  an  equivalent  recurrent  imple-
                                                                                                            Another  beneﬁt  of  recurrent  solutions  is  that  they  require                                                                                                                                                                                                                                                                                                                                                                                                    mentation.  This  anatomical  compression  can  only  be
                                                                                                            fewer  components  in  space  when  physically  implemen-                                                                                                                                                                                                                                                                                                                                                                                                             achieved  when  the  same  function  may  be  applied  itera-
                                                                                                            ted                                  in                          recurrent  circuits,  such  as  brains.  Compare                                                                                                                                                                                                                                                                                                                                                     tively  or  recursively  within  the  network.  The  crucial
                                                                                                            Figure  1b  and  1e:  the  recurrent  network  is  anatomically                                                                                                                                                                                                                                                                                                                                                                                                       question,  therefore,  is:  what  are  these  functions?  What
                                                                                                            more  compact  than  the  feedforward  network  and  has                                                                                                                                                                                                                                                                                                                                                                                                              operations  can  be  applied  repeatedly  in  a  productive
                                                                                                            fewer  connections.  It  is  easy  to  see  why  evolution  might                                                                                                                                                                                                                                                                                                                                                                                                     manner?  The  remainder  of  this  paper  will  reﬂect  on
                                                                                                            have  favored  a  recurrent  implementations  for  many  brain                                                                                                                                                                                                                                                                                                                                                                                                        the  various  roles  that  have  been  proposed  for  recurrent
                                                                                                            functions:  Space,  neural  projections,  and  the  energy  to                                                                                                                                                                                                                                                                                                                                                                                                        processing for visual inference, from superﬁcial to increas-
                                                                                                            develop and maintain them are all costly for the organism.                                                                                                                                                                                                                                                                                                                                                                                                            ingly  profound  forms  of  recurrence.
                                                                                                            In  addition,  synaptic  efﬁcacies  must  be  either  learned
                                                                                                            from  limited  experience  or  encoded  in  a  limited-capacity                                                                                                                                                                                                                                                                                                                                                                                                       Feedback  connections  are  required  to  integrate
                                                                                                            genome. Beyond saving space, material, and energy, thus,                                                                                                                                                                                                                                                                                                                                                                                                              information  from  outside  the  visual  hierarchy
                                                                                                            smaller  descriptive  complexity  (or  parameter  count)                                                                                                                                                                                                                                                                                                                                                                                                              A  key,  established  role  of  recurrent  connections  in  bio-
                                                                                                            might  ease  development  and  learning.                                                                                                                                                                                                                                                                                                                                                                                                                              logical  vision  is  to  propagate  information  from  outside  the
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 cortex,  so  that  it  can  aid  visual  inference  [49].  Here,
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  visual
                                                                                                            Engineered devices face the same setofcosts, although their                                                                                                                                                                                                                                                                                                                                                                                                           we  will  brieﬂy  discuss  two  such  outside  inﬂuences:  atten-
                                                                                                            relative  weighting  changes  from  application  to  application.                                                                                                                                                                                                                                                                                                                                                                                                     tion  and  expectations.
                                                                                                            In  particular,  a  larger  number  of  units  and  weights  must
                                                                                                            either  be  represented  in  the  memory  of  a  conventional                                                                                                                                                                                                                                                                                                                                                                                                         Attentional  prioritization  requires  feedback  connections
                                                                                                            computer  or  implemented  in  specialized  (e.g.  neuro-                                                                                                                                                                                                                                                                                                                                                                                                             Animals have needs and goals that change from moment to
                                                                                                            morphic)  hardware.  The  connection  weights  in  an  NN                                                                                                                                                                                                                                                                                                                                                                                                             moment.  Perception  is  attuned  to  an  animal’s  current
                                                                                                            model  need  to  be  learned  from  limited  data.  This  requires                                                                                                                                                                                                                                                                                                                                                                                                    objectives.  For  instance,  a  primate  foraging  for  red  berries
                                                                                                            extensive training, for example, in a supervised setting, with                                                                                                                                                                                                                                                                                                                                                                                                        may  be  more  successful  if  its  visual  perception  apparatus
                                                                                                            millions  of  hand-labeled  examples  that  show  the  network                                                                                                                                                                                                                                                                                                                                                                                                        prioritizes  or  enhances  the  processing  of  red  items.  Since
                                                                                                            the  desired  output  for  a  given  input.  The  larger  number  of                                                                                                                                                                                                                                                                                                                                                                                                  current goals are represented outside the visual cortex (e.g.
                                                                                                            parameters  associated  with  a  feedforward  solution  might                                                                                                                                                                                                                                                                                                                                                                                                         in                        frontal  regions),  top-down  connections  are  clearly
                                                                                                            overﬁt the training data. The learned parameters then do not                                                                                                                                                                                                                                                                                                                                                                                                          required for this information to inﬂuence visual processing.
                                                                                                            generalize  well  to  new  examples  of  the  same  task.                                                                                                                                                                                                                                                                                                                                                                                                             Such top-down effects have been grouped under the label
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ‘attention’,  and  they  have  been  the  subject  of  an  entire
                                                                                                            FNNs often  turn  out  to  generalize  surprisingly  well  even                                                                                                                                                                                                                                                                                                                                                                                                       subﬁeld  of  study.  For  our  purposes,  it  is  sufﬁcient  to  note
                                                                                                            when they have very large numbers of parameters [45–47].                                                                                                                                                                                                                                                                                                                                                                                                              that  the  effects  and  mechanisms  of  top-down attention  are
                                                                                                            This phenomenon is thought to reﬂect a regularizing effect                                                                                                                                                                                                                                                                                                                                                                                                            well-documented andpervasiveinvisualcortex (forreview,
                                                                                                            of  the  learning  algorithm,  stochastic  gradient  descent.                                                                                                                                                                                                                                                                                                                                                                                                         see  [36–38]),  and  thus  there  is  no  question  that  this  is  one
                                                                                                            Indeed,  the  trend  is  towards  ever  deeper  networks  with                                                                                                                                                                                                                                                                                                                                                                                                        important  function  of  recurrent  connections.
                                                                                                                                                     connections to be optimized, and this trend is associ-
                                                                                                            more
                                                                                                            ated  with  continuing  gains  in  performance  on  computer                                                                                                                                                                                                                                                                                                                                                                                                          Integrating  prior  expectations  into  visual  inference  requires
                                                                                                            vision benchmarks [48]. Nevertheless, it could turn out that                                                                                                                                                                                                                                                                                                                                                                                                          feedback  connections
                                                                                                            recurrent  architectures  that  achieve  high  computational                                                                                                                                                                                                                                                                                                                                                                                                          Organisms  may  constrain  their  visual  inferences  by
                                                                                                            depth  with  fewer  parameters  bring  beneﬁts  not  only  in                                                                                                                                                                                                                                                                                                                                                                                                         expectations  [50].  Visual  input  can  be  ambiguous  and
                                                                                                            terms  of  their  storage,  but  also  in  terms  of  statistical  efﬁ-                                                                                                                                                                                                                                                                                                                                                                                               unreliable,  and  thus  open  to  multiple  interpretations.  To
                                                                                                            ciency,  the  ability  generalize  accurately  based  on  limited                                                                                                                                                                                                                                                                                                                                                                                                     constrain  the  inference,  an  observer  can  make  use  of  prior
                                                                                                            experience. This wouldimply that recurrent networks have                                                                                                                                                                                                                                                                                                                                                                                                              knowledge  [51–53].  One  form  of  prior  knowledge  is
                                                                                                            an inductive bias that makes up for the limited experiential                                                                                                                                                                                                                                                                                                                                                                                                          environmental  constants  (e.g.  ‘light  tends  to  come  from
                                                                                                                                                                                       isexplored further insubsequent sections,where                                                                                                                                                                                                                                                                                                                                                                                                     [54]).  Such  unvarying  knowledge  may  be  stored
                                                                                                            data.This                                                                                                                                                                                                                                                                                                                                                                                                                                                             above’
                                                                                                            we  discuss  how  RNNs  can  exploit  temporal  dependency                                                                                                                                                                                                                                                                                                                                                                                                            within  visual  cortex,  especially  when  it  pertains  to  the
                                                                                                            structures,  and  enable  iterative  inference.                                                                                                                                                                                                                                                                                                                                                                                                                       overall  prevalence  of  basic  visual  features  (e.g.  local  edge
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  orientations  [55]).  Another  form  of  prior  knowledge  is
                                                                                                            Energy  is  another  factor  to  consider  in  both  biology  and                                                                                                                                                                                                                                                                                                                                                                                                     contextual  information  speciﬁc  to  the  current  situation.
                                                                                                            engineering.  Larger  FNNs  take  longer  to  train  on  bigger                                                                                                                                                                                                                                                                                                                                                                                                       Such  time-varying  knowledge  may  require  a  ﬂexible
                                                                                                            computing  clusters,  while  drawing  greater  amounts  of                                                                                                                                                                                                                                                                                                                                                                                                            representation  outside  visual  cortex  (e.g.  ‘I  rang  the
                                                                                                            www.sciencedirect.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Current  Opinion  in  Neurobiology  2020,  65:176–193
                                                                                                182                                  Whole-brain  interactions  between  neural  circuits
                                                                                                Figure  4
                                                                                                                                                                                                                                                                                              (b)
                                                                                                                                                                                                                                                                                              (c)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Current Opinion in Neurobiology
                                                                                                Increasingly  profound  modes  of  recurrent  processing,  unrolled  in  time.  Visual  cortex  likely  combines  all  three  modes  of  recurrence  illustrated  here.
                                                                                                The  left  side  of  each  panel  shows  the  computational  graph  induced  by  each  form  of  recurrence,  while  the  right  side  illustrates  a  (simplified)
                                                                                                example  of  how  this  recurrence  can  be  used.  In  these  examples,  circles  correspond  to  neurons  (or  neural  assemblies)  encoding  the  feature
                                                                                                illustrated  within  the  circle,  and  lines  that  connect  to  circles  indicate  neural  connections  with  significant  activity.  (a)  Top-down  influences  from
                                                                                                outside  the  visual  processing  hierarchy  may  be  incorporated  through  two  computational  sweeps:  a  feedback  sweep  priming  the  network  with  top-
                                                                                                down  information  and  a  feedforward  sweep  to  interpret  visual  input  and  combine  this  interpretation  with  the  top-down  signal.  Note  that  the  lateral
                                                                                                connections  here  merely  copy  neural  activities  in  each  area  to  the  next  time  point;  this  identity  transformation  could  also  be  implemented  in  other
                                                                                                ways,  such  as  slow  membrane  time  constants  or  other  forms  of  local  memory.  In  the  example  on  the  right,  a  top-down  signal  communicates  the
                                                                                                expectation  that  the  upcoming  input  will  be  horizontal  motion.  This  primes  neurons  encoding  this  direction  of  motion  to  be  more  easily  or  strongly
                                                                                                activated,  and  sharpens  the  interpretation  of  the  subsequent  (ambiguous)  visual  input.  (b)  To  efficiently  perform  inference  on  time-varying  visual
                                                                                                input,  recurrent  connections  may  implement  a  fixed  temporal  prediction  function  akin  to  the  transition  kernel  in  a  Kalman  filter,  extrapolating  the
                                                                                                ongoing  dynamics  of  the  world  one  time  step  into  the  future.  For  instance,  in  the  example  on  the  right,  a  downward  moving  square  was  perceived
                                                                                                at  t  ¼  1.  This  motion  is  predicted  to  continue,  and  this  prediction  constrains  the  interpretation  of  the  (ambiguous)  visual  input  at  the  next  time
                                                                                                point.
                                                                                                                                     For  simplicity,  only  lateral  recurrence  is  shown  in  this  example.  Note  that  each  input  is  mapped  onto  its  corresponding  output  in  a  single
                                                                                                recurrent  time  step.  (c)  Static  input  may  also  benefit  from  recurrent  processing  that  iteratively  refines  an  initial,  coarse  feedforward  interpretation.
                                                                                                In  this  mode  of  recurrence,  there  are  several  processing  time  steps  between  input  and  output,  whereas  in  (b)  there  was  one  input  and  output  for
                                                                                                each  time  step.  Illustrated  on  the  right  is  an  iterative  hierarchical  inference  algorithm.  Here,  a  higher-level  hypothesis,  generated  in  the  first  time
                                                                                                step,  refines  the  underlying  lower-level  representation  in  the  next  time  step,  which  in  turn  improves  the  higher-level  hypothesis,  and  so  forth,  until
                                                                                                the  network  converges  to  an  optimal  interpretation  of  the  input  across  the  entire  hierarchy.  For  simplicity,  lateral  recurrent  interactions  are  not
                                                                                                shown  in  this  example.
                                                                                                Current  Opinion  in  Neurobiology  2020,  65:176–193                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          www.sciencedirect.com
                                                                                                                                                                                                                                                Going  in  circles  is  the  way  forward:  the  role  of  recurrence  in  visual  inference  van  Bergen  and  Kriegeskorte                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       183
                                                                                                            doorbell at  my mother’s house, so I expect to see her open                                                                                                                                                                                                                                                                                                                                                                                                           a  feedforward  network,  a  recurrent  network  is  not  limited
                                                                                                            the  door’).  Such  expectations,  represented  in  higher                                                                                                                                                                                                                                                                                                                                                                                                            by  spatial  constraints  in  terms  of  its  retrospective  time
                                                                                                            cortical  regions,  require  feedback  connections  to  affect                                                                                                                                                                                                                                                                                                                                                                                                        horizon.  It  can  maintain  task-relevant  information  indeﬁ-
                                                                                                            processing  in  visual  cortex  [50].                                                                                                                                                                                                                                                                                                                                                                                                                                 nitely,  integrating  long-term  memory  into  its  inferences.
                                                                                                            The  top-down  imposition  of  attention  and  expectation                                                                                                                                                                                                                                                                                                                                                                                                            Recurrent  dynamics  can  simulate  and  predict  the  dynamics
                                                                                                            must  be  mediated  by  feedback  connections.  However,  it                                                                                                                                                                                                                                                                                                                                                                                                          of  the  world
                                                                                                            is  unclear  whether  these  inﬂuences  fundamentally  change                                                                                                                                                                                                                                                                                                                                                                                                         Dynamic  compression  of  the  past  exploits  the  temporal
                                                                                                            the  nature  of  visual  representations  or  merely  modulate                                                                                                                                                                                                                                                                                                                                                                                                        dependency structure of the sensory data. The purpose of
                                                                                                            these representations, adjusting the gain depending on the                                                                                                                                                                                                                                                                                                                                                                                                            representing  the  past  is  to  act  well  in  the  future.  This
                                                                                                            current  relevance  of  different  features  of  the  visual  input.                                                                                                                                                                                                                                                                                                                                                                                                  suggests  that  a  neural  network  should  exploit  temporal
                                                                                                            As  illustrated  in  Figure  4a,  for  a  given  input  this  would                                                                                                                                                                                                                                                                                                                                                                                                   dependencies  not  just  to  compress  the  past,  but  also  to
                                                                                                            require  only  two  ‘sweeps’  of  computation  through  the                                                                                                                                                                                                                                                                                                                                                                                                           predict  the  future.  In  fact,  an  optimal  representation  of
                                                                                                            visual  processing  hierarchy:  a  feedback  sweep  that  primes                                                                                                                                                                                                                                                                                                                                                                                                      even  just  the  present  requires  prediction,  because  the
                                                                                                            visual  areas  with  top-down  information,  and  a  bottom-up                                                                                                                                                                                                                                                                                                                                                                                                        sensory  data  is  delayed  and  noisy.
                                                                                                            sweep to interpret the visual input and integrate or modify
                                                                                                            this interpretationwith the top-downsignal (notnecessarily                                                                                                                                                                                                                                                                                                                                                                                                            Changes  in  the  world  are  governed  by  laws  of  dynamics,
                                                                                                            in  that  order).  Importantly,  if  the  feedback  signal  merely                                                                                                                                                                                                                                                                                                                                                                                                    which  by  deﬁnition  are  temporally  invariant.  An  ideal
                                                                                                            enhances or suppresses some visual features, then the core                                                                                                                                                                                                                                                                                                                                                                                                            observer  will  exploit  these  laws  in  visual  inference  and
                                                                                                            inference  algorithm  need  not  be  fundamentally  recur-                                                                                                                                                                                                                                                                                                                                                                                                            optimally  combine  previous  with  present  observations  to
                                                                                                            rent  —  one  can  imagine  that  the  bottom-up  part  of  such                                                                                                                                                                                                                                                                                                                                                                                                      estimate  the  current  state.  This  implies  an  extrapolation
                                                                                                                            network  is  modeled  perfectly  by  an  FNN,  while  an                                                                                                                                                                                                                                                                                                                                                                                                                      the  past  to  generate  predictions  that  improve  the
                                                                                                            a                                                                                                                                                                                                                                                                                                                                                                                                                                                                     of
                                                                                                            optional  recurrent  module  could  be  added  in  order  to                                                                                                                                                                                                                                                                                                                                                                                                          interpretation  of  the  present  sensory  input.  When  the
                                                                                                            implement  top-down  contextual  inﬂuences.                                                                                                                                                                                                                                                                                                                                                                                                                           dynamics  are  linear  and  noise  is  Gaussian,  the  optimal
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  way  to  infer  the  present  state  by  combining  past  and
                                                                                                            Recurrent  networks  can  exploit  temporal  dependency                                                                                                                                                                                                                                                                                                                                                                                                               present  evidence  is  the  Kalman  ﬁlter  [59]  —  an  algorithm
                                                                                                            structure                                                                                                                                                                                                                                                                                                                                                                                                                                                             widely  used  in  engineering  applications.  A  number  of
                                                                                                            Contextual  constraints  on  visual  inference  include  not                                                                                                                                                                                                                                                                                                                                                                                                          authors  [60–63]  have  proposed  that  the  visual  cortex  may
                                                                                                            only  information  from  outside  the  visual  hierarchy,  such                                                                                                                                                                                                                                                                                                                                                                                                       implement  an  algorithm  similar  to  a  Kalman  ﬁlter.  This
                                                                                                            as  information  from  other  sensory  modalities  and  mem-                                                                                                                                                                                                                                                                                                                                                                                                          theory  is  consistent  with  temporal  biases  that  are  evident
                                                                                                                                                 as  discussed  in  the  previous  section.  The  recent                                                                                                                                                                                                                                                                                                                                                                                               human  perceptual  judgments  [64–66].
                                                                                                            ory,                                                                                                                                                                                                                                                                                                                                                                                                                                                                  in
                                                                                                            stimulus  history  within  the  visual  modality  also  provides
                                                                                                            context,  likely  represented  within  the  visual  system.                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ﬁlters  employ  a  ﬁxed  temporal  transitional  ker-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Kalman
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  nel.  This  kernel  takes  a  representation  of  the  world  (e.g.
                                                                                                            Recurrent  networks  can  dynamically  compress  the  stimulus                                                                                                                                                                                                                                                                                                                                                                                                        variables  encoding  the  present  state  of  a  physical  system,
                                                                                                            history                                                                                                                                                                                                                                                                                                                                                                                                                                                               such  as  positions  and  velocities)  at  time  t,  and  transforms
                                                                                                            The  primate  visual  system  is  thought  to  contain  a  hierar-                                                                                                                                                                                                                                                                                                                                                                                                    it  into  a  predicted  representation  for  time  t  þ  1,  to  be
                                                                                                            chy,  not  only  of  processing  stages  and  spatial  scales,  but                                                                                                                                                                                                                                                                                                                                                                                                   integrated  with  new  sensory  evidence  that  arrives  at  that
                                                                                                            also  of  temporal  scales  [56,57].  Visual  representations                                                                                                                                                                                                                                                                                                                                                                                                         time.  While the resulting prediction varies as a function of
                                                                                                            track  the  environment  moment  by  moment.  However,                                                                                                                                                                                                                                                                                                                                                                                                                the  kernel’s  input,  the  kernel  itself  is  constant,  reﬂecting
                                                                                                            the  duration  of  a  visual  moment,  the  temporal  grain,  may                                                                                                                                                                                                                                                                                                                                                                                                     the  temporal  shift-invariance  of  the  laws  governing  the
                                                                                                            depend  on  the  level  of  representation.  These  principles                                                                                                                                                                                                                                                                                                                                                                                                        dynamics.  Recurrent  neural  networks  provide  a  generali-
                                                                                                            apply  to  all  sensory  modalities  and  have  been  empirically                                                                                                                                                                                                                                                                                                                                                                                                     zation  of  the  Kalman  ﬁlter  and  can  represent  nonlinear
                                                                                                            explored,  in  particular,  for  audition  and  speech  percep-                                                                                                                                                                                                                                                                                                                                                                                                       dynamical  systems  with  non-Gaussian  noise.
                                                                                                            tion.  At  the  simplest  level,  a  neural  network  could  use
                                                                                                            delay  lines  to  detect  spatiotemporal,  rather  than  purely                                                                                                                                                                                                                                                                                                                                                                                                       Note  that  this  type  of  recurrent  processing  is  more  pro-
                                                                                                            spatial,  patterns.  Recurrent  neural  networks  have  internal                                                                                                                                                                                                                                                                                                                                                                                                      found  than  the  two-sweep  algorithm  (Figure  4a)  that
                                                                                                            states  and  can  represent  temporal  context  across  units                                                                                                                                                                                                                                                                                                                                                                                                         incorporated  top-down  inﬂuences  on  visual  inference.
                                                                                                            tuned  to  different  latencies.  An  RNN  could  represent  a                                                                                                                                                                                                                                                                                                                                                                                                        The  two-sweep  algorithm  is  trivial  to  unroll  into  a  feed-
                                                                                                            ﬁxed  temporal  window,  by  replicating  units  tuned  to                                                                                                                                                                                                                                                                                                                                                                                                            forward  architecture.  In  contrast,  unrolling  a  Kalman
                                                                                                                                                                                 patterns  for  multiple  latencies.  However,  RNNs                                                                                                                                                                                                                                                                                                                                                                                                                         recurrent  algorithm  would  induce  an  inﬁnitely
                                                                                                            different                                                                                                                                                                                                                                                                                                                                                                                                                                                             ﬁlter-like
                                                                                                            trained  on  sequence  processing  tasks,  such  as  language                                                                                                                                                                                                                                                                                                                                                                                                         deep  feedforward  network,  with  a  separate  set  of  areas
                                                                                                            translation,  learn  more  sophisticated  representations  of                                                                                                                                                                                                                                                                                                                                                                                                         and  connections  for  each  time  point  to  be  processed.  A
                                                                                                            temporal  context  [58].  They  can  represent  context  at                                                                                                                                                                                                                                                                                                                                                                                                           ﬁnite-depth  feedforward  architecture  can  only  approxi-
                                                                                                            multiple  time  scales,  learning  a  latent  representation  that                                                                                                                                                                                                                                                                                                                                                                                                    mate  the  recurrent  algorithm.  While  the  feedforward
                                                                                                            enables  them  to  dynamically  compress  whatever  infor-                                                                                                                                                                                                                                                                                                                                                                                                            approximation  will  have  a  ﬁnite  temporal  window  of
                                                                                                            mation  from  the  past  is  needed  for  the  task.  In  contrast  to                                                                                                                                                                                                                                                                                                                                                                                                memory  to  constrain  its  present  inferences,  the  recurrent
                                                                                                            www.sciencedirect.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Current  Opinion  in  Neurobiology  2020,  65:176–193
                                                                                                184                                  Whole-brain  interactions  between  neural  circuits
                                                                                                network  can  in  principle  integrate  information  over  arbi-                                                                                                                                                                                                                                                                                                                                                                                                      such  that  the  distribution  of  samples  converges  on  the
                                                                                                trarily  long  periods.                                                                                                                                                                                                                                                                                                                                                                                                                                               posterior  distribution),  and  message  passing  algorithms
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      (such  as  loopy  belief  propagation).  In  particular,  such
                                                                                          Due  to  their  advantages  for  dealing  with  time-varying                                                                                                                                                                                                                                                                                                                                                                                                                iterative  inference  algorithms  are  used  in  probabilistic
                                                                                                (or  otherwise  ordered)  inputs,  recurrent  neural  networks                                                                                                                                                                                                                                                                                                                                                                                                        approaches  to  computer  vision  [31,33].  It  is  somewhat
                                                                                                are  in  fact  widely  employed  in  the  broader  ﬁeld  of                                                                                                                                                                                                                                                                                                                                                                                                           surprising,  then,  that  iterative  computation  is  not  widely
                                                                                                machine  learning  for  tasks  involving  sequential  data.                                                                                                                                                                                                                                                                                                                                                                                                           exploited  to  perform  visual  inference  in  FNNs.
                                                                                                Speech  recognition  and  machine  translation  are  promi-
                                                                                                nent  applications  that  RNNs  excel  at  [58,67–70].  Com-                                                                                                                                                                                                                                                                                                                                                                                                          Visual inference is naturally understood as an optimization
                                                                                                puter  vision,  too,  has  embraced  RNNs  for  recognition  and                                                                                                                                                                                                                                                                                                                                                                                                      problem,  where  the  goal  is  to  ﬁnd  hypotheses  that  can
                                                                                                prediction  of  video  input  [71–73].  Note  that  these  appli-                                                                                                                                                                                                                                                                                                                                                                                                     explain  the  current  visual  input  [51].  A  hypothesis,  in  this
                                                                                                cations  all  exploit  the  dynamics  in  RNNs  to  model  the                                                                                                                                                                                                                                                                                                                                                                                                        case, is  a  proposed set of latent (i.e. unobserved) causes that
                                                                                                dynamics  in  the  data.                                                                                                                                                                                                                                                                                                                                                                                                                                              can  jointly  explain  the  image.  The  hypothesized  latent
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      causes could be the identities and positions of objects in the
                                                                                                What  if  we  trained  a  Kalman  ﬁlter  or  sequence-to-                                                                                                                                                                                                                                                                                                                                                                                                             scene. Visual hypotheses are hierarchical, being subdivided
                                                                                                sequence  RNN  (Figure  4b)  on  a  train  of  independently                                                                                                                                                                                                                                                                                                                                                                                                          into  smaller  hypotheses  about  lower  or  intermediate-level
                                                                                                sampled  static  inputs  to  be  classiﬁed?  The  memory  of  the                                                                                                                                                                                                                                                                                                                                                                                                     features,  such  as  the  local  edges  that  make  up  a  larger
                                                                                                preceding  inputs  would  not  be  useful  then,  so  we  expect                                                                                                                                                                                                                                                                                                                                                                                                      contour.  An  iterative  visual  inference  algorithm  starts  with
                                                                                                the  recurrent  model  to  revert  to  using  essentially  only  its                                                                                                                                                                                                                                                                                                                                                                                                  an initial hypothesis, and reﬁnes it by incremental improve-
                                                                                                feedforward weights. The type of recurrent processing we                                                                                                                                                                                                                                                                                                                                                                                                              ments.  These  improvements  may  include  eliminating
                                                                                                described  in  this  section,  thus  uses  memory  to  improve                                                                                                                                                                                                                                                                                                                                                                                                        hypotheses  that  are  mutually  exclusive,  strengthening
                                                                                                                                                  inference.  In  the  next  section,  we  consider  how                                                                                                                                                                                                                                                                                                                                                                                                                                                     causes,  or  adjusting  a  hypothesis  based  on  its
                                                                                                visual                                                                                                                                                                                                                                                                                                                                                                                                                                                                compatible
                                                                                                recurrent  processing  can  help  with  the  inferential  com-                                                                                                                                                                                                                                                                                                                                                                                                        ability  to  predict  the  data  (the  visual  input).  In  a  probabi-
                                                                                                putations  themselves,  even  for  static  inputs.                                                                                                                                                                                                                                                                                                                                                                                                                    listic  framework,  the  optimization  objective  would  be  the
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      likelihood (probability of the image given the latent repre-
                                                                                                Recurrence  enables  iterative  inference                                                                                                                                                                                                                                                                                                                                                                                                                             sentation)  or  the  posterior  probability  (probability  of  the
                                                                                                Recurrent  processing  can  contribute  even  to  inference  on                                                                                                                                                                                                                                                                                                                                                                                                       latent  representation  given  the  image).
                                                                                                static  inputs,  and  regardless  of  the  agent’s  goals  and
                                                                                                expectations,  by  means  of  an  iterative  algorithm.  An                                                                                                                                                                                                                                                                                                                                                                                                           Incompatible  hypotheses  can  compete  in  the  representation
                                                                                                iterative  algorithm  is  one  that  employs  a  computation                                                                                                                                                                                                                                                                                                                                                                                                          There are  often  multiple  plausible  explanations  for  a  given
                                                                                                                                  improves  an  initial  guess.  Applying  the  computation                                                                                                                                                                                                                                                                                                                                                                                                                                     input  that  are  mutually  exclusive.  The  distributed,
                                                                                                that                                                                                                                                                                                                                                                                                                                                                                                                                                                                  sensory
                                                                                                again  to  the  improved  guess  yields  a  further  improve-                                                                                                                                                                                                                                                                                                                                                                                                         parallel  nature  of  neural  networks  enables  them  to  initially
                                                                                                ment.  This  process  can  be  repeated  until  a  good  solution                                                                                                                                                                                                                                                                                                                                                                                                     activate  and  represent  all  of  these  possible  hypotheses
                                                                                                has  been  achieved  or  until  we  run  out  of  time  or  energy.                                                                                                                                                                                                                                                                                                                                                                                                   simultaneously.  Recurrent  connectivity  between  neurons
                                                                                                Recurrent  networks  can  implement  iterative  algorithms,                                                                                                                                                                                                                                                                                                                                                                                                           can                                   then  implement  competitive  interactions  among
                                                                                                with  the  same  neural  network  functions  applied  succes-                                                                                                                                                                                                                                                                                                                                                                                                         hypotheses,so as to converge on the bestoverallexplanation.
                                                                                                sively  to  some  internal  pattern  of  activity  (Figure  4c).
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      There  is  some  evidence  that  sensory  representations  are
                                                                                                In  many  ﬁelds,  iterative  algorithms  are  used  to  solve                                                                                                                                                                                                                                                                                                                                                                                                         probabilistic                                                                                         [74–76]  —  in                                                                                             this                                    case,                                           the                                  probabilities
                                                                                                estimation  and  optimization  problems.  In  each  iteration,                                                                                                                                                                                                                                                                                                                                                                                                        assigned  to  a  set  of  mutually  exclusive  hypotheses  must
                                                                                                a  small  adjustment  is  made  to  the  problem’s  proposed                                                                                                                                                                                                                                                                                                                                                                                                          sum to  1.  A  strengthening  of  belief  in  one  hypothesis,  thus,
                                                                                                                                                                     to  improve  a  mathematically  formulated  objec-                                                                                                                                                                                                                                                                                                                                                                                                  entail  a  reduction  of  the  probability  of  other  hypoth-
                                                                                                solution,                                                                                                                                                                                                                                                                                                                                                                                                                                                             should
                                                                                                tive.  A  locally  optimal  solution  is  found  by  making  small                                                                                                                                                                                                                                                                                                                                                                                                    eses in the representation. If neurons encode point estimates
                                                                                                improvements until further progress is not required or not                                                                                                                                                                                                                                                                                                                                                                                                            rather  than  probability  distributions,  then  only  one  hypoth-
                                                                                                possible.  The  algorithm  navigates  a  path  in  the  space  of                                                                                                                                                                                                                                                                                                                                                                                                     esis  can  win  (although  that  hypothesis  may  be  encoded by a
                                                                                                the  values  to  be  estimated  or  the  parameters  to  be                                                                                                                                                                                                                                                                                                                                                                                                           population  response  involving  multiple  neurons).  The  win-
                                                                                                optimized,  that  leads  to  a  good  solution  (albeit  not  nec-                                                                                                                                                                                                                                                                                                                                                                                                    ning  hypothesis  could  be  the  maximum  a  posteriori  (MAP)
                                                                                                essarily  the  global  optimum).                                                                                                                                                                                                                                                                                                                                                                                                                                      hypothesis or the maximum likelihood hypothesis. Inﬂuen-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      tial  models  of  visual  inference  involving  competitive  recur-
                                                                                                Much  of  machine  learning  involves  iterative  methods.                                                                                                                                                                                                                                                                                                                                                                                                            rent  interactions  include  divisive  normalization  [35],  biased
                                                                                                                                                                           descent  is  an  iterative  optimization  method,                                                                                                                                                                                                                                                                                                                                                                                                                                     [36],  and  predictive  coding  [30,32,77].
                                                                                                Gradient                                                                                                                                                                                                                                                                                                                                                                                                                                                              competition
                                                                                                whose  stochastic  variant  is  the  most  widely  used  method
                                                                                                for  training  FNNs.  Many  discrete  optimization  techni-                                                                                                                                                                                                                                                                                                                                                                                                           Recent  theoretical  work  has  demonstrated  that  lateral
                                                                                                ques  are  iterative.  Iterative  algorithms  are  also  central  to                                                                                                                                                                                                                                                                                                                                                                                                  competition  can  give  rise  to  a  robust  neural  code,  and
                                                                                                inference  in  machine  learning,  for  example  in  variational                                                                                                                                                                                                                                                                                                                                                                                                      can  explain  certain  puzzling  neural  response  properties
                                                                                                inference  (where  inference  is  achieved  by  optimization),                                                                                                                                                                                                                                                                                                                                                                                                        [77,78].  This  theory  considers  a  spiking  neural  network
                                                                                                sampling  methods  (where  steps  are  chosen  stochastically                                                                                                                                                                                                                                                                                                                                                                                                         setting,                                                            in                            which  different  neurons  encode  highly
                                                                                                Current  Opinion  in  Neurobiology  2020,  65:176–193                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          www.sciencedirect.com
                                                                                                                                                                                                                                                Going  in  circles  is  the  way  forward:  the  role  of  recurrence  in  visual  inference  van  Bergen  and  Kriegeskorte                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       185
                                                                                                            overlapping  or  even  identical  features  in  their  input.  This                                                                                                                                                                                                                                                                                                                                                                                                   be  too  complex  to  be  efﬁciently  represented  with  larger-
                                                                                                            degeneracy  means  that  the  same  signal  can  be  encoded                                                                                                                                                                                                                                                                                                                                                                                                          scale  templates.  What  all  these  contours  have  in  common,
                                                                                                            equally  well  by  a  range  of  different  response  patterns.                                                                                                                                                                                                                                                                                                                                                                                                       however, is that they consist of pairs of edges that are locally
                                                                                                            When a particular neuron spikes, lateral inhibition ensures                                                                                                                                                                                                                                                                                                                                                                                                           contiguous, with sharper angles occurring with lower proba-
                                                                                                            that  other  competing neurons do not encode the same part                                                                                                                                                                                                                                                                                                                                                                                                            bility. Thus, the criteria for ‘contour-ness’ may be compactly
                                                                                                            of  the  input  again.  Which  neuron  gets  to  do  the  encoding                                                                                                                                                                                                                                                                                                                                                                                                    expressed  by  a  set  of  local  association  rules:  these  edges  go
                                                                                                            thus  depends  on  which  neuron  ﬁres  ﬁrst,  because  its                                                                                                                                                                                                                                                                                                                                                                                                           together;  those  do  not  [83,84].  Contours  may  then  be  pieced
                                                                                                            membrane  potential  happened  to  be  closest  to  a  spiking                                                                                                                                                                                                                                                                                                                                                                                                        together  by  repeatedly  applying  the  same  local  association
                                                                                                            threshold.  This  leads  to  trial-to-trial  variability  in  neural                                                                                                                                                                                                                                                                                                                                                                                                  rules.  Those  edge  pairs  which  are  most  clearly  connected
                                                                                                            responses  that  reﬂects  subtle  differences  in  initial  condi-                                                                                                                                                                                                                                                                                                                                                                                                    would be identiﬁed in  early  iterations.  Later  inferences  can
                                                                                                            tions  —  conditions  that  may  not  be  known  to  an  experi-                                                                                                                                                                                                                                                                                                                                                                                                      beneﬁt  from  the  context  provided  by  earlier  inferences,
                                                                                                            menter,  who  may  thus  mistake  this  variability  for  random                                                                                                                                                                                                                                                                                                                                                                                                      enabling  the  process  to  recognize  continuity  even  where
                                                                                                            noise.  This  could  explain  the  puzzling  observation  that                                                                                                                                                                                                                                                                                                                                                                                                        it  is  less  locally  apparent.
                                                                                                            individual  neurons  reliably  reproduce  the  same  output
                                                                                                            given  the  same  electrical  stimulation,  but  populations  of                                                                                                                                                                                                                                                                                                                                                                                                      This insight has inspired network models of visual inference
                                                                                                            neurons,  wired  together,  display  apparently  random  vari-                                                                                                                                                                                                                                                                                                                                                                                                        that  implement  local  association  rules  through  lateral  con-
                                                                                                            ability  under  sensory  stimulation  [79–81].  Since  multiple                                                                                                                                                                                                                                                                                                                                                                                                       nections,  to  aid  contour  integration  and  other  perceptual
                                                                                                            neurons can encode the same feature, the resulting code is                                                                                                                                                                                                                                                                                                                                                                                                            grouping operations [85].  Recent  examples include Linsley
                                                                                                            also robust to neurons being lost or temporarily inactivated.                                                                                                                                                                                                                                                                                                                                                                                                         et  al.,  who  developed horizontal gated-recurrent units (hGRUs)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  that  learn  local  spatial  dependencies  [86 ].  A  network
                                                                                                            FNNs do not incorporate  lateral  connections  for  competi-                                                                                                                                                                                                                                                                                                                                                                                                          equipped  with  this  particular  recurrent  connectivity  was
                                                                                                            tive  interactions,  although  they  very  often  include  compu-                                                                                                                                                                                                                                                                                                                                                                                                     competitive  with  state-of-the-art  feedforward  models  on  a
                                                                                                            tations  that  serve  a  similar  purpose.  Chief  among  these  are                                                                                                                                                                                                                                                                                                                                                                                                  contour  integration  task,  while  using  far  fewer  free  param-
                                                                                                            operations known as max-pooling and local response normali-                                                                                                                                                                                                                                                                                                                                                                                                           eters.  George  et  al.  [87]  similarly  leveraged  lateral  interac-
                                                                                                            zation  (LRN)  [82,16].  In  max-pooling,  only  the  strongest                                                                                                                                                                                                                                                                                                                                                                                                       tions  to  recognize  contiguous  contours  and  surfaces,  by
                                                                                                            responsewithina poolofcompetingneuronsisforwarded to                                                                                                                                                                                                                                                                                                                                                                                                                  modeling thesewith aconditionalrandomﬁeld (CRF),using
                                                                                                            the  next  processing  stage.  In  LRN,  each  neuron  has  its                                                                                                                                                                                                                                                                                                                                                                                                       a  message-passing  algorithm  for  inference.  This  approach
                                                                                                            response divided by a term that is computed from the sum                                                                                                                                                                                                                                                                                                                                                                                                              enabled their Recursive Cortical Network (RCN) to reliably
                                                                                                            of  activity  in  its  normalization  pool.  While  neither  of  these                                                                                                                                                                                                                                                                                                                                                                                                beat  CAPTCHAs — images  of  letter  sequences  under  a
                                                                                                            mechanisms is mediated by explicit lateral connections in a                                                                                                                                                                                                                                                                                                                                                                                                           variety  of  distortions,  noise  and  clutter,  that  are  widely  used
                                                                                                            FNN,  a  strictly  connectionist  implementation  of  these                                                                                                                                                                                                                                                                                                                                                                                                           to verify that queries to a user interface are made by a person,
                                                                                                            mechanisms  (e.g.  in  biological  neurons  or  neuromorphic                                                                                                                                                                                                                                                                                                                                                                                                          and  not  an  algorithm.  CRFs  were  also  used  by  Zheng  et  al.
                                                                                                            hardware)  would  have  to  include  lateral  recurrence.  This,                                                                                                                                                                                                                                                                                                                                                                                                      [88],  who  incorporated  them  as  a  recurrent  extension  of  a
                                                                                                            then,  is  another  way  in  which  apparently  feedforward                                                                                                                                                                                                                                                                                                                                                                                                           convolutional  neural  network  for  image  segmentation.  The
                                                                                                            FNNs can exhibit a (limited)  form  of  recurrent  processing                                                                                                                                                                                                                                                                                                                                                                                                         model  surpassed  state-of-the-art  performance  at  the  time.
                                                                                                            ‘under  the  hood’.  Note,  though,  that  each  of  these  opera-                                                                                                                                                                                                                                                                                                                                                                                                    Association  rules  enforced  through  lateral  connections  may
                                                                                                            tions  is  carried  out  only  once,  rather  than  allowing  compet-                                                                                                                                                                                                                                                                                                                                                                                                 also  help  to  ﬁll  in  missing  information,  such  as  when  objects
                                                                                                            itive  dynamics  to  converge  over  multiple  iterations.  Fur-                                                                                                                                                                                                                                                                                                                                                                                                      are partially hidden from view by occluders. Lateral connec-
                                                                                                            thermore, in contrast to the lateral interactions in predictive                                                                                                                                                                                                                                                                                                                                                                                                       tivity has been shown to improve recognitionperformance in
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
                                                                                                            coding  or  other  normative  models,  LRN  and  max-pooling                                                                                                                                                                                                                                                                                                                                                                                                          such  settings  [23 ,89 ,90].  Montobbio  et  al.  showed  that
                                                                                                            are  not  derived  from  normative  principles,  and  do  not                                                                                                                                                                                                                                                                                                                                                                                                         lateral  diffusion  of  activity  between  neurons with correlated
                                                                                                            necessarily  select  (or  enhance)  the  best  hypothesis  (how-                                                                                                                                                                                                                                                                                                                                                                                                      feedforward  ﬁlter  weights  improves  robustness  to  image
                                                                                                            ever  ‘best’  is  deﬁned).                                                                                                                                                                                                                                                                                                                                                                                                                                            perturbations  including  occlusions  [90].
                                                                                                            Compatible  hypotheses  can  strengthen  each  other  in  the                                                                                                                                                                                                                                                                                                                                                                                                         Enhancement  of  mutually  compatible  hypotheses  (this
                                                                                                            representation                                                                                                                                                                                                                                                                                                                                                                                                                                                        section)  and  competition  between  mutually  exclusive
                                                                                                            In  feedforward models of hierarchical visual inference, neu-                                                                                                                                                                                                                                                                                                                                                                                                         hypotheses  (previous  section)  can  both  contribute  to
                                                                                                            rons  at  higher  stages  selectively  respond  to  combinations  of                                                                                                                                                                                                                                                                                                                                                                                                  inference.  A  more  general  perspective  is  provided  by
                                                                                                            simpler  features  encoded  by  lower-level  neurons.  Higher-                                                                                                                                                                                                                                                                                                                                                                                                        the  insight  that  prior  knowledge  about  what  features  in
                                                                                                            level  neurons  thus  are  sensitive  to  larger-scale  patterns  of                                                                                                                                                                                                                                                                                                                                                                                                  a  scene  are  mutually  compatible  or  exclusive  may  be  part
                                                                                                                                                                                           between subsetsof lower-levelfeatures. Butsuch                                                                                                                                                                                                                                                                                                                                                               an  overarching  generative  model,  which  iterative  algo-
                                                                                                            correlation                                                                                                                                                                                                                                                                                                                                                                                                                                                           of
                                                                                                            larger-scalestatisticalregularitiesmaynotbemostefﬁciently                                                                                                                                                                                                                                                                                                                                                                                                             rithms  can  exploit  for  inference.
                                                                                                            captured  by  a  set  of  larger-scale  building  blocks.  Instead,
                                                                                                            they  may  be  more  compactly  captured  by  local  association                                                                                                                                                                                                                                                                                                                                                                                                      Iterative  algorithms  can  leverage  generative  models  for
                                                                                                            rules.  Consider,  for  instance,  the  problem  of  contour  detec-                                                                                                                                                                                                                                                                                                                                                                                                  inference
                                                                                                            tion. Many combinations of local edges in an image can form                                                                                                                                                                                                                                                                                                                                                                                                           Perceptual inference aims to converge on a set of hypothe-
                                                                                                            a  continuous  contour.  The  resulting  space  of  contours  may                                                                                                                                                                                                                                                                                                                                                                                                     ses  that  best  explain  the  sensory  data.  Typically,  a
                                                                                                            www.sciencedirect.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Current  Opinion  in  Neurobiology  2020,  65:176–193
                                                                                                186                                  Whole-brain  interactions  between  neural  circuits
                                                                                                hypothesis  is  considered  to  be  a  good  explanation  if  it  is                                                                                                                                                                                                                                                                                                                                                                                                  compactly  represented,  more  easily  learned,  more  efﬁ-
                                                                                                consistent  with  both  our  prior  knowledge  and  the  sensory                                                                                                                                                                                                                                                                                                                                                                                                      cient  to  compute,  and  more  generalizable  beyond  the
                                                                                                data. A generative model is a model of the joint distribution                                                                                                                                                                                                                                                                                                                                                                                                         training  distribution  than  its  inverse.
                                                                                                of  latent  causes  and  sensory  data.  Generative  models  can
                                                                                                powerfully  constrain  perceptual  inference  because  they                                                                                                                                                                                                                                                                                                                                                                                                           Another  potential  advantage  of  generative  inference  lies
                                                                                                capture  prior  knowledge  about  the  world.  In  machine                                                                                                                                                                                                                                                                                                                                                                                                            in  robustness  to  variations  in  the  input.  While  FNNs  can
                                                                                                learning,  deﬁning  generative models enables  us to express                                                                                                                                                                                                                                                                                                                                                                                                          accurately  categorize  images  drawn  from  the  same  distri-
                                                                                                and exploit what we know about the domain. A wide range                                                                                                                                                                                                                                                                                                                                                                                                               bution  that  the  training  images  were  drawn  from,  it  does
                                                                                                of  inference  algorithms  can  be  used  to  compute  posterior                                                                                                                                                                                                                                                                                                                                                                                                      not  take  much  to  fool  them.  A  slight  alteration  impercep-
                                                                                                distributions  over  variables  of  interest,  given  observed                                                                                                                                                                                                                                                                                                                                                                                                        tible  to  humans  can  cause  a  FNN  to  misclassify  an  image
                                                                                                variables.  The  algorithms  include  variational  inference,                                                                                                                                                                                                                                                                                                                                                                                                         entirely,                                                                  with  high  conﬁdence  [91].  State-of-the-art
                                                                                                message  passing,  and  Markov  Chain  Monte  Carlo  sam-                                                                                                                                                                                                                                                                                                                                                                                                             FNNs  rely  more  strongly  on  texture  than  humans,  who
                                                                                                pling,  all  of  which  require  iterative  computation.                                                                                                                                                                                                                                                                                                                                                                                                              rely  more  on  shape  [92].  More  generally,  FNNs  seem  to
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ignore  many  image  features  that  are  relevant  to  human
                                                                                                In this section, we focus on a particular approach to leverag-                                                                                                                                                                                                                                                                                                                                                                                                        perception  [93].  One  hypothesized  reason  for  this  is  that
                                                                                                ing generative models in visual inference, in which the joint                                                                                                                                                                                                                                                                                                                                                                                                         these networks are trained to discriminate images, but not
                                                                                                distribution  pðx; zÞ  of  the  image  x  and  the  latents  z  is                                                                                                                                                                                                                                                                                                                                                                                                    to  generate  them.  Thus,  any  visual  feature  that  reliably
                                                                                                factorized  as  pðx; zÞ  ¼  pðzÞpðxjzÞ,  which  we  refer  to  as  the                                                                                                                                                                                                                                                                                                                                                                                               discriminates  categories  in  the  training  data  will  be
                                                                                                top-down  factorization.  The  architecture  contains  com-                                                                                                                                                                                                                                                                                                                                                                                                           weighted heavily in the network’s classiﬁcation decisions.
                                                                                                ponents  that  model  pðxjzÞ  and  predict  the  image  from  the                                                                                                                                                                                                                                                                                                                                                                                                     Importantly,  this  weight  is  unrelated  to  how  much  vari-
                                                                                                latents  (or  more  generally  lower-level  latent  representa-                                                                                                                                                                                                                                                                                                                                                                                                       ance  the  feature  explains  in  the  image,  and  to  the  likeli-
                                                                                                                                       from higher-level latent representations). Compared                                                                                                                                                                                                                                                                                                                                                                                                                     —  that  is,  the  probability  of  the  image  given  either
                                                                                                tions                                                                                                                                                                                                                                                                                                                                                                                                                                                                 hood
                                                                                                to  the  alternative  factorization  pðx; zÞ  ¼  pðxÞpðzjxÞ,  the                                                                                                                                                                                                                                                                                                                                                                                                    of  the  categories.  An  ideal  observer  should  evaluate  the
                                                                                                top-down  factorization  has  the  potential  advantage  that                                                                                                                                                                                                                                                                                                                                                                                                         likelihood for each hypothesis and adjudicate according to
                                                                                                the  model  operates  in  the  causal  direction,  matching  the                                                                                                                                                                                                                                                                                                                                                                                                      their  ratio  [94].  A  feedforward  network  may  instead  latch
                                                                                                causal  process  in  the  world  that  generated  the  image.  The                                                                                                                                                                                                                                                                                                                                                                                                    on  to  a  few  highly  discriminative,  but  subtle  image
                                                                                                top-down  model  predicts  what  visual  input  is  likely  to                                                                                                                                                                                                                                                                                                                                                                                                        features  that  don’t  explain  much  and  may  not  generalize
                                                                                                result  from  a  scene  that  has  the  hypothesized  properties.                                                                                                                                                                                                                                                                                                                                                                                                     to  images  from  a  different  data  set  [93,95].  In  contrast,
                                                                                                This is  somewhat similar  to  the  graphics  engine  of  a  video                                                                                                                                                                                                                                                                                                                                                                                                    visual  features  that  are  important  for  generating  or  recon-
                                                                                                game  or  image  rendering  software.  This  top-down  model                                                                                                                                                                                                                                                                                                                                                                                                          structing  images  of  a  given  class  may  be  more  likely  to
                                                                                                                             be  implemented  via  feedback  connections  that  trans-                                                                                                                                                                                                                                                                                                                                                                                                                                                                    to  other  examples  of  the  same  category.  In
                                                                                                can                                                                                                                                                                                                                                                                                                                                                                                                                                                                   generalize
                                                                                                late  higher-level  hypotheses  in  the  network  to  represen-                                                                                                                                                                                                                                                                                                                                                                                                       support  of  this  intuition,  two  novel  RNN  architectures
                                                                                                tations  at  a  lower  level  of  abstraction.                                                                                                                                                                                                                                                                                                                                                                                                                        that  employ  generative  models  for  inference  were  found
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      to  be  more  robust  to  adversarial  perturbations  [96,97].
                                                                                                Using  generative  models  implemented  with  top-down                                                                                                                                                                                                                                                                                                                                                                                                                Generative  inference  networks  were  also  shown  to  better
                                                                                                predictions  for  inference  is  known  as  analysis-by-synthe-                                                                                                                                                                                                                                                                                                                                                                                                       align  with  human  perception,  compared  to  discriminative
                                                                                                sis  —  an  approach  that  has  a  long  history  in  theories  of                                                                                                                                                                                                                                                                                                                                                                                                   models,  when  presented  with  controversial  stimuli  —
                                                                                                perception  [51,30,32].  Arguably,  the  goal  of  perceptual                                                                                                                                                                                                                                                                                                                                                                                                         images  synthesized  to  evoke  strongly  conﬂicting  classiﬁ-
                                                                                                inference,  by  deﬁnition,  is  to  reason  back  from  effects                                                                                                                                                                                                                                                                                                                                                                                                       cations  from  different  models  [98].
                                                                                                (sensory  data)  to  their  causes  (unobserved  variables  of
                                                                                                interest),  and  thus  invert  the  process  that  generated  the                                                                                                                                                                                                                                                                                                                                                                                                     Despite  these  promising  developments,  generative  infer-
                                                                                                                                                              The  crucial  question,  however,  is  whether  the                                                                                                                                                                                                                                                                                                                                                                                            remains  rare  in  visual  FNN  models.  The  exceptions
                                                                                                effects.                                                                                                                                                                                                                                                                                                                                                                                                                                                              ence
                                                                                                causal  process  is  explicitly  represented  in  the  inference                                                                                                                                                                                                                                                                                                                                                                                                      mentioned  above  are  rather  simple  networks  trained  on
                                                                                                algorithm.  The  alternative,  which  can  be  achieved  with                                                                                                                                                                                                                                                                                                                                                                                                         easy  classiﬁcations  problems,  and  are  not  (yet)  competi-
                                                                                                feedforward  inference,  is  to  directly  approximate  the                                                                                                                                                                                                                                                                                                                                                                                                           tive  with  state-of-the-art  performance  on  more  challeng-
                                                                                                inverse,  without  ever  making  predictions  in  the  causal                                                                                                                                                                                                                                                                                                                                                                                                         ing  computer  vision  benchmarks.  Within  computational
                                                                                                direction.  The  success  of  the  feedforward  approach  then                                                                                                                                                                                                                                                                                                                                                                                                        neuroscience,  by  contrast,  generative  feedback  connec-
                                                                                                depends on how well the inverse  can  be  approximated  by                                                                                                                                                                                                                                                                                                                                                                                                            tions  appear  in  many  network  models  of  visual  inference.
                                                                                                a  ﬁxed  mapping  of  inputs  to  hypotheses.  To  iteratively                                                                                                                                                                                                                                                                                                                                                                                                        Prominent  examples  are  predictive  coding  [30,32]  and
                                                                                                invert  the  causal  process,  a  neural  network  can  evaluate                                                                                                                                                                                                                                                                                                                                                                                                      hierarchical  Bayesian  inference  [99].  However,  these
                                                                                                                             causal  model  for  a  current  hypothesis  and  update  the                                                                                                                                                                                                                                                                                                                                                                                                                                         have  not  had  much  success  in  explaining  visual
                                                                                                the                                                                                                                                                                                                                                                                                                                                                                                                                                                                   models
                                                                                                hypothesis in a beneﬁcial direction. This process can then                                                                                                                                                                                                                                                                                                                                                                                                            inference  beyond  its  earliest  stages.  A  notable  exception
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       
                                                                                                be  repeated  until  convergence.  This  process  of  analysis                                                                                                                                                                                                                                                                                                                                                                                                        is  work  by  Wen  et  al.  [100 ],  which  shows  that  extending
                                                                                                by  repeated  synthesis  may  be  preferable  to  directly                                                                                                                                                                                                                                                                                                                                                                                                            supervised  convolutional  FNNs  with  the  recurrent
                                                                                                approximating  the  inverse  mapping  if  the  causal  process                                                                                                                                                                                                                                                                                                                                                                                                        dynamics  of  predictive  coding  can  improve  classiﬁcation
                                                                                                that  generates  the  sensory  data  is  easier  to  model  than  its                                                                                                                                                                                                                                                                                                                                                                                                 performance.  The  ﬁelds  of  computer  vision  and  compu-
                                                                                                inverse.  In  particular,  the  causal  process  may  be  more                                                                                                                                                                                                                                                                                                                                                                                                        tational  neuroscience  both  stand  to  beneﬁt  from  the
                                                                                                Current  Opinion  in  Neurobiology  2020,  65:176–193                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          www.sciencedirect.com
                                                                                                                                                                                                                                                Going  in  circles  is  the  way  forward:  the  role  of  recurrence  in  visual  inference  van  Bergen  and  Kriegeskorte                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       187
                                                                                                            development  of  more  powerful  generative  inference                                                                                                                                                                                                                                                                                                                                                                                                                explicit  hybrids  of  iterative  and  amortized  inference
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  
                                                                                                            models.                                                                                                                                                                                                                                                                                                                                                                                                                                                               [104 ,105,106],  as  well  as  RNNs  with  arbitrary  dynamics
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  that  are  trained  to  converge  to  a  desired  objective  in  a
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 
                                                                                                            Iteration  is  necessary  to  close  the  amortization  gap                                                                                                                                                                                                                                                                                                                                                                                                           limited  number  of  time  steps  (e.g.  [23 ,107,108 ,109 ]).
                                                                                                            Iterative  inference  has  many  advantages.  A  drawback  of
                                                                                                            iteration,  however,  is  that  it  takes  time  for  the  algorithm  to                                                                                                                                                                                                                                                                                                                                                                                              Recurrence  is  required  for  active  vision
                                                                                                            converge during inference. This is unattractive for animals                                                                                                                                                                                                                                                                                                                                                                                                           Vision is an active exploratory process. Our eye movements
                                                                                                            who need to perform visual inference under time pressure.                                                                                                                                                                                                                                                                                                                                                                                                             scan the scene through a sequence of well-chosen ﬁxations
                                                                                                            It  is  also  a  challenge  when  training  a  FNN,  which  already                                                                                                                                                                                                                                                                                                                                                                                                   that  bring  objects  of  interest  into  foveal  vision.  Moving  our
                                                                                                            requires  many  iterations  of  optimization.  If  each  update  of                                                                                                                                                                                                                                                                                                                                                                                                   heads and our bodies enables us to bring entirely new parts
                                                                                                            the  network’s  connections  additionally  includes  an  itera-                                                                                                                                                                                                                                                                                                                                                                                                       of  the  scene  into  view,  and  closer  for  inspection  at  high
                                                                                                            tive  inner  loop  to  perform  inference  on  each  training                                                                                                                                                                                                                                                                                                                                                                                                         resolution. Active control of our eyes, heads, and bodies can
                                                                                                            example,  this  lengthens  the  time  required  for  training.                                                                                                                                                                                                                                                                                                                                                                                                        also help disambiguate 3D structure as ﬁxation on points at
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  different depths changes binocular disparity, and head and
                                                                                                            A  complementary  inference  mechanism  is  amortized  infer-                                                                                                                                                                                                                                                                                                                                                                                                         body  movements  create  motion  parallax.  Active  vision
                                                                                                            ence  [101,102],  where  a  feedforward  model  approximates                                                                                                                                                                                                                                                                                                                                                                                                          involves a recurrent cycle of sensory processing and muscle
                                                                                                            the  mapping from images to their latent  causes.  FNNs  are                                                                                                                                                                                                                                                                                                                                                                                                          control,  a  cycle  that  runs  through  the  environment.
                                                                                                            eminently  suited  for  learning  complicated  input–output
                                                                                                            mappings. A single transformation then replaces the trajec-                                                                                                                                                                                                                                                                                                                                                                                                           Our  focus  here  has  been  on  the  internal  computational
                                                                                                            tories  that  would  be  navigated  by  an  iterative  inference                                                                                                                                                                                                                                                                                                                                                                                                      functions  of  recurrent  processing,  and  active  vision  has
                                                                                                            algorithm. In some cases, the iterative solution and the best                                                                                                                                                                                                                                                                                                                                                                                                         been reviewed elsewhere [110–112]. However, it is impor-
                                                                                                                                                                                            mapping  may  be  exactly  equivalent.  A  linear                                                                                                                                                                                                                                                                                                                                                                       to  note  that  the  internal  recurrent  processes  of  visual
                                                                                                            amortized                                                                                                                                                                                                                                                                                                                                                                                                                                                             tant
                                                                                                            model,  for  instance,  can  be  estimated  iteratively,  by  per-                                                                                                                                                                                                                                                                                                                                                                                                    inference  from  a  single  glimpse  are  embedded  within  the
                                                                                                            forming gradient descent on the sum of squared prediction                                                                                                                                                                                                                                                                                                                                                                                                             larger  recurrent process  of  active  visual  exploration.  Active
                                                                                                            errors.  However,  if  a  unique  solution  exists,  it  can  equiva-                                                                                                                                                                                                                                                                                                                                                                                                 vision  provides  not  just  the  larger  behavioral  context  of
                                                                                                            lently be found bya lineartransformationthat directly maps                                                                                                                                                                                                                                                                                                                                                                                                            visual  inference.  It  also  provides  a  powerful  illustration  of
                                                                                                            from  the  data  to  the  optimal  coefﬁcients.                                                                                                                                                                                                                                                                                                                                                                                                                       the fundamental advantages that recurrent algorithms offer
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  in  general.  It  illustrates  how  limited  resources  (the  fovea)
                                                                                                            In  general,  however,  amortized  inference  incurs  some                                                                                                                                                                                                                                                                                                                                                                                                            can be dynamically allocated (eye movements) to different
                                                                                                            error,  compared  to  the  optimal  solution  that  might  be                                                                                                                                                                                                                                                                                                                                                                                                         portions  of  the  evidence  (the  visual  scene)  in  temporal
                                                                                                                                                            through  iterative  optimization.  This  error  has  been                                                                                                                                                                                                                                                                                                                                                                                                                                            A  sensory  system  limited  to  a  ﬁnite  number  of
                                                                                                            found                                                                                                                                                                                                                                                                                                                                                                                                                                                                 sequence.
                                                                                                            called  the  amortization  gap  [103,104].  It  is  analogous  to                                                                                                                                                                                                                                                                                                                                                                                                    neurons,  thus,  can  multiply  its  resources  along  time  to
                                                                                                            the  poor  ﬁt  that  may  result  from  buying  clothes  ‘off  the                                                                                                                                                                                                                                                                                                                                                                                                    achieve  a  detailed  analysis.  The  cycle  may  start  with  an
                                                                                                            rack’,  compared  to  a  tailored  version  of  the  same  garment.                                                                                                                                                                                                                                                                                                                                                                                                   initial  rough  analysis  of  the  entire  visual  ﬁeld,  followed  by
                                                                                                            The  amortization  gap  is  deﬁned  in  the  context  of  varia-                                                                                                                                                                                                                                                                                                                                                                                                      ﬁxations  on  locations  likely  to  yield  valuable  information.
                                                                                                            tional  inference,  when  the  iterative  optimization  of  the                                                                                                                                                                                                                                                                                                                                                                                                       This  is  an  example  of  an  essentially  recurrent  process
                                                                                                            variational  approximation  to  the  posterior  is  replaced  by  a                                                                                                                                                                                                                                                                                                                                                                                                   whose  efﬁciency  cannot  be  emulated  with  a  feedforward
                                                                                                            neural  network  that  maps  from  the  image  to  the  param-                                                                                                                                                                                                                                                                                                                                                                                                        system.  The  internal  mechanisms  of  visual  inference  are
                                                                                                            eters  of  the  variational  distribution.  The  resulting  model                                                                                                                                                                                                                                                                                                                                                                                                     faced  with  qualitatively  similar  challenges:  Just  like  our
                                                                                                            suffers  from  two  types  of  error:  (1)  error  caused  be  the                                                                                                                                                                                                                                                                                                                                                                                                    retinae  cannot  afford  foveal  resolution  throughout  the
                                                                                                            choice  of  the  variational  approximation  (variational                                                                                                                                                                                                                                                                                                                                                                                                             visual  ﬁeld,  the  ventral  stream  cannot  afford  to  perform
                                                                                                                                                                                                                               gap)  and  (2)  error  caused  by  the  model                                                                                                                                                                                                                                                                                                                           potentially  relevant  inferences  on  the  evidence  stream-
                                                                                                            approximation                                                                                                                                                                                                                                                                                                                                                                                                                                                         all
                                                                                                            mapping  from  images  to  variational  parameters  (amorti-                                                                                                                                                                                                                                                                                                                                                                                                          ing  in  through  the  optic  nerve  in  a  single  feedforward
                                                                                                            zation  gap).  One  recent  study  has  argued  that  the  amorti-                                                                                                                                                                                                                                                                                                                                                                                                    sweep.  Internal  shifts  of  attention,  like  eye  movements,
                                                                                                            zation  gap  is  often  the  main  source  of  error  in  amortized                                                                                                                                                                                                                                                                                                                                                                                                   can  sequentialize  a  complex  computation  and  avoid  wast-
                                                                                                            inference  models  [103].  Amortized  and  iterative  infer-                                                                                                                                                                                                                                                                                                                                                                                                          ing  energy on  portions  of  the  evidence  that  are  uninforma-
                                                                                                            ence  deﬁne  a  continuum.  At  one  extreme,  iterative  infer-                                                                                                                                                                                                                                                                                                                                                                                                      tive  or  irrelevant  to  the  current  goals  of  the  animal.
                                                                                                            ence  until  convergence  reaches  a  solution  through  a
                                                                                                            trajectory  of  small  improvements,  explicitly  evaluating                                                                                                                                                                                                                                                                                                                                                                                                          Whereas  the  outer  loop  of  active  vision  is  largely  about
                                                                                                            the  quality  of  the  current  solution  at  every  iteration.  At                                                                                                                                                                                                                                                                                                                                                                                                   positioning  our  eyes  relative  to  the  scene  and  bringing
                                                                                                                                              other  extreme,  fully  amortized  inference  takes  a                                                                                                                                                                                                                                                                                                                                                                                                                                                         content into foveal vision, the inner loop of visual
                                                                                                            the                                                                                                                                                                                                                                                                                                                                                                                                                                                                   important
                                                                                                            single  leap  from  input  to  output.  In  between  these                                                                                                                                                                                                                                                                                                                                                                                                            inference  on  each  glimpse  is  far  more  ﬂexible.  Beyond
                                                                                                            extremes lies  a  space  for  algorithms  that  use  intermediate                                                                                                                                                                                                                                                                                                                                                                                                     covert  attentional  shifts  that  select  locations,  features,  or
                                                                                                            numbers  of  steps,  to  approximate  the  optimal  solution                                                                                                                                                                                                                                                                                                                                                                                                          objects  for  scrutiny,  a  recurrent  network  can  decide  what
                                                                                                            through  a  computational  path  that  is  more  reﬁned  than  a                                                                                                                                                                                                                                                                                                                                                                                                      computations  to  perform  so  as  to  most  efﬁciently  reduce
                                                                                                            leap,                                            but                                    more  efﬁcient  than  full-ﬂedged  iterative                                                                                                                                                                                                                                                                                                                                  uncertainty  about  the  important  parts  of  the  scene.  In  a
                                                                                                            optimization.  Models  that  occupy  this  space  include                                                                                                                                                                                                                                                                                                                                                                                                             game of  twenty questions,  we  choose  a  question  that  most
                                                                                                            www.sciencedirect.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Current  Opinion  in  Neurobiology  2020,  65:176–193
                                                                                                188                                  Whole-brain  interactions  between  neural  circuits
                                                                                                reduces  our  remaining  uncertainty  at  each  step.  The  bud-                                                                                                                                                                                                                                                                                                                                                                                                      human  observers  and  in  an  RNN  model,  object  recogni-
                                                                                                get  of  twenty  would  not  sufﬁce  if  we  had  to  decide  all  the                                                                                                                                                                                                                                                                                                                                                                                                tion  under  occlusion  was  impaired  by  backward  masking
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      
                                                                                                questions  before  seeing  any  answers.  The  visual  system                                                                                                                                                                                                                                                                                                                                                                                                         [119 ]  (the  presentation  of  a  meaningless  noise  image,
                                                                                                similarly  has  limited  computational  resources  for  proces-                                                                                                                                                                                                                                                                                                                                                                                                       shortly  after  a  target  stimulus,  to  disrupt  recurrent  proces-
                                                                                                sing  a  massive  stream  of  evidence.  It  must  choose  what                                                                                                                                                                                                                                                                                                                                                                                                       sing  [120,15,13]).  Neural  responses  to  partially  occluded
                                                                                                inferences topursueon thebasisof their computational cost                                                                                                                                                                                                                                                                                                                                                                                                             shapes  in  macaque  visual  cortex  are  also  consistent  with
                                                                                                and  uncertainty-reducing  beneﬁt  as  it  forages  for  insight                                                                                                                                                                                                                                                                                                                                                                                                      recurrent  processing,  and  were  well  explained  by  a  pre-
                                                                                                [113–115].                                                                                                                                                                                                                                                                                                                                                                                                                                                            dictive  coding  model  in  which  prefrontal  cortex  provide  a
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      feedback  signal  to  visual  area  V4  [121,122].
                                                                                                Closing  the  gap  between  biological  and
                                                                                                artiﬁcial  vision                                                                                                                                                                                                                                                                                                                                                                                                                                                     Another  challenge  for  human  perception  is  crowding,
                                                                                                We  have  reviewed  a  number  of  advantages  that  recur-                                                                                                                                                                                                                                                                                                                                                                                                           which  occurs  when  the  detailed  perception  of  a  target
                                                                                                rence  can  bring  to  neural  networks  for  visual  inference.                                                                                                                                                                                                                                                                                                                                                                                                      stimulus  is  disrupted  by  nearby  ﬂanker  stimuli  [123].  In
                                                                                                Going  forward,  neural  network  models  of  vision  should                                                                                                                                                                                                                                                                                                                                                                                                          certain  instances,  the  target  stimulus  can  be  released  from
                                                                                                incorporate  recurrence;  not  just  to  better  understand                                                                                                                                                                                                                                                                                                                                                                                                           crowding  if  further  ﬂankers  are  added  that  form  a  larger,
                                                                                                visual  inference  in  the  brain,  but  also  to  improve  its                                                                                                                                                                                                                                                                                                                                                                                                       coherent  structure  with  the  original  ﬂankers.  This
                                                                                                implementation  in  machines.                                                                                                                                                                                                                                                                                                                                                                                                                                         uncrowding  effect  may  be  due  to  the  ﬂankers  being
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ‘explained  away’,  thus  reducing  their  interference  with
                                                                                                Recurrence  already  improves  performance  on                                                                                                                                                                                                                                                                                                                                                                                                                        the  target  representation  [124,125].  Recent  work  [126]
                                                                                                challenging  visual  tasks                                                                                                                                                                                                                                                                                                                                                                                                                                            has  shown  that  both  effects  can  be  explained  by  archi-
                                                                                                Efforts in  this  direction  are  already  underway,  and turning                                                                                                                                                                                                                                                                                                                                                                                                     tectures  known  as  Capsule  Nets  [127,128],  which  include
                                                                                                                               promising  results.  Some  of  this  work  has  been                                                                                                                                                                                                                                                                                                                                                                                                                                                              information  routing  mechanisms  that  may  be
                                                                                                up                                                                                                                                                                                                                                                                                                                                                                                                                                                                    recurrent
                                                                                                described  in  previous  sections,  such  as  the  use  of  lateral                                                                                                                                                                                                                                                                                                                                                                                                   similar  to  perceptual  grouping  and  segmentation  pro-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                     
                                                                                                connections  to  impose  local  association  rules  [86 ,87,  88]                                                                                                                                                                                                                                                                                                                                                                                                     cesses  in  the  visual  cortex.
                                                                                                and  generative  inference  for  more  robust  performance
                                                                                                outside  the  training  distribution  [96,97].  Several  other                                                                                                                                                                                                                                                                                                                                                                                                        Note that, in all of these cases, it may be possible to develop
                                                                                                recent  ﬁndings  are  worth  highlighting  here,  as  they  have                                                                                                                                                                                                                                                                                                                                                                                                      a  feedforward  architecture  that  performs  the  task  equally
                                                                                                shown  improved  performance  on  visual  tasks,  better                                                                                                                                                                                                                                                                                                                                                                                                              well  or  better.  Trivially,  and  as  we  discussed  previously,  a
                                                                                                approximations  to  biological  vision,  or  both,  through                                                                                                                                                                                                                                                                                                                                                                                                           successful  recurrent  architecture  can  always  be  unrolled
                                                                                                recurrent  computations.                                                                                                                                                                                                                                                                                                                                                                                                                                              (for  a  ﬁnite  number  of  time  steps)  into  a  deep  feedforward
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      network with many more learnable connections. However,
                                                                                                In  particular,  several  studies  have  found  that  recurrence  is                                                                                                                                                                                                                                                                                                                                                                                                  a  realistic recurrent model, when unrolled, may map onto an
                                                                                                required  in  order  to  explain  or  improve  visual  inference  in                                                                                                                                                                                                                                                                                                                                                                                                  unrealistic  feedforward  model  (Figure  2),  where  realism
                                                                                                                                                                                                                                                                                                                                                                                                                               
                                                                                                challenging settings.  Kar  and  colleagues  [108                                                                                                                                                                                                                                                                                           ]  identiﬁed  a                                                                                                           could  refer  to  the  real-world  constraints  faced  by  either
                                                                                                set  of  ‘challenge  images’  that  required  recurrent  processing                                                                                                                                                                                                                                                                                                                                                                                                   biological or artiﬁcial visual systems. Future studies should
                                                                                                in  order  to  be  accurately  recognized.  A  feedforward  FNN                                                                                                                                                                                                                                                                                                                                                                                                       compare  RNN  and  FNN  implementations  for  the  same
                                                                                                struggled to interpret these images, whereas macaque mon-                                                                                                                                                                                                                                                                                                                                                                                                             visual inference task, while matching the complexity of the
                                                                                                keys recognized them as accurately as a set of control images.                                                                                                                                                                                                                                                                                                                                                                                                        models  in  a  meaningful  way.  Setting  a  realistic  budget  of
                                                                                                Challenge  images  were  associated  with  longer  processing                                                                                                                                                                                                                                                                                                                                                                                                         units,  connections,  and  computational  operations  is  one
                                                                                                times  in  the  macaque  inferior  temporal  (IT)  cortex,  consis-                                                                                                                                                                                                                                                                                                                                                                                                   important  approach.  To  understand  the  computational
                                                                                                tent with recurrent computations. Neural responsesin IT for                                                                                                                                                                                                                                                                                                                                                                                                           differences  between  RNN  and  FNN  solutions,  it  is  also
                                                                                                                                                      that  took  longer  were  well  accounted  for  by  a  brain-                                                                                                                                                                                                                                                                                                                                                                                                                                       to  (1)  match  the  parameter  count  (number  of
                                                                                                images                                                                                                                                                                                                                                                                                                                                                                                                                                                                interesting
                                                                                                                                                                                                                                                                                                                                                                                                                                                
                                                                                                inspired  RNN  model.  In  a  different  study  [116 ],  this  same                                                                                                                                                                                                                                                                                                                                                                                                   connection weights that must be learned and stored), which
                                                                                                recurrent architecture was found to account forbehavior, and                                                                                                                                                                                                                                                                                                                                                                                                          requires  granting  the  FNN  larger  feature  kernels,  more
                                                                                                neuraldata frommacaque visualcortex,in object recognition                                                                                                                                                                                                                                                                                                                                                                                                             feature  maps  per  layer,  or  more  layers,  or  (2)  match  the
                                                                                                tasks,  while  also  achieving  good  performance  on  an  impor-                                                                                                                                                                                                                                                                                                                                                                                                     computational  graph,  which  equates  the  distribution  of
                                                                                                tant  computer  vision  benchmark  (ImageNet  [117]).  In                                                                                                                                                                                                                                                                                                                                                                                                             path  lengths  from  input  to  output  and  all  other  statistics
                                                                                                human visual cortex,  recurrent  interactions  were  also  found                                                                                                                                                                                                                                                                                                                                                                                                      of  the  graph,  but  grants  the  FNN  a  much  larger  number  of
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
                                                                                                to be crucial to model the neural dynamics underlying object                                                                                                                                                                                                                                                                                                                                                                                                          parameters  [23 ].
                                                                                                recognition, as measured through magnetoencephalography
                                                                                                (MEG)  [118].                                                                                                                                                                                                                                                                                                                                                                                                                                                         Freeing  ourselves  from  the  feedforward  framework
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Deep  feedforward  neural  networks  constitute  an  essential
                                                                                                One  prominent  challenge  to  visual  inference  is  posed  by                                                                                                                                                                                                                                                                                                                                                                                                       building  block  for  visual  inference,  but  they  are  not  the
                                                                                                partial  occlusions,  which  hide  part  of  a  target  object  from                                                                                                                                                                                                                                                                                                                                                                                                  whole  story.  The  missing  element,  recurrent  dynamics,  is
                                                                                                view.  In  two  recent  studies,  recurrent  architectures  were                                                                                                                                                                                                                                                                                                                                                                                                      central  to  a  range  of  alternative  conceptions  of  visual  infer-
                                                                                                shown  to  be  more  robust  to  occlusions  than  their  feedfor-                                                                                                                                                                                                                                                                                                                                                                                                    ence  that  have  been  proposed  [110,129,31,111,112,130].
                                                                                                                                                                                                                                                                                                                        
                                                                                                ward  counterparts  [89 ,119 ].  Interestingly,  in  both                                                                                                                                                                                                                                                                                                                                                                                                             These  ideas  have  a  long  history,  they  are  essential  to
                                                                                                Current  Opinion  in  Neurobiology  2020,  65:176–193                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          www.sciencedirect.com
                                                                                                                                                                                                                                                Going  in  circles  is  the  way  forward:  the  role  of  recurrence  in  visual  inference  van  Bergen  and  Kriegeskorte                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       189
                                                                                                            understanding biological  vision,  and  they  have  great  poten-                                                                                                                                                                                                                                                                                                                                                                                                     discover  useful  dynamics.  From  a  practical  and  imple-
                                                                                                            tial  for  engineering,  especially  in  the  context  of  modern                                                                                                                                                                                                                                                                                                                                                                                                     mentational  perspective,  BPTT  is  computationally  cum-
                                                                                                            hardware  and  software.  The  promise  of  active  vision  and                                                                                                                                                                                                                                                                                                                                                                                                       bersome,  as  every  additional  recurrent  time  step  extends
                                                                                                            recurrent visual inference is, in fact, boosted by the power of                                                                                                                                                                                                                                                                                                                                                                                                       the  computational  path  that  must  be  retraced  in  order  to
                                                                                                            feedforward  networks.                                                                                                                                                                                                                                                                                                                                                                                                                                                update  the  connections.  This  complication  also  renders
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  BPTT  biologically  implausible.  Although  the  case  for
                                                                                                            However,  the  beauty,  power,  and  simplicity  of  feedfor-                                                                                                                                                                                                                                                                                                                                                                                                         backpropagation  as  potentially  biologically  plausible
                                                                                                            ward neural networks also makes it difﬁcult to engage and                                                                                                                                                                                                                                                                                                                                                                                                             has  recently  been  strengthened  [132–134],  its  extension
                                                                                                            develop  the  space  of  recurrent  neural  network  algorithms                                                                                                                                                                                                                                                                                                                                                                                                       through  time  is  difﬁcult  to  reconcile  with  biology  [135]  or
                                                                                                            for  vision.  The  feedforward  framework,  embellished  by                                                                                                                                                                                                                                                                                                                                                                                                           implement  efﬁciently  in  a  ﬁnite  engineered  system  for
                                                                                                            recurrent  processes  that  serve  auxiliary  and  modulatory                                                                                                                                                                                                                                                                                                                                                                                                         online  learning  —  precisely  because  it  requires  unrolling
                                                                                                            functions  like  normalization  and  attention,  enables                                                                                                                                                                                                                                                                                                                                                                                                              and  keeping  track  of  separate  copies  of  each  weight  as
                                                                                                            computational  neuroscientists  to  hold  on  to  the  idea  of                                                                                                                                                                                                                                                                                                                                                                                                       computational  cycles  are  retraced  in  reverse.
                                                                                                            a  hierarchy  of  feature  detectors.  This  idea  might  not  be
                                                                                                            entirely  mistaken.  However,  it  is  likely  to  be  severely                                                                                                                                                                                                                                                                                                                                                                                                       Given  these  drawbacks,  we  speculate  that  a  true  break-
                                                                                                            incomplete  and  ultimately  limiting.                                                                                                                                                                                                                                                                                                                                                                                                                                through  in  recurrent  vision  models  will  require  a  training
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  regime that does not rely on BPTT. Rather than optimizing
                                                                                                            The  insight  that  any  ﬁnite-time  recurrent  network  can  be                                                                                                                                                                                                                                                                                                                                                                                                      an  RNN’s  state  in  a  ﬁnite  time  window,  future  RNN
                                                                                                            unrolled  compounds  the  problem  by  suggesting  that  the                                                                                                                                                                                                                                                                                                                                                                                                          training  methods  might  directly  target  the  network’s
                                                                                                            feedforward framework is essentially complete. More prac-                                                                                                                                                                                                                                                                                                                                                                                                             dynamics, or the states that those dynamics are encouraged
                                                                                                            tically,  the  fact  that  we  train  RNNs  by  unrolling  them  for                                                                                                                                                                                                                                                                                                                                                                                                  to  converge  to.  This  approach  has  some  history  in  RNN
                                                                                                                                                       time  steps  might  in  some  ways  impede  our  progress.                                                                                                                                                                                                                                                                                                                                                                                                                        ofvision. Predictivecodingmodels, for instance, are
                                                                                                            ﬁnite                                                                                                                                                                                                                                                                                                                                                                                                                                                                 models
                                                                                                            FNNs  are  usually  trained  by  stochastic  gradient  descent                                                                                                                                                                                                                                                                                                                                                                                                        designed with dynamics that explicitly implement iterative
                                                                                                            using  the  backpropagation  algorithm.  This  method  retraces                                                                                                                                                                                                                                                                                                                                                                                                       optimization.  Such  models  can  update  their  connections
                                                                                                            in  reverse  the  computational  steps  that  led  to  the  response                                                                                                                                                                                                                                                                                                                                                                                                  through  learning  rules  that  require  only  the  converged
                                                                                                            in  the output layer, so as to estimate the inﬂuence that each                                                                                                                                                                                                                                                                                                                                                                                                        network  state  as  input  [30],  rather  than  the  entire  compu-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
                                                                                                            connection  in  the  network  had  on  the  response.  Each                                                                                                                                                                                                                                                                                                                                                                                                           tational  path  to  this  state.  Marino  et  al.  [104 ]  recently
                                                                                                            connection  weight  is  then  adjusted,  to  bring  the  network                                                                                                                                                                                                                                                                                                                                                                                                      proposed  iterative  amortized  inference,  training  inference
                                                                                                            output closer to a desired output. The deeper the network,                                                                                                                                                                                                                                                                                                                                                                                                            networks  to  have  recurrent  dynamics  that  improve  the
                                                                                                            thelongerthe computational path that needs tobe retraced.                                                                                                                                                                                                                                                                                                                                                                                                             network’s  hypotheses  in  each  iteration,  without  constrain-
                                                                                                                                                                 for  visual  inference  typically  are  trained  through  a                                                                                                                                                                                                                                                                                                                                                                                 these  dynamics  to  a  particular  form  (such  as  predictive
                                                                                                            RNNs                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ing
                                                                                                            variation  on  this  method,  known as  backpropagation  through                                                                                                                                                                                                                                                                                                                                                                                                      coding). More generally, RNNs whose dynamics converge
                                                                                                            time  (BPTT)  [131].  To  retrace  computations  in  reverse                                                                                                                                                                                                                                                                                                                                                                                                          to  a  steady  state  can  be  optimized  through  variations  on  an
                                                                                                            through  cycles,  the  RNN  is  unrolled  along  time,  so  as  to                                                                                                                                                                                                                                                                                                                                                                                                    algorithm  known  as  recurrent  backpropagation  [136–138],
                                                                                                            convert it into a feedforward network whose depth depends                                                                                                                                                                                                                                                                                                                                                                                                             which  avoids  retracing  the  computational  graph  through
                                                                                                            on the number of time steps as shown in Figure 1b–d. This                                                                                                                                                                                                                                                                                                                                                                                                             time.  However,  it  is  often  difﬁcult  to  design  RNNs  such
                                                                                                            enables  the  RNN  to  be  trained  like  an  FNN.                                                                                                                                                                                                                                                                                                                                                                                                                    that  their  dynamics  converge  to  a  steady  state  (within  the
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  time  window  for  which  the  model  is  trained),  while  main-
                                                                                                            BPTT  is  attractive  for  enabling  us  to  train  RNNs  like                                                                                                                                                                                                                                                                                                                                                                                                        taining  expressivity  (the  ability  of  the  model  to  learn  a  wide
                                                                                                            FNNs  on  arbitrary  objectives.  When  it  comes  to  learning                                                                                                                                                                                                                                                                                                                                                                                                       range  of  functions).  This  challenge  is  addressed  by  the
                                                                                                            recurrent dynamics, however, BPTT strictly optimizes the                                                                                                                                                                                                                                                                                                                                                                                                              recently  developed  contractor  recurrent  backpropagation
                                                                                                                                                               at the speciﬁc timepointsevaluatedby the objective                                                                                                                                                                                                                                                                                                                                                                                                                                 [139],  which  introduces  a  mathematical  penalty
                                                                                                            output                                                                                                                                                                                                                                                                                                                                                                                                                                                                method
                                                                                                            (e.g. the output after exactly N  steps).  Outside  of  this  time                                                                                                                                                                                                                                                                                                                                                                                                    that can be imposed while training any RNN, to encourage
                                                                                                            window, there is no guarantee that the network’s response                                                                                                                                                                                                                                                                                                                                                                                                             it  to  learn  convergent  dynamics.
                                                                                                            will  be  well-behaved.  The  RNN  might  reach  the  desired
                                                                                                            objective  at  the  desired  time,  but  diverge  immediately                                                                                                                                                                                                                                                                                                                                                                                                         Going  forward,  in  circles
                                                                                                            after.  Ideally,  we  would  like  a  visual  RNN  presented  with                                                                                                                                                                                                                                                                                                                                                                                                    We started this review with the puzzling observation that,
                                                                                                            a  stable  image  to  converge  to  an  attractor  that  represents                                                                                                                                                                                                                                                                                                                                                                                                   whereas  biological  vision  is  implemented  in  a  profoundly
                                                                                                            the  image  and  behave  stably  for  arbitrary  lengths  of  time.                                                                                                                                                                                                                                                                                                                                                                                                   recurrent  neural  architecture,  the  most  successful  neural
                                                                                                            This  would  be  consistent  with  iterative  optimization,  in                                                                                                                                                                                                                                                                                                                                                                                                       network  models  of  vision  to  date  are  feedforward.  We
                                                                                                                                                             each  step  improves  the  network’s approximation to                                                                                                                                                                                                                                                                                                                                                                                                            argued,  theoretically  and  empirically,  that  vision
                                                                                                            which                                                                                                                                                                                                                                                                                                                                                                                                                                                                 have
                                                                                                            its  objective.  While  it  is  not  impossible  for  BPTT  to  give                                                                                                                                                                                                                                                                                                                                                                                                  models  will  eventually  converge  to  their  biological  roots
                                                                                                            rise  to  such  dynamics,  it  does  not  speciﬁcally  favor  them.                                                                                                                                                                                                                                                                                                                                                                                                   and implement more powerful recurrent solutions. This is
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  an  appealing  prospect,  as  it  suggests  that  neuroscientists
                                                                                                            From  a  theory  perspective,  BPTT  is  limiting  because  it                                                                                                                                                                                                                                                                                                                                                                                                        and  engineers  can  continue  to  work  synergistically,  to
                                                                                                            shackles  RNNs  to  the  feedforward  framework,  in  which                                                                                                                                                                                                                                                                                                                                                                                                           make  progress  on  common  challenges.  After  all,  visual
                                                                                                            the  goal  is  still  to  map  inputs  to  outputs,  rather  than  to                                                                                                                                                                                                                                                                                                                                                                                                 inference,  and  intelligence  more  generally,  were  solved
                                                                                                            www.sciencedirect.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Current  Opinion  in  Neurobiology  2020,  65:176–193
                                                                                                190                                  Whole-brain  interactions  between  neural  circuits
                                                                                                once  before,  and  so  discovering  nature’s  solutions  should                                                                                                                                                                                                                                                                                                                                                                                                      14.                          Heinen  K,  Jolij  J,  Lamme  VA:  Figure-ground  segregation
                                                                                                go  hand  in  hand  with  building  artiﬁcial  ones.                                                                                                                                                                                                                                                                                                                                                                                                                                               requires  two  distinct  periods  of  activity  in  VI:  a  transcranial
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   magnetic  stimulation  study.  NeuroReport  2005,  16:1483-1487
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   http://dx.doi.org/10.1097/01.wnr.0000175611.26485.c8.
                                                                                                Conﬂict  of  interest  statement                                                                                                                                                                                                                                                                                                                                                                                                                                      15.                          Fahrenfort  JJ,  Scholte  HS,  Lamme  VA:  Masking  disrupts
                                                                                                Nothing  declared.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 reentrant  processing  in  human  visual  cortex.  J  Cogn  Neurosci
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2007,  19:1488-1497  http://dx.doi.org/10.1162/
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   jocn.2007.19.9.1488.
                                                                                                Acknowledgements                                                                                                                                                                                                                                                                                                                                                                                                                                                      16.                          Lecun  Y,  Bengio  Y,  Hinton  G:  Deep  learning.  Nature  2015,
                                                                                                                                                                                                                                                                                                               ¨                                                                                                                                                                                                                                                                                   521:436-444  http://dx.doi.org/10.1038/nature14539.
                                                                                                We  thank  Samuel  Lippl,  Heiko  Schutt,  Andrew  Zaharia,  Tal  Golan  and
                                                                                                Benjamin  Peters  for  detailed  comments  on  a  draft  of  this  paper.  This  work
                                                                                                was  supported  by  a  Rubicon  grant  from  the  Dutch  Research  Council                                                                                                                                                                                                                                                                                                                                                                                            17.                          Schmidhuber J: Deep learning in neural networks: an overview.
                                                                                                (to  RSvB).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Neural  Netw  2015,  61:85-117  http://dx.doi.org/10.1016/j.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   neunet.2014.09.003.
                                                                                                References  and  recommended  reading                                                                                                                                                                                                                                                                                                                                                                                                                                 18.                          He  K,  Zhang  X,  Ren  S,  Sun  J:  Delving  deep  into  rectiﬁers:
                                                                                                Papers  of  particular  interest,  published  within  the  period  of  review,                                                                                                                                                                                                                                                                                                                                                                                                                     surpassing  human-level  performance  on  ImageNet
                                                                                                have  been  highlighted  as:                                                                                                                                                                                                                                                                                                                                                                                                                                                                       classiﬁcation.  2015  IEEE  International  Conference  on  Computer
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Vision
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          (ICCV),  vol.  2015  International  2015:1026-1034  http://dx.
                                                                                                                            of  special  interest                                                                                                                                                                                                                                                                                                                                                                                                                                                 doi.org/10.1109/ICCV.2015.123.
                                                                                                             of  outstanding  interest                                                                                                                                                                                                                                                                                                                                                                                                                              19.                          He  K,  Zhang  X,  Ren  S,  Sun  J:  Deep  residual  learning  for  image
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   recognition.  Proceedings  of  the  IEEE  Computer  Society
                                                                                                1.                           Lamme VA, Roelfsema PR: The distinct modes of vision offered                                                                                                                                                                                                                                                                                                                                                                                                          Conference  on  Computer  Vision  and  Pattern  Recognition  2016-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   December
                                                                                                                             by  feedforward  and  recurrent  processing.  Trends  Neurosci                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2016:770-778  http://dx.doi.org/10.1109/
                                                                                                                             2000,  23:571-579  http://dx.doi.org/10.1016/S0166-2236(00)                                                                                                                                                                                                                                                                                                                                                                                                           CVPR.2016.90.
                                                                                                                             01657-X.                                                                                                                                                                                                                                                                                                                                                                                                                                 20.                          Kemelmacher-Shlizerman  I,  Seitz  SM,  Miller  D,  Brossard  E:  The
                                                                                                2.                           Kreiman  G,  Serre  T:  Beyond  the  feedforward  sweep:  feedback                                                                                                                                                                                                                                                                                                                                                                                                    MegaFace benchmark: 1 million faces for recognition at scale.
                                                                                                                             computations  in  the  visual  cortex.  Ann  N  Y  Acad  Sci  2020,                                                                                                                                                                                                                                                                                                                                                                                                   Proceedings  of  the  IEEE  Computer  Society  Conference  on
                                                                                                                             1464:222-241  http://dx.doi.org/10.1111/nyas.14320.                                                                                                                                                                                                                                                                                                                                                                                                                   Computer  Vision  and  Pattern  Recognition  2016-December
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2016:4873-4882  http://dx.doi.org/10.1109/CVPR.2016.527.
                                                                                                3.                           Angelucci  A,  Bressloff  PC:  Contribution  of  feedforward,  lateral
                                                                                                                                                        feedback  connections  to  the  classical  receptive  ﬁeld
                                                                                                                             and                                                                                                                                                                                                                                                                                                                                                                                                                                      21.                          Kubilius J, Bracci S, Op de Beeck HP: Deep neural networks as a
                                                                                                                             center  and  extra-classical  receptive  ﬁeld  surround  of  primate                                                                                                                                                                                                                                                                                                                                                                                                  computational  model  for  human  shape  sensitivity.  PLOS
                                                                                                                             V1  neurons.  Progress  in  Brain  Research,  vol  154  2006:93-120                                                                                                                                                                                                                                                                                                                                                                                                   Comput Biol 2016, 12:e1004896 http://dx.doi.org/10.1371/journal.
                                                                                                                             http://dx.doi.org/10.1016/S0079-6123(06)54005-1.                                                                                                                                                                                                                                                                                                                                                                                                                      pcbi.1004896.
                                                                                                4.                           Anderson  JC,  Douglas  RJ,  Martin  KAC,  Nelson  JC:  Synaptic                                                                                                                                                                                                                                                                                                                                                                         22.                          Majaj  NJ,  Pelli  DG:  Deep  learning-Using  machine  learning  to
                                                                                                                             output  of  physiologically  identiﬁed  spiny  stellate  neurons  in                                                                                                                                                                                                                                                                                                                                                                                                  study  biological  vision.  J  Vision  2018,  18:1-13  http://dx.doi.org/
                                                                                                                             cat  visual  cortex.  J  Comp  Neurol  1994,  341:16-24  http://dx.doi.                                                                                                                                                                                                                                                                                                                                                                                               10.1167/18.13.2.
                                                                                                                             org/10.1002/cne.903410103.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      23. Spoerer
                                                                                                5.                           Martin  KA:  Microcircuits  in  visual  cortex.  Curr  Opin  Neurobiol                                                                                                                                                                                                                                                                                                                                                                                                                                                   CJ,  Kietzmann  TC,  Mehrer  J,  Charest  I,  Kriegeskorte  N:
                                                                                                                             2002,  12:418-425  http://dx.doi.org/10.1016/S0959-4388(02)                                                                                                                                                                                                                                                                                                                                                                                                         Recurrent  neural  networks  can  explain  ﬂexible  trading  of
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   speed  and  accuracy  in  biological  vision.  PLOS  Comput  Biol
                                                                                                                             00343-4.                                                                                                                                                                                                                                                                                                                                                                                                                                                              2020,  16:e1008215  http://dx.doi.org/10.1371/journal.
                                                                                                6.                           Douglas  RJ,  Martin  KA:  Recurrent  neuronal  circuits  in  the                                                                                                                                                                                                                                                                                                                                                                                                     pcbi.1008215
                                                                                                                             neocortex.  Curr  Biol  2007,  17:496-500  http://dx.doi.org/10.1016/                                                                                                                                                                                                                                                                                                                                                                    Showed  that  RNNs  can  ﬂexibly  prioritize  speed  or  accuracy,  without
                                                                                                                             j.cub.2007.04.024.                                                                                                                                                                                                                                                                                                                                                                                                                       having  to  sacriﬁce  either  when  compared  to  FNNs  with  the  same  com-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      putational  cost.
                                                                                                7.                           Felleman  DJ,  Van  Essen  DC:  Distributed  hierarchical                                                                                                                                                                                                                                                                                                                                                                                24.                          Cadieu  CF,  Hong  H,  Yamins  DLK,  Pinto  N,  Ardila  D,  Solomon  EA,
                                                                                                                             processing  in  the  primate  cerebral  cortex.  Cereb  Cortex  1991,                                                                                                                                                                                                                                                                                                                                                                                                 Majaj  NJ,  DiCarlo  JJ:  Deep  neural  networks  rival  the
                                                                                                                             1:1-47  http://dx.doi.org/10.1093/cercor/1.1.1.                                                                                                                                                                                                                                                                                                                                                                                                                       representation  of  primate  IT  cortex  for  core  visual  object
                                                                                                8.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 recognition.  PLoS  Comput  Biol  2014,  10:e1003963  http://dx.doi.
                                                                                                                             Salin  PA,  Bullier  J:  Corticocortical  connections  in  the  visual
                                                                                                                             system:  structure  and  function.  Physiol  Rev  1995,  75:107-154                                                                                                                                                                                                                                                                                                                                                                                                   org/10.1371/journal.pcbi.1003963.
                                                                                                                             http://dx.doi.org/10.1152/physrev.1995.75.1.107.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      25.                          Khaligh-Razavi  SM,  Kriegeskorte  N:  Deep  supervised,  but  not
                                                                                                9.                           Markov  NT,  Ercsey-Ravasz  MM,  Ribeiro  Gomes  AR,  Lamy  C,                                                                                                                                                                                                                                                                                                                                                                                                        unsupervised,  models  may  explain  IT  cortical  representation.
                                                                                                                             Magrou  L,  Vezoli  J,  Misery  P,  Falchier  A,  Quilodran  R,  Gariel  MA,                                                                                                                                                                                                                                                                                                                                                                                          PLoS
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Comput  Biol  2014,  10  http://dx.doi.org/10.1371/journal.
                                                                                                                             Sallet  J,  Gamanut  R,  Huissoud  C,  Clavagnier  S,  Giroud  P,  Sappey-                                                                                                                                                                                                                                                                                                                                                                                            pcbi.1003915.
                                                                                                                             Marinier  D,  Barone  P,  Dehay  C,  Toroczkai  Z,  Knoblauch  K,  Van
                                                                                                                             Essen                                                                                                                                                                                                                                                                                                                                                                                                                                    26.                          Guclu  U,  van  Gerven  MAJ:  Deep  neural  networks  reveal  a
                                                                                                                                                                     DC,  Kennedy  H:  A  weighted  and  directed  interareal
                                                                                                                             connectivity matrix for macaque cerebral cortex. Cereb Cortex                                                                                                                                                                                                                                                                                                                                                                                                         gradient  in  the  complexity  of  neural  representations  across
                                                                                                                             2014,  24:17-36  http://dx.doi.org/10.1093/cercor/bhs270.                                                                                                                                                                                                                                                                                                                                                                                                             the  ventral  stream.  J  Neurosci  2015,  35:10005-10014  http://dx.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   doi.org/10.1523/JNEUROSCI.  5023-14.2015.
                                                                                                10.                          Douglas  RJ,  Koch  C,  Mahowald  M,  Martin  KA,  Suarez  HH:
                                                                                                                             Recurrent
                                                                                                                                                                                                excitation  in  neocortical  circuits.  Science  1995,                                                                                                                                                                                                                                                                                                                27.                          Kriegeskorte  N:  Deep  neural  networks:  a  new  framework  for
                                                                                                                             269:981-985  http://dx.doi.org/10.1126/science.7638624.                                                                                                                                                                                                                                                                                                                                                                                                               modeling  biological  vision  and  brain  information  processing.
                                                                                                                                                      `                                                                                                                                                                                                                                                                                                                                                                                                                                            Annu  Rev  Vision  Sci  2015,  1:417-446  http://dx.doi.org/10.1146/
                                                                                                11.                          Super  H,  Spekreijse  H,  Lamme  VA:  Two  distinct  modes  of                                                                                                                                                                                                                                                                                                                                                                                                       annurev-vision-082114-035447.
                                                                                                                             sensory processing observed in monkey primary visual cortex
                                                                                                                             (V1).  Nat  Neurosci  2001,  4:304-310  http://dx.doi.org/10.1038/                                                                                                                                                                                                                                                                                                                                                                       28.                          Kheradpisheh SR, Ghodrati M, Ganjtabesh M, Masquelier T: Deep
                                                                                                                             85170.                                                                                                                                                                                                                                                                                                                                                                                                                                                                networks  can  resemble  human  feed-forward  vision  in
                                                                                                12.                          Di  Lollo  V,  Enns  JT,  Rensink  RA:  Competition  for  consciousness                                                                                                                                                                                                                                                                                                                                                                                               invariant  object  recognition.  Sci  Rep  2016,  6:32672  http://dx.
                                                                                                                             among  visual  events:  the  psychophysics  of  reentrant  visual                                                                                                                                                                                                                                                                                                                                                                                                     doi.org/10.1038/srep32672.
                                                                                                                             processes.  J  Exp  Psychol:  Gen  2000,  129:481-507  http://dx.doi.                                                                                                                                                                                                                                                                                                                                                                    29.                          Schrimpf M, Kubilius J, Hong H, Majaj NJ, Rajalingham R, Issa EB,
                                                                                                                             org/10.1037/0096-3445.129.4.481.                                                                                                                                                                                                                                                                                                                                                                                                                                      Kar  K,  Bashivan  P,  Prescott-Roy  J,  Geiger  F,  Schmidt  K,
                                                                                                13.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Yamins  DLK,  DiCarlo  JJ:  Brain-score:  Which  artiﬁcial  neural
                                                                                                                             Lamme  VA,  Zipser  K,  Spekreijse  H:  Masking  interrupts  ﬁgure-                                                                                                                                                                                                                                                                                                                                                                                                   network for object recognition is most brain-like?  bioRxiv 2020
                                                                                                                             ground  signals  in  V1.  J  Vision  2001,  1:1044-1053  http://dx.doi.                                                                                                                                                                                                                                                                                                                                                                                               http://dx.doi.org/10.1101/407007.
                                                                                                                             org/10.1167/1.3.32.
                                                                                                Current  Opinion  in  Neurobiology  2020,  65:176–193                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          www.sciencedirect.com
                                                                                                                                                                                                                                                Going  in  circles  is  the  way  forward:  the  role  of  recurrence  in  visual  inference  van  Bergen  and  Kriegeskorte                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       191
                                                                                                            30.                          Rao  RPN,  Ballard  DH:  Predictive  coding  in  the  visual  cortex:  a                                                                                                                                                                                                                                                                                                                                                                 50.                          Summerﬁeld  C,  Egner  T:  Expectation  (and  attention)  in  visual
                                                                                                                                         functional  interpretation  of  some  extra-classical  receptive-                                                                                                                                                                                                                                                                                                                                                                                                     cognition.  Trends  Cogn  Sci  2009,  13:403-409  http://dx.doi.org/
                                                                                                                                         ﬁeld  effects.  Nat  Neurosci  1999,  2:79-87  http://dx.doi.org/                                                                                                                                                                                                                                                                                                                                                                                                     10.1016/j.tics.2009.06.003.
                                                                                                                                         10.1038/4580.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  51.                          von Helmholtz H: Handbuch der physiologischen Optik.  New York:
                                                                                                            31.                          Yuille  A,  Kersten  D:  Vision  as  Bayesian  inference:  analysis  by                                                                                                                                                                                                                                                                                                                                                                                               Dover  (English  translation);  1860/1962.
                                                                                                                                         synthesis?  Trends  Cogn  Sci  2006,  10:301-308  http://dx.doi.org/
                                                                                                                                         10.1016/j.tics.2006.05.002.                                                                                                                                                                                                                                                                                                                                                                                                              52.                          Weiss Y,  Simoncelli  EP,  Adelson  EH:  Motion  illusions  as  optimal
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               percepts.  Nat  Neurosci  2002,  5:598-604  http://dx.doi.org/
                                                                                                            32.                          Friston  K,  Kiebel  S:  Predictive  coding  under  the  free-energy                                                                                                                                                                                                                                                                                                                                                                                                  10.1038/nn858.
                                                                                                                                         principle.  Philos  Trans  R  Soc  B:  Biol  Sci  2009,  364:1211-1221
                                                                                                                                         http://dx.doi.org/10.1098/rstb.2008.0300.                                                                                                                                                                                                                                                                                                                                                                                                53.                          Stocker  AA,  Simoncelli  EP:  Noise  characteristics  and  prior
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               expectations  in  human  visual  speed  perception.  Nat  Neurosci
                                                                                                            33.                          Prince  SJD:  Computer  Vision:  Models,  Learning  and  Inference.                                                                                                                                                                                                                                                                                                                                                                                                   2006,  9:578-585  http://dx.doi.org/10.1038/nn1669.
                                                                                                                                         Cambridge:  Cambridge  University  Press;  2012  http://dx.doi.org/
                                                                                                                                         10.1017/CBO9780511996504.                                                                                                                                                                                                                                                                                                                                                                                                                54.                          Mamassian P,  Goutcher  R:  Prior  knowledge  on  the  illumination
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               position.  Cognition  2001,  81:1-9  http://dx.doi.org/10.1016/
                                                                                                            34.                          DiCarlo  JJ,  Zoccolan  D,  Rust  NC:  How  does  the  brain  solve                                                                                                                                                                                                                                                                                                                                                                                                   S0010-0277(01)00116-0.
                                                                                                                                         visual  object  recognition?  Neuron  2012,  73:415-434  http://dx.
                                                                                                                                         doi.org/10.1016/j.neuron.2012.01.010.                                                                                                                                                                                                                                                                                                                                                                                                    55.                          Girshick  AR,  Landy  MS,  Simoncelli  EP:  Cardinal  rules:  visual
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               orientation  perception  reﬂects  knowledge  of  environmental
                                                                                                            35.                          Carandini  M,  Heeger  DJ:  Normalization  as  a  canonical  neural                                                                                                                                                                                                                                                                                                                                                                                                   statistics.  Nat  Neurosci  2011,  14:926-932  http://dx.doi.org/
                                                                                                                                         computation. Nat Rev Neurosci 2012, 13:51-62 http://dx.doi.org/                                                                                                                                                                                                                                                                                                                                                                                                       10.1038/nn.2831.
                                                                                                                                         10.1038/nrn3136.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  56.                          Hasson U,  Yang  E,  Vallines  I,  Heeger  DJ,  Rubin  N:  A  hierarchy  of
                                                                                                            36.                          Desimone  R,  Duncan  J:  Neural  mechanisms  of  selective  visual                                                                                                                                                                                                                                                                                                                                                                                                   temporal receptive windows in human cortex. J Neurosci 2008,
                                                                                                                                         attention.  Annu  Rev  Neurosci  1995,  18:193-222  http://dx.doi.org/                                                                                                                                                                                                                                                                                                                                                                                                28:2539-2550  http://dx.doi.org/10.1523/JNEUROSCI.  5487-
                                                                                                                                         10.1146/annurev.neuro.18.1.193.                                                                                                                                                                                                                                                                                                                                                                                                                                       07.2008.
                                                                                                            37.                          Kastner  S,  Ungerleider  LG:  Mechanisms  of  visual  attention  in                                                                                                                                                                                                                                                                                                                                                                     57.                          Murray JD, Bernacchia A, Freedman DJ, Romo R, Wallis JD, Cai X,
                                                                                                                                         the  human  cortex.  Annu  Rev  Neurosci  2000,  23:315-341  http://                                                                                                                                                                                                                                                                                                                                                                                                  Padoa-Schioppa  C,  Pasternak  T,  Seo  H,  Lee  D,  Wang  X-J:  A
                                                                                                                                         dx.doi.org/10.1146/annurev.neuro.23.1.315.                                                                                                                                                                                                                                                                                                                                                                                                                            hierarchy  of  intrinsic  timescales  across  primate  cortex.  Nat
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Neurosci  2014,  17:1661-1663  http://dx.doi.org/10.1038/nn.3862.
                                                                                                            38.                          Maunsell  JH,  Treue  S:  Feature-based  attention  in  visual  cortex.
                                                                                                                                         Trends  Neurosci  2006,  29:317-322  http://dx.doi.org/10.1016/j.                                                                                                                                                                                                                                                                                                                                                                        58.                          Sutskever  I,  Vinyals  O,  Le  QV:  Sequence  to  sequence  learning
                                                                                                                                         tins.2006.04.001.                                                                                                                                                                                                                                                                                                                                                                                                                                                     with  neural  networks.  Adv  Neural  Inform  Process  Syst  2014,
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               4:3104-3112.
                                                                                                            39.                          Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN,
                                                                                                                                         Kaiser  Lu,  Polosukhin  I:  Attention  is  all  you  need.  Advances  in                                                                                                                                                                                                                                                                                                                                                                59.                          Kalman  RE:  A  new  approach  to  linear  ﬁltering  and  prediction
                                                                                                                                         Neural  Information  Processing  Systems  2017:5998-6008.                                                                                                                                                                                                                                                                                                                                                                                                             problems.  J  Basic  Eng  1960,  82:35-45  http://dx.doi.org/10.1115/
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               1.3662552.
                                                                                                            40. Liao  Q,  Poggio  T:  Bridging  the  Gaps  Between  Residual  Learning,
                                                                                                                                       Recurrent  Neural  Networks  and  Visual  Cortex.  2016.                                                                                                                                                                                                                                                                                                                                                                                 60.                          Wolpert  D,  Ghahramani  Z,  Jordan  M:  An  internal  model  for
                                                                                                                                         arXiv:1604.03640                                                                                                                                                                                                                                                                                                                                                                                                                                                      sensorimotor  integration.  Science  1995,  269:1880-1882  http://
                                                                                                            This  paper  highlighted  the  important  equivalence  between  ResNet  archi-                                                                                                                                                                                                                                                                                                                                                                                                                     dx.doi.org/10.1126/science.7569931.
                                                                                                            tectures  and  unrolled  RNNs,  and  showed  that  ResNets  could  be  made
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  61.
                                                                                                            more  parameter-efﬁcient  (while  retaining  similar  performance)  by  impos-                                                                                                                                                                                                                                                                                                                                                                                                                     Rao  RPN,  Ballard  DH:  Dynamic  model  of  visual  recognition
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     neural response properties in the visual cortex. Neural
                                                                                                            ing  recurrent-equivalent  weight-sharing  constraints.                                                                                                                                                                                                                                                                                                                                                                                                                                            predicts
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Comput  1997,  9:721-763  http://dx.doi.org/10.1162/
                                                                                                            41.                          JastrzSebski  S,  Arpit  D,  Ballas  N,  Verma  V,  Che  T,  Bengio  Y:                                                                                                                                                                                                                                                                                                                                                                                               neco.1997.9.4.721.
                                                                                                                                         Residual  Connections  Encourage  Iterative  Inference.  2017.
                                                                                                                                         arXiv:1710.04773.                                                                                                                                                                                                                                                                                                                                                                                                                        62.                          Rao  RPN:  Bayesian  computation  in  recurrent  neural  circuits.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Neural  Comput  2004,  16:1-38.
                                                                                                            42.                          Greff  K,  Srivastava  RK,  Schmidhuber  J:  Highway  and  residual
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         `
                                                                                                                                         networks  learn  unrolled  iterative  estimation.  5th  International                                                                                                                                                                                                                                                                                                                                                                    63.                          Deneve  S,  Duhamel  J-R,  Pouget  A:  Optimal  sensorimotor
                                                                                                                                         Conference  on  Learning  Representations,  ICLR  2017  —                                                                                                                                                                                                                                                                                                                                                                                                             integration  in  recurrent  cortical  networks:  a  neural
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               implementation
                                                                                                                                         Conference  Track  Proceedings  (2015)  2016:1-14arXiv:1612.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 of  kalman  ﬁlters.  J  Neurosci  2007,  27:5744-
                                                                                                                                         07771.                                                                                                                                                                                                                                                                                                                                                                                                                                                                5756  http://dx.doi.org/10.1523/JNEUROSCI.  3985-06.2007.
                                                                                                            43.                          Huang  G,  Liu  Z,  Van  Der  Maaten  L,  Weinberger  KQ:  Densely                                                                                                                                                                                                                                                                                                                                                                       64.                          Orban  de  Xivry  J-J,  Coppe  S,  Blohm  G,  Lefevre  P:  Kalman
                                                                                                                                         connected  convolutional  networks.  Proceedings  –  30th  IEEE                                                                                                                                                                                                                                                                                                                                                                                                       ﬁltering  naturally  accounts  for  visually  guided  and  predictive
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   pursuit  dynamics.  J  Neurosci  2013,  33:17301-17313
                                                                                                                                         Conference  on  Computer  Vision  and  Pattern  Recognition,  CVPR                                                                                                                                                                                                                                                                                                                                                                                                    smooth
                                                                                                                                         2017  2017-January  2017:2261-2269  http://dx.doi.org/10.1109/                                                                                                                                                                                                                                                                                                                                                                                                        http://dx.doi.org/10.1523/JNEUROSCI.  2321-13.2013.
                                                                                                                                         CVPR.2017.243.                                                                                                                                                                                                                                                                                                                                                                                                                           65.                          Kwon O-S,  Tadin  D,  Knill  DC:  Unifying  account  of  visual  motion
                                                                                                            44.                          Dayan  P,  Abbott  LF:  Theoretical  Neuroscience.  Cambridge,  MA:                                                                                                                                                                                                                                                                                                                                                                                                   and  position  perception.  Proc  Natl  Acad  Sci  U  S  A  2015,
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            http://dx.doi.org/10.1073/pnas.1500361112.
                                                                                                                                         MIT  Press;  2001.                                                                                                                                                                                                                                                                                                                                                                                                                                                    112:8142-8147
                                                                                                            45.                          Advani  MS,  Saxe  AM:  High-dimensional  Dynamics  of                                                                                                                                                                                                                                                                                                                                                                                   66.                          van  Bergen  RS,  Jehee  JFM:  Probabilistic  representation  in
                                                                                                                                         Generalization  Error  in  Neural  Networks.  2017.  arXiv:1710.03667.                                                                                                                                                                                                                                                                                                                                                                                                human visual  cortex  reﬂects  uncertainty  in  serial  decisions.  J
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Neurosci
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Off  J  Soc  Neurosci 2019, 39:8164-8176 http://dx.doi.org/
                                                                                                            46.                          Belkin M, Hsu D, Ma S, Mandal S: Reconciling modern machine-                                                                                                                                                                                                                                                                                                                                                                                                          10.1523/JNEUROSCI.3212-18.2019.
                                                                                                                                         learning  practice  and  the  classical  bias-variance  trade-off.
                                                                                                                                         Proc  Natl  Acad  Sci  U  S  A  2019,  116:15849-15854  http://dx.doi.                                                                                                                                                                                                                                                                                                                                                                   67.                          Graves  A,  Mohamed  A-R,  Hinton  G:  Speech  recognition  with
                                                                                                                                         org/10.1073/pnas.1903070116.                                                                                                                                                                                                                                                                                                                                                                                                                                          deep  recurrent  neural  networks.  2013  IEEE  International
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Conference  on  Acoustics,  Speech  and  Signal  Processing,  no.  3
                                                                                                            47.                          Nakkiran  P,  Kaplun  G,  Bansal  Y,  Yang  T,  Barak  B,  Sutskever  I:                                                                                                                                                                                                                                                                                                                                                                                              2013:6645-6649  http://dx.doi.org/10.1109/
                                                                                                                                         Deep Double Descent: Where Bigger Models and More Data Hurt.                                                                                                                                                                                                                                                                                                                                                                                                          ICASSP.2013.6638947.
                                                                                                                                         2019.  arXiv:1912.02292.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  68.                          Sak  H,  Senior  A,  Beaufays  F:  Long  Short-term  Memory  Based
                                                                                                            48.                          Rawat  W,  Wang  Z:  Deep  convolutional  neural  networks  for                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Neural  Network  Architectures  for  Large  Vocabulary
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Recurrent
                                                                                                                                         image  classiﬁcation:  a  comprehensive  review.  Neural  Comput                                                                                                                                                                                                                                                                                                                                                                                                      Speech  Recognition.  2014.  arXiv:1402.1128.
                                                                                                                                         2017,  29:2352-2449  http://dx.doi.org/10.1162/neco_a_00990.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  69.                          Bahdanau  D,  Cho  K,  Bengio  Y:  Neural  machine  translation  by
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               jointly
                                                                                                            49.                          Gilbert  CD,  Li  W:  Top-down  inﬂuences  on  visual  processing.                                                                                                                                                                                                                                                                                                                                                                                                                                              learning  to  align  and  translate.  3rd  International
                                                                                                                                         Nat  Rev  Neurosci  2013,  14:350-363  http://dx.doi.org/10.1038/                                                                                                                                                                                                                                                                                                                                                                                                     Conference  on  Learning  Representations,  ICLR  2015  —
                                                                                                                                         nrn3476.                                                                                                                                                                                                                                                                                                                                                                                                                                                              Conference  Track  Proceedings  2014arXiv:1409.0473.
                                                                                                            www.sciencedirect.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Current  Opinion  in  Neurobiology  2020,  65:176–193
                                                                                                192                                  Whole-brain  interactions  between  neural  circuits
                                                                                                70.                          Cho  K,  van  Merrienboer  B,  Gulcehre  C,  Bahdanau  D,  Bougares  F,                                                                                                                                                                                                                                                                                                                                                                  89. Spoerer CJ, McClure P, Kriegeskorte N: Recurrent convolutional
                                                                                                                             Schwenk  H,  Bengio  Y:  Learning  Phrase  Representations  Using                                                                                                                                                                                                                                                                                                                                                                                                    neural  networks:  a  better  model  of  biological  object
                                                                                                                             Rnn  Encoder-decoder  for  Statistical  Machine  Translation.  2014.                                                                                                                                                                                                                                                                                                                                                                                                  recognition.  Front  Psychol  2017,  8:1-14  http://dx.doi.org/
                                                                                                                             arXiv:1406.1078.                                                                                                                                                                                                                                                                                                                                                                                                                                                      10.3389/fpsyg.2017.01551
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Showed  that  lateral  and  feedback  connections  improve  object  recogni-
                                                                                                71.                          Ranzato  M,  Szlam  A,  Bruna  J,  Mathieu  M,  Collobert  R,  Chopra  S:                                                                                                                                                                                                                                                                                                                                                                tion  under  clutter  and  occlusions  in  convolutional  neural  networks,  com-
                                                                                                                             Video  (language)modeling:  a  Baseline  for  Generative  Models  of                                                                                                                                                                                                                                                                                                                                                                     pared  to  FNNs  matched  in  complexity.
                                                                                                                             Natural  Videos.  2014.  arXiv:1412.6604.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      90.                          Montobbio  N,  Bonnasse-Gahot  L,  Citti  G,  Sarti  A:  Kercnns:
                                                                                                72.                          Srivastava  N,  Mansimov  E,  Salakhutdinov  R:  Unsupervised                                                                                                                                                                                                                                                                                                                                                                                                         Biologically  Inspired  Lateral  Connections  for  Classiﬁcation  of
                                                                                                                             Learning  of  Video  Representations  Using  LSTMs.  2015.                                                                                                                                                                                                                                                                                                                                                                                                            Corrupted  Images.  2019.  arXiv:1910.08336.
                                                                                                                             arXiv:1502.04681.
                                                                                                73.                          Lotter  W,  Kreiman  G,  Cox  D:  Deep  Predictive  Coding  Networks  for                                                                                                                                                                                                                                                                                                                                                                91.                          Szegedy  C,  Zaremba  W,  Sutskever  I,  Bruna  J,  Erhan  D,
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Goodfellow
                                                                                                                             Video  Prediction  and  Unsupervised  Learning.  2016.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       I,  Fergus  R:  Intriguing  properties  of  neural
                                                                                                                             arXiv:1605.08104.                                                                                                                                                                                                                                                                                                                                                                                                                                                     networks.  2nd  International  Conference  on  Learning
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Representations,  ICLR  2014  2014arXiv:1312.6199.
                                                                                                74.                          Pouget  A,  Beck  J,  Ma  WJ,  Latham  P:  Probabilistic  brains:                                                                                                                                                                                                                                                                                                                                                                        92.                          Geirhos  R,  Michaelis  C,  Wichmann  FA,  Rubisch  P,  Bethge  M,
                                                                                                                             knowns and unknowns. Nat Neurosci 2013, 16:1170-1178 http://                                                                                                                                                                                                                                                                                                                                                                                                          Brendel  W:  Imagenet-trained  CNNs  are  biased  towards
                                                                                                                             dx.doi.org/10.1038/nn.3495.                                                                                                                                                                                                                                                                                                                                                                                                                                           texture;  increasing  shape  bias  improves  accuracy  and
                                                                                                75.                          Ma  WJ,  Jazayeri  M:  Neural  coding  of  uncertainty  and                                                                                                                                                                                                                                                                                                                                                                                                           robustness.  7th  International  Conference  on  Learning
                                                                                                                             probability.  Annu  Rev  Neurosci  2014,  37:205-220  http://dx.doi.                                                                                                                                                                                                                                                                                                                                                                                                  Representations,  ICLR  2019  2019arXiv:1811.12231.
                                                                                                                             org/10.1146/annurev-neuro-071013-014017.                                                                                                                                                                                                                                                                                                                                                                                                 93.                          Jacobsen  JH,  Behrmann  J,  Zemel  R,  Bethge  M:  Excessive
                                                                                                                                                     ´                                                                                                                                                                                                                                                                                                                                                                                                                                             invariance  causes  adversarial  vulnerability.  7th  International
                                                                                                76.                          Orban  G,  Berkes  P,  Fiser  J,  Lengyel  M:  Neural  variability  and                                                                                                                                                                                                                                                                                                                                                                                               Conference  on  Learning  Representations,  ICLR  2019
                                                                                                                             sampling-based
                                                                                                                                                                                                                                      probabilistic  representations  in  the  visual                                                                                                                                                                                                                                                                                                              2019arXiv:1811.00401.
                                                                                                                             cortex.  Neuron  2016,  92:530-543  http://dx.doi.org/10.1016/j.
                                                                                                                             neuron.2016.09.038.                                                                                                                                                                                                                                                                                                                                                                                                                      94.                          Neyman J, Pearson ES: IX. On the problem of the most efﬁcient
                                                                                                                                                                                                                                                                                                             `                                                                                                                                                                                                                                                                                     tests  of  statistical  hypotheses.  Philos  Trans  R  Soc  Lond  Ser  A,
                                                                                                77.                          Boerlin  M,  Machens  CK,  Deneve  S:  Predictive  coding  of                                                                                                                                                                                                                                                                                                                                                                                                         Containing  Papers  of  a  Mathematical  or  Physical  Character  1933,
                                                                                                                             dynamical  variables  in  balanced  spiking  networks.  PLoS                                                                                                                                                                                                                                                                                                                                                                                                          231:289-337  http://dx.doi.org/10.1098/rsta.1933.0009.
                                                                                                                             Comput  Biol  2013,  9  http://dx.doi.org/10.1371/journal.
                                                                                                                             pcbi.1003258.                                                                                                                                                                                                                                                                                                                                                                                                                            95.                          Ilyas  A,  Santurkar  S,  Tsipras  D,  Engstrom  L,  Tran  B,  Madry  A:
                                                                                                                                                                                                                              `                                                                                                                                                                                                                                                                                                                                                                    Adversarial  Examples  Are  Not  Bugs,  They  Are  Features.  2019.
                                                                                                78.                          Barrett  DG,  Deneve  S,  Machens  CK:  Optimal  compensation  for                                                                                                                                                                                                                                                                                                                                                                                                    arXiv:1905.02175.
                                                                                                                             neuron  loss.  eLife  2016,  5:1-36  http://dx.doi.org/10.7554/
                                                                                                                             eLife.12454.                                                                                                                                                                                                                                                                                                                                                                                                                             96.                          Li  Y,  Bradshaw  J,  Sharma  Y:  Are  generative  classiﬁers  more
                                                                                                79.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                robust  to  adversarial  attacks?  36th  International  Conference  on
                                                                                                                             Schiller  PH,  Finlay  BL,  Volman  SF:  Short-term  response
                                                                                                                                                                                            of  monkey  striate  neurons.  Brain  Res  1976,  105:347-                                                                                                                                                                                                                                                                                                                                             Machine  Learning,  ICML  2019  2019:6754-6783arXiv:1802.06552.
                                                                                                                             variability
                                                                                                                             349.                                                                                                                                                                                                                                                                                                                                                                                                                                     97.                          Schott  L,  Rauber  J,  Bethge  M,  Brendel  W:  Towards  the  ﬁrst
                                                                                                80.                          Dean  A:  The  variability  of  discharge  of  simple  cells  in  the  cat                                                                                                                                                                                                                                                                                                                                                                                            adversarially  robust  neural  network  model  on  MNIST.  7th
                                                                                                                             striate                                                                                                                                                                                                                                                                                                                                                                                                                                                               International  Conference  on  Learning  Representations,  ICLR  2019
                                                                                                                                                                        cortex.  Exp  Brain  Res  1981,  44  http://dx.doi.org/10.1007/
                                                                                                                             BF00238837.                                                                                                                                                                                                                                                                                                                                                                                                                                                           2019arXiv:1805.09190.
                                                                                                81.                          Mainen  ZF,  Sejnowski  TJ:  Reliability  of  spike  timing  in                                                                                                                                                                                                                                                                                                                                                                          98. Golan  T,  Raju  PC,  Kriegeskorte  N:  Controversial  Stimuli:  Pitting
                                                                                                                             neocortical                                                                                                                                                                                                                                                                                                                                                                                                                                                          Neural  Networks  Against  Each  Other  as  Models  of  Human
                                                                                                                                                                                                        neurons.  Science  1995,  268:1503-1506.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Recognition.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 2019.  arXiv:1911.09288
                                                                                                82.                          Krizhevsky  A,  Sutskever  I,  Hinton  GE:  ImageNet  classiﬁcation                                                                                                                                                                                                                                                                                                                                                                      Showed  that  generative  inference  networks,  compared  to  discriminative
                                                                                                                             with  deep  convolutional  neural  networks.  Advances  in  Neural                                                                                                                                                                                                                                                                                                                                                                       models,  better  aligned  with  human  perception,  when  probed  with  stimuli
                                                                                                                             Information  Processing  Systems  2012arXiv:1102.0183.                                                                                                                                                                                                                                                                                                                                                                                   designed  to  maximally  distinguish  between  models.
                                                                                                83.                          Field  DJ,  Hayes  A,  Hess  RF:  Contour  integration  by  the  human                                                                                                                                                                                                                                                                                                                                                                   99.                          Lee  TS,  Mumford  D:  Hierarchical  Bayesian  inference  in  the
                                                                                                                             visual  system:  evidence  for  a  local  “association  ﬁeld”.  Vision                                                                                                                                                                                                                                                                                                                                                                                                visual  cortex.  J  Opt  Soc  Am  A  Opt  Image  Sci  Vision  2003,
                                                                                                                             Res  1993,  33:173-193  http://dx.doi.org/10.1016/0042-6989(93)                                                                                                                                                                                                                                                                                                                                                                                                       20:1434-1448.
                                                                                                                             90156-q.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      100. Wen H, Han K, Shi J, Zhang Y, Culurciello E, Liu Z: Deep Predictive
                                                                                                84.                          Geisler  WS,  Perry  JS,  Super  BJ,  Gallogly  DP:  Edge  co-                                                                                                                                                                                                                                                                                                                                                                                                       Coding
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Network  for  Object  Recognition.  2018.  arXiv:1802.04762
                                                                                                                             occurrence  in  natural  images  predicts  contour  grouping                                                                                                                                                                                                                                                                                                                                                                                                                                                                   better  object  recognition  performance when generic FNNs
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Demonstrated
                                                                                                                             performance.  Vision  Res  2001,  41:711-724  http://dx.doi.org/                                                                                                                                                                                                                                                                                                                                                                         were  augmented  with  the  recurrent  connectivity  and  dynamics  of  pre-
                                                                                                                             10.1016/S0042-6989(00)00277-7.                                                                                                                                                                                                                                                                                                                                                                                                           dictive  coding.
                                                                                                85.                          Roelfsema  PR:  Cortical  algorithms  for  perceptual  grouping.                                                                                                                                                                                                                                                                                                                                                                         101.  Srikumar  V,  Kundu  G,  Roth  D:  On  amortizing  inference  cost  for
                                                                                                                             Annu  Rev  Neurosci  2006,  29:203-227  http://dx.doi.org/10.1146/                                                                                                                                                                                                                                                                                                                                                                                                    structured prediction.  Proceedings of the 2012 Joint Conference
                                                                                                                             annurev.neuro.29.051605.112939.                                                                                                                                                                                                                                                                                                                                                                                                                                       on  Empirical  Methods  in  Natural  Language  Processing  and
                                                                                                86. Linsley  D,  Kim  J,  Veerabadran  V,  Windolf  C,  Serre  T:  Learning                                                                                                                                                                                                                                                                                                                                                                                                                        Computational  Natural  Language  Learning  2012:1114-1124.
                                                                                                                           long-range  spatial  dependencies  with  horizontal  gated                                                                                                                                                                                                                                                                                                                                                                                                                                                       ¨
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      102.  Stuhlmuller  A,  Taylor  J,  Goodman  N:  Learning  stochastic
                                                                                                                             recurrent  units.  Advances  in  Neural  Information  Processing                                                                                                                                                                                                                                                                                                                                                                                                      inverses.  Advances  in  Neural  Information  Processing  Systems
                                                                                                                             Systems  2018:152-164                                                                                                                                                                                                                                                                                                                                                                                                                                                 2013:3048-3056.
                                                                                                Developed a new type of lateral  recurrent  connectivity  to  build  RNNs  that
                                                                                                solve  long-range  path  integration  tasks  far  more  efﬁciently  than  feedfor-                                                                                                                                                                                                                                                                                                                                                                                    103.  Cremer  C,  Li  X,  Duvenaud  D:  Inference  suboptimality  in
                                                                                                ward  architectures.                                                                                                                                                                                                                                                                                                                                                                                                                                                                               variational  autoencoders.  35th  International  Conference  on
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Machine  Learning,  ICML  2018  2018:1749-1760arXiv:1801.03558.
                                                                                                                                                                                                                                                                                                                                                 ´
                                                                                                87.                          George  D,  Lehrach  W,  Kansky  K,  Lazaro-Gredilla  M,  Laan  C,
                                                                                                                             Marthi  B,  Lou  X,  Meng  Z,  Liu  Y,  Wang  H,  Lavin  A,  Phoenix  DS:  A                                                                                                                                                                                                                                                                                                                                                             104. Marino  J,  Yue  Y,  Mandt  S:  Iterative  amortized  inference.  35th
                                                                                                                             generative  vision  model  that  trains  with  high  data  efﬁciency                                                                                                                                                                                                                                                                                                                                                                                                 International  Conference  on  Machine  Learning,  ICML  2018  2018,
                                                                                                                             and breaks text-based CAPTCHAs. Science 2017, 358 http://dx.                                                                                                                                                                                                                                                                                                                                                                                                          8:5444-5462arXiv:1807.09356
                                                                                                                             doi.org/10.1126/science.aag2612.                                                                                                                                                                                                                                                                                                                                                                                                         Proposed  a  method  to  amortize  iterative  optimization  dynamics  in  varia-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      tional  inference  networks,  to  close  the  amortization  gap.
                                                                                                88.                          Zheng S, Jayasumana S, Romera-Paredes B, Vineet V, Su Z, Du D,
                                                                                                                             Huang  C,  Torr  PH:  Conditional  random  ﬁelds  as  recurrent                                                                                                                                                                                                                                                                                                                                                                          105.  Hjelm  RD,  Cho  K,  Chung  J,  Salakhutdinov  R,  Calhoun  V,  Jojic  N:
                                                                                                                             neural                                                                                                                                                                                                                                                                                                                                                                                                                                                                Iterative
                                                                                                                                                                        networks.  Proceedings  of  the  IEEE  International                                                                                                                                                                                                                                                                                                                                                                                                                             reﬁnement  of  the  approximate  posterior  for  directed
                                                                                                                             Conference  on  Computer  Vision  2015  nation  2015:1529-1537                                                                                                                                                                                                                                                                                                                                                                                                        belief  networks.  Advances  in  Neural  Information  Processing
                                                                                                                             http://dx.doi.org/10.1109/ICCV.2015.179.                                                                                                                                                                                                                                                                                                                                                                                                                              Systems  (NIPS  2016)  2016:4698-4706arXiv:1511.06382.
                                                                                                Current  Opinion  in  Neurobiology  2020,  65:176–193                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          www.sciencedirect.com
                                                                                                                                                                                                                                                Going  in  circles  is  the  way  forward:  the  role  of  recurrence  in  visual  inference  van  Bergen  and  Kriegeskorte                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       193
                                                                                                            106.  Krishnan  RG,  Liang  D,  Hoffman  MD:  On  the  challenges  of                                                                                                                                                                                                                                                                                                                                                                                                 121.  Fyall  AM,  El-Shamayleh  Y,  Choi  H,  Shea-Brown  E,  Pasupathy  A:
                                                                                                                                         learning with inference networks on sparse, high-dimensional                                                                                                                                                                                                                                                                                                                                                                                                          Dynamic  representation  of  partially  occluded  objects  in
                                                                                                                                         data.  International  Conference  on  Artiﬁcial  Intelligence  and                                                                                                                                                                                                                                                                                                                                                                                                    primate  prefrontal  and  visual  cortex.  eLife  2017,  6:1-25  http://
                                                                                                                                         Statistics,  AISTATS  2018  84  2018:143-151arXiv:1710.06085.                                                                                                                                                                                                                                                                                                                                                                                                         dx.doi.org/10.7554/eLife.25784.
                                                                                                            107.  Liang  M,  Hu  X:  Recurrent  convolutional  neural  network  for                                                                                                                                                                                                                                                                                                                                                                                               122.  Choi  H,  Pasupathy  A,  Shea-Brown  E:  Predictive  coding  in  area
                                                                                                                                         object  recognition.  Proceedings  of  the  IEEE  Computer  Society                                                                                                                                                                                                                                                                                                                                                                                                   V4:  dynamic  shape  discrimination  under  partial  occlusion.
                                                                                                                                         Conference  on  Computer  Vision  and  Pattern  Recognition  07–12-                                                                                                                                                                                                                                                                                                                                                                                                   Neural  Comput  2018,  30:1209-1257  http://dx.doi.org/10.1162/
                                                                                                                                                                          2015:3367-3375  http://dx.doi.org/10.1109/
                                                                                                                                         June                                                                                                                                                                                                                                                                                                                                                                                                                                                                  neco_a_01072.
                                                                                                                                         CVPR.2015.7298958.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  123.  Levi  DM:  Crowding-An  essential  bottleneck  for  object
                                                                                                            108. Kar  K,  Kubilius  J,  Schmidt  K,  Issa  EB,  DiCarlo  JJ:  Evidence  that                                                                                                                                                                                                                                                                                                                                                                                                                   recognition:  a  mini-review.  Vision  Res  2008,  48:635-654  http://
                                                                                                                                       recurrent circuits are critical to the  ventral  stream’s  execution                                                                                                                                                                                                                                                                                                                                                                                                  dx.doi.org/10.1016/j.visres.2007.12.009.
                                                                                                                                         of  core  object  recognition  behavior. Nat Neurosci 2019, 22:974-
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  124.
                                                                                                                                         983  http://dx.doi.org/10.1038/s41593-019-0392-5                                                                                                                                                                                                                                                                                                                                                                                                                      Manassi  M,  Sayim  B,  Herzog  MH:  Grouping,  pooling,  and  when
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            is  better  in  visual  crowding.  J  Vision  2012,  12  13–13,
                                                                                                            Identiﬁed  a  set  of  ‘challenge  images’  that,  in  both  neural  network  models                                                                                                                                                                                                                                                                                                                                                                                                               bigger
                                                                                                            and primate visual cortex, required recurrent processing to be recognized                                                                                                                                                                                                                                                                                                                                                                                                                          doi:10.1167/12.10.13.
                                                                                                            as  accurately  as  a  set  of  control  images.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  125.  Manassi  M,  Lonchampt  S,  Clarke  A,  Herzog  MH:  What  crowding
                                                                                                            109. Nayebi  A,  Bear  D,  Kubilius  J,  Kar  K,  Ganguli  S,  Sussillo  D,                                                                                                                                                                                                                                                                                                                                                                                                                        can  tell  us  about  object  representations.  J  Vision  2016,  16:35
                                                                                                                                        DiCarlo  JJ,  Yamins  DL:  Task-driven  convolutional  recurrent                                                                                                                                                                                                                                                                                                                                                                                                      http://dx.doi.org/10.1167/16.3.35.
                                                                                                                                                                                            of  the  visual  system.  Advances  in  Neural  Information
                                                                                                                                         models
                                                                                                                                         Processing  Systems  2018:5290-5301                                                                                                                                                                                                                                                                                                                                                                                                      126.  Doerig  A,  Bornet  A,  Choung  O,  Herzog  M:  Crowding  reveals
                                                                                                            Explored  a  large  space  of  recurrent  connectivity  motifs  and  compared                                                                                                                                                                                                                                                                                                                                                                                                                      fundamental  differences  in  local  vs.  global  processing  in
                                                                                                            their  effects  on  object  recognition  performance.                                                                                                                                                                                                                                                                                                                                                                                                                                              humans and machines. Vision Res 2020, 167:39-45 http://dx.doi.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               org/10.1016/j.visres.2019.12.006.
                                                                                                            110.  Ballard  DH:  Animate  vision.  Artif  Intell  1991,  48:57-86  http://dx.
                                                                                                                                         doi.org/10.1016/0004-3702(91)90080-4.                                                                                                                                                                                                                                                                                                                                                                                                    127. Sabour  S,  Frosst  N,  Hinton  GE:  Dynamic  routing  between
                                                                                                            111.  Findlay  JM,  Gilchrist  ID:  Active  Vision.  Oxford  University  Press;                                                                                                                                                                                                                                                                                                                                                                                                                  capsules.  Advances  in  Neural  Information  Processing  Systems
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               2017:3856-3866
                                                                                                                                         2003  http://dx.doi.org/10.1093/acprof:oso/                                                                                                                                                                                                                                                                                                                                                                                              Introduced  the  inﬂuential  Capsule  Networks,  which  implement  iterative
                                                                                                                                         9780198524793.001.0001.                                                                                                                                                                                                                                                                                                                                                                                                                  recurrent  information  routing  dynamics  for  visual  segmentation  and
                                                                                                            112.                                                                                                                                                                                                                                                                                                                                                                                                                                                                  grouping.
                                                                                                                                         Bajcsy R, Aloimonos Y, Tsotsos JK: Revisiting active perception.
                                                                                                                                         Autonom  Robots  2018,  42:177-196  http://dx.doi.org/10.1007/                                                                                                                                                                                                                                                                                                                                                                           128.  Sabour S, Frosst N, Hinton GE: Matrix capsules with EM routing.
                                                                                                                                         s10514-017-9615-3.                                                                                                                                                                                                                                                                                                                                                                                                                                                    ICLR  2018,  2018arXiv:1710.09829.
                                                                                                            113.  Russell  SJ:  Rationality  and  intelligence.  Artif  Intell  1997,  94:57-                                                                                                                                                                                                                                                                                                                                                                                     129.                                                                                                                            ¨
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               O’Regan  JK,  Noe A:  A  sensorimotor  account  of  vision  and
                                                                                                                                         77
                                                                                                                                                            http://dx.doi.org/10.1016/S0004-3702(97)00026-X.                                                                                                                                                                                                                                                                                                                                                                                                   visual  consciousness.  Behav  Brain  Sci  2001,  24:939-973  http://
                                                                                                            114.  Gershman  SJ,  Horvitz  EJ,  Tenenbaum  JB:  Computational                                                                                                                                                                                                                                                                                                                                                                                                                                   dx.doi.org/10.1017/S0140525X01000115.
                                                                                                                                         rationality:  a  converging  paradigm  for  intelligence  in  brains,                                                                                                                                                                                                                                                                                                                                                                                                                                ´
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  130.  Buzsaki  G:  The  Brain  from  Inside  Out.  Oxford  University  Press;
                                                                                                                                         minds,  and  machines.  Science  2015,  349:273-278  http://dx.doi.                                                                                                                                                                                                                                                                                                                                                                                                   2019  http://dx.doi.org/10.1093/oso/9780190905385.001.0001.
                                                                                                                                         org/10.1126/science.aac6076.
                                                                                                            115.  Grifﬁths  TL,  Lieder  F,  Goodman  ND:  Rational  use  of  cognitive                                                                                                                                                                                                                                                                                                                                                                                           131.  Werbos  P:  Backpropagation  through  time:  what  it  does  and
                                                                                                                                         resources:  levels  of  analysis  between  the  computational  and                                                                                                                                                                                                                                                                                                                                                                                                    how  to  do  it.  Proc  IEEE  1990,  78:1550-1560  http://dx.doi.org/
                                                                                                                                         the  algorithmic.  Topics  Cogn  Sci  2015,  7:217-229  http://dx.doi.                                                                                                                                                                                                                                                                                                                                                                                                10.1109/5.58337.
                                                                                                                                         org/10.1111/tops.12142.                                                                                                                                                                                                                                                                                                                                                                                                                  132.  Guerguiev  J,  Lillicrap  TP,  Richards  BA:  Towards  deep  learning
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               with
                                                                                                            116. Kubilius  J,  Schrimpf  M,  Kar  K,  Rajalingham  R,  Hong  H,  Majaj  N,                                                                                                                                                                                                                                                                                                                                                                                                                                                    segregated  dendrites.  eLife  2017,  6:1-37  http://dx.doi.org/
                                                                                                                                        Issa  E,  Bashivan  P,  Prescott-Roy  J,  Schmidt  K,  Nayebi  A,  Bear  D,                                                                                                                                                                                                                                                                                                                                                                                           10.7554/eLife.22901.
                                                                                                                                         Yamins  DL,  DiCarlo  JJ:  Brain-like  object  recognition  with  high-                                                                                                                                                                                                                                                                                                                                                                  133.  Sacramento  J,  Ponte  Costa  R,  Bengio  Y,  Senn  W:  Dendritic
                                                                                                                                         performing  shallow  recurrent  anns.  Advances  in  Neural                                                                                                                                                                                                                                                                                                                                                                                                           cortical  microcircuits  approximate  the  backpropagation
                                                                                                                                         Information  Processing  Systems  2019:12805-12816                                                                                                                                                                                                                                                                                                                                                                                                                    algorithm.  Advances  in  Neural  Information  Processing  Systems
                                                                                                            Developed  a  compact,  brain-inspired  RNN  architecture  that  provides  a                                                                                                                                                                                                                                                                                                                                                                                                                       2018:8721-8732.
                                                                                                            good
                                                                                                                                              model of  neural  responses  and  behavior,  while  also  scoring  well  on
                                                                                                            a  prominent  object  recognition  task.                                                                                                                                                                                                                                                                                                                                                                                                                              134.  Whittington  JC,  Bogacz  R:  Theories  of  error  back-propagation
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               in  the  brain.  Trends  Cogn  Sci  2019,  23:235-250  http://dx.doi.org/
                                                                                                            117.  Deng  J,  Dong  W,  Socher  R,  Li  L-J,  Li  Kai,  Fei-Fei  Li:  ImageNet:  a                                                                                                                                                                                                                                                                                                                                                                                                               10.1016/j.tics.2018.12.005.
                                                                                                                                         large-scale  hierarchical  image  database.  2009  IEEE
                                                                                                                                         Conference  on  Computer  Vision  and  Pattern  Recognition;                                                                                                                                                                                                                                                                                                                                                                             135.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Lillicrap  TP,  Santoro  A:  Backpropagation  through  time  and  the
                                                                                                                                         doi:10.1109/CVPR.2009.5206848:  IEEE;  2009:248-255.                                                                                                                                                                                                                                                                                                                                                                                                                  brain.  Curr  Opin  Neurobiol  2019,  55:82-89  http://dx.doi.org/
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               10.1016/j.conb.2019.01.011.
                                                                                                                                                                                                                                                                                                                            ¨
                                                                                                            118.  Kietzmann  TC,  Spoerer  CJ,  Sorensen  LKA,  Cichy  RM,  Hauk  O,
                                                                                                                                         Kriegeskorte  N:  Recurrence  is  required  to  capture  the                                                                                                                                                                                                                                                                                                                                                                             136.  Almeida  L:  A  learning  rule  for  asynchronous  perceptrons  with
                                                                                                                                         representational  dynamics  of  the  human  visual  system.  Proc                                                                                                                                                                                                                                                                                                                                                                                                     feedback  in  a  combinatorial  environment.  Proceedings,  1st
                                                                                                                                         Natl  Acad  Sci  u  S  A  2019,  116:201905544  http://dx.doi.org/                                                                                                                                                                                                                                                                                                                                                                                                    First  International  Conference  on  Neural  Networks  1987,  2:609-
                                                                                                                                         10.1073/pnas.1905544116.                                                                                                                                                                                                                                                                                                                                                                                                                                              618.
                                                                                                            119. Tang  H,  Schrimpf  M,  Lotter  W,  Moerman  C,  Paredes  A,  Caro  JO,                                                                                                                                                                                                                                                                                                                                                                                          137.  Pineda  FJ:  Generalization  of  back-propagation  to  recurrent
                                                                                                                                        Hardesty  W,  Cox  D,  Kreiman  G:  Recurrent  computations  for                                                                                                                                                                                                                                                                                                                                                                                                      neural networks. Phys Rev Lett 1987, 59:2229-2232 http://dx.doi.
                                                                                                                                         visual  pattern  completion.  Proc  Natl  Acad  Sci  U  S  A  2018,                                                                                                                                                                                                                                                                                                                                                                                                   org/10.1103/PhysRevLett.59.2229.
                                                                                                                                         115:8835-8840  http://dx.doi.org/10.1073/pnas.1719397115
                                                                                                            Demonstrated  robust  object  recognition  under  partial  occlusions  in                                                                                                                                                                                                                                                                                                                                                                                             138.  Liao  R,  Xiong  Y,  Fetaya  E,  Zhang  L,  Yoon  KJ,  Pitkow  X,  Urtasun  R,
                                                                                                            recurrent,  but  not  feedforward  architectures.  Like  human  observers,                                                                                                                                                                                                                                                                                                                                                                                                                         Zemel  R:  Reviving  and  improving  recurrent  back-propagation.
                                                                                                            the  RNNs  were  sensitive  to  backward  masking.                                                                                                                                                                                                                                                                                                                                                                                                                                                 35th  International  Conference  on  Machine  Learning,  ICML  2018
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               2018:4807-4820.  arXiv:1803.06396.
                                                                                                            120.  Enns JT,  Di  Lollo  V:  What’s  new  in  visual  masking?  Trends Cogn
                                                                                                                                         Sci  2000,  4:345-352  http://dx.doi.org/10.1016/S1364-6613(00)                                                                                                                                                                                                                                                                                                                                                                          139.  Linsley  D,  Ashok  AK,  Govindarajan  LN,  Liu  R,  Serre  T:  Stable  and
                                                                                                                                         01520-5.                                                                                                                                                                                                                                                                                                                                                                                                                                                              Expressive  Recurrent  Vision  Models.  2020.  arXiv:2005.11362.
                                                                                                            www.sciencedirect.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Current  Opinion  in  Neurobiology  2020,  65:176–193
