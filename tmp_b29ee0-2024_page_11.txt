                                                                                                        SegPoint      11
                                  Table 1: 3D instruction segmentation benchmark results on Instruct3D val
                                  split evaluated by Acc and mIoU. † denotes our vanilla baseline removing geometric
                                  enhancer module and geometric-guided feature propagation. ∗ represents adding an
                                  auxiliary mask head through our implementation.
                                         Stage        Method                    Reference        Acc         mIoU
                                          Two         ScanRefer [4]            [ECCV’20]         12.0         6.9
                                          Two         ReferIt3D [1]            [ECCV’20]         11.7         6.4
                                          Two         M3DRef-CLIP [79]          [ICCV’23]        18.1         12.8
                                         Single       TGNN[22]                  [AAAI’21]        12.9         7.1
                                                                      ∗
                                         Single       BUTD-DETR[23]            [ECCV’22]         16.3         10.9
                                                              ∗
                                         Single       EDA[67]                  [CVPR’23]         16.6         12.1
                                         Single       SegPoint†                [ECCV’24]         21.8        16.1
                                         Single       SegPoint                 [ECCV’24]         31.6        27.5
                                  Table 2: 3D Semantic segmentation benchmark results on S3DIS [3], Scan-
                                  Net [7], and ScanNet200 [53]. We evaluate on the Area 5 of S3DIS and validation split
                                  of ScanNet and ScanNet200.
                                       Method                  Reference        ScanNet      ScanNet200       S3DIS
                                       PointNet++ [46]       [NeurIPS’17]         53.5            -             -
                                       MinkUNet [6]           [CVPR’19]           72.2           25.0          65.4
                                       PTv1 [80]               [ICCV’21]          70.6           27.8          70.4
                                       PTv2 [66]             [NeurIPS’22]         75.4           30.2          71.6
                                       PointNeXt [48]        [NeurIPS’22]         71.5            -            70.5
                                       OctFormer [60]       [SIGGRAPH’23]         75.7           32.6           -
                                       Swin3D [72]              [ArXiv]           75.5            -           72.5
                                       SegPoint               [ECCV’24]           74.1           35.3          72.4
                                  Enhancer Module and Geometric-guided Feature Propagation components. No-
                                  tably, even in its baseline form, SegPoint† surpasses all competing methods,
                                  validating the effectiveness and rationale behind our pipeline design.
                                      Besides, different from traditional two-stage approaches that first generate
                                  mask proposals using a pre-trained segmentor like Mask3D [54] and then ap-
                                  ply language-aware networks for selection, SegPoint directly tackles the task,
                                  bypassing the need for preliminary mask proposals, enhancing its efÏciency.
                                  4.4    Results on Semantic Segmentation
                                  Table 2 present SegPoint’s performance on semantic segmentation, delivering
                                  competitive results across diverse datasets. Our model uses a simple yet effective
                                  answer format, category <SEG>, to use category name as predicted labels,
                                  achieving particularly stronger performance in datasets with various categories
                                  like ScanNet200 [53], where it surpasses SOTA methods by 2.1% mIoU. To ensure
                                  fair comparisons, we fine-tune our model on each semantic segmentation dataset
                                  to accommodate the varying class category definitions.
                                  4.5    Results on Referring Segmentation
                                  Table 3 presents results on referring segmentation datasets. SegPoint showcases
                                  outstanding performance in both single-target (e.g., ScanRefer [4], Nr3D [1])
                                  and multi-target and zero-target contexts within the Multi3DRefer [79] dataset.
                                  For multi-targets, we aggregate masks into a single ground truth, and for zero-
                                  target, we use an empty mask, indicated by “ASSISTANT: There is no mask.”
                                  SegPointsignificantly surpasses other approaches, achieving 2.5% mIoU increase.
                                  The evaluation process of two-stage method M3DRef-CLIP is similar to Sec.4.3.
