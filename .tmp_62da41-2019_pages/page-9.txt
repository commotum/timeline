                                                           Ponder Net: Learning to Ponder
                         Appendix A. Comparison to ACT
                         PonderNet builds on the ideas introduced in Adaptive Computation Time (ACT; Graves,
                         2016). The main contribution of this paper is to reformulate how the network learns to halt
                         in a probabilistic way. This has consequences in all aspects of the model, including: the
                         architecture and forward computation; the loss used to train the network; the deployment
                         of the model; and the limitation of how multiple pondering modules can be combined. We
                         explain in more detail all these diï¬€erences below.
                         A.1 Forward computation
                         PonderNetâ€™s step function (that is computed on every step) is identical to the one proposed
                         in ACT. Theybothassumeamappingy ,h                         , Î»   =s(x,h ). Themaindiï¬€erencebetween
                                                                           n    n+1    n            n
                         ACTandPonderNetâ€™s forward computation is how the halting node Î»n is used.
                                                                                                                              P
                             In ACT, the network is unrolled for a number of steps N                          =min{N :           N Î» â‰¥
                                                                                                        ACT                      n=1 n
                         1âˆ’}. ACTâ€™s halting nodes learn to predict the overall probability that the network halted
                         at step n, so that Î» = p . The value of the halting node in the last step is replaced with
                                                  n      n                      P
                         a remainder quantity R = Î»             =p =1âˆ’ Nâˆ’1Î»n. In ACT it would not make sense to
                                                             N       N             n=1
                         unroll the network for a larger number of steps than NACT because the sum of probabilities
                         of halting would be > 1. When training ACT, higher values of N are not necessarily
                         better, and N is being determined (and learnt) via the halting node Î» . In PonderNet, any
                                                                                                                 n
                         suï¬ƒciently high value of N can be used, and the unroll length of the network at training
                         is distinguished from the learning of the halting policy (which is most critical for saving
                         computation when deployed at evaluation).
                             The output of ACT is not treated probabilistically but as a weighted average yË†                              =
                         P                                                                                                          ACT
                            NACT yË† Î»     over the outputs at each step. The halting, as well as the output, are com-
                            n=1     n n
                         puted identically for training and evaluation. In PonderNet, the output is probabilistic. In
                         training, we compute the output and halting probabilities across many steps so that we can
                         compute a weighted average of the loss. In evaluation, the network returns its prediction
                         as soon as a halt state is sampled.
                             Finally, ACT considers the case of sequential data, where the step function can ponder
                         dynamically for each new item in the input sequence. Given the introduction of attention
                         mechanisms in the recent years (e.g. Transformers; Vaswani et al., 2017) that can process
                         arrays with dynamic shapes, we suggest that pondering should be done holistically instead
                         of independently for each item in the sequence. This can be useful in learning e.g. how
                         many message-passing steps to do in a graph network (VeliË‡ckoviÂ´c et al., 2019).
                         A.2 Training loss
                         ACT proposes a heuristic training loss that combines two intuitive costs: the accuracy of
                         the model, and the cost of computation. These two costs are in diï¬€erent units, and not
                         easily comparable. Since N                is not diï¬€erentiable with respect to Î»n, ACT utilizes the
                                                   P        ACT
                         remainder R = 1 âˆ’            Nâˆ’1 as a proxy for minimizing the total number of computational
                                                      n=1
                         steps. This is unlike in PonderNet, where the expected number of steps can be computed
                                                                P
                         (and diï¬€erentiated) exactly as            N np .
                                                                   n=1     n
                                                                                  9
