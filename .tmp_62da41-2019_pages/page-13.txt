                                            Ponder Net: Learning to Ponder
                      Each memorycontent is created by storing all the possible pair wise association between
                  the items in the sequence, e.g. A B and B C , A B and B C , ..., A B       and B C .
                                                   1 1       1 1    2 2       2 2       N N        N N
                  With N = 16, this process results in a memory with M = 32 rows each one with 2
                  embeddings of size 1000.
                  Each query is composed of 3 images, namely:
                      • the cue
                      • the match
                      • the lure
                  Thecue(e.g. A ) and the match (e.g. C ) are images extracted from the sequence; whereas
                                 1                      1
                  the lure is an image from the same memory content but from a diﬀerent sequence (e.g. C7).
                  There are two types of queries - “direct” and “indirect”. In “direct” queries the cue and the
                  match are sampled from the same memory slot. For example, if the sequence is A1 - B1 -
                  C , then an example of direct query would be, A (cue) - B (match) - B   (lure). More of
                    1                                            1         1            12
                  interests here is the case of “indirect” queries, as they require an inference across multiple
                  facts stored at diﬀerent location in memory. For instance, if we consider again the previous
                  example sequence: A - B - C , then an example of inference trial would be A (cue) - C
                                      1    1    1                                            1          1
                  (match) - C (lure).
                              6
                      The queries are presented to the network as a concatenation of three image embedding
                  vectors (the cue, the match and the lure), that is a 3 × 1000 dimensional vector. The cue
                  is always placed in the ﬁrst position in the concatenation, but to avoid any trivial solution,
                  the position of the match and lure are randomized. It is worth noting that the lure image
                  always has the same position in the sequence (e.g. if the match image is a C the lure is also
                  a C) but it is randomly drawn from a diﬀerent sequence that is also present in the current
                  memory. This way the task can only be solved by appreciating the correct connection
                  between the images, and this need to be done by avoiding the interference coming for other
                  items in memory. For each entry in the batch we generated all possible queries that the
                  current memory store could support and then one was selected at random. Finally, the
                  batch was balanced, i.e. half of the elements were direct queries and the other half was
                  indirect. Finally, the targets represent the ImageNet class-ID of the matches.
                  To summarize, for each entry in each batch:
                      • Memory was of size 32∗2∗1000
                      • Queries were of size 1 ∗ 3 ∗ 1000
                      • Target was of size 1
                  D.2 PAI - Architecture details
                  We used an architecture similar to Universal Transformers (Dehghani et al., 2018, UT),
                  but we augmented the transformer with a memory as in Dai et al. (2019). The number
                  of layers in the encoder and the decoder was learnt, but constrained to be the same. This
                  number was identiﬁed as the “pondering time” in our PonderNet architecture. Also, we set
                  an upper bound N to the number of layers. The initial state h was a learnt embedding of
                                                                              0
                                                             13
