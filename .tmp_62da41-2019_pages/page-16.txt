                        Banino, Balaguer, Blundell
          Appendix E. Broader impact statement
          In this work we introduced PonderNet, a new method that enables neural networks to adapt
          their computational complexity to the task they are trying to solve. Neural networks achieve
          state of the art in a wide range of applications, including natural language processing,
          reinforcement learning, computer vision and more. Currently, they require much time,
          expensive hardware and energy to train and to deploy. They also often fail to generalize
          and to extrapolate to conditions beyond their training.
           PonderNetexpandsthecapabilities of neural networks, by letting them decide to ponder
          for an indeﬁnite amount of time (analogous to how both humans and computers think). This
          can be used to reduce the amount of compute and energy at inference time, which makes it
          particularly well suited for platforms with limited resources such as mobile phones. Addi-
          tionally, our experiments show that enabling neural networks to adapt their computational
          complexity has also beneﬁts for their performance (beyond the computational requirements)
          whenevaluatingoutsideofthetrainingdistribution, whichisoneofthelimitingfactorswhen
          applying neural networks for real-world problems.
           Weencourageotherresearchers to pursue the questions we have considered on this work.
          We believe that biasing neural network architectures to behave more like algorithms, and
          less like “ﬂat” mappings, will help develop deep learning methods to their the full potential.
                               16
