                                       Ponder Net: Learning to Ponder
                Figure 1: Performance on the parity task. a) Interpolation. Top: accuracy for both PonderNet(blue)
                and ACT(orange). Bottom: number of ponder steps at evaluation time. Error bars calculated over
                10 random seeds. b) Extrapolation. Top: accuracy for both PonderNet(blue) and ACT(orange).
                Bottom: number of ponder steps at evaluation time. Error bars calculated over 10 random seeds.
                c) Total number of compute steps calculated as the number of actual forward passes performed by
                each network. Blue is PonderNet, Green is ACT and Orange is an RNN without adaptive compute.
                our method is particularly robust with respect to the prior, and a clear advancement in
                comparison to ACT, where the τ parameter is diﬃcult to set and it is a source of training
                instability, as explained in the original paper and conﬁrmed by our results. Indeed, Fig.
                2a shows that only for few conﬁguration of τ ACT is able to solve the task and even when
                it does so there is a great variance across seeds. Finally, one advantage of setting a prior
                probability is that this parameter is easy to interpret as the inverse of the “number of
                ponder steps”, whereas the τ parameter does not have any straightforward interpretation,
                which makes it harder to deﬁne a priori.
                Figure 2: Sensitivity to hyper-parameter. a) Sensitivity of ACT to τ. Each box-plot is over 10
                random seeds. b) Sensitivity of PonderNet to λ . Each box-plot is over 10 random seeds. c)
                                                       p
                Box-plot over 30 random seeds for number of ponder steps when λp = 0.1.
                                                      5
