                                          9.25                          Content Paraphrasing       9.6                                                                                                                                      Self-predicted Context
                                                                        Format Paraphrasing                                                                          8.5                                                        9.0         Golden Context
                                          9.20                                                     9.4
                                                                                                                                                                                                                                8.5
                                          9.15                                                     9.2                                                               8.0
                                         verage Score                                             verage Score9.0                Topic Shift                        verage Score                                               verage Score8.0
                                         A9.10                                                    A                              Content Confusion                  A7.5                                                       A
                                                                                                   8.8                           Contextual Memory                                               Self-predicted Context         7.5
                                                                                                                                 Anaphora Resolution                                             Golden Context
                                          9.05                                                     8.6                                                               7.0                                                        7.0
                                                1                                          2             1             2              3              4                     1             2              3             4              1              2             3              4
                                                                    Turn                                                     Turn                                                              Turn                                                      Turn
                                                                (a)                                                      (b)                                                 (a) Separate Input                               (b) Instruction Clarification
                                          9                                                        6.5                                                            Figure 6: Comparison of model performance across
                                          8                                                        6.0                                                            dialogue turns using golden or self-predicted context.
                                                                                                                              Mathematical Reasoning
                                                                                                                              General Reasoning
                                         verage Score                                             verage Score5.5
                                         A7                         Separate Input                A                                                                                Model                         SFT RLHF/DPO Avg.                                         ∆
                                                                    Instruction Clarification      5.0
                                                                    Proactive Interaction                                                                              InternLM2-Chat-7B                           ✓                                       6.69             -
                                              1        2        3        4        5        6             1             2              3              4
                                                                  Turn                                                       Turn                                      InternLM2-Chat-7B                                                ✓                  6.85         +0.16
                                                                (c)                                                      (d)                                         InternLM2-Chat-20B                            ✓                                       6.95             -
                                                                                                                                                                     InternLM2-Chat-20B                                                 ✓                  7.05         +0.10
                                         Figure 4: Model performance across dialogue turns.                                                                                    Mistral-7B                          ✓                                       6.95             -
                                                         Interference                                              Interference                                                Mistral-7B                                               ✓                  6.89         -0.06
                                                                               Understanding                                            Understanding
                                       Paraphrasing                                             Paraphrasing                                                              Table 4: Performance of SFT and RLHF/DPO.
                                                                    0 2 4 6 8 10                                              0 2 4 6 8 10
                                                                                     Memory                                                    Memory             formance on multi-turn dialogue tasks. Notably,
                                         Reflection                                                Reflection
                                                                              Questioning                                               Questioning               the growth in model size exhibits a particularly
                                                           Reasoning                                                Reasoning                                     significant effect on the questioning ability of the
                                                   Llama2-7B               Llama2-13B                          Qwen-7B               Qwen-14B                     models, suggesting that larger models exhibit en-
                                                        (a) Llama2                                                 (b) Qwen                                       hanced interactivity capabilities.
                                                         Interference                                              Interference
                                                                               Understanding                                            Understanding             Effect of Human Preference Alignment                                                                     Sev-
                                       Paraphrasing                                             Paraphrasing
                                                                    0 2 4 6 8 10                                              0 2 4 6 8 10                        eral techniques (Ouyang et al., 2022; Rafailov et al.,
                                                                                     Memory                                                    Memory             2024; Zhou et al., 2023, 2024a,b; Liu et al., 2024b)
                                         Reflection                                                Reflection                                                     have been proposed to align language models with
                                                                              Questioning                                               Questioning
                                                           Reasoning                                                Reasoning                                     humanvalues. We study the effect of RLHF/DPO
                                                        Yi-6B              Yi-34B                         InternLM2-7B               InternLM2-20B                on multi-turn dialogues by comparing three pairs
                                                             (c) Yi                                            (d) InternLM                                       of open-source models, each pair consisting of ver-
                                           Figure 5: Performance of various sizes of models.                                                                      sions trained with Supervised Fine-Tuning (SFT)
                                      information allows the model to learn the current                                                                           andenhancedwithRLHF/DPOtechniques. Table4
                                      conversational style and response patterns from the                                                                         shows that the application of RLHF/DPO tech-
                                      golden context, resulting in an illusory improve-                                                                           niques results in marginal improvements for the
                                      mentinperformance. This phenomenon will be an-                                                                              InternLM2-Chat models, with the 7B and 20B ver-
                                      alyzed in detail below. Similarly, as shown in Fig-                                                                         sions experiencing score increases of 0.16 and 0.10,
                                      ure 4d, in mathematical reasoning tasks, the model                                                                          respectively. In contrast, the Mistral-7B model
                                      also benefits from the golden context by adopt-                                                                             shows a performance decrease of 0.06. This obser-
                                      ing the reasoning format and solution paradigms                                                                            vationdemonstratesthatcurrentRLHFandDPOdo
                                      (such as the step-by-step paradigm). Conversely,                                                                            not invariably lead to substantial enhancements in
                                      in general reasoning tasks, where there is no fixed                                                                         multi-turn tasks, as opposed to the notable improve-
                                      paradigm to follow, the model’s performance tends                                                                           ments observed in single-turn scenarios. We sug-
                                      to decline as the dialogue progresses due to the                                                                            gest that the primary reason is that existing efforts
                                      increasing complexity.                                                                                                      mainly focus on collecting data from single-turn,
                                                                                                                                                                  thereby neglecting the complexities of multi-turn
                                      4.3          Further Analysis                                                                                               interaction.
                                      Effect of Model Size                                 Figure 5 presents a compre-
                                      hensive comparison across four groups of models                                                                             Effect of the Golden Context We employ
                                      varying in size. The trend of increasing model size                                                                         ChatGLM3-6B on separate input and instruction
                                      is associated with a universal improvement in per-                                                                          clarification tasks with the golden context or self-
                                                                                                                                                        7427
