                 et al., 2023b) and PandaLM (Wang et al., 2023c)        Context Memory: Toensurecontinuity and rel-
                 attempt to automatically assess open-ended instruc-    evance in dialogues, chatbots must exhibit a robust
                 tions, but they remain confined to single-turn set-    context memory capability. This involves accu-
                 tings. MT-Bench (Zheng et al., 2024) and MT-           rately retrieving and utilizing past dialogue infor-
                 Bench++(Sunetal., 2023) expand multi-turn eval-        mationtoaddresscurrentuserinquiries. Wenamed
                 uations across eight topics. BotChat (Duan et al.,    Context Memory (CM) for the third-level ability.
                 2023)andMINT(Wangetal.,2023b)focusonspe-               Context Understanding:      Anaphora Resolution
                 cialized tasks such as dialogue generation abilities. (AR). It is common for users to use demonstrative
                 Despitetheseefforts, there remains a notable gap in    pronouns (e.g., "these," "it") in dialogues. A key
                 fine-grained evaluations for multi-turn interactions.  ability for chatbots is to identify the referents of
                 BenchmarksforFine-grained Abilities        Thead-      these pronouns accurately to generate appropriate
                 vent of general LLMs has highlighted the need for      responses; Separate Input (SI). Dialogues typically
                 morecomprehensive evaluation. Hendrycks et al.,        unfold over several turns, with the initial turn out-
                 2020 introduces MMLU with an extensive suite of        lining the task requirements and subsequent turns
                 57tasks spanning social science and STEM. Sub-         specifying the task input. Understanding the re-
                 sequent benchmarks (Huang et al., 2024; Li et al.,     lationship between instructions and inputs is de-
                 2023a; Zhong et al., 2023; Srivastava et al., 2022;    mandedforeffective chatbots.
                 Yuetal., 2023; Li et al., 2024b; Guo et al., 2024a)    Context Interference:     Topic Shift (TS). Users
                 aim to rigorously assess LLMs’ knowledge and           might unpredictively switch topics in multi-turn
                 logic. ConceptMath (Wu et al., 2024) and Follow-       dialogues. This task assesses the chatbot’s ability
                 Bench(Jiang et al., 2023b) develop a hierarchical      to recognize a topic shift and ignore unrelated pre-
                 framework for evaluating model capabilities.           ceding information, thereby concentrating on the
                 3 MT-Bench-101                                         newtopic at hand; Content Confusion (CC) centers
                                                                        on the chatbot’s skill in managing situations where
                 This section begins with a detailed description        users pose questions that, while textually similar in
                 of the three-tier hierarchical ability taxonomy for    history questions, necessitate distinct responses.
                 multi-turn dialogues. Following that, we explain       3.1.2  Adaptability
                 themethodologyusedtocollectthedataset. Finally,        Chatbotsadjusttheirearlyresponseswiththeuser’s
                 wepresent an analysis of the dataset’s statistics.     new requirements (Rephrasing), new conditions,
                 3.1   Hierarchical Ability Taxonomy                    and hypotheses (Reasoning) and can correct or in-
                 After analyzing real dialogues from ShareGPT           sist on answers according to user-challenging feed-
                 (Gudibandeetal.,2023)andRealChat(Zhengetal.,           back (Reflective) in user-triggered dialogue.
                 2023) and the teaching taxonomy of multi-turn di-      Rephrasing:    Content Rephrasing (CR) requires
                 alogues from educational psychology (Alexander,        chatbots to have a thorough understanding of the
                 2018; Marchel, 2007; Peng et al., 2020; Gao et al.,    text to rephrase the content of the last response
                 2018), we have developed a hierarchical taxonomy       based on the user’s latest requirement (e.g., sum-
                 of abilities crucial for chatbots to engage effec-     marizing this paragraph). Format Rephrasing (FR)
                 tively in multi-turn dialogues with human users.       involves a transformation in structure while pre-
                 This taxonomy is structured into three levels, with    serving the original information (e.g., converting
                 the third level encompassing 13 distinct tasks. Ta-    this paragraph into a list format).
                 ble 1 provides a brief one-sentence description for    Reflection:  Self-correction (SC). Upon receiving
                 each third-level task. This section will deliver a     user feedback indicating skepticism or errors in
                 detailed explanation of these three-level abilities    the last response, the chatbot will correct mistakes,
                 and tasks. We also provide cases for each task in      and provide a more accurate subsequent response.
                 the Appendix F.                                       Within our dataset, this task is limited to instances
                 3.1.1   Perceptivity                                  where the chatbot’s initial reply was erroneous or
                 Perceptivity requires chatbots to adeptly track and    not precise, and the user’s critique is deemed valid.
                 use historical dialogue data to provide logical and   Self-affirmation (SA). Unlike self-correction task,
                 consistent responses, encompassing the following       self-affirmation comes into play when the chatbot’s
                 three core abilities.                                  initial response is correct or accurate, yet it encoun-
                                                                   7423
