                          MT-Bench-101: AFine-GrainedBenchmarkforEvaluatingLarge
                                             LanguageModelsinMulti-TurnDialogues
                                 ∗1           ∗2,3                    ∗†1                    1                  1                     3
                        GeBai ,JieLiu             , Xingyuan Bu          , Yancheng He , Jiaheng Liu , Zhanhui Zhou ,
                                                 1                1                   1               1                     2,3
                                ZhuoranLin ,WenboSu ,TiezhengGe ,BoZheng ,WanliOuyang
                                           1Alibaba Group 2The Chinese University of Hong Kong
                                                               3Shanghai AI Laboratory
                                                  {bg427839, buxingyuan.bxy}@taobao.com
                                          Abstract                                                     Perceptivity
                                                                                          Abilities:  Context Memory, Understanding,  Anaphora, Topic Shift...
                                                                                          Examples:
                        TheadventofLargeLanguageModels(LLMs)                               User: I want to buy a new laptop for my graphic design work.
                                                                                           User: My budget is under $1500.
                        has drastically enhanced dialogue systems.                         User: Considering my budget and requirements, which one
                        However, comprehensively evaluating the di-                           would be the better?
                                                                                                       Adaptability
                        alogue abilities of LLMs remains a challenge.                     Abilities: Content/Format Rephrasing, Multi-turn Reasoning...
                                                                                          Example:
                        Previous benchmarks have primarily focused                         User: How can quantum computing change the world?
                                                                                           User: Can you rewrite that explanation in simple terms?
                        on single-turn dialogues or provided coarse-                       User: Can you present that explanation in a bullet point format?
                        grained and incomplete assessments of multi-                                   Interactivity
                        turn dialogues, overlooking the complexity and                    Abilities:  Questioning, Clarification, Proactive Interaction...
                                                                                          Example:
                        fine-grained nuances of real-life dialogues. To                    User: I'm planning to visit Japan for the cherry blossom season.
                                                                                           Bot: That sounds like a beautiful plan! Have you thought about     
                        address this issue, we introduce MT-Bench-                            which cities you want to visit for cherry blossom viewing?
                        101, specifically designed to evaluate the fine-          Figure 1: MT-Bench-101 encompasses three overarch-
                        grained abilities of LLMs in multi-turn dia-              ing abilities and thirteen distinct tasks within multi-turn
                        logues. By conducting a detailed analysis of              dialogue scenarios, facilitating a granular benchmarking
                        real multi-turn dialogue data, we construct a             from basic perceptivity to advanced interactivity. On
                        three-tier hierarchical ability taxonomy com-             the right, a model with a broader range of abilities is
                        prising 4208 turns across 1388 multi-turn di-             considered better in multi-turn scenarios.
                        alogues in 13 distinct tasks.     We then eval-
                        uate 21 popular LLMs based on MT-Bench-                   2023), which include multiple utterances as part of
                        101, conducting comprehensive analyses from               the dialogue history. Therefore, it is essential to
                        bothabilityandtaskperspectivesandobserving
                        differing trends in LLMs performance across               evaluate the proficiency of LLMs in generating co-
                        dialogue turns within various tasks. Further              herent responses utilizing multiple utterances (Lan
                        analysis indicates that neither utilizing com-            et al., 2020). Early studies like MT-bench (Zheng
                        monalignment techniques nor chat-specific de-             et al., 2024) mainly focus on two-turn dialogues
                        signs has led to obvious enhancements in the              and coarse-grained abilities, not sufficiently cov-
                        multi-turn abilities of LLMs. Extensive case              ering the complexity of real-world multi-turn di-
                        studies suggest that our designed tasks accu-             alogue scenarios. This indicates a considerable
                        rately assess the corresponding multi-turn abil-          scope for improvement in current benchmarks for
                        ities. The data and code are available at https:
                        //github.com/mtbench101/mt-bench-101.                     multi-turn dialogues, underscoring the urgent need
                   1 Introduction                                                 to develop a comprehensive benchmark that can
                                                                                  effectively compare the chat abilities of LLMs in
                   Large Language Models (LLMs) based chatbots                    multi-turn dialogues.
                   have made remarkable advances and significantly                   In this paper, we introduce MT-Bench-101, a
                   enhanced dialogue systems. Several benchmarks                  newbenchmarkdesignedspecifically for evaluat-
                   have been introduced to assess the capabilities of             ing the chat capabilities of LLMs in multi-turn
                   Large Language Models (LLMs) in single-turn di-                dialogues, as shown in Figure 1. During the abil-
                   alogues, e.g., MMLU (Hendrycks et al., 2020),                  ity modeling process for multi-turn dialogue, we
                   BBH(Srivastava et al., 2022), and AlpacaEval (Li               undertake a systematical analysis combining real-
                   et al., 2023b). However, daily dialogues between               world multi-turn dialogue data (Gudibande et al.,
                   users and chatbots usually involve multi-turn con-             2023; Zheng et al., 2023) with the teaching tax-
                   versations (Gudibande et al., 2023; Zheng et al.,              onomyfromeducational psychology (Alexander,
                        ∗Equalcontribution. † Corresponding author.               2018; Marchel, 2007). This integrated approach
                                                                             7421
               Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 7421–7454
                                              August 11-16, 2024 ©2024 Association for Computational Linguistics
