                     The AI assistant’s interactivity, represented by its ability to proactively initiate and sustain
                     engaging dialogues with ‘Human’, is a key aspect of a dynamic conversational experience. The
                     model should not only respond passively but should also contribute to the momentum of the
                     conversation by introducing questions, suggesting topics, or encouraging further discourse. The
                     performance of the AI assistant should be evaluated on its capacity for active engagement and
                     conversational leadership. The evaluation criteria are as follows:
                     1.  Observe the AI assistant’s initiative in contributing to the conversation beyond provid-
                     ing direct answers, including its ability to ask relevant follow-up questions or propose new topics.
                     2. Assess the AI assistant’s aptness in maintaining the flow of the conversation, including how
                     well it encourages ‘Human’ to provide more information or share their thoughts.
                     3. Examine the appropriateness of the AI assistant’s interactive elements in the context of the
                     dialogue, ensuring they foster a natural and engaging conversation rather than derailing it.
                     4. Evaluate the AI assistant’s responsiveness to ‘Human’s input while being proactive, ensuring
                     that it listens and adapts to the conversation’s direction as set by ‘Human’.
                     Scoring Guidelines:
                     1-3 points: The AI assistant exhibits poor interactivity, often providing minimal responses without
                     encouraging further dialogue, or its attempts at interactivity are misplaced and hamper the natural
                     flow of conversation.
                     4-6 points: The AI assistant demonstrates moderate interactivity; it occasionally asks questions
                     or suggests new topics but may not consistently maintain the conversational momentum or fully
                     engage ‘Human’.
                     7-9 points: The AI assistant is highly interactive, regularly using questions and topics to keep the
                     conversation going, while mostly preserving relevancy and a natural exchange with ‘Human’.
                     10 points: The AI assistant excels at interactivity, skillfully using questions and dialogue prompts
                     to enrich the conversation, actively engaging ‘Human’, and enhancing the overall dialogue
                     experience without dominating the conversation.
                     Whenscoring, consider the balance the AI assistant strikes between guiding the conversation and
                     allowing ‘Human’ to steer the dialogue. The AI assistant’s interactivity should feel like a natural
                     extension of the conversation, not forced or distracting from ‘Human’s intent. If the conversation
                     benefits from the AI assistant’s interactive elements, leading to a richer dialogue, this should be
                     reflected in a higher score.
                     Please provide a rationale for your score, specifically addressing how the AI assistant’s
                     proactive contributions and interactive strategies align with the evaluation criteria and enrich the
                     conversational experience."
                                         Figure 34: The evaluation prompt for proactive interactions task.
                                                                      7451
