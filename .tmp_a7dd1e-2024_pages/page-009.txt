                         Evaluation Method         Agreement       ∆         References
                           HumanExperts                80%         0%        Robin Alexander. 2018. Developing dialogic teaching:
                           MT-Bench-101                87%       +7%            Genesis, process, trial. Research papers in education,
                                                                                33(5):561–598.
                        w/o scoring guidelines         77%        -3%
                     w/o minimumvalues metrics         75%        -5%        Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang,
                                                                                Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei
                  Table 5: Agreement between human experts and various          Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin,
                  evaluation methods. The agreement between our auto-           Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu,
                  evaluation method and humans reaches 87%, which is            KemingLu,JianxinMa,RuiMen,XingzhangRen,
                  even higher than the agreement among humans (80%).            XuanchengRen,ChuanqiTan,SinanTan,Jianhong
                                                                                Tu, Peng Wang, Shijie Wang, Wei Wang, Sheng-
                                                                                guang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang,
                  tional insights. We evaluate 21 LLMs using our                Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu,
                  MT-Bench-101, revealing that neither alignment                Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingx-
                  techniques nor chat designs notably improve their             uan Zhang, Yichang Zhang, Zhenru Zhang, Chang
                  multi-turn abilities. Furthermore, extensive case             Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang
                                                                                Zhu. 2023. Qwen technical report. arXiv preprint
                  studies indicate that tasks in our benchmark effec-           arXiv:2309.16609.
                  tively measure the multi-turn chat abilities.              Baichuan. 2023. Baichuan 2: Open large-scale lan-
                  6 Limitations                                                 guage models. arXiv preprint arXiv:2309.10305.
                                                                             Tom Brown, Benjamin Mann, Nick Ryder, Melanie
                  With LLM technologies rapidly evolving, new                   Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
                  multi-turn capabilities are likely to emerge. Conse-          Neelakantan, Pranav Shyam, Girish Sastry, Amanda
                  quently, the findings of this study may not encom-            Askell, et al. 2020. Language models are few-shot
                  pass all multi-turn abilities. We intend to regularly         learners. Advances in neural information processing
                                                                                systems, 33:1877–1901.
                  update our benchmark, from MT-Bench-101 to fu-
                  ture iterations, to incorporate new developments.          Xingyuan Bu, Junran Peng, Junjie Yan, Tieniu Tan, and
                                                                                Zhaoxiang Zhang. 2021. Gaia: A transfer learning
                  7 EthicsStatement                                             systemofobjectdetectionthatfitsyourneeds. InPro-
                                                                                ceedings of the IEEE/CVF Conference on Computer
                  Wecollected and annotated data using GPT-4 and                Vision and Pattern Recognition, pages 274–283.
                  had it reviewed by humans. Additionally, we ob-            Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,
                  tained the participants’ informed consent and en-             ZhanghaoWu,HaoZhang,LianminZheng,Siyuan
                  sured their privacy and autonomy. All participants            Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion
                  werefullyawareofandconsentedtotheannotation                   Stoica, and Eric P. Xing. 2023. Vicuna: An open-
                                                                                source chatbot impressing gpt-4 with 90%* chatgpt
                  process. We have taken rigorous steps to ensure               quality.
                  that the dataset is devoid of offensive content or per-    Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi
                  sonal identity information. However, there might              Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun,
                  still be residual errors or biases due to inadvertent         and Bowen Zhou. 2023. Enhancing chat language
                  mistakes by GPT-4 or oversights by annotators. We             models by scaling high-quality instructional conver-
                  havemadeourbestefforttorectifytheseissues,but                 sations. arXiv preprint arXiv:2305.14233.
                  it’s challenging to eliminate them entirely. These         Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding,
                  issues may be present in all similar datasets. Fur-           Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. Glm:
                  thermore, the dataset will be publicly available and          General language model pretraining with autoregres-
                  could be misused for training, which might make               sive blank infilling. In Proceedings of the 60th An-
                  ourbenchmarklesseffective. AsLLMscontinueto                   nual Meeting of the Association for Computational
                                                                                Linguistics (Volume 1: Long Papers), pages 320–335.
                  evolve, the current capability taxonomy for multi-
                  turn dialogues might be incomplete. In response,           HaodongDuan,JueqiWei,ChonghuaWang,Hongwei
                  wewill continue to release updated versions of the            Liu, Yixiao Fang, Songyang Zhang, Dahua Lin, and
                  dataset to address data leaks and extend capabilities.        Kai Chen. 2023. Botchat: Evaluating llms’ capabil-
                                                                                ities of having multi-turn dialogues. arXiv preprint
                  Lastly, the dataset released in this work is intended         arXiv:2310.13650.
                  solely for research and may not be suitable for com-       Yann Dubois, Chen Xuechen Li, Rohan Taori, Tianyi
                  mercial use without additional verification.                  Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin,
                                                                                Percy S Liang, and Tatsunori B Hashimoto. 2024.
                                                                         7429
