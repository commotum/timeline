file_name,file_title,csv_year,csv_title,csv_url,similarity
Are We on the Right Way for Evaluating Large Vision-Language Models.pdf,Are We on the Right Way for Evaluating Large Vision-Language Models,2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf,1.000
Behind RoPE - How Does Causal Mask Encode Positional Information.pdf,Behind RoPE - How Does Causal Mask Encode Positional Information,2025,Behind RoPE: How Does Causal Mask Encode Positional Information?,https://arxiv.org/pdf/2509.21042.pdf,1.000
CamPoint- Boosting Point Cloud Segmentation with Virtual Camera.pdf,CamPoint- Boosting Point Cloud Segmentation with Virtual Camera,2025,CamPoint: Boosting Point Cloud Segmentation with Virtual Camera,https://cvpr.thecvf.com/virtual/2025/poster/34611,1.000
Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features.pdf,Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features,2025,Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features,https://arxiv.org/pdf/2509.16629.pdf,1.000
DeLiVoTr- Deep and light-weight voxel transformer for 3D object detection.pdf,DeLiVoTr- Deep and light-weight voxel transformer for 3D object detection,2024,DeLiVoTr: Deep and Light-weight Voxel Transformer for 3D Object Detection,https://www.sciencedirect.com/science/article/pii/S2667305324000371,1.000
Deterministic Nonperiodic Flow.pdf,Deterministic Nonperiodic Flow,1963,Deterministic Nonperiodic Flow,https://journals.ametsoc.org/downloadpdf/view/journals/atsc/20/2/1520-0469_1963_020_0130_dnf_2_0_co_2.pdf,1.000
Deterministic Policy Gradient Algorithms.pdf,Deterministic Policy Gradient Algorithms,2014,Deterministic Policy Gradient Algorithms,https://proceedings.mlr.press/v32/silver14.pdf,1.000
Efficient Evolutionary Program Synthesis.pdf,Efficient Evolutionary Program Synthesis,2025,Efficient Evolutionary Program Synthesis,https://ctpang.substack.com/p/arc-agi-2-sota-efficient-evolutionary,1.000
Evolutionary Test-Time Compute.pdf,Evolutionary Test-Time Compute,2024,Evolutionary Test-Time Compute,https://jeremyberman.substack.com/p/how-i-got-a-record-536-on-arc-agi,1.000
Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains.pdf,Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains,2020,Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains,https://arxiv.org/pdf/2006.10739.pdf,1.000
Generative Verifiers- Reward Modeling as Next-Token Prediction.pdf,Generative Verifiers- Reward Modeling as Next-Token Prediction,2024,Generative Verifiers: Reward Modeling as Next-Token Prediction,https://neurips.cc/virtual/2024/104300,1.000
HoPE - Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models.pdf,HoPE - Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models,2025,HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models,https://arxiv.org/pdf/2509.05218.pdf,1.000
Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics.pdf,Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics,2024,Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics,https://arxiv.org/pdf/2405.14806.pdf,1.000
Positional Encoding Field.pdf,Positional Encoding Field,2025,Positional Encoding Field,https://arxiv.org/pdf/2510.20385v1.pdf,1.000
Sigmoid Loss for Language Image Pre-Training.pdf,Sigmoid Loss for Language Image Pre-Training,2023,Sigmoid Loss for Language Image Pre-Training,https://arxiv.org/pdf/2303.15343.pdf,1.000
"You Only Look Once - Unified, Real-Time Object Detection.pdf","You Only Look Once - Unified, Real-Time Object Detection",2015,"You Only Look Once: Unified, Real-Time Object Detection",https://arxiv.org/pdf/1506.02640.pdf,1.000
Dream to Control- Learning Behaviors by Latent Imagination.pdf,Dream to Control- Learning Behaviors by Latent Imagination,2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.935
A Theory of the Learnable.pdf,A Theory of the Learnable,1984,A Theory of the Learnable (PAC Learning),https://web.mit.edu/6.435/www/Valiant84.pdf,0.792
3DETR- An End-to-End Transformer Model for 3D Object Detection.pdf,3DETR- An End-to-End Transformer Model for 3D Object Detection,2024,DeLiVoTr: Deep and Light-weight Voxel Transformer for 3D Object Detection,https://www.sciencedirect.com/science/article/pii/S2667305324000371,0.726
Deformable DETR- Deformable Transformers for End-to-End Object Detection.pdf,Deformable DETR- Deformable Transformers for End-to-End Object Detection,2024,DeLiVoTr: Deep and Light-weight Voxel Transformer for 3D Object Detection,https://www.sciencedirect.com/science/article/pii/S2667305324000371,0.629
Training data-efficient image transformers & distillation through attention.pdf,Training data-efficient image transformers & distillation through attention,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.620
BEIT- BERT Pre-Training of Image Transformers.pdf,BEIT- BERT Pre-Training of Image Transformers,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.611
Adaptive Attention Span in Transformers.pdf,Adaptive Attention Span in Transformers,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.609
Evaluating Large Language Models Trained on Code.pdf,Evaluating Large Language Models Trained on Code,2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf,0.592
Beyond A*- Planning with Transformers.pdf,Beyond A*- Planning with Transformers,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.585
BLIP-2- Bootstrapping Language-Image Pre-training with Frozen Models.pdf,BLIP-2- Bootstrapping Language-Image Pre-training with Frozen Models,2023,Sigmoid Loss for Language Image Pre-Training,https://arxiv.org/pdf/2303.15343.pdf,0.583
Circle-RoPE- Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models.pdf,Circle-RoPE- Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models,2025,HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models,https://arxiv.org/pdf/2509.05218.pdf,0.571
AST- Audio Spectrogram Transformer.pdf,AST- Audio Spectrogram Transformer,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.562
CoPE- A Lightweight Complex Positional Encoding.pdf,CoPE- A Lightweight Complex Positional Encoding,2025,Positional Encoding Field,https://arxiv.org/pdf/2510.20385v1.pdf,0.562
AGIEval- A Human-Centric Benchmark for Evaluating Foundation Models.pdf,AGIEval- A Human-Centric Benchmark for Evaluating Foundation Models,2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf,0.561
YaRN- Efficient Context Window Extension of Large Language Models.pdf,YaRN- Efficient Context Window Extension of Large Language Models,2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf,0.554
Align before Fuse- Vision and Language Representation Learning with Momentum Distillation.pdf,Align before Fuse- Vision and Language Representation Learning with Momentum Distillation,2025,Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features,https://arxiv.org/pdf/2509.16629.pdf,0.545
Graph of Thoughts- Solving Elaborate Problems with Large Language Models.pdf,Graph of Thoughts- Solving Elaborate Problems with Large Language Models,2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf,0.525
Beyond the Imitation Game- Quantifying and extrapolating the capabilities of language models.pdf,Beyond the Imitation Game- Quantifying and extrapolating the capabilities of language models,2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf,0.515
Extending Context Window of Large Language Models via Positional Interpolation (PI).pdf,Extending Context Window of Large Language Models via Positional Interpolation (PI),2025,Behind RoPE: How Does Causal Mask Encode Positional Information?,https://arxiv.org/pdf/2509.21042.pdf,0.512
VideoBERT- A Joint Model for Video and Language Representation Learning.pdf,VideoBERT- A Joint Model for Video and Language Representation Learning,2023,Sigmoid Loss for Language Image Pre-Training,https://arxiv.org/pdf/2303.15343.pdf,0.505
Deep Residual Learning for Image Recognition.pdf,Deep Residual Learning for Image Recognition,2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.500
Exposing Numeracy Gaps- A Benchmark to Evaluate Fundamental Numerical Abilities in Large Language Models.pdf,Exposing Numeracy Gaps- A Benchmark to Evaluate Fundamental Numerical Abilities in Large Language Models,2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf,0.493
CoCa- Contrastive Captioners are Image-Text Foundation Models.pdf,CoCa- Contrastive Captioners are Image-Text Foundation Models,2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.491
DocVQA- A Dataset for VQA on Document Images.pdf,DocVQA- A Dataset for VQA on Document Images,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.486
CrossViT- Cross-Attention Multi-Scale Vision Transformer for Image Classification.pdf,CrossViT- Cross-Attention Multi-Scale Vision Transformer for Image Classification,2024,Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics,https://arxiv.org/pdf/2405.14806.pdf,0.482
Flamingo- a Visual Language Model for Few-Shot Learning.pdf,Flamingo- a Visual Language Model for Few-Shot Learning,2023,Sigmoid Loss for Language Image Pre-Training,https://arxiv.org/pdf/2303.15343.pdf,0.476
VisualBERT- A Simple and Performant Baseline for Vision and Language.pdf,VisualBERT- A Simple and Performant Baseline for Vision and Language,2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf,0.474
Image as a Foreign Language- BEIT Pretraining for All Vision and Vision-Language Tasks.pdf,Image as a Foreign Language- BEIT Pretraining for All Vision and Vision-Language Tasks,2023,Sigmoid Loss for Language Image Pre-Training,https://arxiv.org/pdf/2303.15343.pdf,0.473
Average-Hard Attention Transformers Are Threshold Circuits.pdf,Average-Hard Attention Transformers Are Threshold Circuits,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.465
Efficient Large-Scale Language Model Training on GPU Clusters.pdf,Efficient Large-Scale Language Model Training on GPU Clusters,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.460
Generating Long Sequences with Sparse Transformers.pdf,Generating Long Sequences with Sparse Transformers,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.456
AN IMAGE IS WORTH 16X16 WORDS- TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.pdf,AN IMAGE IS WORTH 16X16 WORDS- TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE,2024,DeLiVoTr: Deep and Light-weight Voxel Transformer for 3D Object Detection,https://www.sciencedirect.com/science/article/pii/S2667305324000371,0.452
Convolutional Sequence to Sequence Learning.pdf,Convolutional Sequence to Sequence Learning,2025,Positional Encoding Field,https://arxiv.org/pdf/2510.20385v1.pdf,0.452
DeepCoder- Learning to Write Programs.pdf,DeepCoder- Learning to Write Programs,2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.449
Context-aware Rotary Position Embedding.pdf,Context-aware Rotary Position Embedding,2025,Positional Encoding Field,https://arxiv.org/pdf/2510.20385v1.pdf,0.448
LXMERT- Learning Cross-Modality Encoder Representations from Transformers.pdf,LXMERT- Learning Cross-Modality Encoder Representations from Transformers,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.444
DoPE- Denoising Rotary Position Embedding.pdf,DoPE- Denoising Rotary Position Embedding,2025,Positional Encoding Field,https://arxiv.org/pdf/2510.20385v1.pdf,0.441
BLIP- Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation.pdf,BLIP- Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation,2023,Sigmoid Loss for Language Image Pre-Training,https://arxiv.org/pdf/2303.15343.pdf,0.434
CoAtNet- Marrying Convolution and Attention for All Data Sizes.pdf,CoAtNet- Marrying Convolution and Attention for All Data Sizes,2020,Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains,https://arxiv.org/pdf/2006.10739.pdf,0.434
Beyond Position- the emergence of wavelet-like properties in Transformers.pdf,Beyond Position- the emergence of wavelet-like properties in Transformers,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.433
Graph Perceiver IO- A General Architecture for Graph Structured Data.pdf,Graph Perceiver IO- A General Architecture for Graph Structured Data,2025,Graph Perceiver IO,https://www.sciencedirect.com/science/article/abs/pii/S0031320325005497,0.432
Asynchronous Methods for Deep Reinforcement Learning.pdf,Asynchronous Methods for Deep Reinforcement Learning,1984,A Theory of the Learnable (PAC Learning),https://web.mit.edu/6.435/www/Valiant84.pdf,0.430
Analysing Mathematical Reasoning Abilities of Neural Models.pdf,Analysing Mathematical Reasoning Abilities of Neural Models,2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf,0.422
A Distributional Perspective on Reinforcement Learning.pdf,A Distributional Perspective on Reinforcement Learning,1984,A Theory of the Learnable (PAC Learning),https://web.mit.edu/6.435/www/Valiant84.pdf,0.420
Graphormer- Do Transformers Really Perform Bad for Graph Representation.pdf,Graphormer- Do Transformers Really Perform Bad for Graph Representation,2024,DeLiVoTr: Deep and Light-weight Voxel Transformer for 3D Object Detection,https://www.sciencedirect.com/science/article/pii/S2667305324000371,0.419
FOLIO- Natural Language Reasoning with First-Order Logic.pdf,FOLIO- Natural Language Reasoning with First-Order Logic,2023,Sigmoid Loss for Language Image Pre-Training,https://arxiv.org/pdf/2303.15343.pdf,0.419
Rainbow- Combining Improvements in Deep Reinforcement Learning.pdf,Rainbow- Combining Improvements in Deep Reinforcement Learning,2025,CamPoint: Boosting Point Cloud Segmentation with Virtual Camera,https://cvpr.thecvf.com/virtual/2025/poster/34611,0.418
Differentiable Convex Optimization Layers.pdf,Differentiable Convex Optimization Layers,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.417
CvT- Introducing Convolutions to Vision Transformers.pdf,CvT- Introducing Convolutions to Vision Transformers,2025,CamPoint: Boosting Point Cloud Segmentation with Virtual Camera,https://cvpr.thecvf.com/virtual/2025/poster/34611,0.416
Generalized Planning for the Abstraction and Reasoning Corpus.pdf,Generalized Planning for the Abstraction and Reasoning Corpus,2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.414
Chatbot Arena- An Open Platform for Evaluating LLMs by Human Preference.pdf,Chatbot Arena- An Open Platform for Evaluating LLMs by Human Preference,2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf,0.414
ZeRO- Memory Optimizations Toward Training Trillion Parameter Models.pdf,ZeRO- Memory Optimizations Toward Training Trillion Parameter Models,2025,HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models,https://arxiv.org/pdf/2509.05218.pdf,0.413
DeepProbLog- Neural Probabilistic Logic Programming.pdf,DeepProbLog- Neural Probabilistic Logic Programming,2014,Deterministic Policy Gradient Algorithms,https://proceedings.mlr.press/v32/silver14.pdf,0.410
Adam- A Method for Stochastic Optimization.pdf,Adam- A Method for Stochastic Optimization,2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.409
Swin Transformer V2- Scaling Up Capacity and Resolution.pdf,Swin Transformer V2- Scaling Up Capacity and Resolution,2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf,0.408
Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (T5).pdf,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (T5),2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.406
Direct Preference Optimization- Your Language Model is Secretly a Reward Model.pdf,Direct Preference Optimization- Your Language Model is Secretly a Reward Model,2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.403
CAIL2019-SCM- A Dataset of Similar Case Matching in Legal Domain.pdf,CAIL2019-SCM- A Dataset of Similar Case Matching in Legal Domain,2020,Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains,https://arxiv.org/pdf/2006.10739.pdf,0.403
BEVFormer- Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers.pdf,BEVFormer- Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers,2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.400
GPT-4 Technical Report.pdf,GPT-4 Technical Report,2025,Graph Perceiver IO,https://www.sciencedirect.com/science/article/abs/pii/S0031320325005497,0.400
Do Transformer Modifications Transfer Across Implementations and Applications.pdf,Do Transformer Modifications Transfer Across Implementations and Applications,2020,Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains,https://arxiv.org/pdf/2006.10739.pdf,0.397
Continuous Control with Deep Reinforcement Learning.pdf,Continuous Control with Deep Reinforcement Learning,2025,CamPoint: Boosting Point Cloud Segmentation with Virtual Camera,https://cvpr.thecvf.com/virtual/2025/poster/34611,0.396
MaxViT- Multi-Axis Vision Transformer.pdf,MaxViT- Multi-Axis Vision Transformer,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.394
Visual Instruction Tuning.pdf,Visual Instruction Tuning,2023,Sigmoid Loss for Language Image Pre-Training,https://arxiv.org/pdf/2303.15343.pdf,0.393
A Fully First-Order Layer for Differentiable Optimization.pdf,A Fully First-Order Layer for Differentiable Optimization,2024,DeLiVoTr: Deep and Light-weight Voxel Transformer for 3D Object Detection,https://www.sciencedirect.com/science/article/pii/S2667305324000371,0.393
DETR3D- 3D Object Detection from Multi-view Images via 3D-to-2D Queries.pdf,DETR3D- 3D Object Detection from Multi-view Images via 3D-to-2D Queries,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.391
The ConceptARC Benchmark- Evaluating Understanding and Generalization in the ARC Domain.pdf,The ConceptARC Benchmark- Evaluating Understanding and Generalization in the ARC Domain,2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.391
EVA02-AT- Egocentric Video-Language with Spatial-Temporal RoPE.pdf,EVA02-AT- Egocentric Video-Language with Spatial-Temporal RoPE,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.391
GQA- A New Dataset for Real-World Visual Reasoning and Compositional Question Answering.pdf,GQA- A New Dataset for Real-World Visual Reasoning and Compositional Question Answering,2025,Behind RoPE: How Does Causal Mask Encode Positional Information?,https://arxiv.org/pdf/2509.21042.pdf,0.391
"Gated Attention for LLMs- Non-linearity, Sparsity, Sink-Free.pdf","Gated Attention for LLMs- Non-linearity, Sparsity, Sink-Free",2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.386
GSM8K- Training Verifiers to Solve Math Word Problems.pdf,GSM8K- Training Verifiers to Solve Math Word Problems,2024,Generative Verifiers: Reward Modeling as Next-Token Prediction,https://neurips.cc/virtual/2024/104300,0.384
ConViT- Improving Vision Transformers with Soft Convolutional Inductive Biases.pdf,ConViT- Improving Vision Transformers with Soft Convolutional Inductive Biases,2025,Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features,https://arxiv.org/pdf/2509.16629.pdf,0.383
Deep Reinforcement Learning with Double Q-learning (Double DQN).pdf,Deep Reinforcement Learning with Double Q-learning (Double DQN),2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.382
Goal-Aware Neural SAT Solver.pdf,Goal-Aware Neural SAT Solver,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.379
Batch Normalization- Accelerating Deep Network Training by Reducing Internal Covariate Shift.pdf,Batch Normalization- Accelerating Deep Network Training by Reducing Internal Covariate Shift,2025,HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models,https://arxiv.org/pdf/2509.05218.pdf,0.375
Distributed Prioritized Experience Replay.pdf,Distributed Prioritized Experience Replay,1984,A Theory of the Learnable (PAC Learning),https://web.mit.edu/6.435/www/Valiant84.pdf,0.371
GAIA- a benchmark for General AI Assistants.pdf,GAIA- a benchmark for General AI Assistants,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.371
DeBERTa- Decoding-enhanced BERT with Disentangled Attention.pdf,DeBERTa- Decoding-enhanced BERT with Disentangled Attention,2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.367
CSWin Transformer- A General Vision Transformer Backbone with Cross-Shaped Windows.pdf,CSWin Transformer- A General Vision Transformer Backbone with Cross-Shaped Windows,2025,Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features,https://arxiv.org/pdf/2509.16629.pdf,0.367
ChartQA- A Benchmark for Question Answering about Charts with Visual and Logical Reasoning.pdf,ChartQA- A Benchmark for Question Answering about Charts with Visual and Logical Reasoning,2025,CamPoint: Boosting Point Cloud Segmentation with Virtual Camera,https://cvpr.thecvf.com/virtual/2025/poster/34611,0.364
Gemini- A Family of Highly Capable Multimodal Models.pdf,Gemini- A Family of Highly Capable Multimodal Models,2024,Are We on the Right Way for Evaluating Large Vision-Language Models?,https://arxiv.org/pdf/2403.20330.pdf,0.360
H-ARC- A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark.pdf,H-ARC- A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark,2025,Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features,https://arxiv.org/pdf/2509.16629.pdf,0.360
Density Adaptive Attention is All You Need- Robust Parameter-Efficient Fine-Tuning Across Multiple Modalities.pdf,Density Adaptive Attention is All You Need- Robust Parameter-Efficient Fine-Tuning Across Multiple Modalities,2021,DeiT: Data-efficient Image Transformers,https://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf,0.359
Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them.pdf,Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them,2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.359
Constructing Datasets for Multi-hop Reading Comprehension.pdf,Constructing Datasets for Multi-hop Reading Comprehension,2024,Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics,https://arxiv.org/pdf/2405.14806.pdf,0.359
Grokking Modular Polynomials.pdf,Grokking Modular Polynomials,2014,Deterministic Policy Gradient Algorithms,https://proceedings.mlr.press/v32/silver14.pdf,0.349
Grokking Modular Arithmetic.pdf,Grokking Modular Arithmetic,2024,Evolutionary Test-Time Compute,https://jeremyberman.substack.com/p/how-i-got-a-record-536-on-arc-agi,0.346
Segment Anything.pdf,Segment Anything,2025,Efficient Evolutionary Program Synthesis,https://ctpang.substack.com/p/arc-agi-2-sota-efficient-evolutionary,0.346
Guiding High-Performance SAT Solvers with Unsat-Core Predictions.pdf,Guiding High-Performance SAT Solvers with Unsat-Core Predictions,2024,Generative Verifiers: Reward Modeling as Next-Token Prediction,https://neurips.cc/virtual/2024/104300,0.345
GLUE- A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding.pdf,GLUE- A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding,2019,Dream to Control: Learning Behaviors by Latent Imagination (Dreamer),https://openreview.net/attachment?id=S1lOTC4tDS&name=original_pdf,0.338
Base of RoPE Bounds Context Length.pdf,Base of RoPE Bounds Context Length,2025,Behind RoPE: How Does Causal Mask Encode Positional Information?,https://arxiv.org/pdf/2509.21042.pdf,0.337
A-OKVQA- A Benchmark for Visual Question Answering using World Knowledge.pdf,A-OKVQA- A Benchmark for Visual Question Answering using World Knowledge,1963,Deterministic Nonperiodic Flow,https://journals.ametsoc.org/downloadpdf/view/journals/atsc/20/2/1520-0469_1963_020_0130_dnf_2_0_co_2.pdf,0.337
Encoding Word Order in Complex Embeddings.pdf,Encoding Word Order in Complex Embeddings,2025,HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models,https://arxiv.org/pdf/2509.05218.pdf,0.336
DeepSeek-R1- Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.pdf,DeepSeek-R1- Incentivizing Reasoning Capability in LLMs via Reinforcement Learning,2025,HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models,https://arxiv.org/pdf/2509.05218.pdf,0.335
GPQA- A Graduate-Level Google-Proof Q&A Benchmark.pdf,GPQA- A Graduate-Level Google-Proof Q&A Benchmark,1984,A Theory of the Learnable (PAC Learning),https://web.mit.edu/6.435/www/Valiant84.pdf,0.333
Grokking- Generalization Beyond Overfitting on Small Algorithmic Datasets.pdf,Grokking- Generalization Beyond Overfitting on Small Algorithmic Datasets,2025,Positional Encoding Field,https://arxiv.org/pdf/2510.20385v1.pdf,0.318
miniF2F- a cross-system benchmark for formal Olympiad-level mathematics.pdf,miniF2F- a cross-system benchmark for formal Olympiad-level mathematics,2025,Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features,https://arxiv.org/pdf/2509.16629.pdf,0.314
