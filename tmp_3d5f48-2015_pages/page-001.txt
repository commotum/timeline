    © ACM 2015. This is the author's version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record 
    was published in GECCO 2015, http://dx.doi.org/10.1145/2739480.2754769. 
    Citation: T. Helmuth and L. Spector. General Program Synthesis Benchmark Suite. In GECCO '15: Proceedings of the 17th annual conference on 
    Genetic and evolutionary computation, pp. 1039-1046. July 2015. ACM.
                                        General Program Synthesis Benchmark Suite
                                                     ThomasHelmuth                                                                        Lee Spector
                                                      Computer Science                                                                 Cognitive Science
                                               University of Massachusetts                                                            Hampshire College
                                                     Amherst, MA 01003                                                                Amherst, MA 01002
                                             thelmuth@cs.umass.edu                                                            lspector@hampshire.edu
                    ABSTRACT                                                                                     programming techniques including the use of control ﬂow,
                    Recent interest in the development and use of non-trivial                                    modularity, and large, diverse instruction sets covering mul-
                    benchmark problems for genetic programming research has                                      tiple data types and data structures. Also, minimal sizes for
                    highlighted the scarcity of general program synthesis (also                                  solution programs should cover a range beyond what could
                    called“traditional programming”) benchmark problems. We                                      be found using brute-force search. This contrasts with most
                    present a suite of 29 general program synthesis benchmark                                    existing benchmark problems used in GP and other program
                    problems systematically selected from sources of introduc-                                   synthesis ﬁelds [6], which prescribe small, domain-speciﬁc in-
                    tory computer science programming problems. This suite is                                    struction sets and assess a system’s abilities only on a narrow
                    suitable for experiments with any program synthesis system                                   range of programming techniques.
                    driven by input/output examples. We present results from                                         In this paper we present a suite of 29 general program
                    illustrative experiments using our reference implementation                                  synthesis benchmark problems, systematically selected from
                    of the problems in the PushGP genetic programming sys-                                       sourcesofintroductorycomputerscienceprogrammingprob-
                    tem. The results show that the problems in the suite vary                                    lems. We present each problem’s speciﬁcations in the form
                    in diﬃculty and can be useful for assessing the capabilities                                 of input/output examples, making them suitable to a wide
                    of a program synthesis system.                                                               range of program synthesis techniques, including GP. While
                                                                                                                 the problems are not particularly challenging for skilled hu-
                    Categories and Subject Descriptors                                                           man programmers, they are reasonably challenging for be-
                                                                                                                 ginners and many are arguably too diﬃcult for existing pro-
                    I.2.2 [Artiﬁcial Intelligence]: Automatic Programming—                                       gram synthesis systems, including GP. As textbook prob-
                    Program synthesis                                                                            lems, they are not likely representative of real general pro-
                                                                                                                 gramsynthesis applications, yet they should prove useful for
                    Keywords                                                                                     assessing progress toward this goal.
                    program synthesis; genetic programming; benchmarks                                           2.      BENCHMARK-BASEDCOMPARISONS
                    1.     INTRODUCTION                                                                              We designate the solution of a general program synthe-
                                                                                                                 sis problem as a program that perfectly maps inputs to the
                       Several genetic programming (GP) researchers have high-                                   correct outputs. While one might argue that human-written
                    lighted the need for better benchmark problems to guide re-                                  software is often useful even if it has known bugs, the goal
                    search in the ﬁeld [9, 17, 18]. While benchmarks have been                                   here is to pass all input/output tests. Therefore, we are not
                    proposed, few are for general programming problems (also                                     interested in programs that are only approximately correct,
                    called“traditional”or“algorithmic”programming problems)                                      as might be appropriate in the context of other problems
                    even though this category received the second highest level                                  for which GP is used, such as symbolic regression. We rec-
                    of interest in a recent community survey about the need for                                  ommendmeasuring performance on the problems presented
                    benchmarks [17].                                                                             here primarily in terms of success rates, quantifying how of-
                       Automating human programming has long been a goal of                                      ten a stochastic algorithm ﬁnds a successful program across
                    GP, as articulated for example in Koza’s ﬁrst book [7]. The                                                     1
                                                                                                                 a set of runs . A more thorough argument for assessment
                    purpose of a general program synthesis benchmark is to help                                  in terms of success rates can be found in [3]. Furthermore,
                    researchers assess the ability of a system to automate hu-                                   in order to be considered successful, a program must not
                    manprogramming. Such problems should require a range of                                      only achieve zero error on all of the example data used to
                                                                                                                 train the program (the “training set”), but also on a set of
                    Permission to make digital or hard copies of all or part of this work for personal or        withheld generalization data (the“test set”).
                    classroom use is granted without fee provided that copies are not made or distributed            When using this benchmark suite to compare diﬀerent
                    for proﬁt or commercial advantage and that copies bear this notice and the full cita-
                    tion on the ﬁrst page. Copyrights for components of this work owned by others than           settings within one system, we recommend limiting com-
                    ACMmustbehonored. Abstractingwithcreditispermitted. Tocopyotherwise,orre-                    putation with a budget based on the maximum number of
                    publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission   program evaluations allowed in a run. This ensures that the
                    and/or a fee. Request permissions from permissions@acm.org.
                    GECCO’15,July11-15,2015,Madrid,Spain                                                          1Fordeterministic synthesis algorithms other measures must
                     c                                                                                           be used, such as whether a correct program is found within
                    2015ACM.ISBN978-1-4503-3472-3/15/07...$15.00                                                a set period of time.
                    DOI:http://dx.doi.org/10.1145/2739480.2754769
