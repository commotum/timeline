year,title,url
2024,Rotary Position Embedding for Vision Transformer,https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01584.pdf
2020,SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks,https://proceedings.neurips.cc/paper/2020/hash/15231a7ce4ba789d13b722cc5c955834-Abstract.html
2020,SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks,https://proceedings.neurips.cc/paper/2020/hash/15231a7ce4ba789d13b722cc5c955834-Abstract.html
2024,SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension,https://openaccess.thecvf.com/content/CVPR2024/papers/Li_SEED-Bench_Benchmarking_Multimodal_Large_Language_Models_CVPR_2024_paper.pdf
2022,SRBench,https://github.com/cavalab/srbench
2021,SRBench (Symbolic Regression Benchmarks),https://cavalab.github.io/symbolic-regression/
2024,SRBench++: principled benchmarking of symbolic regression,https://pmc.ncbi.nlm.nih.gov/articles/PMC12321164/
2024,SRBench++: principled benchmarking of symbolic regression,https://pubmed.ncbi.nlm.nih.gov/40761553/
2021,SVAMP: Simple Variations on Arithmetic Math Word Problems,https://aclanthology.org/2021.naacl-main.168/
2024,SWE-bench,https://proceedings.iclr.cc/paper_files/paper/2024/file/edac78c3e300629acfe6cbe9ca88fb84-Paper-Conference.pdf
2025,Scaling Transformer-Based Novel View Synthesis with Models Token Disentanglement and Synthetic Data,https://openaccess.thecvf.com/content/ICCV2025/papers/Nair_Scaling_Transformer-Based_Novel_View_Synthesis_with_Models_Token_Disentanglement_and_ICCV_2025_paper.pdf
2025,Scaling up Test-Time Compute with Latent Reasoning,https://neurips.cc/virtual/2025/poster/117966
2024,ScatterFormer: Efficient Voxel Transformer with Scattered Linear Attention,MISSING
