Below is a **timeline-form** list of cross-disciplinary “external foundations” papers/books that are routinely used as **theoretical grounding / conceptual motivation** for ML—especially around **working memory**, **visual cortex**, **prefrontal cortex**, **communications / information**, **dynamical systems**, and **representation**. (These are *out-of-scope by design*: they explain *why* learning/representation/computation might look the way it does.)

---

## 1924 — Communications as a rate / code / distortion problem

* **Certain Factors Affecting Telegraph Speed** (Nyquist, 1924)
  **Context:** early formalization of limits on reliable transmission (“transmission of intelligence”)
  **Why ML cares:** pre-Shannon framing of **capacity constraints**, coding choices, and distortion tradeoffs. ([Monoskop][1])

---

## 1928 — Information as a measurable quantity

* **Transmission of Information** (Hartley, 1928)
  **Context:** quantitative measure of “information” based on physical (not psychological) considerations
  **Why ML cares:** precursor to modern **entropy-like** measures and communication limits. ([Monoskop][2])

---

## 1935 — Nonlocality, correlations, and “hidden variables”

* **Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?** (Einstein–Podolsky–Rosen, 1935)
  **Context:** the **EPR paradox**; challenges completeness of quantum description
  **Why ML cares:** a canonical example of **correlation vs causation/latent structure** debates; inspires later thinking about constraints on representations and inference. ([APS Link][3])

---

## 1948 — The modern mathematical foundation of communication

* **A Mathematical Theory of Communication** (Shannon, 1948)
  **Context:** entropy, channel capacity, coding theorems
  **Why ML cares:** underpins **cross-entropy / KL**, compression, generalization arguments, and modern probabilistic modeling language. ([Harvard Math People][4])

* **Cognitive Maps in Rats and Men** (Tolman, 1948)
  **Context:** organisms build internal **cognitive maps** of environments
  **Why ML cares:** conceptual backbone for **representation learning** in navigation, model-based RL, and world models. ([PubMed][5])

---

## 1949 — Synapses, assemblies, and learning as wiring change

* **The Organization of Behavior** (Hebb, 1949)
  **Context:** “cell assemblies,” Hebbian learning principles
  **Why ML cares:** core conceptual ancestor for **associative memory**, representation formation, and learning as **correlation-driven plasticity**. ([Deng Fanxin][6])

---

## 1956 — Capacity limits and chunking

* **The Magical Number Seven, Plus or Minus Two** (Miller, 1956)
  **Context:** short-term capacity limits + **chunking**
  **Why ML cares:** motivates bounded working memory, compression, and discrete abstraction as a necessity, not a preference. ([PubMed][7])

---

## 1959–1962 — Visual cortex as feature detectors + hierarchy

* **Receptive fields of single neurones in the cat’s striate cortex** (Hubel & Wiesel, 1959)
  **Context:** simple receptive fields, orientation selectivity
  **Why ML cares:** prototypical story for **local features → composition**, inspiring convolutional ideas and hierarchical representation. ([PMC][8])

* **Receptive Fields, Binocular Interaction, and Functional Architecture in the Cat’s Visual Cortex** (Hubel & Wiesel, 1962)
  **Context:** functional architecture, binocular integration
  **Why ML cares:** deeper support for structured hierarchical processing in vision. ([Gatsby][9])

---

## 1957 — MaxEnt and statistical mechanics as inference

* **Information Theory and Statistical Mechanics** (Jaynes, 1957)
  **Context:** maximum entropy as principled inference under constraints
  **Why ML cares:** conceptual bridge connecting **probabilistic modeling** to **optimization under constraints**; influences variational methods and modern Bayesian framing. ([Bayes WUSTL][10])

---

## 1971 — Place cells: representation as a cognitive “state”

* **The hippocampus as a spatial map…** (O’Keefe & Dostrovsky, 1971)
  **Context:** place cells encode location
  **Why ML cares:** anchors ML analogies for **state representations**, latent variables for navigation, and memory-based planning. ([PubMed][11])

---

## 1972 — Multi-user communication as structured constraints

* **Broadcast Channels** (Cover, 1972)
  **Context:** communicating to multiple receivers; capacity regions
  **Why ML cares:** foundational to thinking about **multi-objective / multi-agent information constraints**, and how “one representation must serve many consumers.” ([Information Systems Laboratory][12])

---

## 1974 — Working memory as a system, not a buffer

* **Working Memory** (Baddeley & Hitch, 1974)
  **Context:** working memory as multi-component system (not just short-term storage)
  **Why ML cares:** motivates **active maintenance**, modular buffers, and control mechanisms that look more like systems than single vectors. ([ScienceDirect][13])

---

## 1982 — Vision as computation + levels of explanation

* **Vision: A Computational Investigation into the Human Representation and Processing of Visual Information** (Marr, 1982)
  **Context:** Marr’s levels (computational / algorithmic / implementational)
  **Why ML cares:** the cleanest framework for separating *what* is computed from *how*, used constantly in ML theory + neuroscience-to-ML translation. ([MIT Press Direct][14])

* **Neural networks and physical systems with emergent collective computational abilities** (Hopfield, 1982)
  **Context:** energy-based associative memory as dynamical system
  **Why ML cares:** foundational for **energy-based models**, attractors, and “computation as dynamics.” ([PNAS][15])

---

## 1999 — Predictive coding: representation via error correction

* **Predictive coding in the visual cortex: a functional interpretation…** (Rao & Ballard, 1999)
  **Context:** feedback sends predictions; feedforward sends **residual errors**
  **Why ML cares:** a major root for **predictive processing**, hierarchical generative models, and error-driven learning narratives used in modern deep learning interpretations. ([PubMed][16])

---

## 2001 — Prefrontal cortex as active maintenance for control

* **An Integrative Theory of Prefrontal Cortex Function** (Miller & Cohen, 2001)
  **Context:** cognitive control from **active maintenance** of goal/context representations in PFC
  **Why ML cares:** strongly informs “**working memory + control**” motifs in sequence modeling, agents, and attention-as-control analogies. ([PubMed][17])

---

## 2005 — Grid cells: structured latent codes for space

* **Microstructure of a spatial map in the entorhinal cortex** (Hafting et al., 2005)
  **Context:** discovery/characterization of **grid cells**
  **Why ML cares:** motivates structured latent spaces, periodic codes, and modern “grid-like representations” work in RL and representation learning. ([Nature][18])

---

## 2006–2010 — Free-energy / active inference as a unifying lens

* **A free energy principle for the brain** (Friston, 2006)
  **Context:** perception/action/learning framed as minimizing free energy under hierarchical generative models
  **Why ML cares:** a major unifying narrative linking Bayesian inference, learning, and action (often invoked alongside predictive coding). ([PubMed][19])

* **The free-energy principle: a unified brain theory?** (Friston, 2010)
  **Context:** broad synthesis of the free-energy principle and its implications
  **Why ML cares:** conceptual scaffolding for “agents as inference machines,” inspiring modern work in active inference and generative world models. ([University of Alabama at Birmingham][20])

---

## 2012 — Modern consolidation of working memory debates

* **Working Memory: Theories, Models, and Controversies** (Baddeley, 2012)
  **Context:** review consolidating competing theories and open controversies
  **Why ML cares:** a compact map of what “working memory” does (and doesn’t) explain—helpful when importing WM analogies into neural architectures. ([PubMed][21])

---

## 2019 — A cortex-wide intelligence theory motivated by grid cells

* **A Framework for Intelligence and Cortical Function Based on Grid Cells in the Neocortex** (Hawkins, Lewis, Klukas, Purdy, Ahmad, 2019)
  **Context:** cross-area theory tying cortical function/intelligence to grid-cell-like mechanisms
  **Why ML cares:** conceptual motivation for **factorized object-centric models**, structured latent spaces, and “thousand brains”-style reasoning about cortical computation. ([Frontiers][22])

---

If you want the next round in the same format, I can do an **“aggressive completeness pass”** that expands this list with more “famous-but-easy-to-miss” foundations specifically in:

* **visual hierarchy / dorsal–ventral streams**,
* **PFC + basal ganglia gating models for working memory**,
* **control theory & Kalman filtering as inference**, and
* **dynamical systems / synergetics** used to justify attractors, stability, and iterative computation in neural nets.

[1]: https://monoskop.org/images/9/9f/Nyquist_Harry_1924_Certain_Factors_Affecting_Telegraph_Speed.pdf "Nyquist 1924 - Certain Factors Affecting Telegraph Speed"
[2]: https://monoskop.org/images/a/a6/Hartley_Ralph_VL_1928_Transmission_of_Information.pdf "Transmission of Information¹ - By RVL HARTLEY"
[3]: https://link.aps.org/doi/10.1103/PhysRev.47.777 "Can Quantum-Mechanical Description of Physical Reality Be ..."
[4]: https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf "A Mathematical Theory of Communication"
[5]: https://pubmed.ncbi.nlm.nih.gov/18870876/ "Cognitive maps in rats and men"
[6]: https://www.dengfanxin.cn/wp-content/uploads/2016/03/1949Hebb.pdf "Chap4 - (1949) Donald O.Hebb, <cite>The Organization of ..."
[7]: https://pubmed.ncbi.nlm.nih.gov/13310704/ "The magical number seven plus or minus two"
[8]: https://pmc.ncbi.nlm.nih.gov/articles/PMC1363130/ "Receptive fields of single neurones in the cat's striate cortex"
[9]: https://www.gatsby.ucl.ac.uk/~lmatthey/teaching/tn1/additional/systems/JPhysiol-1962-Hubel-106-54.pdf "receptive fields, binocular interaction and functional ..."
[10]: https://bayes.wustl.edu/etj/articles/theory.1.pdf "Information Theory and Statistical Mechanics"
[11]: https://pubmed.ncbi.nlm.nih.gov/5124915/ "The hippocampus as a spatial map. Preliminary evidence ..."
[12]: https://isl.stanford.edu/~cover/papers/transIT/0002cove.pdf "Broadcast Channels - Information Systems Laboratory"
[13]: https://www.sciencedirect.com/science/article/pii/S0079742108604521 "Working Memory"
[14]: https://direct.mit.edu/books/monograph/3299/VisionA-Computational-Investigation-into-the-Human "Vision: A Computational Investigation into the Human ..."
[15]: https://www.pnas.org/doi/10.1073/pnas.79.8.2554 "Neural networks and physical systems with emergent ..."
[16]: https://pubmed.ncbi.nlm.nih.gov/10195184/ "Predictive coding in the visual cortex: a functional ..."
[17]: https://pubmed.ncbi.nlm.nih.gov/11283309/ "An integrative theory of prefrontal cortex function"
[18]: https://www.nature.com/articles/nature03721 "Microstructure of a spatial map in the entorhinal cortex"
[19]: https://pubmed.ncbi.nlm.nih.gov/17097864/ "A free energy principle for the brain"
[20]: https://www.uab.edu/medicine/cinl/images/KFriston_FreeEnergy_BrainTheory.pdf "The free-energy principle: a unified brain theory?"
[21]: https://pubmed.ncbi.nlm.nih.gov/21961947/ "Working memory: theories, models, and controversies"
[22]: https://www.frontiersin.org/journals/neural-circuits/articles/10.3389/fncir.2018.00121/full "A Framework for Intelligence and Cortical Function Based ..."
