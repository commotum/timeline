year,title,url
2000,Feedforward and Recurrent Processing in Vision,https://pubmed.ncbi.nlm.nih.gov/10925037/
2007,Core Knowledge,https://projects.iq.harvard.edu/files/lds/files/core_knowledge.pdf
2012,Canonical Microcircuits for Predictive Coding,https://pubmed.ncbi.nlm.nih.gov/23238495/
2014,Hierarchy of Intrinsic Timescales in Cortex,https://www.cns.nyu.edu/wanglab/papers/Murray_NatNeuro_2014.pdf
2014,Neural Turing Machines,https://arxiv.org/pdf/1410.5401.pdf
2016,Adaptive Computation Time,https://arxiv.org/pdf/1603.08983.pdf
2017,Attention Is All You Need,https://arxiv.org/pdf/1706.03762.pdf
2018,Recurrent Relational Networks,https://proceedings.neurips.cc/paper_files/paper/2018/file/e2a2dcc36a08a345332c751b2f2e476c-Paper.pdf
2018,Universal Transformers,https://arxiv.org/pdf/1807.03819.pdf
2018,"Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset",https://arxiv.org/pdf/1803.10137.pdf
2018,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/pdf/1810.04805.pdf
2019,LXMERT: Learning Cross-Modality Encoder Representations,https://arxiv.org/pdf/1908.07490.pdf
2019,ViLBERT: Pretraining Task-Agnostic V-L Representations,https://arxiv.org/pdf/1908.02265.pdf
2019,VisualBERT: A Simple and Performant Baseline for Vision and Language,https://arxiv.org/pdf/1908.03557.pdf
2019,Deep Equilibrium Models,https://arxiv.org/pdf/1909.01377.pdf
2019,VideoBERT: A Joint Model for Video and Language Representation Learning,https://arxiv.org/pdf/1904.01766.pdf
2019,HowTo100M: Learning a Text-Video Embedding by Watching Narrated Videos,https://arxiv.org/pdf/1906.03327.pdf
2019,On the Measure of Intelligence,https://arxiv.org/pdf/1911.01547.pdf
2020,UNITER: Universal Image-Text Representation Learning,https://arxiv.org/pdf/1909.11740.pdf
2020,OSCAR: Object-Semantics Aligned Pre-training for Vision-Language Tasks,https://arxiv.org/pdf/2004.06165.pdf
2020,End-to-End Object Detection with Transformers (DETR),https://arxiv.org/pdf/2005.12872.pdf
2020,An Image is Worth 16Ã—16 Words: Vision Transformer (ViT),https://arxiv.org/pdf/2010.11929.pdf
2021,Is Space-Time Attention All You Need for Video Understanding? (TimeSformer),https://arxiv.org/pdf/2102.05095.pdf
2021,Scaling Up Vision-Language Learning With Noisy Text Supervision (ALIGN),https://arxiv.org/pdf/2102.05918.pdf
2021,Learning Transferable Visual Models From Natural Language Supervision (CLIP),https://arxiv.org/pdf/2103.00020.pdf
2021,Swin Transformer,https://arxiv.org/pdf/2103.14030.pdf
2021,RoFormer: Enhanced Transformer with Rotary Position Embedding (RoPE),https://arxiv.org/pdf/2104.09864.pdf
2021,VATT: Transformers for Multimodal Self-Supervised Learning,https://arxiv.org/pdf/2104.11178.pdf
2021,ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision,https://arxiv.org/pdf/2102.03334.pdf
2021,VideoCLIP: Contrastive Pretraining for Zero-Shot Video-Text Understanding,https://arxiv.org/pdf/2109.14084.pdf
2021,ALBEF: Align Before Fuse,https://arxiv.org/pdf/2107.07651.pdf
2021,"Train Short, Test Long: Attention with Linear Biases (ALiBi)",https://arxiv.org/pdf/2108.12409.pdf
2021,LAION-400M: Open Dataset for CLIP Training,https://arxiv.org/pdf/2111.02114.pdf
2021,Masked Autoencoders Are Scalable Vision Learners (MAE),https://arxiv.org/pdf/2111.06377.pdf
2022,BLIP: Bootstrapping Language-Image Pre-training,https://arxiv.org/pdf/2201.12086.pdf
2022,CoCa: Contrastive Captioners,https://arxiv.org/pdf/2205.01917.pdf
2022,Flamingo: a Visual Language Model for Few-Shot Learning,https://arxiv.org/pdf/2204.14198.pdf
2022,Winoground: Probing Vision-Language Models for Compositionality,https://arxiv.org/pdf/2204.03162.pdf
2022,LAION-5B: An Open Large-Scale Dataset for Training Next Generation Image-Text Models,https://arxiv.org/pdf/2210.08402.pdf
2022,ScienceQA: Benchmark for Multimodal Reasoning,https://arxiv.org/pdf/2209.09513.pdf
2023,BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Models,https://arxiv.org/pdf/2301.12597.pdf
2023,GPT-4 Technical Report,https://arxiv.org/pdf/2303.08774.pdf
2023,Kosmos-1: Language Is Not All You Need,https://arxiv.org/pdf/2302.14045.pdf
2023,PaLM-E: An Embodied Multimodal Language Model,https://arxiv.org/pdf/2303.03378.pdf
2023,LLaVA: Large Language-and-Vision Assistant,https://arxiv.org/pdf/2304.08485.pdf
2023,MiniGPT-4,https://arxiv.org/pdf/2304.10592.pdf
2023,ConceptARC,https://arxiv.org/pdf/2305.07141.pdf
2023,MMBench: Evaluating Multimodal LLMs,https://arxiv.org/pdf/2307.06281.pdf
2023,A Length-Extrapolatable Transformer (XPOS / LeX),https://aclanthology.org/2023.acl-long.816.pdf
2023,YaRN: Efficient Context Window Extension of Large Language Models,https://arxiv.org/pdf/2309.00071.pdf
2023,MMMU: A Massive Multidiscipline Multimodal Benchmark,https://arxiv.org/pdf/2311.16502.pdf
2023,Gemini: A Family of Highly Capable Multimodal Models,https://arxiv.org/pdf/2312.11805.pdf
2023,Uni3DL: Unified Model for 3D and Language Understanding,https://arxiv.org/pdf/2312.03026.pdf
2024,Evolutionary Test-Time Compute (write-up),https://jeremyberman.substack.com/p/how-i-got-a-record-536-on-arc-agi
2024,Fixed Point Diffusion Models,https://openaccess.thecvf.com/content/CVPR2024/papers/Bai_Fixed_Point_Diffusion_Models_CVPR_2024_paper.pdf
2024,Solving olympiad geometry without human demonstrations (AlphaGeometry),https://www.nature.com/articles/s41586-023-06747-5.pdf
2024,Beyond A*: Planning with Transformers,https://arxiv.org/pdf/2402.14083.pdf
2024,VG4D: Vision-Language Model Goes 4D Video Recognition,https://arxiv.org/pdf/2404.11605.pdf
2024,DAPE: Data-Adaptive Positional Encoding for Length Extrapolation,https://proceedings.neurips.cc/paper_files/paper/2024/file/2f050fa9f0d898e3f265d515f50ae8f9-Paper-Conference.pdf
2024,What matters when building vision-language models? (Idefics2),https://arxiv.org/pdf/2405.02246.pdf
2024,Learning Iterative Reasoning through Energy Diffusion,https://arxiv.org/pdf/2406.11179.pdf
2024,Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters,https://arxiv.org/pdf/2408.03314.pdf
2024,Length Extrapolation of Causal Transformers without Position Encoding (NoPE),https://aclanthology.org/2024.findings-acl.834.pdf
2024,H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark,https://arxiv.org/pdf/2409.01374.pdf
2024,Rotary Position Embedding for Vision Transformer (RoPE-Mixed / 2D RoPE study),https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01584.pdf
2024,Length Extrapolation of Transformers: A Survey from the Perspective of Positional Encoding,https://aclanthology.org/2024.findings-emnlp.582.pdf
2024,ARC-Heavy / ARC-Potpourri (dataset description embedded in Cornell report),https://www.cs.cornell.edu/~ellisk/documents/arc_induction_vs_transduction.pdf
2024,Combining Induction and Transduction for Abstract Reasoning,https://arxiv.org/pdf/2411.02272.pdf
2024,Searching Latent Program Spaces,https://arxiv.org/pdf/2411.08706.pdf
2024,The Surprising Effectiveness of Test-Time Training for Few-Shot Learning,https://ekinakyurek.github.io/papers/ttt.pdf
2024,Towards Efficient Neurally-Guided Program Induction for ARC-AGI,https://arxiv.org/pdf/2411.17708.pdf
2024,DAPE: Data-Adaptive Positional Encoding for Length Extrapolation,https://proceedings.neurips.cc/paper_files/paper/2024/file/2f050fa9f0d898e3f265d515f50ae8f9-Paper-Conference.pdf
2024,Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced Extrapolation in LLMs,https://proceedings.neurips.cc/paper_files/paper/2024/file/9446c291a8744a125a0bda5b18f4d5a1-Paper-Conference.pdf
2025,Olympiad-level formal mathematical reasoning with large language models (AlphaProof),https://www.nature.com/articles/s41586-025-09833-y.pdf
2025,VRoPE: Rotary Position Embedding for Video Large Language Models,https://arxiv.org/pdf/2502.11664.pdf
2025,SmolVLM: Redefining small and efficient multimodal models,https://arxiv.org/pdf/2504.05299.pdf
2025,Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models,https://arxiv.org/pdf/2505.16416.pdf
2025,ComRoPE: Scalable and Robust Rotary Position Embedding Parameterized by Trainable Commuting Angle Matrices,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_ComRoPE_Scalable_and_Robust_Rotary_Position_Embedding_Parameterized_by_Trainable_CVPR_2025_paper.pdf
2025,Hierarchical Reasoning Model (HRM),https://arxiv.org/pdf/2506.21734.pdf
2025,"Decoupling the ""What"" and ""Where"" With Polar Coordinate Positional Embeddings (PoPE)",https://arxiv.org/pdf/2509.10534.pdf
2025,Less is More: Recursive Reasoning with Tiny Networks,https://arxiv.org/pdf/2510.04871.pdf
2025,DoPE: Denoising Rotary Position Embedding,https://arxiv.org/pdf/2511.09146.pdf
2025,Selective Rotary Position Embedding,https://arxiv.org/pdf/2511.17388.pdf
