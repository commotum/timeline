            problem, in isolation, to stay under different time limits at the IMO in        demonstrating great successes in premise selection and proof guid-
                                                                                                 46–49                         50                                     18
            Extended Data Fig. 1.                                                           ance     , as well as SAT solving . On the other hand, transformer  
                                                                                                                                                                   51–53
                                                                                            exhibits outstanding reasoning capabilities across a variety of tasks      . 
            The effect of data and search                                                   The first success in applying transformer language models to theorem 
            We trained AlphaGeometry on smaller fractions of the original training          proving is GPT-f (ref. 15). Its follow up extensions2,16 further developed 
            data (20%, 40%, 60% and 80%) and found that, even at 20% of training            this direction, allowing machines to solve some olympiad-level prob-
            data, AlphaGeometry still solves 21 problems, more than the strong-             lems for the first time. Innovation in the proof-search algorithm and 
                                                                                                            3
            est baseline (DD + AR + human-designed heuristics) with 18 problems             online training  also improves transformer-based methods, solving 
            solved, as shown in Extended Data Fig. 6a. To study the effect of beam          a total of ten (adapted) IMO problems in algebra and number theory. 
            search on top of the language model, we reduced the beam size and               These advances, however, are predicated on a substantial amount of 
            search depth separately during proof search and reported the results            human proof examples and standalone problem statements designed 
            in Extended Data Fig. 6c,d. We find that, with a beam size of 8, that is, a     and curated by humans.
            64 times reduction from the original beam size of 512, AlphaGeometry 
            still solves 21 problems. A similar result of 21 problems can be obtained       Geometry theorem proving. Geometry theorem proving evolves in 
            by reducing the search depth from 16 to only two, while keeping the             an entirely separate space. Its literature is divided into two branch-
            beam size constant at 512.                                                      es, one of computer algebra methods and one of search methods. 
                                                                                            The former is largely considered solved since the introduction of 
            Evaluation on a larger test set                                                                21
                                                                                            Wu’s method , which can theoretically decide the truth value of 
            We evaluated AlphaGeometry and other baselines on a larger test set             any geometrical statement of equality type, building on specialized 
                                                                                                                                             54,55
            of 231 geometry problems, curated in ref. 17. This set covers a wider           algebraic tools introduced in earlier works          . Even though com-
            range of sources outside IMO competitions: textbook examples and                puter algebra has strong theoretical guarantees, its performance 
            exercises, regional olympiads and famous geometry theorems; some                can be limited in practice owing to their large time and space com-
                                                                                                    56
            are even more complex than typical IMO problems, such as the five               plexity . Further, the methodology of computer algebra is not 
            circles theorem, Morley’s theorem or Sawayama and Thébault’s theo-              of interest to AI research, which instead seeks to prove theorems 
            rem. The results are reported in Extended Data Fig. 6b. The overall             using search methods, a more human-like and general-purpose  
            rankings of different approaches remained the same as in Table 1, with          process.
            AlphaGeometry solving almost all problems (98.7%). The strongest                  Search methods also started as early as the 1950s (refs. 6,7) and 
                                                                                                                                                            57–60
            baseline DD + AR + human-designed heuristics solves 92.2%, whereas              continued to develop throughout the twentieth century                . With 
                                                                                                                     10,17               61                          30
            the previous state of the art solves 75%.                                       the introduction of DD      , area methods  and full-angle methods , 
                                                                                            geometry solvers use higher-level deduction rules than Tarski’s or 
            AlphaGeometry framework and applicability to other domains. The                 Hilbert’s axioms and are able to prove a larger number of more com-
            strength of AlphaGeometry’s neuro-symbolic set-up lies in its ability           plex theorems than those operating in formal languages. Geometry 
            to generate auxiliary constructions, which is an important ingredient           theorem proving of today, however, is still relying on human-designed 
                                                                                                                                    10–14
            across many mathematical domains. In Extended Data Table 3, we give             heuristics for auxiliary constructions      . Geometry theorem proving 
            examples in four other mathematical domains in which coming up with             falls behind the recent advances made by machine learning because its 
                                                                                                                                                        31            62
            auxiliary constructions is key to the solution. In Extended Data Table 4,       presence in formal mathematical libraries such as Lean  or Isabelle  
            we give a line-by-line comparison of a geometry proof and an inequality         is extremely limited.
            proof for the IMO 1964 Problem 2, highlighting how they both fit into 
            the same framework.                                                             Synthetic data in theorem proving. Synthetic data has long been 
               Our paper shows that language models can learn to come up with aux-          recognized and used as an important ingredient in theorem prov-
                                                                                               63–66
            iliary constructions from synthetic data, in which problem statements           ing     . State-of-the-art machine learning methods make use of  
                                                                                                                                                                   2,3,15
            and auxiliary constructions are randomly generated together and then            expert iteration to generate a curriculum of synthetic proofs              . 
            separated using the traceback algorithm to identify the dependency              Their methods, however, only generate synthetic proofs for a fixed 
            difference. Concretely, the AlphaGeometry framework requires the                set of predefined problems, designed and selected by humans. Our 
            following ingredients:                                                          method, on the other hand, generates both synthetic problems and 
                                                                                                                                      67
            (1) An implementation of the domain’s objects and definitions.                  proofs entirely from scratch. Aygun et al.  similarly generated synthetic 
                                                                                                                                        68
            (2) A random premise sampler.                                                   proofs with hindsight experience replay , providing a smooth range 
            (3) The symbolic engine(s) that operate within the implementation (1).          of theorem difficulty to aid learning similar to our work. AlphaGeo-
            (4) A traceback procedure for the symbolic engine.                              metry, however, is not trained on existing conjectures curated by 
                                                                                            humans and does not learn from proof attempts on the target theo-
               Using these four ingredients and the algorithm described in the main         rems. Their approach is thus orthogonal and can be used to further 
                                                                                                                                                                     69
            text, one can generate synthetic data for any target domain. As shown           improve AlphaGeometry. Most similar to our work is Firoiu et al. , 
            in our paper, there are non-trivial engineering challenges in building          whose method uses a forward proposer to generate synthetic data by 
            each ingredient. For example, current formalizations of combinatorics           depth-first exploration and trains a neural network purely on these 
            are very nascent, posing challenges to (1) and (2). Also, building pow-         synthetic data. Our work, on the other hand, uses breadth-first explora-
            erful symbolic engines for different domains requires deep domain               tion, necessary to obtain the minimal proofs and premises, and uses a 
            expertise, posing challenges to (3) and (4). We consider applying this          traceback algorithm to identify auxiliary constructions, thus introduc-
            framework to a wider scope as future work and look forward to further           ing new symbols and hypotheses that the forward proposer cannot  
            innovations that tackle these challenges.                                       propose.
            Transformer in theorem proving
            Research in automated theorem proving has a long history dating back            Data availability
            to the 1950s (refs. 6,42,43), resulting in highly optimized first-order         The data supporting the findings of this work are available in the 
                                                           45
            logic solvers such as E (ref. 44) or Vampire . In the 2010s, deep learn-        Extended Data and the Supplementary Information. Source data are 
            ing matured as a new powerful tool for automated theorem proving,               provided with this paper.
