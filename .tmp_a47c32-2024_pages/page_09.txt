               fromourmodelinresource-constrained settings stem largely                   [9] C. G. Broyden. A class of methods for solving nonlinear
               from smoothing and reusing, but in scenarios with saturated                    simultaneous equations. Mathematics of Computation, 19
               timesteps and iterations, the efficacy of these techniques                     (92):577–593, 1965. 2
               is reduced. In such cases, our network resembles a trans-                [10] Ricky T. Q. Chen, Brandon Amos, and Maximilian Nickel.
               former with weight sharing [30, 39], which underperform                        Learning neural event functions for ordinary differential equa-
               vanilla transformers. Hence, we do not expect to match the                     tions. In 9th International Conference on Learning Represen-
               performance of DiT, which has 8× more parameters, when                         tations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021.
               sampling with an unlimited amount of resources.                                OpenReview.net, 2021. 3
                                                                                        [11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li
               6. Conclusions                                                                 Fei-Fei. Imagenet: A large-scale hierarchical image database.
                                                                                              In IEEE Conference on Computer Vision and Pattern Recog-
               We introduce FPDM, a pioneering diffusion model                                nition, pages 248–255, 2009. 1, 2
               characterized by fixed point implicit layers.          Compared          [12] Prafulla Dhariwal and Alexander Nichol. Diffusion mod-
               to  traditional   Diffusion Transformers (DiT), FPDM                           els beat gans on image synthesis. In Advances in Neural
               significantly reduces model size and memory usage.                             Information Processing Systems, pages 8780–8794, 2021. 2
               In the context of diffusion sampling, FPDM enables                       [13] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
               us to develop new techniques such as solution reusing                          Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
               and timestep smoothing, which give FPDM enhanced                               Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-
               flexibility in computational allocation during inference.                      vain Gelly, et al. An image is worth 16x16 words: Transform-
               This flexibility makes it particularly effective in scenarios                  ers for imagerecognitionatscale. InInternationalConference
               where computational resources are constrained. Future work                     onLearning Representations, 2020. 2, 3
               could explore new ways of leveraging this flexibility as                 [14] Samy WuFung,HowardHeaton,QiuweiLi,DanielMcKen-
               well as scaling to larger datasets such as LAION-5B [45].                      zie, Stanley J. Osher, and Wotao Yin. JFB: jacobian-free back-
                                                                                              propagation for implicit networks. In Thirty-Sixth AAAI Con-
                                                                                              ference on Artificial Intelligence, AAAI 2022, Thirty-Fourth
               References                                                                     Conference on Innovative Applications of Artificial Intelli-
                                                                                              gence, IAAI 2022, The Twelveth Symposium on Educational
                [1] Ravi P Agarwal, Maria Meehan, and Donal O’regan. Fixed                    Advances in Artificial Intelligence, EAAI 2022 Virtual Event,
                    point theory and applications. Cambridge university press,                February 22 - March 1, 2022, pages 6648–6656. AAAI Press,
                    2001. 3                                                                   2022. 2, 3, 4, 5, 8
                [2] Namrata Anand and Tudor Achim. Protein structure and se-            [15] Samir Yitzhak Gadre, Gabriel Ilharco, Alex Fang, Jonathan
                    quence generation with equivariant denoising diffusion prob-              Hayase, Georgios Smyrnis, Thao Nguyen, Ryan Marten,
                    abilistic models. arXiv preprint arXiv:2205.15019, 2022.                  Mitchell Wortsman, Dhruba Ghosh, Jieyu Zhang, Eyal Or-
                    2                                                                         gad, Rahim Entezari, Giannis Daras, Sarah M. Pratt, Vivek
                [3] Donald G. Anderson. Iterative procedures for nonlinear inte-              Ramanujan, Yonatan Bitton, Kalyani Marathe, Stephen
                    gral equations. J. ACM, 12(4):547–560, 1965. 2                            Mussmann, Richard Vencu, Mehdi Cherti, Ranjay Krishna,
                                                                                              Pang Wei Koh, Olga Saukh, Alexander Ratner, Shuran
                [4] Haoran Bai, Di Kang, Haoxian Zhang, Jin-shan Pan, and                     Song, Hannaneh Hajishirzi, Ali Farhadi, Romain Beaumont,
                    Linchao Bao. Ffhq-uv: Normalized facial uv-texture dataset                Sewoong Oh, Alex Dimakis, Jenia Jitsev, Yair Carmon,
                    for 3d face reconstruction. ArXiv, abs/2211.13874, 2022. 1, 2             Vaishaal Shankar, and Ludwig Schmidt.         Datacomp: In
                [5] Shaojie Bai, J. Zico Kolter, and Vladlen Koltun. Deep equilib-            search of the next generation of multimodal datasets. CoRR,
                    rium models. In Advances in Neural Information Processing                 abs/2304.14108, 2023. 1
                    Systems 32: Annual Conference on Neural Information Pro-            [16] Zhengyang Geng and J. Zico Kolter. Torchdeq: A library
                    cessing Systems 2019, NeurIPS 2019, December 8-14, 2019,                  for deep equilibrium models. https://github.com/
                    Vancouver, BC, Canada, pages 688–699, 2019. 2, 3, 4, 7                    locuslab/torchdeq,2023. 2
                [6] Shaojie Bai, Vladlen Koltun, and J Zico Kolter. Multiscale          [17] Zhengyang Geng, Xin-Yu Zhang, Shaojie Bai, Yisen Wang,
                    deep equilibrium models. Advances in Neural Information                   and Zhouchen Lin. On training implicit models. In Ad-
                    Processing Systems, 33:5238–5250, 2020. 3                                 vances in Neural Information Processing Systems 34: Annual
                [7] Shaojie Bai, Zhengyang Geng, Yash Savani, and J Zico Kolter.              Conference on Neural Information Processing Systems 2021,
                    Deepequilibrium optical flow estimation. In Proceedings of                NeurIPS 2021, December 6-14, 2021, virtual, pages 24247–
                    the IEEE/CVF Conference on Computer Vision and Pattern                    24260, 2021. 2
                    Recognition, pages 620–630, 2022. 3                                 [18] Zhengyang Geng, Ashwini Pokle, and J Zico Kolter. One-
                [8] Shaojie Bai, Zhengyang Geng, Yash Savani, and J. Zico                     step diffusion distillation via deep equilibrium models. In
                    Kolter.    Deep equilibrium optical flow estimation.        In            Thirty-seventh Conference on Neural Information Processing
                    IEEE/CVF Conference on Computer Vision and Pattern                        Systems, 2023. 3
                    Recognition, CVPR2022,NewOrleans,LA,USA,June18-24,                  [19] Davis Gilton, Gregory Ongie, and Rebecca Willett. Deep
                    2022, pages 610–620. IEEE, 2022. 4                                        equilibrium architectures for inverse problems in imaging.
                                                                                    9
